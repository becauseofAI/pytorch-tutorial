



<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="PyTorch Tutorial for Deep Learning Research and Product.">
      
      
        <link rel="canonical" href="https://becauseofAI.github.io/pytorch-tutorial/chapter02_basics/2_1_pytorch-basics-tensor/">
      
      
        <meta name="author" content="becauseofAI">
      
      
        <meta name="lang:clipboard.copy" content="复制">
      
        <meta name="lang:clipboard.copied" content="已复制">
      
        <meta name="lang:search.language" content="zh">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="没有找到符合条件的结果">
      
        <meta name="lang:search.result.one" content="找到 1 个符合条件的结果">
      
        <meta name="lang:search.result.other" content="# 个符合条件的结果">
      
        <meta name="lang:search.tokenizer" content="[\uff0c\u3002]+">
      
      <link rel="shortcut icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.4.0">
    
    
      
        <title>2.1 Tensor - PyTorch Tutorial</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/application.0284f74d.css">
      
        <link rel="stylesheet" href="../../assets/stylesheets/application-palette.01803549.css">
      
      
        
        
        <meta name="theme-color" content="#546e7a">
      
    
    
      <script src="../../assets/javascripts/modernizr.74668098.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../../assets/fonts/material-icons.css">
    
    
      <link rel="stylesheet" href="../../css/extra.css">
    
    
      
        
<script>
  window.ga = window.ga || function() {
    (ga.q = ga.q || []).push(arguments)
  }
  ga.l = +new Date
  /* Setup integration and send page view */
  ga("create", "UA-27795084-5", "mkdocs.org")
  ga("set", "anonymizeIp", true)
  ga("send", "pageview")
  /* Register handler to log search on blur */
  document.addEventListener("DOMContentLoaded", () => {
    if (document.forms.search) {
      var query = document.forms.search.query
      query.addEventListener("blur", function() {
        if (this.value) {
          var path = document.location.pathname;
          ga("send", "pageview", path + "?q=" + this.value)
        }
      })
    }
  })
</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
      
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="blue-grey" data-md-color-accent="pink">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#pytorch" tabindex="1" class="md-skip">
        跳转至
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="https://becauseofAI.github.io/pytorch-tutorial/" title="PyTorch Tutorial" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              PyTorch Tutorial
            </span>
            <span class="md-header-nav__topic">
              
                2.1 Tensor
              
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            键入以开始搜索
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/becauseofAI/pytorch-tutorial/" title="前往 Github 仓库" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    pytorch-tutorial
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="https://becauseofAI.github.io/pytorch-tutorial/" title="PyTorch Tutorial" class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </a>
    PyTorch Tutorial
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/becauseofAI/pytorch-tutorial/" title="前往 Github 仓库" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    pytorch-tutorial
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../.." title="Introduction" class="md-nav__link">
      Introduction
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2" checked>
    
    <label class="md-nav__link" for="nav-2">
      Tutorials
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        Tutorials
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2-1" type="checkbox" id="nav-2-1">
    
    <label class="md-nav__link" for="nav-2-1">
      Ghapter01 Getting Started
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-2-1">
        Ghapter01 Getting Started
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../chapter01_getting-started/1_1_pytorch-introduction/" title="1.1 PyTorch Tntroduction" class="md-nav__link">
      1.1 PyTorch Tntroduction
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../chapter01_getting-started/1_3_deep-learning-with-pytorch-60-minute-blitz/" title="1.3 PyTorch 60 Minute Blitz" class="md-nav__link">
      1.3 PyTorch 60 Minute Blitz
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2-2" type="checkbox" id="nav-2-2" checked>
    
    <label class="md-nav__link" for="nav-2-2">
      Ghapter02 Basics
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-2-2">
        Ghapter02 Basics
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        2.1 Tensor
      </label>
    
    <a href="./" title="2.1 Tensor" class="md-nav__link md-nav__link--active">
      2.1 Tensor
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#tensor" title="张量(Tensor)" class="md-nav__link">
    张量(Tensor)
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_1" title="基本类型" class="md-nav__link">
    基本类型
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#numpy" title="Numpy转换" class="md-nav__link">
    Numpy转换
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_2" title="设备间转换" class="md-nav__link">
    设备间转换
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" title="初始化" class="md-nav__link">
    初始化
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" title="常用方法" class="md-nav__link">
    常用方法
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../about/" title="About" class="md-nav__link">
      About
    </a>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#tensor" title="张量(Tensor)" class="md-nav__link">
    张量(Tensor)
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_1" title="基本类型" class="md-nav__link">
    基本类型
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#numpy" title="Numpy转换" class="md-nav__link">
    Numpy转换
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_2" title="设备间转换" class="md-nav__link">
    设备间转换
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" title="初始化" class="md-nav__link">
    初始化
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" title="常用方法" class="md-nav__link">
    常用方法
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h1 id="pytorch">PyTorch 基础 : 张量<a class="headerlink" href="#pytorch" title="Permanent link">&para;</a></h1>
<p>在第一章中我们已经通过官方的入门教程对PyTorch有了一定的了解，这一章会详细介绍PyTorch 里面的基础知识。
全部掌握了这些基础知识，在后面的应用中才能更加快速进阶，如果你已经对PyTorch有一定的了解，可以跳过此章</p>
<div class="codehilite"><pre><span></span><span class="c1"># 首先要引入相关的包</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="c1">#打印一下版本</span>
<span class="n">torch</span><span class="o">.</span><span class="n">__version__</span>
</pre></div>

<div class="codehilite"><pre><span></span>&#39;1.0.0&#39;
</pre></div>


<h2 id="tensor">张量(Tensor)<a class="headerlink" href="#tensor" title="Permanent link">&para;</a></h2>
<p>张量的英文是Tensor，它是PyTorch里面基础的运算单位,与Numpy的ndarray相同都表示的是一个多维的矩阵。
与ndarray的最大区别就是，PyTorch的Tensor可以在 GPU 上运行，而 numpy 的 ndarray 只能在 CPU 上运行，在GPU上运行大大加快了运算速度。</p>
<p>下面我们生成一个简单的张量</p>
<div class="codehilite"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">x</span>
</pre></div>

<div class="codehilite"><pre><span></span>tensor([[0.6904, 0.7419, 0.8010],
        [0.1722, 0.2442, 0.8181]])
</pre></div>


<p>以上生成了一个，2行3列的的矩阵，我们看一下他的大小：</p>
<div class="codehilite"><pre><span></span><span class="c1"># 可以使用与numpy相同的shape属性查看</span>
<span class="k">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1"># 也可以使用size()函数，返回的结果都是相同的</span>
<span class="k">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>

<div class="codehilite"><pre><span></span>torch.Size([2, 3])
torch.Size([2, 3])
</pre></div>


<p>张量（Tensor）是一个定义在一些向量空间和一些对偶空间的笛卡儿积上的多重线性映射，其坐标是|n|维空间内，有|n|个分量的一种量， 其中每个分量都是坐标的函数， 而在坐标变换时，这些分量也依照某些规则作线性变换。r称为该张量的秩或阶（与矩阵的秩和阶均无关系）。 (来自百度百科)</p>
<p>下面我们来生成一些多维的张量：</p>
<div class="codehilite"><pre><span></span><span class="n">y</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="n">y</span>
</pre></div>

<div class="codehilite"><pre><span></span>torch.Size([2, 3, 4, 5])





tensor([[[[0.9071, 0.0616, 0.0006, 0.6031, 0.0714],
          [0.6592, 0.9700, 0.0253, 0.0726, 0.5360],
          [0.5416, 0.1138, 0.9592, 0.6779, 0.6501],
          [0.0546, 0.8287, 0.7748, 0.4352, 0.9232]],

         [[0.0730, 0.4228, 0.7407, 0.4099, 0.1482],
          [0.5408, 0.9156, 0.6554, 0.5787, 0.9775],
          [0.4262, 0.3644, 0.1993, 0.4143, 0.5757],
          [0.9307, 0.8839, 0.8462, 0.0933, 0.6688]],

         [[0.4447, 0.0929, 0.9882, 0.5392, 0.1159],
          [0.4790, 0.5115, 0.4005, 0.9486, 0.0054],
          [0.8955, 0.8097, 0.1227, 0.2250, 0.5830],
          [0.8483, 0.2070, 0.1067, 0.4727, 0.5095]]],


        [[[0.9438, 0.2601, 0.2885, 0.5457, 0.7528],
          [0.2971, 0.2171, 0.3910, 0.1924, 0.2570],
          [0.7491, 0.9749, 0.2703, 0.2198, 0.9472],
          [0.1216, 0.6647, 0.8809, 0.0125, 0.5513]],

         [[0.0870, 0.6622, 0.7252, 0.4783, 0.0160],
          [0.7832, 0.6050, 0.7469, 0.7947, 0.8052],
          [0.1755, 0.4489, 0.0602, 0.8073, 0.3028],
          [0.9937, 0.6780, 0.9425, 0.0059, 0.0451]],

         [[0.3851, 0.8742, 0.5932, 0.4899, 0.8354],
          [0.8577, 0.3705, 0.0229, 0.7097, 0.7557],
          [0.1505, 0.3527, 0.0843, 0.0088, 0.8741],
          [0.6041, 0.8797, 0.6189, 0.9495, 0.1479]]]])
</pre></div>


<p>在同构的意义下，第零阶张量 （r = 0） 为标量 （Scalar），第一阶张量 （r = 1） 为向量 （Vector）， 第二阶张量 （r = 2） 则成为矩阵 （Matrix），第三阶以上的统称为多维张量。</p>
<p>其中要特别注意的就是标量，我们先生成一个标量：</p>
<div class="codehilite"><pre><span></span><span class="c1">#我们直接使用现有数字生成</span>
<span class="n">scalar</span> <span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">3.1433223</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">scalar</span><span class="p">)</span>
<span class="c1">#打印标量的大小</span>
<span class="n">scalar</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
</pre></div>

<div class="codehilite"><pre><span></span>tensor(3.1433)





torch.Size([])
</pre></div>


<p>对于标量，我们可以直接使用 .item() 从中取出其对应的python对象的数值</p>
<div class="codehilite"><pre><span></span><span class="n">scalar</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</pre></div>

<div class="codehilite"><pre><span></span>3.143322229385376
</pre></div>


<p>特别的：如果张量中只有一个元素的tensor也可以调用<code>tensor.item</code>方法</p>
<div class="codehilite"><pre><span></span><span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">3.1433223</span><span class="p">])</span> 
<span class="k">print</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
<span class="n">tensor</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
</pre></div>

<div class="codehilite"><pre><span></span>tensor([3.1433])





torch.Size([1])
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">tensor</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</pre></div>

<div class="codehilite"><pre><span></span>3.143322229385376
</pre></div>


<h3 id="_1">基本类型<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h3>
<p>Tensor的基本数据类型有五种：
- 32位浮点型：torch.FloatTensor。 (默认)
- 64位整型：torch.LongTensor。
- 32位整型：torch.IntTensor。
- 16位整型：torch.ShortTensor。
- 64位浮点型：torch.DoubleTensor。</p>
<p>除以上数字类型外，还有
byte和chart型</p>
<div class="codehilite"><pre><span></span><span class="nb">long</span><span class="o">=</span><span class="n">tensor</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
<span class="nb">long</span>
</pre></div>

<div class="codehilite"><pre><span></span>tensor([3])
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">half</span><span class="o">=</span><span class="n">tensor</span><span class="o">.</span><span class="n">half</span><span class="p">()</span>
<span class="n">half</span>
</pre></div>

<div class="codehilite"><pre><span></span>tensor([3.1426], dtype=torch.float16)
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">int_t</span><span class="o">=</span><span class="n">tensor</span><span class="o">.</span><span class="n">int</span><span class="p">()</span>
<span class="n">int_t</span>
</pre></div>

<div class="codehilite"><pre><span></span>tensor([3], dtype=torch.int32)
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">flo</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">flo</span>
</pre></div>

<div class="codehilite"><pre><span></span>tensor([3.1433])
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">short</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">short</span><span class="p">()</span>
<span class="n">short</span>
</pre></div>

<div class="codehilite"><pre><span></span>tensor([3], dtype=torch.int16)
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">ch</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">char</span><span class="p">()</span>
<span class="n">ch</span>
</pre></div>

<div class="codehilite"><pre><span></span>tensor([3], dtype=torch.int8)
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">bt</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">byte</span><span class="p">()</span>
<span class="n">bt</span>
</pre></div>

<div class="codehilite"><pre><span></span>tensor([3], dtype=torch.uint8)
</pre></div>


<h3 id="numpy">Numpy转换<a class="headerlink" href="#numpy" title="Permanent link">&para;</a></h3>
<p>使用numpy方法将Tensor转为ndarray</p>
<div class="codehilite"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="c1"># tensor转化为numpy</span>
<span class="n">numpy_a</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">numpy_a</span><span class="p">)</span>
</pre></div>

<div class="codehilite"><pre><span></span>[[ 0.46819344  1.3774964 ]
 [ 0.9491934   1.4543315 ]
 [-0.42792308  0.99790514]]
</pre></div>


<p>numpy转化为Tensor</p>
<div class="codehilite"><pre><span></span><span class="n">torch_a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">numpy_a</span><span class="p">)</span>
<span class="n">torch_a</span>
</pre></div>

<div class="codehilite"><pre><span></span>tensor([[ 0.4682,  1.3775],
        [ 0.9492,  1.4543],
        [-0.4279,  0.9979]])
</pre></div>


<p><strong><em>Tensor和numpy对象共享内存，所以他们之间的转换很快，而且几乎不会消耗什么资源。但这也意味着，如果其中一个变了，另外一个也会随之改变。</em></strong></p>
<h3 id="_2">设备间转换<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h3>
<p>一般情况下可以使用.cuda方法将tensor移动到gpu，这步操作需要cuda设备支持</p>
<div class="codehilite"><pre><span></span><span class="n">cpu_a</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">cpu_a</span><span class="o">.</span><span class="n">type</span><span class="p">()</span>
</pre></div>

<div class="codehilite"><pre><span></span>&#39;torch.FloatTensor&#39;
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">gpu_a</span><span class="o">=</span><span class="n">cpu_a</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">gpu_a</span><span class="o">.</span><span class="n">type</span><span class="p">()</span>
</pre></div>

<div class="codehilite"><pre><span></span>&#39;torch.cuda.FloatTensor&#39;
</pre></div>


<p>使用.cpu方法将tensor移动到cpu</p>
<div class="codehilite"><pre><span></span><span class="n">cpu_b</span><span class="o">=</span><span class="n">gpu_a</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
<span class="n">cpu_b</span><span class="o">.</span><span class="n">type</span><span class="p">()</span>
</pre></div>

<div class="codehilite"><pre><span></span>&#39;torch.FloatTensor&#39;
</pre></div>


<p>如果我们有多GPU的情况，可以使用to方法来确定使用那个设备，这里只做个简单的实例：</p>
<div class="codehilite"><pre><span></span><span class="c1">#使用torch.cuda.is_available()来确定是否有cuda设备</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="c1">#将tensor传送到设备</span>
<span class="n">gpu_b</span><span class="o">=</span><span class="n">cpu_b</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">gpu_b</span><span class="o">.</span><span class="n">type</span><span class="p">()</span>
</pre></div>

<div class="codehilite"><pre><span></span>cuda





&#39;torch.cuda.FloatTensor&#39;
</pre></div>


<h3 id="_3">初始化<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h3>
<p>Pytorch中有许多默认的初始化方法可以使用</p>
<div class="codehilite"><pre><span></span><span class="c1"># 使用[0,1]均匀分布随机初始化二维数组</span>
<span class="n">rnd</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">rnd</span>
</pre></div>

<div class="codehilite"><pre><span></span>tensor([[0.3804, 0.0297, 0.5241],
        [0.4111, 0.8887, 0.4642],
        [0.7302, 0.5913, 0.7182],
        [0.3048, 0.8055, 0.2176],
        [0.6195, 0.1620, 0.7726]])
</pre></div>


<div class="codehilite"><pre><span></span><span class="c1">##初始化，使用1填充</span>
<span class="n">one</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">one</span>
</pre></div>

<div class="codehilite"><pre><span></span>tensor([[1., 1.],
        [1., 1.]])
</pre></div>


<div class="codehilite"><pre><span></span><span class="c1">##初始化，使用0填充</span>
<span class="n">zero</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">zero</span>
</pre></div>

<div class="codehilite"><pre><span></span>tensor([[0., 0.],
        [0., 0.]])
</pre></div>


<div class="codehilite"><pre><span></span><span class="c1">#初始化一个单位矩阵，即对角线为1 其他为0</span>
<span class="n">eye</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">eye</span>
</pre></div>

<div class="codehilite"><pre><span></span>tensor([[1., 0.],
        [0., 1.]])
</pre></div>


<h3 id="_4">常用方法<a class="headerlink" href="#_4" title="Permanent link">&para;</a></h3>
<p>PyTorch中对张量的操作api 和 NumPy 非常相似，如果熟悉 NumPy 中的操作，那么 他们二者 基本是一致的：</p>
<div class="codehilite"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>

<div class="codehilite"><pre><span></span>tensor([[ 0.6922, -0.4824,  0.8594],
        [ 0.4509, -0.8155, -0.0368],
        [ 1.3533,  0.5545, -0.0509]])
</pre></div>


<div class="codehilite"><pre><span></span><span class="c1"># 沿着行取最大值</span>
<span class="n">max_value</span><span class="p">,</span> <span class="n">max_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">max_value</span><span class="p">,</span> <span class="n">max_idx</span><span class="p">)</span>
</pre></div>

<div class="codehilite"><pre><span></span>tensor([0.8594, 0.4509, 1.3533]) tensor([2, 0, 0])
</pre></div>


<div class="codehilite"><pre><span></span><span class="c1"># 每行 x 求和</span>
<span class="n">sum_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">sum_x</span><span class="p">)</span>
</pre></div>

<div class="codehilite"><pre><span></span>tensor([ 1.0692, -0.4014,  1.8568])
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">y</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>
<span class="k">print</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
</pre></div>

<div class="codehilite"><pre><span></span>tensor([[-0.3821, -2.6932, -1.3884],
        [ 0.7468, -0.7697, -0.0883],
        [ 0.7688, -1.3485,  0.7517]])
</pre></div>


<p>正如官方60分钟教程中所说，以_为结尾的，均会改变调用值</p>
<div class="codehilite"><pre><span></span><span class="c1"># add 完成后x的值改变了</span>
<span class="n">x</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>

<div class="codehilite"><pre><span></span>tensor([[-0.3821, -2.6932, -1.3884],
        [ 0.7468, -0.7697, -0.0883],
        [ 0.7688, -1.3485,  0.7517]])
</pre></div>


<p>张量的基本操作都介绍的的差不多了，下一章介绍PyTorch的自动求导机制</p>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../../chapter01_getting-started/1_3_deep-learning-with-pytorch-60-minute-blitz/" title="1.3 PyTorch 60 Minute Blitz" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  上一页
                </span>
                1.3 PyTorch 60 Minute Blitz
              </span>
            </div>
          </a>
        
        
          <a href="../../about/" title="About" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  下一页
                </span>
                About
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2019 <a href="https://github.com/becauseofAI">becauseofAI</a>, Maintained by the <a href="https://github.com/becauseofAI">becauseofAI</a>.
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
  <div class="md-footer-social">
    <link rel="stylesheet" href="../../assets/fonts/font-awesome.css">
    
      <a href="https://github.com/becauseofAI" class="md-footer-social__link fa fa-github"></a>
    
  </div>

    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../assets/javascripts/application.245445c6.js"></script>
      
        
        
          
          <script src="../../assets/javascripts/lunr/lunr.stemmer.support.js"></script>
          
            
              
              
            
          
          
        
      
      <script>app.initialize({version:"1.0.4",url:{base:"../.."}})</script>
      
        <script src="../../js/extra.js"></script>
      
        <script src="../../js/baidu-tongji.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>