{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"PyTorch Tutorial \u00b6 Introduction \u00b6 PyTorch Tutorial for Deep Learning Research and Product. Note It is still at a very early stage and is being written gradually.","title":"Introduction"},{"location":"#pytorch-tutorial","text":"","title":" PyTorch Tutorial "},{"location":"#introduction","text":"PyTorch Tutorial for Deep Learning Research and Product. Note It is still at a very early stage and is being written gradually.","title":"Introduction"},{"location":"about/","text":"Author \u00b6 becauseofAI Contact \u00b6 Email: helloai777@gmail.com License \u00b6 Apache-2.0","title":"About"},{"location":"about/#author","text":"becauseofAI","title":"Author"},{"location":"about/#contact","text":"Email: helloai777@gmail.com","title":"Contact"},{"location":"about/#license","text":"Apache-2.0","title":"License"},{"location":"tutorial/chapter01_getting-started/","text":"PyTorch \u4e2d\u6587\u624b\u518c\u7b2c\u4e00\u7ae0 \uff1a PyTorch\u5165\u95e8 \u00b6 \u76ee\u5f55 \u00b6 PyTorch \u7b80\u4ecb PyTorch \u73af\u5883\u642d\u5efa PyTorch \u6df1\u5ea6\u5b66\u4e60\uff1a60\u5206\u949f\u5feb\u901f\u5165\u95e8\uff08\u5b98\u65b9\uff09 \u5f20\u91cf Autograd\uff1a\u81ea\u52a8\u6c42\u5bfc \u795e\u7ecf\u7f51\u7edc \u8bad\u7ec3\u4e00\u4e2a\u5206\u7c7b\u5668 \u9009\u8bfb\uff1a\u6570\u636e\u5e76\u884c\u5904\u7406\uff08\u591aGPU\uff09 \u76f8\u5173\u8d44\u6e90\u4ecb\u7ecd","title":"PyTorch \u4e2d\u6587\u624b\u518c\u7b2c\u4e00\u7ae0 \uff1a PyTorch\u5165\u95e8"},{"location":"tutorial/chapter01_getting-started/#pytorch-pytorch","text":"","title":"PyTorch \u4e2d\u6587\u624b\u518c\u7b2c\u4e00\u7ae0 \uff1a PyTorch\u5165\u95e8"},{"location":"tutorial/chapter01_getting-started/#_1","text":"PyTorch \u7b80\u4ecb PyTorch \u73af\u5883\u642d\u5efa PyTorch \u6df1\u5ea6\u5b66\u4e60\uff1a60\u5206\u949f\u5feb\u901f\u5165\u95e8\uff08\u5b98\u65b9\uff09 \u5f20\u91cf Autograd\uff1a\u81ea\u52a8\u6c42\u5bfc \u795e\u7ecf\u7f51\u7edc \u8bad\u7ec3\u4e00\u4e2a\u5206\u7c7b\u5668 \u9009\u8bfb\uff1a\u6570\u636e\u5e76\u884c\u5904\u7406\uff08\u591aGPU\uff09 \u76f8\u5173\u8d44\u6e90\u4ecb\u7ecd","title":"\u76ee\u5f55"},{"location":"tutorial/chapter01_getting-started/1_1_pytorch-introduction/","text":"Pytorch \u7b80\u4ecb \u00b6 PyTorch\u7684\u7531\u6765 \u00b6 \u5f88\u591a\u4eba\u90fd\u4f1a\u62ffPyTorch\u548cGoogle\u7684Tensorflow\u8fdb\u884c\u6bd4\u8f83\uff0c\u8fd9\u4e2a\u80af\u5b9a\u662f\u6ca1\u6709\u95ee\u9898\u7684\uff0c\u56e0\u4e3a\u4ed6\u4eec\u662f\u6700\u706b\u7684\u4e24\u4e2a\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u4e86\u3002\u4f46\u662f\u8bf4\u5230PyTorch\uff0c\u5176\u5b9e\u5e94\u8be5\u5148\u8bf4 Torch \u3002 Torch\u662f\u4ec0\u4e48\uff1f \u00b6 Torch\u82f1\u8bd1\u4e2d\uff1a\u706b\u70ac A Tensor library like Numpy, unlike Numpy it has strong GPU support. Lua is a wrapper for Torch (Yes! you need to have a good understanding of Lua), and for that you will need LuaRocks package manager. Torch\u662f\u4e00\u4e2a\u4e0eNumpy\u7c7b\u4f3c\u7684\u5f20\u91cf\uff08Tensor\uff09\u64cd\u4f5c\u5e93\uff0c\u4e0eNumpy\u4e0d\u540c\u7684\u662fTorch\u5bf9GPU\u652f\u6301\u7684\u5f88\u597d\uff0cLua\u662fTorch\u3002 [1] Torch is not going anywhere. PyTorch and Torch use the same C libraries that contain all the performance: TH, THC, THNN, THCUNN and they will continue to be shared. We still and will have continued engineering on Torch itself, and we have no immediate plan to remove that. PyTorch\u548cTorch\u4f7f\u7528\u5305\u542b\u6240\u6709\u76f8\u540c\u6027\u80fd\u7684C\u5e93\uff1aTH, THC, THNN, THCUNN\uff0c\u5e76\u4e14\u5b83\u4eec\u5c06\u7ee7\u7eed\u5171\u4eab\u8fd9\u4e9b\u5e93\u3002 \u8fd9\u6837\u7684\u56de\u7b54\u5c31\u5f88\u660e\u786e\u4e86\uff0c\u5176\u5b9ePyTorch\u548cTorch\u90fd\u4f7f\u7528\u7684\u662f\u76f8\u540c\u7684\u5e95\u5c42\uff0c\u53ea\u662f\u4f7f\u7528\u4e86\u4e0d\u540c\u7684\u4e0a\u5c42\u5305\u88c5\u8bed\u8a00\u3002 LUA\u867d\u7136\u5feb\uff0c\u4f46\u662f\u592a\u5c0f\u4f17\u4e86\uff0c\u6240\u4ee5\u624d\u4f1a\u6709PyTorch\u7684\u51fa\u73b0\u3002 [2] \u91cd\u65b0\u4ecb\u7ecd PyTorch \u00b6 PyTorch is an open source machine learning library for Python, based on Torch, used for applications such as natural language processing. It is primarily developed by Facebook's artificial-intelligence research group, and Uber's \"Pyro\" software for probabilistic programming is built on it. PyTorch\u662f\u4e00\u4e2a\u57fa\u4e8eTorch\u7684Python\u5f00\u6e90\u673a\u5668\u5b66\u4e60\u5e93\uff0c\u7528\u4e8e\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7b49\u5e94\u7528\u7a0b\u5e8f\u3002 \u5b83\u4e3b\u8981\u7531Facebook\u7684\u4eba\u5de5\u667a\u80fd\u7814\u7a76\u5c0f\u7ec4\u5f00\u53d1\u3002Uber\u7684\"Pyro\"\u4e5f\u662f\u4f7f\u7528\u7684\u8fd9\u4e2a\u5e93\u3002 [3] PyTorch is a Python package that provides two high-level features: - Tensor computation (like NumPy) with strong GPU acceleration - Deep neural networks built on a tape-based autograd system You can reuse your favorite Python packages such as NumPy, SciPy and Cython to extend PyTorch when needed. PyTorch\u662f\u4e00\u4e2aPython\u5305\uff0c\u63d0\u4f9b\u4e24\u4e2a\u9ad8\u7ea7\u529f\u80fd\uff1a * \u5177\u6709\u5f3a\u5927\u7684GPU\u52a0\u901f\u7684\u5f20\u91cf\u8ba1\u7b97\uff08\u5982NumPy\uff09 * \u5305\u542b\u81ea\u52a8\u6c42\u5bfc\u7cfb\u7edf\u7684\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc \u4efb\u4f55\u65f6\u5019\uff0c\u4f60\u53ef\u4ee5\u7528\u4f60\u559c\u6b22\u7684Python\u5305\uff0c\u5982NumPy\u3001SciPy \u548c Cython\u53bb\u6269\u5c55PyTorch\u3002 [4] \u5bf9\u6bd4PyTorch\u548cTensorflow \u00b6 \u6ca1\u6709\u597d\u7684\u6846\u67b6\uff0c\u53ea\u6709\u5408\u9002\u7684\u6846\u67b6\uff0c \u8fd9\u7bc7\u77e5\u4e4e\u6587\u7ae0 \u6709\u4e2a\u7b80\u5355\u7684\u5bf9\u6bd4\uff0c2019\u5e746\u670825\u65e5[\u673a\u5668\u4e4b\u5fc3]\u7ffb\u8bd1\u7684 PyTorch\u548cKeras\u7684\u6700\u65b0\u5bf9\u6bd4 \uff0c\u6240\u4ee5\u8fd9\u91cc\u5c31\u4e0d\u8be6\u7ec6\u518d\u8bf4\u4e86\u3002 \u5e76\u4e14\u6280\u672f\u662f\u53d1\u5c55\u7684\uff0c\u77e5\u4e4e\u4e0a\u7684\u5bf9\u6bd4\u4e5f\u4e0d\u662f\u7edd\u5bf9\u7684\uff0c\u6bd4\u5982Tensorflow\u57281.5\u7248\u7684\u65f6\u5019\u5c31\u5f15\u5165\u4e86Eager Execution\u673a\u5236\u5b9e\u73b0\u4e86\u52a8\u6001\u56fe\uff0cPyTorch\u7684\u53ef\u89c6\u5316,windows\u652f\u6301\uff0c\u6cbf\u7ef4\u7ffb\u8f6c\u5f20\u91cf\u7b49\u95ee\u9898\u90fd\u5df2\u7ecf\u4e0d\u662f\u95ee\u9898\u4e86\u3002 \u518d\u6b21\u603b\u7ed3 \u00b6 PyTorch\u7b97\u662f\u76f8\u5f53\u7b80\u6d01\u4f18\u96c5\u4e14\u9ad8\u6548\u5feb\u901f\u7684\u6846\u67b6 \u8bbe\u8ba1\u8ffd\u6c42\u6700\u5c11\u7684\u5c01\u88c5\uff0c\u5c3d\u91cf\u907f\u514d\u91cd\u590d\u9020\u8f6e\u5b50 \u7b97\u662f\u6240\u6709\u7684\u6846\u67b6\u4e2d\u9762\u5411\u5bf9\u8c61\u8bbe\u8ba1\u7684\u6700\u4f18\u96c5\u7684\u4e00\u4e2a\uff0c\u8bbe\u8ba1\u6700\u7b26\u5408\u4eba\u4eec\u7684\u601d\u7ef4\uff0c\u5b83\u8ba9\u7528\u6237\u5c3d\u53ef\u80fd\u5730\u4e13\u6ce8\u4e8e\u5b9e\u73b0\u81ea\u5df1\u7684\u60f3\u6cd5 \u5927\u4f6c\u652f\u6301\uff0c\u4e0egoogle\u7684Tensorflow\u7c7b\u4f3c\uff0cFAIR\u7684\u652f\u6301\u8db3\u4ee5\u786e\u4fddPyTorch\u83b7\u5f97\u6301\u7eed\u7684\u5f00\u53d1\u66f4\u65b0 \u4e0d\u9519\u7684\u7684\u6587\u6863\uff08\u76f8\u6bd4FB\u7684\u5176\u4ed6\u9879\u76ee\uff0cPyTorch\u7684\u6587\u6863\u7b80\u76f4\u7b97\u662f\u5b8c\u5584\u4e86\uff0c\u53c2\u8003Thrift\uff09\uff0cPyTorch\u4f5c\u8005\u4eb2\u81ea\u7ef4\u62a4\u7684\u8bba\u575b \u4f9b\u7528\u6237\u4ea4\u6d41\u548c\u6c42\u6559\u95ee\u9898 \u5165\u95e8\u7b80\u5355","title":"1.1 PyTorch Tntroduction"},{"location":"tutorial/chapter01_getting-started/1_1_pytorch-introduction/#pytorch","text":"","title":"Pytorch \u7b80\u4ecb"},{"location":"tutorial/chapter01_getting-started/1_1_pytorch-introduction/#pytorch_1","text":"\u5f88\u591a\u4eba\u90fd\u4f1a\u62ffPyTorch\u548cGoogle\u7684Tensorflow\u8fdb\u884c\u6bd4\u8f83\uff0c\u8fd9\u4e2a\u80af\u5b9a\u662f\u6ca1\u6709\u95ee\u9898\u7684\uff0c\u56e0\u4e3a\u4ed6\u4eec\u662f\u6700\u706b\u7684\u4e24\u4e2a\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u4e86\u3002\u4f46\u662f\u8bf4\u5230PyTorch\uff0c\u5176\u5b9e\u5e94\u8be5\u5148\u8bf4 Torch \u3002","title":"PyTorch\u7684\u7531\u6765"},{"location":"tutorial/chapter01_getting-started/1_1_pytorch-introduction/#torch","text":"Torch\u82f1\u8bd1\u4e2d\uff1a\u706b\u70ac A Tensor library like Numpy, unlike Numpy it has strong GPU support. Lua is a wrapper for Torch (Yes! you need to have a good understanding of Lua), and for that you will need LuaRocks package manager. Torch\u662f\u4e00\u4e2a\u4e0eNumpy\u7c7b\u4f3c\u7684\u5f20\u91cf\uff08Tensor\uff09\u64cd\u4f5c\u5e93\uff0c\u4e0eNumpy\u4e0d\u540c\u7684\u662fTorch\u5bf9GPU\u652f\u6301\u7684\u5f88\u597d\uff0cLua\u662fTorch\u3002 [1] Torch is not going anywhere. PyTorch and Torch use the same C libraries that contain all the performance: TH, THC, THNN, THCUNN and they will continue to be shared. We still and will have continued engineering on Torch itself, and we have no immediate plan to remove that. PyTorch\u548cTorch\u4f7f\u7528\u5305\u542b\u6240\u6709\u76f8\u540c\u6027\u80fd\u7684C\u5e93\uff1aTH, THC, THNN, THCUNN\uff0c\u5e76\u4e14\u5b83\u4eec\u5c06\u7ee7\u7eed\u5171\u4eab\u8fd9\u4e9b\u5e93\u3002 \u8fd9\u6837\u7684\u56de\u7b54\u5c31\u5f88\u660e\u786e\u4e86\uff0c\u5176\u5b9ePyTorch\u548cTorch\u90fd\u4f7f\u7528\u7684\u662f\u76f8\u540c\u7684\u5e95\u5c42\uff0c\u53ea\u662f\u4f7f\u7528\u4e86\u4e0d\u540c\u7684\u4e0a\u5c42\u5305\u88c5\u8bed\u8a00\u3002 LUA\u867d\u7136\u5feb\uff0c\u4f46\u662f\u592a\u5c0f\u4f17\u4e86\uff0c\u6240\u4ee5\u624d\u4f1a\u6709PyTorch\u7684\u51fa\u73b0\u3002 [2]","title":"Torch\u662f\u4ec0\u4e48\uff1f"},{"location":"tutorial/chapter01_getting-started/1_1_pytorch-introduction/#pytorch_2","text":"PyTorch is an open source machine learning library for Python, based on Torch, used for applications such as natural language processing. It is primarily developed by Facebook's artificial-intelligence research group, and Uber's \"Pyro\" software for probabilistic programming is built on it. PyTorch\u662f\u4e00\u4e2a\u57fa\u4e8eTorch\u7684Python\u5f00\u6e90\u673a\u5668\u5b66\u4e60\u5e93\uff0c\u7528\u4e8e\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7b49\u5e94\u7528\u7a0b\u5e8f\u3002 \u5b83\u4e3b\u8981\u7531Facebook\u7684\u4eba\u5de5\u667a\u80fd\u7814\u7a76\u5c0f\u7ec4\u5f00\u53d1\u3002Uber\u7684\"Pyro\"\u4e5f\u662f\u4f7f\u7528\u7684\u8fd9\u4e2a\u5e93\u3002 [3] PyTorch is a Python package that provides two high-level features: - Tensor computation (like NumPy) with strong GPU acceleration - Deep neural networks built on a tape-based autograd system You can reuse your favorite Python packages such as NumPy, SciPy and Cython to extend PyTorch when needed. PyTorch\u662f\u4e00\u4e2aPython\u5305\uff0c\u63d0\u4f9b\u4e24\u4e2a\u9ad8\u7ea7\u529f\u80fd\uff1a * \u5177\u6709\u5f3a\u5927\u7684GPU\u52a0\u901f\u7684\u5f20\u91cf\u8ba1\u7b97\uff08\u5982NumPy\uff09 * \u5305\u542b\u81ea\u52a8\u6c42\u5bfc\u7cfb\u7edf\u7684\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc \u4efb\u4f55\u65f6\u5019\uff0c\u4f60\u53ef\u4ee5\u7528\u4f60\u559c\u6b22\u7684Python\u5305\uff0c\u5982NumPy\u3001SciPy \u548c Cython\u53bb\u6269\u5c55PyTorch\u3002 [4]","title":"\u91cd\u65b0\u4ecb\u7ecd PyTorch"},{"location":"tutorial/chapter01_getting-started/1_1_pytorch-introduction/#pytorchtensorflow","text":"\u6ca1\u6709\u597d\u7684\u6846\u67b6\uff0c\u53ea\u6709\u5408\u9002\u7684\u6846\u67b6\uff0c \u8fd9\u7bc7\u77e5\u4e4e\u6587\u7ae0 \u6709\u4e2a\u7b80\u5355\u7684\u5bf9\u6bd4\uff0c2019\u5e746\u670825\u65e5[\u673a\u5668\u4e4b\u5fc3]\u7ffb\u8bd1\u7684 PyTorch\u548cKeras\u7684\u6700\u65b0\u5bf9\u6bd4 \uff0c\u6240\u4ee5\u8fd9\u91cc\u5c31\u4e0d\u8be6\u7ec6\u518d\u8bf4\u4e86\u3002 \u5e76\u4e14\u6280\u672f\u662f\u53d1\u5c55\u7684\uff0c\u77e5\u4e4e\u4e0a\u7684\u5bf9\u6bd4\u4e5f\u4e0d\u662f\u7edd\u5bf9\u7684\uff0c\u6bd4\u5982Tensorflow\u57281.5\u7248\u7684\u65f6\u5019\u5c31\u5f15\u5165\u4e86Eager Execution\u673a\u5236\u5b9e\u73b0\u4e86\u52a8\u6001\u56fe\uff0cPyTorch\u7684\u53ef\u89c6\u5316,windows\u652f\u6301\uff0c\u6cbf\u7ef4\u7ffb\u8f6c\u5f20\u91cf\u7b49\u95ee\u9898\u90fd\u5df2\u7ecf\u4e0d\u662f\u95ee\u9898\u4e86\u3002","title":"\u5bf9\u6bd4PyTorch\u548cTensorflow"},{"location":"tutorial/chapter01_getting-started/1_1_pytorch-introduction/#_1","text":"PyTorch\u7b97\u662f\u76f8\u5f53\u7b80\u6d01\u4f18\u96c5\u4e14\u9ad8\u6548\u5feb\u901f\u7684\u6846\u67b6 \u8bbe\u8ba1\u8ffd\u6c42\u6700\u5c11\u7684\u5c01\u88c5\uff0c\u5c3d\u91cf\u907f\u514d\u91cd\u590d\u9020\u8f6e\u5b50 \u7b97\u662f\u6240\u6709\u7684\u6846\u67b6\u4e2d\u9762\u5411\u5bf9\u8c61\u8bbe\u8ba1\u7684\u6700\u4f18\u96c5\u7684\u4e00\u4e2a\uff0c\u8bbe\u8ba1\u6700\u7b26\u5408\u4eba\u4eec\u7684\u601d\u7ef4\uff0c\u5b83\u8ba9\u7528\u6237\u5c3d\u53ef\u80fd\u5730\u4e13\u6ce8\u4e8e\u5b9e\u73b0\u81ea\u5df1\u7684\u60f3\u6cd5 \u5927\u4f6c\u652f\u6301\uff0c\u4e0egoogle\u7684Tensorflow\u7c7b\u4f3c\uff0cFAIR\u7684\u652f\u6301\u8db3\u4ee5\u786e\u4fddPyTorch\u83b7\u5f97\u6301\u7eed\u7684\u5f00\u53d1\u66f4\u65b0 \u4e0d\u9519\u7684\u7684\u6587\u6863\uff08\u76f8\u6bd4FB\u7684\u5176\u4ed6\u9879\u76ee\uff0cPyTorch\u7684\u6587\u6863\u7b80\u76f4\u7b97\u662f\u5b8c\u5584\u4e86\uff0c\u53c2\u8003Thrift\uff09\uff0cPyTorch\u4f5c\u8005\u4eb2\u81ea\u7ef4\u62a4\u7684\u8bba\u575b \u4f9b\u7528\u6237\u4ea4\u6d41\u548c\u6c42\u6559\u95ee\u9898 \u5165\u95e8\u7b80\u5355","title":"\u518d\u6b21\u603b\u7ed3"},{"location":"tutorial/chapter01_getting-started/1_3_1_tensor_tutorial/","text":"PyTorch\u662f\u4ec0\u4e48? \u00b6 \u57fa\u4e8ePython\u7684\u79d1\u5b66\u8ba1\u7b97\u5305\uff0c\u670d\u52a1\u4e8e\u4ee5\u4e0b\u4e24\u79cd\u573a\u666f: \u4f5c\u4e3aNumPy\u7684\u66ff\u4ee3\u54c1\uff0c\u53ef\u4ee5\u4f7f\u7528GPU\u7684\u5f3a\u5927\u8ba1\u7b97\u80fd\u529b \u63d0\u4f9b\u6700\u5927\u7684\u7075\u6d3b\u6027\u548c\u9ad8\u901f\u7684\u6df1\u5ea6\u5b66\u4e60\u7814\u7a76\u5e73\u53f0 \u5f00\u59cb \u00b6 Tensors\uff08\u5f20\u91cf\uff09 \u00b6 Tensors\u4e0eNumpy\u4e2d\u7684 ndarrays\u7c7b\u4f3c\uff0c\u4f46\u662f\u5728PyTorch\u4e2d Tensors \u53ef\u4ee5\u4f7f\u7528GPU\u8fdb\u884c\u8ba1\u7b97. from __future__ import print_function import torch \u521b\u5efa\u4e00\u4e2a 5x3 \u77e9\u9635, \u4f46\u662f\u672a\u521d\u59cb\u5316: x = torch . empty ( 5 , 3 ) print ( x ) tensor([[0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000]]) \u521b\u5efa\u4e00\u4e2a\u968f\u673a\u521d\u59cb\u5316\u7684\u77e9\u9635: x = torch . rand ( 5 , 3 ) print ( x ) tensor([[0.6972, 0.0231, 0.3087], [0.2083, 0.6141, 0.6896], [0.7228, 0.9715, 0.5304], [0.7727, 0.1621, 0.9777], [0.6526, 0.6170, 0.2605]]) \u521b\u5efa\u4e00\u4e2a0\u586b\u5145\u7684\u77e9\u9635\uff0c\u6570\u636e\u7c7b\u578b\u4e3along: x = torch . zeros ( 5 , 3 , dtype = torch . long ) print ( x ) tensor([[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]]) \u521b\u5efatensor\u5e76\u4f7f\u7528\u73b0\u6709\u6570\u636e\u521d\u59cb\u5316: x = torch . tensor ([ 5.5 , 3 ]) print ( x ) tensor([5.5000, 3.0000]) \u6839\u636e\u73b0\u6709\u7684\u5f20\u91cf\u521b\u5efa\u5f20\u91cf\u3002 \u8fd9\u4e9b\u65b9\u6cd5\u5c06\u91cd\u7528\u8f93\u5165\u5f20\u91cf\u7684\u5c5e\u6027\uff0c\u4f8b\u5982\uff0c dtype\uff0c\u9664\u975e\u8bbe\u7f6e\u65b0\u7684\u503c\u8fdb\u884c\u8986\u76d6 x = x . new_ones ( 5 , 3 , dtype = torch . double ) # new_* \u65b9\u6cd5\u6765\u521b\u5efa\u5bf9\u8c61 print ( x ) x = torch . randn_like ( x , dtype = torch . float ) # \u8986\u76d6 dtype! print ( x ) # \u5bf9\u8c61\u7684size \u662f\u76f8\u540c\u7684\uff0c\u53ea\u662f\u503c\u548c\u7c7b\u578b\u53d1\u751f\u4e86\u53d8\u5316 tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]], dtype=torch.float64) tensor([[ 0.5691, -2.0126, -0.4064], [-0.0863, 0.4692, -1.1209], [-1.1177, -0.5764, -0.5363], [-0.4390, 0.6688, 0.0889], [ 1.3334, -1.1600, 1.8457]]) \u83b7\u53d6 size \u8bd1\u8005\u6ce8\uff1a\u4f7f\u7528size\u65b9\u6cd5\u4e0eNumpy\u7684shape\u5c5e\u6027\u8fd4\u56de\u7684\u76f8\u540c\uff0c\u5f20\u91cf\u4e5f\u652f\u6301shape\u5c5e\u6027\uff0c\u540e\u9762\u4f1a\u8be6\u7ec6\u4ecb\u7ecd print ( x . size ()) torch.Size([5, 3]) Note torch.Size \u8fd4\u56de\u503c\u662f tuple\u7c7b\u578b, \u6240\u4ee5\u5b83\u652f\u6301tuple\u7c7b\u578b\u7684\u6240\u6709\u64cd\u4f5c\u3002 Operations\uff08\u64cd\u4f5c\uff09 \u00b6 \u64cd\u4f5c\u6709\u591a\u79cd\u8bed\u6cd5\u3002 \u6211\u4eec\u5c06\u770b\u4e00\u4e0b\u52a0\u6cd5\u8fd0\u7b97\u3002 \u52a0\u6cd5\uff1a\u8bed\u6cd51 y = torch . rand ( 5 , 3 ) print ( x + y ) tensor([[ 0.7808, -1.4388, 0.3151], [-0.0076, 1.0716, -0.8465], [-0.8175, 0.3625, -0.2005], [ 0.2435, 0.8512, 0.7142], [ 1.4737, -0.8545, 2.4833]]) \u52a0\u6cd5\uff1a\u8bed\u6cd52 print ( torch . add ( x , y )) tensor([[ 0.7808, -1.4388, 0.3151], [-0.0076, 1.0716, -0.8465], [-0.8175, 0.3625, -0.2005], [ 0.2435, 0.8512, 0.7142], [ 1.4737, -0.8545, 2.4833]]) \u52a0\u6cd5\uff1a\u63d0\u4f9b\u8f93\u51fatensor\u4f5c\u4e3a\u53c2\u6570 result = torch . empty ( 5 , 3 ) torch . add ( x , y , out = result ) print ( result ) tensor([[ 0.7808, -1.4388, 0.3151], [-0.0076, 1.0716, -0.8465], [-0.8175, 0.3625, -0.2005], [ 0.2435, 0.8512, 0.7142], [ 1.4737, -0.8545, 2.4833]]) \u52a0\u6cd5\uff1a\u539f\u5730 # adds x to y y . add_ ( x ) print ( y ) tensor([[ 0.7808, -1.4388, 0.3151], [-0.0076, 1.0716, -0.8465], [-0.8175, 0.3625, -0.2005], [ 0.2435, 0.8512, 0.7142], [ 1.4737, -0.8545, 2.4833]]) Note \u4efb\u4f55 \u4ee5 _ \u7ed3\u5c3e\u7684\u64cd\u4f5c\u90fd\u4f1a\u7528\u7ed3\u679c\u66ff\u6362\u539f\u53d8\u91cf. \u4f8b\u5982: x.copy_(y) , x.t_() , \u90fd\u4f1a\u6539\u53d8 x \u3002 \u4f60\u53ef\u4ee5\u4f7f\u7528\u4e0eNumPy\u7d22\u5f15\u65b9\u5f0f\u76f8\u540c\u7684\u64cd\u4f5c\u6765\u8fdb\u884c\u5bf9\u5f20\u91cf\u7684\u64cd\u4f5c! print ( x [:, 1 ]) tensor([-2.0126, 0.4692, -0.5764, 0.6688, -1.1600]) \u6539\u53d8\u5927\u5c0f\uff1a\u53ef\u4ee5\u7528 torch.view \u6539\u53d8\u5f20\u91cf\u7684\u7ef4\u5ea6\u548c\u5927\u5c0f \u8bd1\u8005\u6ce8\uff1atorch.view \u4e0eNumpy\u7684reshape\u7c7b\u4f3c x = torch . randn ( 4 , 4 ) y = x . view ( 16 ) z = x . view ( - 1 , 8 ) # size -1 \u4ece\u5176\u4ed6\u7ef4\u5ea6\u63a8\u65ad print ( x . size (), y . size (), z . size ()) torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8]) \u5982\u679c\u4f60\u6709\u53ea\u6709\u4e00\u4e2a\u5143\u7d20\u7684\u5f20\u91cf\uff0c\u4f7f\u7528 .item() \u6765\u5f97\u5230Python\u6570\u636e\u7c7b\u578b\u7684\u6570\u503c x = torch . randn ( 1 ) print ( x ) print ( x . item ()) tensor([-0.2368]) -0.23680149018764496 Read later: 100+ Tensor operations, including transposing, indexing, slicing, mathematical operations, linear algebra, random numbers, etc., are described here <https://pytorch.org/docs/torch> _. NumPy \u8f6c\u6362 \u00b6 Converting a Torch Tensor to a NumPy array and vice versa is a breeze. The Torch Tensor and NumPy array will share their underlying memory locations, and changing one will change the other. Torch Tensor \u8f6c\u6210 NumPy Array \u00b6 a = torch . ones ( 5 ) print ( a ) tensor([1., 1., 1., 1., 1.]) b = a . numpy () print ( b ) [1. 1. 1. 1. 1.] See how the numpy array changed in value. a . add_ ( 1 ) print ( a ) print ( b ) tensor([2., 2., 2., 2., 2.]) [2. 2. 2. 2. 2.] NumPy Array \u8f6c\u6210 Torch Tensor \u00b6 \u4f7f\u7528from_numpy\u81ea\u52a8\u8f6c\u5316 import numpy as np a = np . ones ( 5 ) b = torch . from_numpy ( a ) np . add ( a , 1 , out = a ) print ( a ) print ( b ) [2. 2. 2. 2. 2.] tensor([2., 2., 2., 2., 2.], dtype=torch.float64) \u6240\u6709\u7684 Tensor \u7c7b\u578b\u9ed8\u8ba4\u90fd\u662f\u57fa\u4e8eCPU\uff0c CharTensor \u7c7b\u578b\u4e0d\u652f\u6301\u5230 NumPy \u7684\u8f6c\u6362. CUDA \u5f20\u91cf \u00b6 \u4f7f\u7528 .to \u65b9\u6cd5 \u53ef\u4ee5\u5c06Tensor\u79fb\u52a8\u5230\u4efb\u4f55\u8bbe\u5907\u4e2d # is_available \u51fd\u6570\u5224\u65ad\u662f\u5426\u6709cuda\u53ef\u4ee5\u4f7f\u7528 # ``torch.device``\u5c06\u5f20\u91cf\u79fb\u52a8\u5230\u6307\u5b9a\u7684\u8bbe\u5907\u4e2d if torch . cuda . is_available (): device = torch . device ( \"cuda\" ) # a CUDA \u8bbe\u5907\u5bf9\u8c61 y = torch . ones_like ( x , device = device ) # \u76f4\u63a5\u4eceGPU\u521b\u5efa\u5f20\u91cf x = x . to ( device ) # \u6216\u8005\u76f4\u63a5\u4f7f\u7528``.to(\"cuda\")``\u5c06\u5f20\u91cf\u79fb\u52a8\u5230cuda\u4e2d z = x + y print ( z ) print ( z . to ( \"cpu\" , torch . double )) # ``.to`` \u4e5f\u4f1a\u5bf9\u53d8\u91cf\u7684\u7c7b\u578b\u505a\u66f4\u6539 tensor([0.7632], device='cuda:0') tensor([0.7632], dtype=torch.float64)","title":"1.3.1 Tensor"},{"location":"tutorial/chapter01_getting-started/1_3_1_tensor_tutorial/#pytorch","text":"\u57fa\u4e8ePython\u7684\u79d1\u5b66\u8ba1\u7b97\u5305\uff0c\u670d\u52a1\u4e8e\u4ee5\u4e0b\u4e24\u79cd\u573a\u666f: \u4f5c\u4e3aNumPy\u7684\u66ff\u4ee3\u54c1\uff0c\u53ef\u4ee5\u4f7f\u7528GPU\u7684\u5f3a\u5927\u8ba1\u7b97\u80fd\u529b \u63d0\u4f9b\u6700\u5927\u7684\u7075\u6d3b\u6027\u548c\u9ad8\u901f\u7684\u6df1\u5ea6\u5b66\u4e60\u7814\u7a76\u5e73\u53f0","title":"PyTorch\u662f\u4ec0\u4e48?"},{"location":"tutorial/chapter01_getting-started/1_3_1_tensor_tutorial/#_1","text":"","title":"\u5f00\u59cb"},{"location":"tutorial/chapter01_getting-started/1_3_1_tensor_tutorial/#tensors","text":"Tensors\u4e0eNumpy\u4e2d\u7684 ndarrays\u7c7b\u4f3c\uff0c\u4f46\u662f\u5728PyTorch\u4e2d Tensors \u53ef\u4ee5\u4f7f\u7528GPU\u8fdb\u884c\u8ba1\u7b97. from __future__ import print_function import torch \u521b\u5efa\u4e00\u4e2a 5x3 \u77e9\u9635, \u4f46\u662f\u672a\u521d\u59cb\u5316: x = torch . empty ( 5 , 3 ) print ( x ) tensor([[0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000]]) \u521b\u5efa\u4e00\u4e2a\u968f\u673a\u521d\u59cb\u5316\u7684\u77e9\u9635: x = torch . rand ( 5 , 3 ) print ( x ) tensor([[0.6972, 0.0231, 0.3087], [0.2083, 0.6141, 0.6896], [0.7228, 0.9715, 0.5304], [0.7727, 0.1621, 0.9777], [0.6526, 0.6170, 0.2605]]) \u521b\u5efa\u4e00\u4e2a0\u586b\u5145\u7684\u77e9\u9635\uff0c\u6570\u636e\u7c7b\u578b\u4e3along: x = torch . zeros ( 5 , 3 , dtype = torch . long ) print ( x ) tensor([[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]]) \u521b\u5efatensor\u5e76\u4f7f\u7528\u73b0\u6709\u6570\u636e\u521d\u59cb\u5316: x = torch . tensor ([ 5.5 , 3 ]) print ( x ) tensor([5.5000, 3.0000]) \u6839\u636e\u73b0\u6709\u7684\u5f20\u91cf\u521b\u5efa\u5f20\u91cf\u3002 \u8fd9\u4e9b\u65b9\u6cd5\u5c06\u91cd\u7528\u8f93\u5165\u5f20\u91cf\u7684\u5c5e\u6027\uff0c\u4f8b\u5982\uff0c dtype\uff0c\u9664\u975e\u8bbe\u7f6e\u65b0\u7684\u503c\u8fdb\u884c\u8986\u76d6 x = x . new_ones ( 5 , 3 , dtype = torch . double ) # new_* \u65b9\u6cd5\u6765\u521b\u5efa\u5bf9\u8c61 print ( x ) x = torch . randn_like ( x , dtype = torch . float ) # \u8986\u76d6 dtype! print ( x ) # \u5bf9\u8c61\u7684size \u662f\u76f8\u540c\u7684\uff0c\u53ea\u662f\u503c\u548c\u7c7b\u578b\u53d1\u751f\u4e86\u53d8\u5316 tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]], dtype=torch.float64) tensor([[ 0.5691, -2.0126, -0.4064], [-0.0863, 0.4692, -1.1209], [-1.1177, -0.5764, -0.5363], [-0.4390, 0.6688, 0.0889], [ 1.3334, -1.1600, 1.8457]]) \u83b7\u53d6 size \u8bd1\u8005\u6ce8\uff1a\u4f7f\u7528size\u65b9\u6cd5\u4e0eNumpy\u7684shape\u5c5e\u6027\u8fd4\u56de\u7684\u76f8\u540c\uff0c\u5f20\u91cf\u4e5f\u652f\u6301shape\u5c5e\u6027\uff0c\u540e\u9762\u4f1a\u8be6\u7ec6\u4ecb\u7ecd print ( x . size ()) torch.Size([5, 3]) Note torch.Size \u8fd4\u56de\u503c\u662f tuple\u7c7b\u578b, \u6240\u4ee5\u5b83\u652f\u6301tuple\u7c7b\u578b\u7684\u6240\u6709\u64cd\u4f5c\u3002","title":"Tensors\uff08\u5f20\u91cf\uff09"},{"location":"tutorial/chapter01_getting-started/1_3_1_tensor_tutorial/#operations","text":"\u64cd\u4f5c\u6709\u591a\u79cd\u8bed\u6cd5\u3002 \u6211\u4eec\u5c06\u770b\u4e00\u4e0b\u52a0\u6cd5\u8fd0\u7b97\u3002 \u52a0\u6cd5\uff1a\u8bed\u6cd51 y = torch . rand ( 5 , 3 ) print ( x + y ) tensor([[ 0.7808, -1.4388, 0.3151], [-0.0076, 1.0716, -0.8465], [-0.8175, 0.3625, -0.2005], [ 0.2435, 0.8512, 0.7142], [ 1.4737, -0.8545, 2.4833]]) \u52a0\u6cd5\uff1a\u8bed\u6cd52 print ( torch . add ( x , y )) tensor([[ 0.7808, -1.4388, 0.3151], [-0.0076, 1.0716, -0.8465], [-0.8175, 0.3625, -0.2005], [ 0.2435, 0.8512, 0.7142], [ 1.4737, -0.8545, 2.4833]]) \u52a0\u6cd5\uff1a\u63d0\u4f9b\u8f93\u51fatensor\u4f5c\u4e3a\u53c2\u6570 result = torch . empty ( 5 , 3 ) torch . add ( x , y , out = result ) print ( result ) tensor([[ 0.7808, -1.4388, 0.3151], [-0.0076, 1.0716, -0.8465], [-0.8175, 0.3625, -0.2005], [ 0.2435, 0.8512, 0.7142], [ 1.4737, -0.8545, 2.4833]]) \u52a0\u6cd5\uff1a\u539f\u5730 # adds x to y y . add_ ( x ) print ( y ) tensor([[ 0.7808, -1.4388, 0.3151], [-0.0076, 1.0716, -0.8465], [-0.8175, 0.3625, -0.2005], [ 0.2435, 0.8512, 0.7142], [ 1.4737, -0.8545, 2.4833]]) Note \u4efb\u4f55 \u4ee5 _ \u7ed3\u5c3e\u7684\u64cd\u4f5c\u90fd\u4f1a\u7528\u7ed3\u679c\u66ff\u6362\u539f\u53d8\u91cf. \u4f8b\u5982: x.copy_(y) , x.t_() , \u90fd\u4f1a\u6539\u53d8 x \u3002 \u4f60\u53ef\u4ee5\u4f7f\u7528\u4e0eNumPy\u7d22\u5f15\u65b9\u5f0f\u76f8\u540c\u7684\u64cd\u4f5c\u6765\u8fdb\u884c\u5bf9\u5f20\u91cf\u7684\u64cd\u4f5c! print ( x [:, 1 ]) tensor([-2.0126, 0.4692, -0.5764, 0.6688, -1.1600]) \u6539\u53d8\u5927\u5c0f\uff1a\u53ef\u4ee5\u7528 torch.view \u6539\u53d8\u5f20\u91cf\u7684\u7ef4\u5ea6\u548c\u5927\u5c0f \u8bd1\u8005\u6ce8\uff1atorch.view \u4e0eNumpy\u7684reshape\u7c7b\u4f3c x = torch . randn ( 4 , 4 ) y = x . view ( 16 ) z = x . view ( - 1 , 8 ) # size -1 \u4ece\u5176\u4ed6\u7ef4\u5ea6\u63a8\u65ad print ( x . size (), y . size (), z . size ()) torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8]) \u5982\u679c\u4f60\u6709\u53ea\u6709\u4e00\u4e2a\u5143\u7d20\u7684\u5f20\u91cf\uff0c\u4f7f\u7528 .item() \u6765\u5f97\u5230Python\u6570\u636e\u7c7b\u578b\u7684\u6570\u503c x = torch . randn ( 1 ) print ( x ) print ( x . item ()) tensor([-0.2368]) -0.23680149018764496 Read later: 100+ Tensor operations, including transposing, indexing, slicing, mathematical operations, linear algebra, random numbers, etc., are described here <https://pytorch.org/docs/torch> _.","title":"Operations\uff08\u64cd\u4f5c\uff09"},{"location":"tutorial/chapter01_getting-started/1_3_1_tensor_tutorial/#numpy","text":"Converting a Torch Tensor to a NumPy array and vice versa is a breeze. The Torch Tensor and NumPy array will share their underlying memory locations, and changing one will change the other.","title":"NumPy \u8f6c\u6362"},{"location":"tutorial/chapter01_getting-started/1_3_1_tensor_tutorial/#torch-tensor-numpy-array","text":"a = torch . ones ( 5 ) print ( a ) tensor([1., 1., 1., 1., 1.]) b = a . numpy () print ( b ) [1. 1. 1. 1. 1.] See how the numpy array changed in value. a . add_ ( 1 ) print ( a ) print ( b ) tensor([2., 2., 2., 2., 2.]) [2. 2. 2. 2. 2.]","title":"Torch Tensor \u8f6c\u6210 NumPy Array"},{"location":"tutorial/chapter01_getting-started/1_3_1_tensor_tutorial/#numpy-array-torch-tensor","text":"\u4f7f\u7528from_numpy\u81ea\u52a8\u8f6c\u5316 import numpy as np a = np . ones ( 5 ) b = torch . from_numpy ( a ) np . add ( a , 1 , out = a ) print ( a ) print ( b ) [2. 2. 2. 2. 2.] tensor([2., 2., 2., 2., 2.], dtype=torch.float64) \u6240\u6709\u7684 Tensor \u7c7b\u578b\u9ed8\u8ba4\u90fd\u662f\u57fa\u4e8eCPU\uff0c CharTensor \u7c7b\u578b\u4e0d\u652f\u6301\u5230 NumPy \u7684\u8f6c\u6362.","title":"NumPy Array \u8f6c\u6210 Torch Tensor"},{"location":"tutorial/chapter01_getting-started/1_3_1_tensor_tutorial/#cuda","text":"\u4f7f\u7528 .to \u65b9\u6cd5 \u53ef\u4ee5\u5c06Tensor\u79fb\u52a8\u5230\u4efb\u4f55\u8bbe\u5907\u4e2d # is_available \u51fd\u6570\u5224\u65ad\u662f\u5426\u6709cuda\u53ef\u4ee5\u4f7f\u7528 # ``torch.device``\u5c06\u5f20\u91cf\u79fb\u52a8\u5230\u6307\u5b9a\u7684\u8bbe\u5907\u4e2d if torch . cuda . is_available (): device = torch . device ( \"cuda\" ) # a CUDA \u8bbe\u5907\u5bf9\u8c61 y = torch . ones_like ( x , device = device ) # \u76f4\u63a5\u4eceGPU\u521b\u5efa\u5f20\u91cf x = x . to ( device ) # \u6216\u8005\u76f4\u63a5\u4f7f\u7528``.to(\"cuda\")``\u5c06\u5f20\u91cf\u79fb\u52a8\u5230cuda\u4e2d z = x + y print ( z ) print ( z . to ( \"cpu\" , torch . double )) # ``.to`` \u4e5f\u4f1a\u5bf9\u53d8\u91cf\u7684\u7c7b\u578b\u505a\u66f4\u6539 tensor([0.7632], device='cuda:0') tensor([0.7632], dtype=torch.float64)","title":"CUDA \u5f20\u91cf"},{"location":"tutorial/chapter01_getting-started/1_3_2_autograd_tutorial/","text":"% matplotlib inline Autograd: \u81ea\u52a8\u6c42\u5bfc\u673a\u5236 \u00b6 PyTorch \u4e2d\u6240\u6709\u795e\u7ecf\u7f51\u7edc\u7684\u6838\u5fc3\u662f autograd \u5305\u3002 \u6211\u4eec\u5148\u7b80\u5355\u4ecb\u7ecd\u4e00\u4e0b\u8fd9\u4e2a\u5305\uff0c\u7136\u540e\u8bad\u7ec3\u7b2c\u4e00\u4e2a\u7b80\u5355\u7684\u795e\u7ecf\u7f51\u7edc\u3002 autograd \u5305\u4e3a\u5f20\u91cf\u4e0a\u7684\u6240\u6709\u64cd\u4f5c\u63d0\u4f9b\u4e86\u81ea\u52a8\u6c42\u5bfc\u3002 \u5b83\u662f\u4e00\u4e2a\u5728\u8fd0\u884c\u65f6\u5b9a\u4e49\u7684\u6846\u67b6\uff0c\u8fd9\u610f\u5473\u7740\u53cd\u5411\u4f20\u64ad\u662f\u6839\u636e\u4f60\u7684\u4ee3\u7801\u6765\u786e\u5b9a\u5982\u4f55\u8fd0\u884c\uff0c\u5e76\u4e14\u6bcf\u6b21\u8fed\u4ee3\u53ef\u4ee5\u662f\u4e0d\u540c\u7684\u3002 \u793a\u4f8b \u5f20\u91cf\uff08Tensor\uff09 \u00b6 torch.Tensor \u662f\u8fd9\u4e2a\u5305\u7684\u6838\u5fc3\u7c7b\u3002\u5982\u679c\u8bbe\u7f6e .requires_grad \u4e3a True \uff0c\u90a3\u4e48\u5c06\u4f1a\u8ffd\u8e2a\u6240\u6709\u5bf9\u4e8e\u8be5\u5f20\u91cf\u7684\u64cd\u4f5c\u3002 \u5f53\u5b8c\u6210\u8ba1\u7b97\u540e\u901a\u8fc7\u8c03\u7528 .backward() \uff0c\u81ea\u52a8\u8ba1\u7b97\u6240\u6709\u7684\u68af\u5ea6\uff0c \u8fd9\u4e2a\u5f20\u91cf\u7684\u6240\u6709\u68af\u5ea6\u5c06\u4f1a\u81ea\u52a8\u79ef\u7d2f\u5230 .grad \u5c5e\u6027\u3002 \u8981\u963b\u6b62\u5f20\u91cf\u8ddf\u8e2a\u5386\u53f2\u8bb0\u5f55\uff0c\u53ef\u4ee5\u8c03\u7528 .detach() \u65b9\u6cd5\u5c06\u5176\u4e0e\u8ba1\u7b97\u5386\u53f2\u8bb0\u5f55\u5206\u79bb\uff0c\u5e76\u7981\u6b62\u8ddf\u8e2a\u5b83\u5c06\u6765\u7684\u8ba1\u7b97\u8bb0\u5f55\u3002 \u4e3a\u4e86\u9632\u6b62\u8ddf\u8e2a\u5386\u53f2\u8bb0\u5f55\uff08\u548c\u4f7f\u7528\u5185\u5b58\uff09\uff0c\u53ef\u4ee5\u5c06\u4ee3\u7801\u5757\u5305\u88c5\u5728 with torch.no_grad()\uff1a \u4e2d\u3002 \u5728\u8bc4\u4f30\u6a21\u578b\u65f6\u7279\u522b\u6709\u7528\uff0c\u56e0\u4e3a\u6a21\u578b\u53ef\u80fd\u5177\u6709 requires_grad = True \u7684\u53ef\u8bad\u7ec3\u53c2\u6570\uff0c\u4f46\u662f\u6211\u4eec\u4e0d\u9700\u8981\u68af\u5ea6\u8ba1\u7b97\u3002 \u5728\u81ea\u52a8\u68af\u5ea6\u8ba1\u7b97\u4e2d\u8fd8\u6709\u53e6\u5916\u4e00\u4e2a\u91cd\u8981\u7684\u7c7b Function . Tensor and Function are interconnected and build up an acyclic graph, that encodes a complete history of computation. Each tensor has a .grad_fn attribute that references a Function that has created the Tensor (except for Tensors created by the user - their grad_fn is None ). Tensor \u548c Function \u4e92\u76f8\u8fde\u63a5\u5e76\u751f\u6210\u4e00\u4e2a\u975e\u5faa\u73af\u56fe\uff0c\u5b83\u8868\u793a\u548c\u5b58\u50a8\u4e86\u5b8c\u6574\u7684\u8ba1\u7b97\u5386\u53f2\u3002 \u6bcf\u4e2a\u5f20\u91cf\u90fd\u6709\u4e00\u4e2a .grad_fn \u5c5e\u6027\uff0c\u8fd9\u4e2a\u5c5e\u6027\u5f15\u7528\u4e86\u4e00\u4e2a\u521b\u5efa\u4e86 Tensor \u7684 Function \uff08\u9664\u975e\u8fd9\u4e2a\u5f20\u91cf\u662f\u7528\u6237\u624b\u52a8\u521b\u5efa\u7684\uff0c\u5373\uff0c\u8fd9\u4e2a\u5f20\u91cf\u7684 grad_fn \u662f None \uff09\u3002 \u5982\u679c\u9700\u8981\u8ba1\u7b97\u5bfc\u6570\uff0c\u4f60\u53ef\u4ee5\u5728 Tensor \u4e0a\u8c03\u7528 .backward() \u3002 \u5982\u679c Tensor \u662f\u4e00\u4e2a\u6807\u91cf\uff08\u5373\u5b83\u5305\u542b\u4e00\u4e2a\u5143\u7d20\u6570\u636e\uff09\u5219\u4e0d\u9700\u8981\u4e3a backward() \u6307\u5b9a\u4efb\u4f55\u53c2\u6570\uff0c \u4f46\u662f\u5982\u679c\u5b83\u6709\u66f4\u591a\u7684\u5143\u7d20\uff0c\u4f60\u9700\u8981\u6307\u5b9a\u4e00\u4e2a gradient \u53c2\u6570\u6765\u5339\u914d\u5f20\u91cf\u7684\u5f62\u72b6\u3002 \u8bd1\u8005\u6ce8\uff1a\u5728\u5176\u4ed6\u7684\u6587\u7ae0\u4e2d\u4f60\u53ef\u80fd\u4f1a\u770b\u5230\u8bf4\u5c06Tensor\u5305\u88f9\u5230Variable\u4e2d\u63d0\u4f9b\u81ea\u52a8\u68af\u5ea6\u8ba1\u7b97\uff0cVariable \u8fd9\u4e2a\u57280.41\u7248\u4e2d\u5df2\u7ecf\u88ab\u6807\u6ce8\u4e3a\u8fc7\u671f\u4e86\uff0c\u73b0\u5728\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528Tensor\uff0c\u5b98\u65b9\u6587\u6863\u5728\u8fd9\u91cc\uff1a ( https://pytorch.org/docs/stable/autograd.html#variable-deprecated ) \u5177\u4f53\u7684\u540e\u9762\u4f1a\u6709\u8be6\u7ec6\u8bf4\u660e import torch \u521b\u5efa\u4e00\u4e2a\u5f20\u91cf\u5e76\u8bbe\u7f6e requires_grad=True \u7528\u6765\u8ffd\u8e2a\u4ed6\u7684\u8ba1\u7b97\u5386\u53f2 x = torch . ones ( 2 , 2 , requires_grad = True ) print ( x ) tensor([[1., 1.], [1., 1.]], requires_grad=True) \u5bf9\u5f20\u91cf\u8fdb\u884c\u64cd\u4f5c: y = x + 2 print ( y ) tensor([[3., 3.], [3., 3.]], grad_fn=<AddBackward>) \u7ed3\u679c y \u5df2\u7ecf\u88ab\u8ba1\u7b97\u51fa\u6765\u4e86\uff0c\u6240\u4ee5\uff0c grad_fn \u5df2\u7ecf\u88ab\u81ea\u52a8\u751f\u6210\u4e86\u3002 print ( y . grad_fn ) <AddBackward object at 0x00000232535FD860> \u5bf9y\u8fdb\u884c\u4e00\u4e2a\u64cd\u4f5c z = y * y * 3 out = z . mean () print ( z , out ) tensor([[27., 27.], [27., 27.]], grad_fn=<MulBackward>) tensor(27., grad_fn=<MeanBackward1>) .requires_grad_( ... ) \u53ef\u4ee5\u6539\u53d8\u73b0\u6709\u5f20\u91cf\u7684 requires_grad \u5c5e\u6027\u3002 \u5982\u679c\u6ca1\u6709\u6307\u5b9a\u7684\u8bdd\uff0c\u9ed8\u8ba4\u8f93\u5165\u7684flag\u662f False \u3002 a = torch . randn ( 2 , 2 ) a = (( a * 3 ) / ( a - 1 )) print ( a . requires_grad ) a . requires_grad_ ( True ) print ( a . requires_grad ) b = ( a * a ) . sum () print ( b . grad_fn ) False True <SumBackward0 object at 0x000002325360B438> \u68af\u5ea6 \u00b6 \u53cd\u5411\u4f20\u64ad \u56e0\u4e3a out \u662f\u4e00\u4e2a\u7eaf\u91cf\uff08scalar\uff09\uff0c out.backward() \u7b49\u4e8e out.backward(torch.tensor(1)) \u3002 out . backward () print gradients d(out)/dx print ( x . grad ) tensor([[4.5000, 4.5000], [4.5000, 4.5000]]) \u5f97\u5230\u77e9\u9635 4.5 .\u8c03\u7528 out Tensor \u201c o o \u201d. \u5f97\u5230 o = \\frac{1}{4}\\sum_i z_i o = \\frac{1}{4}\\sum_i z_i , z_i = 3(x_i+2)^2 z_i = 3(x_i+2)^2 and z_i\\bigr\\rvert_{x_i=1} = 27 z_i\\bigr\\rvert_{x_i=1} = 27 . \u56e0\u6b64, \\frac{\\partial o}{\\partial x_i} = \\frac{3}{2}(x_i+2) \\frac{\\partial o}{\\partial x_i} = \\frac{3}{2}(x_i+2) , hence \\frac{\\partial o}{\\partial x_i}\\bigr\\rvert_{x_i=1} = \\frac{9}{2} = 4.5 \\frac{\\partial o}{\\partial x_i}\\bigr\\rvert_{x_i=1} = \\frac{9}{2} = 4.5 . \u53ef\u4ee5\u4f7f\u7528 autograd \u505a\u66f4\u591a\u7684\u64cd\u4f5c x = torch . randn ( 3 , requires_grad = True ) y = x * 2 while y . data . norm () < 1000 : y = y * 2 print ( y ) tensor([-920.6895, -115.7301, -867.6995], grad_fn=<MulBackward>) gradients = torch . tensor ([ 0.1 , 1.0 , 0.0001 ], dtype = torch . float ) y . backward ( gradients ) print ( x . grad ) tensor([ 51.2000, 512.0000, 0.0512]) \u5982\u679c .requires_grad=True \u4f46\u662f\u4f60\u53c8\u4e0d\u5e0c\u671b\u8fdb\u884cautograd\u7684\u8ba1\u7b97\uff0c \u90a3\u4e48\u53ef\u4ee5\u5c06\u53d8\u91cf\u5305\u88f9\u5728 with torch.no_grad() \u4e2d: print ( x . requires_grad ) print (( x ** 2 ) . requires_grad ) with torch . no_grad (): print (( x ** 2 ) . requires_grad ) True True False \u7a0d\u540e\u9605\u8bfb: autograd \u548c Function \u7684\u5b98\u65b9\u6587\u6863 https://pytorch.org/docs/autograd","title":"1.3.2 Autograd"},{"location":"tutorial/chapter01_getting-started/1_3_2_autograd_tutorial/#autograd","text":"PyTorch \u4e2d\u6240\u6709\u795e\u7ecf\u7f51\u7edc\u7684\u6838\u5fc3\u662f autograd \u5305\u3002 \u6211\u4eec\u5148\u7b80\u5355\u4ecb\u7ecd\u4e00\u4e0b\u8fd9\u4e2a\u5305\uff0c\u7136\u540e\u8bad\u7ec3\u7b2c\u4e00\u4e2a\u7b80\u5355\u7684\u795e\u7ecf\u7f51\u7edc\u3002 autograd \u5305\u4e3a\u5f20\u91cf\u4e0a\u7684\u6240\u6709\u64cd\u4f5c\u63d0\u4f9b\u4e86\u81ea\u52a8\u6c42\u5bfc\u3002 \u5b83\u662f\u4e00\u4e2a\u5728\u8fd0\u884c\u65f6\u5b9a\u4e49\u7684\u6846\u67b6\uff0c\u8fd9\u610f\u5473\u7740\u53cd\u5411\u4f20\u64ad\u662f\u6839\u636e\u4f60\u7684\u4ee3\u7801\u6765\u786e\u5b9a\u5982\u4f55\u8fd0\u884c\uff0c\u5e76\u4e14\u6bcf\u6b21\u8fed\u4ee3\u53ef\u4ee5\u662f\u4e0d\u540c\u7684\u3002 \u793a\u4f8b","title":"Autograd: \u81ea\u52a8\u6c42\u5bfc\u673a\u5236"},{"location":"tutorial/chapter01_getting-started/1_3_2_autograd_tutorial/#tensor","text":"torch.Tensor \u662f\u8fd9\u4e2a\u5305\u7684\u6838\u5fc3\u7c7b\u3002\u5982\u679c\u8bbe\u7f6e .requires_grad \u4e3a True \uff0c\u90a3\u4e48\u5c06\u4f1a\u8ffd\u8e2a\u6240\u6709\u5bf9\u4e8e\u8be5\u5f20\u91cf\u7684\u64cd\u4f5c\u3002 \u5f53\u5b8c\u6210\u8ba1\u7b97\u540e\u901a\u8fc7\u8c03\u7528 .backward() \uff0c\u81ea\u52a8\u8ba1\u7b97\u6240\u6709\u7684\u68af\u5ea6\uff0c \u8fd9\u4e2a\u5f20\u91cf\u7684\u6240\u6709\u68af\u5ea6\u5c06\u4f1a\u81ea\u52a8\u79ef\u7d2f\u5230 .grad \u5c5e\u6027\u3002 \u8981\u963b\u6b62\u5f20\u91cf\u8ddf\u8e2a\u5386\u53f2\u8bb0\u5f55\uff0c\u53ef\u4ee5\u8c03\u7528 .detach() \u65b9\u6cd5\u5c06\u5176\u4e0e\u8ba1\u7b97\u5386\u53f2\u8bb0\u5f55\u5206\u79bb\uff0c\u5e76\u7981\u6b62\u8ddf\u8e2a\u5b83\u5c06\u6765\u7684\u8ba1\u7b97\u8bb0\u5f55\u3002 \u4e3a\u4e86\u9632\u6b62\u8ddf\u8e2a\u5386\u53f2\u8bb0\u5f55\uff08\u548c\u4f7f\u7528\u5185\u5b58\uff09\uff0c\u53ef\u4ee5\u5c06\u4ee3\u7801\u5757\u5305\u88c5\u5728 with torch.no_grad()\uff1a \u4e2d\u3002 \u5728\u8bc4\u4f30\u6a21\u578b\u65f6\u7279\u522b\u6709\u7528\uff0c\u56e0\u4e3a\u6a21\u578b\u53ef\u80fd\u5177\u6709 requires_grad = True \u7684\u53ef\u8bad\u7ec3\u53c2\u6570\uff0c\u4f46\u662f\u6211\u4eec\u4e0d\u9700\u8981\u68af\u5ea6\u8ba1\u7b97\u3002 \u5728\u81ea\u52a8\u68af\u5ea6\u8ba1\u7b97\u4e2d\u8fd8\u6709\u53e6\u5916\u4e00\u4e2a\u91cd\u8981\u7684\u7c7b Function . Tensor and Function are interconnected and build up an acyclic graph, that encodes a complete history of computation. Each tensor has a .grad_fn attribute that references a Function that has created the Tensor (except for Tensors created by the user - their grad_fn is None ). Tensor \u548c Function \u4e92\u76f8\u8fde\u63a5\u5e76\u751f\u6210\u4e00\u4e2a\u975e\u5faa\u73af\u56fe\uff0c\u5b83\u8868\u793a\u548c\u5b58\u50a8\u4e86\u5b8c\u6574\u7684\u8ba1\u7b97\u5386\u53f2\u3002 \u6bcf\u4e2a\u5f20\u91cf\u90fd\u6709\u4e00\u4e2a .grad_fn \u5c5e\u6027\uff0c\u8fd9\u4e2a\u5c5e\u6027\u5f15\u7528\u4e86\u4e00\u4e2a\u521b\u5efa\u4e86 Tensor \u7684 Function \uff08\u9664\u975e\u8fd9\u4e2a\u5f20\u91cf\u662f\u7528\u6237\u624b\u52a8\u521b\u5efa\u7684\uff0c\u5373\uff0c\u8fd9\u4e2a\u5f20\u91cf\u7684 grad_fn \u662f None \uff09\u3002 \u5982\u679c\u9700\u8981\u8ba1\u7b97\u5bfc\u6570\uff0c\u4f60\u53ef\u4ee5\u5728 Tensor \u4e0a\u8c03\u7528 .backward() \u3002 \u5982\u679c Tensor \u662f\u4e00\u4e2a\u6807\u91cf\uff08\u5373\u5b83\u5305\u542b\u4e00\u4e2a\u5143\u7d20\u6570\u636e\uff09\u5219\u4e0d\u9700\u8981\u4e3a backward() \u6307\u5b9a\u4efb\u4f55\u53c2\u6570\uff0c \u4f46\u662f\u5982\u679c\u5b83\u6709\u66f4\u591a\u7684\u5143\u7d20\uff0c\u4f60\u9700\u8981\u6307\u5b9a\u4e00\u4e2a gradient \u53c2\u6570\u6765\u5339\u914d\u5f20\u91cf\u7684\u5f62\u72b6\u3002 \u8bd1\u8005\u6ce8\uff1a\u5728\u5176\u4ed6\u7684\u6587\u7ae0\u4e2d\u4f60\u53ef\u80fd\u4f1a\u770b\u5230\u8bf4\u5c06Tensor\u5305\u88f9\u5230Variable\u4e2d\u63d0\u4f9b\u81ea\u52a8\u68af\u5ea6\u8ba1\u7b97\uff0cVariable \u8fd9\u4e2a\u57280.41\u7248\u4e2d\u5df2\u7ecf\u88ab\u6807\u6ce8\u4e3a\u8fc7\u671f\u4e86\uff0c\u73b0\u5728\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528Tensor\uff0c\u5b98\u65b9\u6587\u6863\u5728\u8fd9\u91cc\uff1a ( https://pytorch.org/docs/stable/autograd.html#variable-deprecated ) \u5177\u4f53\u7684\u540e\u9762\u4f1a\u6709\u8be6\u7ec6\u8bf4\u660e import torch \u521b\u5efa\u4e00\u4e2a\u5f20\u91cf\u5e76\u8bbe\u7f6e requires_grad=True \u7528\u6765\u8ffd\u8e2a\u4ed6\u7684\u8ba1\u7b97\u5386\u53f2 x = torch . ones ( 2 , 2 , requires_grad = True ) print ( x ) tensor([[1., 1.], [1., 1.]], requires_grad=True) \u5bf9\u5f20\u91cf\u8fdb\u884c\u64cd\u4f5c: y = x + 2 print ( y ) tensor([[3., 3.], [3., 3.]], grad_fn=<AddBackward>) \u7ed3\u679c y \u5df2\u7ecf\u88ab\u8ba1\u7b97\u51fa\u6765\u4e86\uff0c\u6240\u4ee5\uff0c grad_fn \u5df2\u7ecf\u88ab\u81ea\u52a8\u751f\u6210\u4e86\u3002 print ( y . grad_fn ) <AddBackward object at 0x00000232535FD860> \u5bf9y\u8fdb\u884c\u4e00\u4e2a\u64cd\u4f5c z = y * y * 3 out = z . mean () print ( z , out ) tensor([[27., 27.], [27., 27.]], grad_fn=<MulBackward>) tensor(27., grad_fn=<MeanBackward1>) .requires_grad_( ... ) \u53ef\u4ee5\u6539\u53d8\u73b0\u6709\u5f20\u91cf\u7684 requires_grad \u5c5e\u6027\u3002 \u5982\u679c\u6ca1\u6709\u6307\u5b9a\u7684\u8bdd\uff0c\u9ed8\u8ba4\u8f93\u5165\u7684flag\u662f False \u3002 a = torch . randn ( 2 , 2 ) a = (( a * 3 ) / ( a - 1 )) print ( a . requires_grad ) a . requires_grad_ ( True ) print ( a . requires_grad ) b = ( a * a ) . sum () print ( b . grad_fn ) False True <SumBackward0 object at 0x000002325360B438>","title":"\u5f20\u91cf\uff08Tensor\uff09"},{"location":"tutorial/chapter01_getting-started/1_3_2_autograd_tutorial/#_1","text":"\u53cd\u5411\u4f20\u64ad \u56e0\u4e3a out \u662f\u4e00\u4e2a\u7eaf\u91cf\uff08scalar\uff09\uff0c out.backward() \u7b49\u4e8e out.backward(torch.tensor(1)) \u3002 out . backward () print gradients d(out)/dx print ( x . grad ) tensor([[4.5000, 4.5000], [4.5000, 4.5000]]) \u5f97\u5230\u77e9\u9635 4.5 .\u8c03\u7528 out Tensor \u201c o o \u201d. \u5f97\u5230 o = \\frac{1}{4}\\sum_i z_i o = \\frac{1}{4}\\sum_i z_i , z_i = 3(x_i+2)^2 z_i = 3(x_i+2)^2 and z_i\\bigr\\rvert_{x_i=1} = 27 z_i\\bigr\\rvert_{x_i=1} = 27 . \u56e0\u6b64, \\frac{\\partial o}{\\partial x_i} = \\frac{3}{2}(x_i+2) \\frac{\\partial o}{\\partial x_i} = \\frac{3}{2}(x_i+2) , hence \\frac{\\partial o}{\\partial x_i}\\bigr\\rvert_{x_i=1} = \\frac{9}{2} = 4.5 \\frac{\\partial o}{\\partial x_i}\\bigr\\rvert_{x_i=1} = \\frac{9}{2} = 4.5 . \u53ef\u4ee5\u4f7f\u7528 autograd \u505a\u66f4\u591a\u7684\u64cd\u4f5c x = torch . randn ( 3 , requires_grad = True ) y = x * 2 while y . data . norm () < 1000 : y = y * 2 print ( y ) tensor([-920.6895, -115.7301, -867.6995], grad_fn=<MulBackward>) gradients = torch . tensor ([ 0.1 , 1.0 , 0.0001 ], dtype = torch . float ) y . backward ( gradients ) print ( x . grad ) tensor([ 51.2000, 512.0000, 0.0512]) \u5982\u679c .requires_grad=True \u4f46\u662f\u4f60\u53c8\u4e0d\u5e0c\u671b\u8fdb\u884cautograd\u7684\u8ba1\u7b97\uff0c \u90a3\u4e48\u53ef\u4ee5\u5c06\u53d8\u91cf\u5305\u88f9\u5728 with torch.no_grad() \u4e2d: print ( x . requires_grad ) print (( x ** 2 ) . requires_grad ) with torch . no_grad (): print (( x ** 2 ) . requires_grad ) True True False \u7a0d\u540e\u9605\u8bfb: autograd \u548c Function \u7684\u5b98\u65b9\u6587\u6863 https://pytorch.org/docs/autograd","title":"\u68af\u5ea6"},{"location":"tutorial/chapter01_getting-started/1_3_3_neural_networks_tutorial/","text":"% matplotlib inline Neural Networks \u00b6 \u4f7f\u7528torch.nn\u5305\u6765\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\u3002 \u4e0a\u4e00\u8bb2\u5df2\u7ecf\u8bb2\u8fc7\u4e86 autograd \uff0c nn \u5305\u4f9d\u8d56 autograd \u5305\u6765\u5b9a\u4e49\u6a21\u578b\u5e76\u6c42\u5bfc\u3002 \u4e00\u4e2a nn.Module \u5305\u542b\u5404\u4e2a\u5c42\u548c\u4e00\u4e2a forward(input) \u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u8fd4\u56de output \u3002 \u4f8b\u5982\uff1a \u5b83\u662f\u4e00\u4e2a\u7b80\u5355\u7684\u524d\u9988\u795e\u7ecf\u7f51\u7edc\uff0c\u5b83\u63a5\u53d7\u4e00\u4e2a\u8f93\u5165\uff0c\u7136\u540e\u4e00\u5c42\u63a5\u7740\u4e00\u5c42\u5730\u4f20\u9012\uff0c\u6700\u540e\u8f93\u51fa\u8ba1\u7b97\u7684\u7ed3\u679c\u3002 \u795e\u7ecf\u7f51\u7edc\u7684\u5178\u578b\u8bad\u7ec3\u8fc7\u7a0b\u5982\u4e0b\uff1a \u5b9a\u4e49\u5305\u542b\u4e00\u4e9b\u53ef\u5b66\u4e60\u7684\u53c2\u6570(\u6216\u8005\u53eb\u6743\u91cd)\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff1b \u5728\u6570\u636e\u96c6\u4e0a\u8fed\u4ee3\uff1b \u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u5904\u7406\u8f93\u5165\uff1b \u8ba1\u7b97\u635f\u5931(\u8f93\u51fa\u7ed3\u679c\u548c\u6b63\u786e\u503c\u7684\u5dee\u503c\u5927\u5c0f)\uff1b \u5c06\u68af\u5ea6\u53cd\u5411\u4f20\u64ad\u56de\u7f51\u7edc\u7684\u53c2\u6570\uff1b \u66f4\u65b0\u7f51\u7edc\u7684\u53c2\u6570\uff0c\u4e3b\u8981\u4f7f\u7528\u5982\u4e0b\u7b80\u5355\u7684\u66f4\u65b0\u539f\u5219\uff1a weight = weight - learning_rate * gradient \u5b9a\u4e49\u7f51\u7edc \u00b6 \u5f00\u59cb\u5b9a\u4e49\u4e00\u4e2a\u7f51\u7edc\uff1a import torch import torch.nn as nn import torch.nn.functional as F class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () # 1 input image channel, 6 output channels, 5x5 square convolution # kernel self . conv1 = nn . Conv2d ( 1 , 6 , 5 ) self . conv2 = nn . Conv2d ( 6 , 16 , 5 ) # an affine operation: y = Wx + b self . fc1 = nn . Linear ( 16 * 5 * 5 , 120 ) self . fc2 = nn . Linear ( 120 , 84 ) self . fc3 = nn . Linear ( 84 , 10 ) def forward ( self , x ): # Max pooling over a (2, 2) window x = F . max_pool2d ( F . relu ( self . conv1 ( x )), ( 2 , 2 )) # If the size is a square you can only specify a single number x = F . max_pool2d ( F . relu ( self . conv2 ( x )), 2 ) x = x . view ( - 1 , self . num_flat_features ( x )) x = F . relu ( self . fc1 ( x )) x = F . relu ( self . fc2 ( x )) x = self . fc3 ( x ) return x def num_flat_features ( self , x ): size = x . size ()[ 1 :] # all dimensions except the batch dimension num_features = 1 for s in size : num_features *= s return num_features net = Net () print ( net ) Net( (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1)) (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)) (fc1): Linear(in_features=400, out_features=120, bias=True) (fc2): Linear(in_features=120, out_features=84, bias=True) (fc3): Linear(in_features=84, out_features=10, bias=True) ) \u5728\u6a21\u578b\u4e2d\u5fc5\u987b\u8981\u5b9a\u4e49 forward \u51fd\u6570\uff0c backward \u51fd\u6570\uff08\u7528\u6765\u8ba1\u7b97\u68af\u5ea6\uff09\u4f1a\u88ab autograd \u81ea\u52a8\u521b\u5efa\u3002 \u53ef\u4ee5\u5728 forward \u51fd\u6570\u4e2d\u4f7f\u7528\u4efb\u4f55\u9488\u5bf9 Tensor \u7684\u64cd\u4f5c\u3002 net.parameters() \u8fd4\u56de\u53ef\u88ab\u5b66\u4e60\u7684\u53c2\u6570\uff08\u6743\u91cd\uff09\u5217\u8868\u548c\u503c params = list ( net . parameters ()) print ( len ( params )) print ( params [ 0 ] . size ()) # conv1's .weight 10 torch.Size([6, 1, 5, 5]) \u6d4b\u8bd5\u968f\u673a\u8f93\u516532\u00d732\u3002 \u6ce8\uff1a\u8fd9\u4e2a\u7f51\u7edc\uff08LeNet\uff09\u671f\u671b\u7684\u8f93\u5165\u5927\u5c0f\u662f32\u00d732\uff0c\u5982\u679c\u4f7f\u7528MNIST\u6570\u636e\u96c6\u6765\u8bad\u7ec3\u8fd9\u4e2a\u7f51\u7edc\uff0c\u8bf7\u628a\u56fe\u7247\u5927\u5c0f\u91cd\u65b0\u8c03\u6574\u523032\u00d732\u3002 input = torch . randn ( 1 , 1 , 32 , 32 ) out = net ( input ) print ( out ) tensor([[-0.0204, -0.0268, -0.0829, 0.1420, -0.0192, 0.1848, 0.0723, -0.0393, -0.0275, 0.0867]], grad_fn=<ThAddmmBackward>) \u5c06\u6240\u6709\u53c2\u6570\u7684\u68af\u5ea6\u7f13\u5b58\u6e05\u96f6\uff0c\u7136\u540e\u8fdb\u884c\u968f\u673a\u68af\u5ea6\u7684\u7684\u53cd\u5411\u4f20\u64ad\uff1a net . zero_grad () out . backward ( torch . randn ( 1 , 10 )) Note ``torch.nn`` \u53ea\u652f\u6301\u5c0f\u6279\u91cf\u8f93\u5165\u3002\u6574\u4e2a ``torch.nn`` \u5305\u90fd\u53ea\u652f\u6301\u5c0f\u6279\u91cf\u6837\u672c\uff0c\u800c\u4e0d\u652f\u6301\u5355\u4e2a\u6837\u672c\u3002 \u4f8b\u5982\uff0c``nn.Conv2d`` \u63a5\u53d7\u4e00\u4e2a4\u7ef4\u7684\u5f20\u91cf\uff0c ``\u6bcf\u4e00\u7ef4\u5206\u522b\u662fsSamples * nChannels * Height * Width\uff08\u6837\u672c\u6570*\u901a\u9053\u6570*\u9ad8*\u5bbd\uff09``\u3002 \u5982\u679c\u4f60\u6709\u5355\u4e2a\u6837\u672c\uff0c\u53ea\u9700\u4f7f\u7528 ``input.unsqueeze(0)`` \u6765\u6dfb\u52a0\u5176\u5b83\u7684\u7ef4\u6570 \u5728\u7ee7\u7eed\u4e4b\u524d\uff0c\u6211\u4eec\u56de\u987e\u4e00\u4e0b\u5230\u76ee\u524d\u4e3a\u6b62\u7528\u5230\u7684\u7c7b\u3002 \u56de\u987e: - torch.Tensor \uff1a\u4e00\u4e2a\u7528\u8fc7\u81ea\u52a8\u8c03\u7528 backward() \u5b9e\u73b0\u652f\u6301\u81ea\u52a8\u68af\u5ea6\u8ba1\u7b97\u7684 \u591a\u7ef4\u6570\u7ec4 \uff0c \u5e76\u4e14\u4fdd\u5b58\u5173\u4e8e\u8fd9\u4e2a\u5411\u91cf\u7684*\u68af\u5ea6* w.r.t. - nn.Module \uff1a\u795e\u7ecf\u7f51\u7edc\u6a21\u5757\u3002\u5c01\u88c5\u53c2\u6570\u3001\u79fb\u52a8\u5230GPU\u4e0a\u8fd0\u884c\u3001\u5bfc\u51fa\u3001\u52a0\u8f7d\u7b49\u3002 - nn.Parameter \uff1a\u4e00\u79cd\u53d8\u91cf\uff0c\u5f53\u628a\u5b83\u8d4b\u503c\u7ed9\u4e00\u4e2a Module \u65f6\uff0c\u88ab \u81ea\u52a8 \u5730\u6ce8\u518c\u4e3a\u4e00\u4e2a\u53c2\u6570\u3002 - autograd.Function \uff1a\u5b9e\u73b0\u4e00\u4e2a\u81ea\u52a8\u6c42\u5bfc\u64cd\u4f5c\u7684\u524d\u5411\u548c\u53cd\u5411\u5b9a\u4e49\uff0c\u6bcf\u4e2a\u53d8\u91cf\u64cd\u4f5c\u81f3\u5c11\u521b\u5efa\u4e00\u4e2a\u51fd\u6570\u8282\u70b9\uff0c\u6bcf\u4e00\u4e2a Tensor \u7684\u64cd\u4f5c\u90fd\u56de\u521b\u5efa\u4e00\u4e2a\u63a5\u5230\u521b\u5efa Tensor \u548c \u7f16\u7801\u5176\u5386\u53f2 \u7684\u51fd\u6570\u7684 Function \u8282\u70b9\u3002 \u91cd\u70b9\u5982\u4e0b\uff1a - \u5b9a\u4e49\u4e00\u4e2a\u7f51\u7edc - \u5904\u7406\u8f93\u5165\uff0c\u8c03\u7528backword \u8fd8\u5269\uff1a - \u8ba1\u7b97\u635f\u5931 - \u66f4\u65b0\u7f51\u7edc\u6743\u91cd \u635f\u5931\u51fd\u6570 \u00b6 \u4e00\u4e2a\u635f\u5931\u51fd\u6570\u63a5\u53d7\u4e00\u5bf9 (output, target) \u4f5c\u4e3a\u8f93\u5165\uff0c\u8ba1\u7b97\u4e00\u4e2a\u503c\u6765\u4f30\u8ba1\u7f51\u7edc\u7684\u8f93\u51fa\u548c\u76ee\u6807\u503c\u76f8\u5dee\u591a\u5c11\u3002 \u8bd1\u8005\u6ce8\uff1aoutput\u4e3a\u7f51\u7edc\u7684\u8f93\u51fa\uff0ctarget\u4e3a\u5b9e\u9645\u503c nn\u5305\u4e2d\u6709\u5f88\u591a\u4e0d\u540c\u7684 \u635f\u5931\u51fd\u6570 \u3002 nn.MSELoss \u662f\u4e00\u4e2a\u6bd4\u8f83\u7b80\u5355\u7684\u635f\u5931\u51fd\u6570\uff0c\u5b83\u8ba1\u7b97\u8f93\u51fa\u548c\u76ee\u6807\u95f4\u7684**\u5747\u65b9\u8bef\u5dee**\uff0c \u4f8b\u5982\uff1a output = net ( input ) target = torch . randn ( 10 ) # \u968f\u673a\u503c\u4f5c\u4e3a\u6837\u4f8b target = target . view ( 1 , - 1 ) # \u4f7ftarget\u548coutput\u7684shape\u76f8\u540c criterion = nn . MSELoss () loss = criterion ( output , target ) print ( loss ) tensor(1.3172, grad_fn=<MseLossBackward>) Now, if you follow loss in the backward direction, using its .grad_fn attribute, you will see a graph of computations that looks like this: :: input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d -> view -> linear -> relu -> linear -> relu -> linear -> MSELoss -> loss So, when we call loss.backward() , the whole graph is differentiated w.r.t. the loss, and all Tensors in the graph that has requires_grad=True will have their .grad Tensor accumulated with the gradient. For illustration, let us follow a few steps backward: print ( loss . grad_fn ) # MSELoss print ( loss . grad_fn . next_functions [ 0 ][ 0 ]) # Linear print ( loss . grad_fn . next_functions [ 0 ][ 0 ] . next_functions [ 0 ][ 0 ]) # ReLU \u53cd\u5411\u4f20\u64ad \u00b6 \u8c03\u7528loss.backward()\u83b7\u5f97\u53cd\u5411\u4f20\u64ad\u7684\u8bef\u5dee\u3002 \u4f46\u662f\u5728\u8c03\u7528\u524d\u9700\u8981\u6e05\u9664\u5df2\u5b58\u5728\u7684\u68af\u5ea6\uff0c\u5426\u5219\u68af\u5ea6\u5c06\u88ab\u7d2f\u52a0\u5230\u5df2\u5b58\u5728\u7684\u68af\u5ea6\u3002 \u73b0\u5728\uff0c\u6211\u4eec\u5c06\u8c03\u7528loss.backward()\uff0c\u5e76\u67e5\u770bconv1\u5c42\u7684\u504f\u5dee\uff08bias\uff09\u9879\u5728\u53cd\u5411\u4f20\u64ad\u524d\u540e\u7684\u68af\u5ea6\u3002 net . zero_grad () # \u6e05\u9664\u68af\u5ea6 print ( 'conv1.bias.grad before backward' ) print ( net . conv1 . bias . grad ) loss . backward () print ( 'conv1.bias.grad after backward' ) print ( net . conv1 . bias . grad ) conv1.bias.grad before backward tensor([0., 0., 0., 0., 0., 0.]) conv1.bias.grad after backward tensor([ 0.0074, -0.0249, -0.0107, 0.0326, -0.0017, -0.0059]) \u5982\u4f55\u4f7f\u7528\u635f\u5931\u51fd\u6570 \u7a0d\u540e\u9605\u8bfb\uff1a nn \u5305\uff0c\u5305\u542b\u4e86\u5404\u79cd\u7528\u6765\u6784\u6210\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6784\u5efa\u5757\u7684\u6a21\u5757\u548c\u635f\u5931\u51fd\u6570\uff0c\u5b8c\u6574\u7684\u6587\u6863\u8bf7\u67e5\u770b here \u3002 \u5269\u4e0b\u7684\u6700\u540e\u4e00\u4ef6\u4e8b: \u65b0\u7f51\u7edc\u7684\u6743\u91cd \u66f4\u65b0\u6743\u91cd \u00b6 \u5728\u5b9e\u8df5\u4e2d\u6700\u7b80\u5355\u7684\u6743\u91cd\u66f4\u65b0\u89c4\u5219\u662f\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff08SGD\uff09\uff1a ``weight = weight - learning_rate * gradient`` \u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u7b80\u5355\u7684Python\u4ee3\u7801\u5b9e\u73b0\u8fd9\u4e2a\u89c4\u5219\uff1a learning_rate = 0.01 for f in net . parameters (): f . data . sub_ ( f . grad . data * learning_rate ) \u4f46\u662f\u5f53\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u662f\u60f3\u8981\u4f7f\u7528\u5404\u79cd\u4e0d\u540c\u7684\u66f4\u65b0\u89c4\u5219\u65f6\uff0c\u6bd4\u5982SGD\u3001Nesterov-SGD\u3001Adam\u3001RMSPROP\u7b49\uff0cPyTorch\u4e2d\u6784\u5efa\u4e86\u4e00\u4e2a\u5305 torch.optim \u5b9e\u73b0\u4e86\u6240\u6709\u7684\u8fd9\u4e9b\u89c4\u5219\u3002 \u4f7f\u7528\u5b83\u4eec\u975e\u5e38\u7b80\u5355\uff1a import torch.optim as optim # create your optimizer optimizer = optim . SGD ( net . parameters (), lr = 0.01 ) # in your training loop: optimizer . zero_grad () # zero the gradient buffers output = net ( input ) loss = criterion ( output , target ) loss . backward () optimizer . step () # Does the update .. Note:: Observe how gradient buffers had to be manually set to zero using ``optimizer.zero_grad()``. This is because gradients are accumulated as explained in `Backprop`_ section.","title":"1.3.3 Neural Networks"},{"location":"tutorial/chapter01_getting-started/1_3_3_neural_networks_tutorial/#neural-networks","text":"\u4f7f\u7528torch.nn\u5305\u6765\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\u3002 \u4e0a\u4e00\u8bb2\u5df2\u7ecf\u8bb2\u8fc7\u4e86 autograd \uff0c nn \u5305\u4f9d\u8d56 autograd \u5305\u6765\u5b9a\u4e49\u6a21\u578b\u5e76\u6c42\u5bfc\u3002 \u4e00\u4e2a nn.Module \u5305\u542b\u5404\u4e2a\u5c42\u548c\u4e00\u4e2a forward(input) \u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u8fd4\u56de output \u3002 \u4f8b\u5982\uff1a \u5b83\u662f\u4e00\u4e2a\u7b80\u5355\u7684\u524d\u9988\u795e\u7ecf\u7f51\u7edc\uff0c\u5b83\u63a5\u53d7\u4e00\u4e2a\u8f93\u5165\uff0c\u7136\u540e\u4e00\u5c42\u63a5\u7740\u4e00\u5c42\u5730\u4f20\u9012\uff0c\u6700\u540e\u8f93\u51fa\u8ba1\u7b97\u7684\u7ed3\u679c\u3002 \u795e\u7ecf\u7f51\u7edc\u7684\u5178\u578b\u8bad\u7ec3\u8fc7\u7a0b\u5982\u4e0b\uff1a \u5b9a\u4e49\u5305\u542b\u4e00\u4e9b\u53ef\u5b66\u4e60\u7684\u53c2\u6570(\u6216\u8005\u53eb\u6743\u91cd)\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff1b \u5728\u6570\u636e\u96c6\u4e0a\u8fed\u4ee3\uff1b \u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u5904\u7406\u8f93\u5165\uff1b \u8ba1\u7b97\u635f\u5931(\u8f93\u51fa\u7ed3\u679c\u548c\u6b63\u786e\u503c\u7684\u5dee\u503c\u5927\u5c0f)\uff1b \u5c06\u68af\u5ea6\u53cd\u5411\u4f20\u64ad\u56de\u7f51\u7edc\u7684\u53c2\u6570\uff1b \u66f4\u65b0\u7f51\u7edc\u7684\u53c2\u6570\uff0c\u4e3b\u8981\u4f7f\u7528\u5982\u4e0b\u7b80\u5355\u7684\u66f4\u65b0\u539f\u5219\uff1a weight = weight - learning_rate * gradient","title":"Neural Networks"},{"location":"tutorial/chapter01_getting-started/1_3_3_neural_networks_tutorial/#_1","text":"\u5f00\u59cb\u5b9a\u4e49\u4e00\u4e2a\u7f51\u7edc\uff1a import torch import torch.nn as nn import torch.nn.functional as F class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () # 1 input image channel, 6 output channels, 5x5 square convolution # kernel self . conv1 = nn . Conv2d ( 1 , 6 , 5 ) self . conv2 = nn . Conv2d ( 6 , 16 , 5 ) # an affine operation: y = Wx + b self . fc1 = nn . Linear ( 16 * 5 * 5 , 120 ) self . fc2 = nn . Linear ( 120 , 84 ) self . fc3 = nn . Linear ( 84 , 10 ) def forward ( self , x ): # Max pooling over a (2, 2) window x = F . max_pool2d ( F . relu ( self . conv1 ( x )), ( 2 , 2 )) # If the size is a square you can only specify a single number x = F . max_pool2d ( F . relu ( self . conv2 ( x )), 2 ) x = x . view ( - 1 , self . num_flat_features ( x )) x = F . relu ( self . fc1 ( x )) x = F . relu ( self . fc2 ( x )) x = self . fc3 ( x ) return x def num_flat_features ( self , x ): size = x . size ()[ 1 :] # all dimensions except the batch dimension num_features = 1 for s in size : num_features *= s return num_features net = Net () print ( net ) Net( (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1)) (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)) (fc1): Linear(in_features=400, out_features=120, bias=True) (fc2): Linear(in_features=120, out_features=84, bias=True) (fc3): Linear(in_features=84, out_features=10, bias=True) ) \u5728\u6a21\u578b\u4e2d\u5fc5\u987b\u8981\u5b9a\u4e49 forward \u51fd\u6570\uff0c backward \u51fd\u6570\uff08\u7528\u6765\u8ba1\u7b97\u68af\u5ea6\uff09\u4f1a\u88ab autograd \u81ea\u52a8\u521b\u5efa\u3002 \u53ef\u4ee5\u5728 forward \u51fd\u6570\u4e2d\u4f7f\u7528\u4efb\u4f55\u9488\u5bf9 Tensor \u7684\u64cd\u4f5c\u3002 net.parameters() \u8fd4\u56de\u53ef\u88ab\u5b66\u4e60\u7684\u53c2\u6570\uff08\u6743\u91cd\uff09\u5217\u8868\u548c\u503c params = list ( net . parameters ()) print ( len ( params )) print ( params [ 0 ] . size ()) # conv1's .weight 10 torch.Size([6, 1, 5, 5]) \u6d4b\u8bd5\u968f\u673a\u8f93\u516532\u00d732\u3002 \u6ce8\uff1a\u8fd9\u4e2a\u7f51\u7edc\uff08LeNet\uff09\u671f\u671b\u7684\u8f93\u5165\u5927\u5c0f\u662f32\u00d732\uff0c\u5982\u679c\u4f7f\u7528MNIST\u6570\u636e\u96c6\u6765\u8bad\u7ec3\u8fd9\u4e2a\u7f51\u7edc\uff0c\u8bf7\u628a\u56fe\u7247\u5927\u5c0f\u91cd\u65b0\u8c03\u6574\u523032\u00d732\u3002 input = torch . randn ( 1 , 1 , 32 , 32 ) out = net ( input ) print ( out ) tensor([[-0.0204, -0.0268, -0.0829, 0.1420, -0.0192, 0.1848, 0.0723, -0.0393, -0.0275, 0.0867]], grad_fn=<ThAddmmBackward>) \u5c06\u6240\u6709\u53c2\u6570\u7684\u68af\u5ea6\u7f13\u5b58\u6e05\u96f6\uff0c\u7136\u540e\u8fdb\u884c\u968f\u673a\u68af\u5ea6\u7684\u7684\u53cd\u5411\u4f20\u64ad\uff1a net . zero_grad () out . backward ( torch . randn ( 1 , 10 ))","title":"\u5b9a\u4e49\u7f51\u7edc"},{"location":"tutorial/chapter01_getting-started/1_3_3_neural_networks_tutorial/#_2","text":"\u4e00\u4e2a\u635f\u5931\u51fd\u6570\u63a5\u53d7\u4e00\u5bf9 (output, target) \u4f5c\u4e3a\u8f93\u5165\uff0c\u8ba1\u7b97\u4e00\u4e2a\u503c\u6765\u4f30\u8ba1\u7f51\u7edc\u7684\u8f93\u51fa\u548c\u76ee\u6807\u503c\u76f8\u5dee\u591a\u5c11\u3002 \u8bd1\u8005\u6ce8\uff1aoutput\u4e3a\u7f51\u7edc\u7684\u8f93\u51fa\uff0ctarget\u4e3a\u5b9e\u9645\u503c nn\u5305\u4e2d\u6709\u5f88\u591a\u4e0d\u540c\u7684 \u635f\u5931\u51fd\u6570 \u3002 nn.MSELoss \u662f\u4e00\u4e2a\u6bd4\u8f83\u7b80\u5355\u7684\u635f\u5931\u51fd\u6570\uff0c\u5b83\u8ba1\u7b97\u8f93\u51fa\u548c\u76ee\u6807\u95f4\u7684**\u5747\u65b9\u8bef\u5dee**\uff0c \u4f8b\u5982\uff1a output = net ( input ) target = torch . randn ( 10 ) # \u968f\u673a\u503c\u4f5c\u4e3a\u6837\u4f8b target = target . view ( 1 , - 1 ) # \u4f7ftarget\u548coutput\u7684shape\u76f8\u540c criterion = nn . MSELoss () loss = criterion ( output , target ) print ( loss ) tensor(1.3172, grad_fn=<MseLossBackward>) Now, if you follow loss in the backward direction, using its .grad_fn attribute, you will see a graph of computations that looks like this: :: input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d -> view -> linear -> relu -> linear -> relu -> linear -> MSELoss -> loss So, when we call loss.backward() , the whole graph is differentiated w.r.t. the loss, and all Tensors in the graph that has requires_grad=True will have their .grad Tensor accumulated with the gradient. For illustration, let us follow a few steps backward: print ( loss . grad_fn ) # MSELoss print ( loss . grad_fn . next_functions [ 0 ][ 0 ]) # Linear print ( loss . grad_fn . next_functions [ 0 ][ 0 ] . next_functions [ 0 ][ 0 ]) # ReLU","title":"\u635f\u5931\u51fd\u6570"},{"location":"tutorial/chapter01_getting-started/1_3_3_neural_networks_tutorial/#_3","text":"\u8c03\u7528loss.backward()\u83b7\u5f97\u53cd\u5411\u4f20\u64ad\u7684\u8bef\u5dee\u3002 \u4f46\u662f\u5728\u8c03\u7528\u524d\u9700\u8981\u6e05\u9664\u5df2\u5b58\u5728\u7684\u68af\u5ea6\uff0c\u5426\u5219\u68af\u5ea6\u5c06\u88ab\u7d2f\u52a0\u5230\u5df2\u5b58\u5728\u7684\u68af\u5ea6\u3002 \u73b0\u5728\uff0c\u6211\u4eec\u5c06\u8c03\u7528loss.backward()\uff0c\u5e76\u67e5\u770bconv1\u5c42\u7684\u504f\u5dee\uff08bias\uff09\u9879\u5728\u53cd\u5411\u4f20\u64ad\u524d\u540e\u7684\u68af\u5ea6\u3002 net . zero_grad () # \u6e05\u9664\u68af\u5ea6 print ( 'conv1.bias.grad before backward' ) print ( net . conv1 . bias . grad ) loss . backward () print ( 'conv1.bias.grad after backward' ) print ( net . conv1 . bias . grad ) conv1.bias.grad before backward tensor([0., 0., 0., 0., 0., 0.]) conv1.bias.grad after backward tensor([ 0.0074, -0.0249, -0.0107, 0.0326, -0.0017, -0.0059]) \u5982\u4f55\u4f7f\u7528\u635f\u5931\u51fd\u6570 \u7a0d\u540e\u9605\u8bfb\uff1a nn \u5305\uff0c\u5305\u542b\u4e86\u5404\u79cd\u7528\u6765\u6784\u6210\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6784\u5efa\u5757\u7684\u6a21\u5757\u548c\u635f\u5931\u51fd\u6570\uff0c\u5b8c\u6574\u7684\u6587\u6863\u8bf7\u67e5\u770b here \u3002 \u5269\u4e0b\u7684\u6700\u540e\u4e00\u4ef6\u4e8b: \u65b0\u7f51\u7edc\u7684\u6743\u91cd","title":"\u53cd\u5411\u4f20\u64ad"},{"location":"tutorial/chapter01_getting-started/1_3_3_neural_networks_tutorial/#_4","text":"\u5728\u5b9e\u8df5\u4e2d\u6700\u7b80\u5355\u7684\u6743\u91cd\u66f4\u65b0\u89c4\u5219\u662f\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff08SGD\uff09\uff1a ``weight = weight - learning_rate * gradient`` \u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u7b80\u5355\u7684Python\u4ee3\u7801\u5b9e\u73b0\u8fd9\u4e2a\u89c4\u5219\uff1a learning_rate = 0.01 for f in net . parameters (): f . data . sub_ ( f . grad . data * learning_rate ) \u4f46\u662f\u5f53\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u662f\u60f3\u8981\u4f7f\u7528\u5404\u79cd\u4e0d\u540c\u7684\u66f4\u65b0\u89c4\u5219\u65f6\uff0c\u6bd4\u5982SGD\u3001Nesterov-SGD\u3001Adam\u3001RMSPROP\u7b49\uff0cPyTorch\u4e2d\u6784\u5efa\u4e86\u4e00\u4e2a\u5305 torch.optim \u5b9e\u73b0\u4e86\u6240\u6709\u7684\u8fd9\u4e9b\u89c4\u5219\u3002 \u4f7f\u7528\u5b83\u4eec\u975e\u5e38\u7b80\u5355\uff1a import torch.optim as optim # create your optimizer optimizer = optim . SGD ( net . parameters (), lr = 0.01 ) # in your training loop: optimizer . zero_grad () # zero the gradient buffers output = net ( input ) loss = criterion ( output , target ) loss . backward () optimizer . step () # Does the update .. Note:: Observe how gradient buffers had to be manually set to zero using ``optimizer.zero_grad()``. This is because gradients are accumulated as explained in `Backprop`_ section.","title":"\u66f4\u65b0\u6743\u91cd"},{"location":"tutorial/chapter01_getting-started/1_3_4_cifar10_tutorial/","text":"% matplotlib inline \u8bad\u7ec3\u4e00\u4e2a\u5206\u7c7b\u5668 \u00b6 \u4e0a\u4e00\u8bb2\u4e2d\u5df2\u7ecf\u770b\u5230\u5982\u4f55\u53bb\u5b9a\u4e49\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\uff0c\u8ba1\u7b97\u635f\u5931\u503c\u548c\u66f4\u65b0\u7f51\u7edc\u7684\u6743\u91cd\u3002 \u4f60\u73b0\u5728\u53ef\u80fd\u5728\u60f3\u4e0b\u4e00\u6b65\u3002 \u5173\u4e8e\u6570\u636e\uff1f \u00b6 \u4e00\u822c\u60c5\u51b5\u4e0b\u5904\u7406\u56fe\u50cf\u3001\u6587\u672c\u3001\u97f3\u9891\u548c\u89c6\u9891\u6570\u636e\u65f6\uff0c\u53ef\u4ee5\u4f7f\u7528\u6807\u51c6\u7684Python\u5305\u6765\u52a0\u8f7d\u6570\u636e\u5230\u4e00\u4e2anumpy\u6570\u7ec4\u4e2d\u3002 \u7136\u540e\u628a\u8fd9\u4e2a\u6570\u7ec4\u8f6c\u6362\u6210 torch.*Tensor \u3002 \u56fe\u50cf\u53ef\u4ee5\u4f7f\u7528 Pillow, OpenCV \u97f3\u9891\u53ef\u4ee5\u4f7f\u7528 scipy, librosa \u6587\u672c\u53ef\u4ee5\u4f7f\u7528\u539f\u59cbPython\u548cCython\u6765\u52a0\u8f7d\uff0c\u6216\u8005\u4f7f\u7528 NLTK\u6216 SpaCy \u5904\u7406 \u7279\u522b\u7684\uff0c\u5bf9\u4e8e\u56fe\u50cf\u4efb\u52a1\uff0c\u6211\u4eec\u521b\u5efa\u4e86\u4e00\u4e2a\u5305 torchvision \uff0c\u5b83\u5305\u542b\u4e86\u5904\u7406\u4e00\u4e9b\u57fa\u672c\u56fe\u50cf\u6570\u636e\u96c6\u7684\u65b9\u6cd5\u3002\u8fd9\u4e9b\u6570\u636e\u96c6\u5305\u62ec Imagenet, CIFAR10, MNIST \u7b49\u3002\u9664\u4e86\u6570\u636e\u52a0\u8f7d\u4ee5\u5916\uff0c torchvision \u8fd8\u5305\u542b\u4e86\u56fe\u50cf\u8f6c\u6362\u5668\uff0c torchvision.datasets \u548c torch.utils.data.DataLoader \u3002 torchvision \u5305\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u5de8\u5927\u7684\u4fbf\u5229\uff0c\u4e5f\u907f\u514d\u4e86\u4ee3\u7801\u7684\u91cd\u590d\u3002 \u5728\u8fd9\u4e2a\u6559\u7a0b\u4e2d\uff0c\u6211\u4eec\u4f7f\u7528CIFAR10\u6570\u636e\u96c6\uff0c\u5b83\u6709\u5982\u4e0b10\u4e2a\u7c7b\u522b \uff1a\u2018airplane\u2019, \u2018automobile\u2019, \u2018bird\u2019, \u2018cat\u2019, \u2018deer\u2019, \u2018dog\u2019, \u2018frog\u2019, \u2018horse\u2019, \u2018ship\u2019, \u2018truck\u2019\u3002CIFAR-10\u7684\u56fe\u50cf\u90fd\u662f 3x32x32\u5927\u5c0f\u7684\uff0c\u5373\uff0c3\u989c\u8272\u901a\u9053\uff0c32x32\u50cf\u7d20\u3002 \u8bad\u7ec3\u4e00\u4e2a\u56fe\u50cf\u5206\u7c7b\u5668 \u00b6 \u4f9d\u6b21\u6309\u7167\u4e0b\u5217\u987a\u5e8f\u8fdb\u884c\uff1a \u4f7f\u7528 torchvision \u52a0\u8f7d\u548c\u5f52\u4e00\u5316CIFAR10\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6 \u5b9a\u4e49\u4e00\u4e2a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc \u5b9a\u4e49\u635f\u5931\u51fd\u6570 \u5728\u8bad\u7ec3\u96c6\u4e0a\u8bad\u7ec3\u7f51\u7edc \u5728\u6d4b\u8bd5\u96c6\u4e0a\u6d4b\u8bd5\u7f51\u7edc 1. \u8bfb\u53d6\u548c\u5f52\u4e00\u5316 CIFAR10 \u00b6 \u4f7f\u7528 torchvision \u53ef\u4ee5\u975e\u5e38\u5bb9\u6613\u5730\u52a0\u8f7dCIFAR10\u3002 import torch import torchvision import torchvision.transforms as transforms torchvision\u7684\u8f93\u51fa\u662f[0,1]\u7684PILImage\u56fe\u50cf\uff0c\u6211\u4eec\u628a\u5b83\u8f6c\u6362\u4e3a\u5f52\u4e00\u5316\u8303\u56f4\u4e3a[-1, 1]\u7684\u5f20\u91cf\u3002 transform = transforms . Compose ( [ transforms . ToTensor (), transforms . Normalize (( 0.5 , 0.5 , 0.5 ), ( 0.5 , 0.5 , 0.5 ))]) trainset = torchvision . datasets . CIFAR10 ( root = './data' , train = True , download = True , transform = transform ) trainloader = torch . utils . data . DataLoader ( trainset , batch_size = 4 , shuffle = True , num_workers = 2 ) testset = torchvision . datasets . CIFAR10 ( root = './data' , train = False , download = True , transform = transform ) testloader = torch . utils . data . DataLoader ( testset , batch_size = 4 , shuffle = False , num_workers = 2 ) classes = ( 'plane' , 'car' , 'bird' , 'cat' , 'deer' , 'dog' , 'frog' , 'horse' , 'ship' , 'truck' ) Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 170M/170M [20:39<00:00, 155kB/s] Files already downloaded and verified \u6211\u4eec\u5c55\u793a\u4e00\u4e9b\u8bad\u7ec3\u56fe\u50cf\u3002 import matplotlib.pyplot as plt import numpy as np # \u5c55\u793a\u56fe\u50cf\u7684\u51fd\u6570 def imshow ( img ): img = img / 2 + 0.5 # unnormalize npimg = img . numpy () plt . imshow ( np . transpose ( npimg , ( 1 , 2 , 0 ))) # \u83b7\u53d6\u968f\u673a\u6570\u636e dataiter = iter ( trainloader ) images , labels = dataiter . next () # \u5c55\u793a\u56fe\u50cf imshow ( torchvision . utils . make_grid ( images )) # \u663e\u793a\u56fe\u50cf\u6807\u7b7e print ( ' ' . join ( ' %5s ' % classes [ labels [ j ]] for j in range ( 4 ))) 171MB [20:51, 155kB/s] cat car cat ship 2. \u5b9a\u4e49\u4e00\u4e2a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc \u00b6 \u4ece\u4e4b\u524d\u7684\u795e\u7ecf\u7f51\u7edc\u4e00\u8282\u590d\u5236\u795e\u7ecf\u7f51\u7edc\u4ee3\u7801\uff0c\u5e76\u4fee\u6539\u4e3a\u8f93\u51653\u901a\u9053\u56fe\u50cf\u3002 import torch.nn as nn import torch.nn.functional as F class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () self . conv1 = nn . Conv2d ( 3 , 6 , 5 ) self . pool = nn . MaxPool2d ( 2 , 2 ) self . conv2 = nn . Conv2d ( 6 , 16 , 5 ) self . fc1 = nn . Linear ( 16 * 5 * 5 , 120 ) self . fc2 = nn . Linear ( 120 , 84 ) self . fc3 = nn . Linear ( 84 , 10 ) def forward ( self , x ): x = self . pool ( F . relu ( self . conv1 ( x ))) x = self . pool ( F . relu ( self . conv2 ( x ))) x = x . view ( - 1 , 16 * 5 * 5 ) x = F . relu ( self . fc1 ( x )) x = F . relu ( self . fc2 ( x )) x = self . fc3 ( x ) return x net = Net () 3. \u5b9a\u4e49\u635f\u5931\u51fd\u6570\u548c\u4f18\u5316\u5668 \u00b6 \u6211\u4eec\u4f7f\u7528\u4ea4\u53c9\u71b5\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\uff0c\u4f7f\u7528\u5e26\u52a8\u91cf\u7684\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u3002 import torch.optim as optim criterion = nn . CrossEntropyLoss () optimizer = optim . SGD ( net . parameters (), lr = 0.001 , momentum = 0.9 ) 4. \u8bad\u7ec3\u7f51\u8def \u00b6 \u6709\u8da3\u7684\u65f6\u523b\u5f00\u59cb\u4e86\u3002 \u6211\u4eec\u53ea\u9700\u5728\u6570\u636e\u8fed\u4ee3\u5668\u4e0a\u5faa\u73af\uff0c\u5c06\u6570\u636e\u8f93\u5165\u7ed9\u7f51\u7edc\uff0c\u5e76\u4f18\u5316\u3002 for epoch in range ( 2 ): # \u591a\u6279\u6b21\u5faa\u73af running_loss = 0.0 for i , data in enumerate ( trainloader , 0 ): # \u83b7\u53d6\u8f93\u5165 inputs , labels = data # \u68af\u5ea6\u7f6e0 optimizer . zero_grad () # \u6b63\u5411\u4f20\u64ad\uff0c\u53cd\u5411\u4f20\u64ad\uff0c\u4f18\u5316 outputs = net ( inputs ) loss = criterion ( outputs , labels ) loss . backward () optimizer . step () # \u6253\u5370\u72b6\u6001\u4fe1\u606f running_loss += loss . item () if i % 2000 == 1999 : # \u6bcf2000\u6279\u6b21\u6253\u5370\u4e00\u6b21 print ( '[ %d , %5d ] loss: %.3f ' % ( epoch + 1 , i + 1 , running_loss / 2000 )) running_loss = 0.0 print ( 'Finished Training' ) 5. \u5728\u6d4b\u8bd5\u96c6\u4e0a\u6d4b\u8bd5\u7f51\u7edc \u00b6 \u6211\u4eec\u5728\u6574\u4e2a\u8bad\u7ec3\u96c6\u4e0a\u8fdb\u884c\u4e862\u6b21\u8bad\u7ec3\uff0c\u4f46\u662f\u6211\u4eec\u9700\u8981\u68c0\u67e5\u7f51\u7edc\u662f\u5426\u4ece\u6570\u636e\u96c6\u4e2d\u5b66\u4e60\u5230\u6709\u7528\u7684\u4e1c\u897f\u3002 \u901a\u8fc7\u9884\u6d4b\u795e\u7ecf\u7f51\u7edc\u8f93\u51fa\u7684\u7c7b\u522b\u6807\u7b7e\u4e0e\u5b9e\u9645\u60c5\u51b5\u6807\u7b7e\u8fdb\u884c\u5bf9\u6bd4\u6765\u8fdb\u884c\u68c0\u6d4b\u3002 \u5982\u679c\u9884\u6d4b\u6b63\u786e\uff0c\u6211\u4eec\u628a\u8be5\u6837\u672c\u6dfb\u52a0\u5230\u6b63\u786e\u9884\u6d4b\u5217\u8868\u3002 \u7b2c\u4e00\u6b65\uff0c\u663e\u793a\u6d4b\u8bd5\u96c6\u4e2d\u7684\u56fe\u7247\u5e76\u719f\u6089\u56fe\u7247\u5185\u5bb9\u3002 dataiter = iter ( testloader ) images , labels = dataiter . next () # \u663e\u793a\u56fe\u7247 imshow ( torchvision . utils . make_grid ( images )) print ( 'GroundTruth: ' , ' ' . join ( ' %5s ' % classes [ labels [ j ]] for j in range ( 4 ))) GroundTruth: cat ship ship plane \u8ba9\u6211\u4eec\u770b\u770b\u795e\u7ecf\u7f51\u7edc\u8ba4\u4e3a\u4ee5\u4e0a\u56fe\u7247\u662f\u4ec0\u4e48\u3002 outputs = net ( images ) \u8f93\u51fa\u662f10\u4e2a\u6807\u7b7e\u7684\u80fd\u91cf\u3002 \u4e00\u4e2a\u7c7b\u522b\u7684\u80fd\u91cf\u8d8a\u5927\uff0c\u795e\u7ecf\u7f51\u7edc\u8d8a\u8ba4\u4e3a\u5b83\u662f\u8fd9\u4e2a\u7c7b\u522b\u3002\u6240\u4ee5\u8ba9\u6211\u4eec\u5f97\u5230\u6700\u9ad8\u80fd\u91cf\u7684\u6807\u7b7e\u3002 _ , predicted = torch . max ( outputs , 1 ) print ( 'Predicted: ' , ' ' . join ( ' %5s ' % classes [ predicted [ j ]] for j in range ( 4 ))) Predicted: plane plane plane plane \u7ed3\u679c\u770b\u6765\u4e0d\u9519\u3002 \u63a5\u4e0b\u6765\u8ba9\u770b\u770b\u7f51\u7edc\u5728\u6574\u4e2a\u6d4b\u8bd5\u96c6\u4e0a\u7684\u7ed3\u679c\u5982\u4f55\u3002 correct = 0 total = 0 with torch . no_grad (): for data in testloader : images , labels = data outputs = net ( images ) _ , predicted = torch . max ( outputs . data , 1 ) total += labels . size ( 0 ) correct += ( predicted == labels ) . sum () . item () print ( 'Accuracy of the network on the 10000 test images: %d %% ' % ( 100 * correct / total )) Accuracy of the network on the 10000 test images: 9 % \u7ed3\u679c\u770b\u8d77\u6765\u4e0d\u9519\uff0c\u81f3\u5c11\u6bd4\u968f\u673a\u9009\u62e9\u8981\u597d\uff0c\u968f\u673a\u9009\u62e9\u7684\u6b63\u786e\u7387\u4e3a10%\u3002 \u4f3c\u4e4e\u7f51\u7edc\u5b66\u4e60\u5230\u4e86\u4e00\u4e9b\u4e1c\u897f\u3002 \u5728\u8bc6\u522b\u54ea\u4e00\u4e2a\u7c7b\u7684\u65f6\u5019\u597d\uff0c\u54ea\u4e00\u4e2a\u4e0d\u597d\u5462\uff1f class_correct = list ( 0. for i in range ( 10 )) class_total = list ( 0. for i in range ( 10 )) with torch . no_grad (): for data in testloader : images , labels = data outputs = net ( images ) _ , predicted = torch . max ( outputs , 1 ) c = ( predicted == labels ) . squeeze () for i in range ( 4 ): label = labels [ i ] class_correct [ label ] += c [ i ] . item () class_total [ label ] += 1 for i in range ( 10 ): print ( 'Accuracy of %5s : %2d %% ' % ( classes [ i ], 100 * class_correct [ i ] / class_total [ i ])) Accuracy of plane : 99 % Accuracy of car : 0 % Accuracy of bird : 0 % Accuracy of cat : 0 % Accuracy of deer : 0 % Accuracy of dog : 0 % Accuracy of frog : 0 % Accuracy of horse : 0 % Accuracy of ship : 0 % Accuracy of truck : 0 % \u4e0b\u4e00\u6b65? \u6211\u4eec\u5982\u4f55\u5728GPU\u4e0a\u8fd0\u884c\u795e\u7ecf\u7f51\u7edc\u5462\uff1f \u5728GPU\u4e0a\u8bad\u7ec3 \u00b6 \u628a\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u79fb\u52a8\u5230GPU\u4e0a\u8bad\u7ec3\u5c31\u50cf\u628a\u4e00\u4e2aTensor\u8f6c\u6362GPU\u4e0a\u4e00\u6837\u7b80\u5355\u3002\u5e76\u4e14\u8fd9\u4e2a\u64cd\u4f5c\u4f1a\u9012\u5f52\u904d\u5386\u6709\u6240\u6a21\u5757\uff0c\u5e76\u5c06\u5176\u53c2\u6570\u548c\u7f13\u51b2\u533a\u8f6c\u6362\u4e3aCUDA\u5f20\u91cf\u3002 device = torch . device ( \"cuda:0\" if torch . cuda . is_available () else \"cpu\" ) # \u786e\u8ba4\u6211\u4eec\u7684\u7535\u8111\u652f\u6301CUDA\uff0c\u7136\u540e\u663e\u793aCUDA\u4fe1\u606f\uff1a print ( device ) \u672c\u8282\u7684\u5176\u4f59\u90e8\u5206\u5047\u5b9a device \u662fCUDA\u8bbe\u5907\u3002 \u7136\u540e\u8fd9\u4e9b\u65b9\u6cd5\u5c06\u9012\u5f52\u904d\u5386\u6240\u6709\u6a21\u5757\u5e76\u5c06\u6a21\u5757\u7684\u53c2\u6570\u548c\u7f13\u51b2\u533a \u8f6c\u6362\u6210CUDA\u5f20\u91cf\uff1a net . to ( device ) \u8bb0\u4f4f\uff1ainputs \u548c targets \u4e5f\u8981\u8f6c\u6362\u3002 inputs , labels = inputs . to ( device ), labels . to ( device ) \u4e3a\u4ec0\u4e48\u6211\u4eec\u6ca1\u6ce8\u610f\u5230GPU\u7684\u901f\u5ea6\u63d0\u5347\u5f88\u591a\uff1f\u90a3\u662f\u56e0\u4e3a\u7f51\u7edc\u975e\u5e38\u7684\u5c0f\u3002 \u5b9e\u8df5: \u5c1d\u8bd5\u589e\u52a0\u4f60\u7684\u7f51\u7edc\u7684\u5bbd\u5ea6\uff08\u7b2c\u4e00\u4e2a nn.Conv2d \u7684\u7b2c2\u4e2a\u53c2\u6570\uff0c\u7b2c\u4e8c\u4e2a nn.Conv2d \u7684\u7b2c\u4e00\u4e2a\u53c2\u6570\uff0c\u5b83\u4eec\u9700\u8981\u662f\u76f8\u540c\u7684\u6570\u5b57\uff09\uff0c\u770b\u770b\u4f60\u5f97\u5230\u4e86\u4ec0\u4e48\u6837\u7684\u52a0\u901f\u3002 \u5b9e\u73b0\u7684\u76ee\u6807 : \u6df1\u5165\u4e86\u89e3\u4e86PyTorch\u7684\u5f20\u91cf\u5e93\u548c\u795e\u7ecf\u7f51\u7edc \u8bad\u7ec3\u4e86\u4e00\u4e2a\u5c0f\u7f51\u7edc\u6765\u5206\u7c7b\u56fe\u7247 \u8bd1\u8005\u6ce8\uff1a\u540e\u9762\u6211\u4eec\u6559\u7a0b\u4f1a\u8bad\u7ec3\u4e00\u4e2a\u771f\u6b63\u7684\u7f51\u7edc\uff0c\u4f7f\u8bc6\u522b\u7387\u8fbe\u523090%\u4ee5\u4e0a\u3002 \u591aGPU\u8bad\u7ec3 \u00b6 \u5982\u679c\u4f60\u60f3\u4f7f\u7528\u6240\u6709\u7684GPU\u5f97\u5230\u66f4\u5927\u7684\u52a0\u901f\uff0c \u8bf7\u67e5\u770b \u6570\u636e\u5e76\u884c\u5904\u7406 \u3002 \u4e0b\u4e00\u6b65\uff1f \u00b6 :doc: \u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u73a9\u7535\u5b50\u6e38\u620f </intermediate/reinforcement_q_learning> \u5728ImageNet\u4e0a\u8bad\u7ec3\u6700\u597d\u7684ResNet \u4f7f\u7528\u5bf9\u6297\u751f\u6210\u7f51\u7edc\u6765\u8bad\u7ec3\u4e00\u4e2a\u4eba\u8138\u751f\u6210\u5668 \u4f7f\u7528LSTM\u7f51\u7edc\u8bad\u7ec3\u4e00\u4e2a\u5b57\u7b26\u7ea7\u7684\u8bed\u8a00\u6a21\u578b \u66f4\u591a\u793a\u4f8b \u66f4\u591a\u6559\u7a0b \u5728\u8bba\u575b\u4e0a\u8ba8\u8bbaPyTorch Slack\u4e0a\u4e0e\u5176\u4ed6\u7528\u6237\u8ba8\u8bba","title":"1.3.4 Classifier"},{"location":"tutorial/chapter01_getting-started/1_3_4_cifar10_tutorial/#_1","text":"\u4e0a\u4e00\u8bb2\u4e2d\u5df2\u7ecf\u770b\u5230\u5982\u4f55\u53bb\u5b9a\u4e49\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\uff0c\u8ba1\u7b97\u635f\u5931\u503c\u548c\u66f4\u65b0\u7f51\u7edc\u7684\u6743\u91cd\u3002 \u4f60\u73b0\u5728\u53ef\u80fd\u5728\u60f3\u4e0b\u4e00\u6b65\u3002","title":"\u8bad\u7ec3\u4e00\u4e2a\u5206\u7c7b\u5668"},{"location":"tutorial/chapter01_getting-started/1_3_4_cifar10_tutorial/#_2","text":"\u4e00\u822c\u60c5\u51b5\u4e0b\u5904\u7406\u56fe\u50cf\u3001\u6587\u672c\u3001\u97f3\u9891\u548c\u89c6\u9891\u6570\u636e\u65f6\uff0c\u53ef\u4ee5\u4f7f\u7528\u6807\u51c6\u7684Python\u5305\u6765\u52a0\u8f7d\u6570\u636e\u5230\u4e00\u4e2anumpy\u6570\u7ec4\u4e2d\u3002 \u7136\u540e\u628a\u8fd9\u4e2a\u6570\u7ec4\u8f6c\u6362\u6210 torch.*Tensor \u3002 \u56fe\u50cf\u53ef\u4ee5\u4f7f\u7528 Pillow, OpenCV \u97f3\u9891\u53ef\u4ee5\u4f7f\u7528 scipy, librosa \u6587\u672c\u53ef\u4ee5\u4f7f\u7528\u539f\u59cbPython\u548cCython\u6765\u52a0\u8f7d\uff0c\u6216\u8005\u4f7f\u7528 NLTK\u6216 SpaCy \u5904\u7406 \u7279\u522b\u7684\uff0c\u5bf9\u4e8e\u56fe\u50cf\u4efb\u52a1\uff0c\u6211\u4eec\u521b\u5efa\u4e86\u4e00\u4e2a\u5305 torchvision \uff0c\u5b83\u5305\u542b\u4e86\u5904\u7406\u4e00\u4e9b\u57fa\u672c\u56fe\u50cf\u6570\u636e\u96c6\u7684\u65b9\u6cd5\u3002\u8fd9\u4e9b\u6570\u636e\u96c6\u5305\u62ec Imagenet, CIFAR10, MNIST \u7b49\u3002\u9664\u4e86\u6570\u636e\u52a0\u8f7d\u4ee5\u5916\uff0c torchvision \u8fd8\u5305\u542b\u4e86\u56fe\u50cf\u8f6c\u6362\u5668\uff0c torchvision.datasets \u548c torch.utils.data.DataLoader \u3002 torchvision \u5305\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u5de8\u5927\u7684\u4fbf\u5229\uff0c\u4e5f\u907f\u514d\u4e86\u4ee3\u7801\u7684\u91cd\u590d\u3002 \u5728\u8fd9\u4e2a\u6559\u7a0b\u4e2d\uff0c\u6211\u4eec\u4f7f\u7528CIFAR10\u6570\u636e\u96c6\uff0c\u5b83\u6709\u5982\u4e0b10\u4e2a\u7c7b\u522b \uff1a\u2018airplane\u2019, \u2018automobile\u2019, \u2018bird\u2019, \u2018cat\u2019, \u2018deer\u2019, \u2018dog\u2019, \u2018frog\u2019, \u2018horse\u2019, \u2018ship\u2019, \u2018truck\u2019\u3002CIFAR-10\u7684\u56fe\u50cf\u90fd\u662f 3x32x32\u5927\u5c0f\u7684\uff0c\u5373\uff0c3\u989c\u8272\u901a\u9053\uff0c32x32\u50cf\u7d20\u3002","title":"\u5173\u4e8e\u6570\u636e\uff1f"},{"location":"tutorial/chapter01_getting-started/1_3_4_cifar10_tutorial/#_3","text":"\u4f9d\u6b21\u6309\u7167\u4e0b\u5217\u987a\u5e8f\u8fdb\u884c\uff1a \u4f7f\u7528 torchvision \u52a0\u8f7d\u548c\u5f52\u4e00\u5316CIFAR10\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6 \u5b9a\u4e49\u4e00\u4e2a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc \u5b9a\u4e49\u635f\u5931\u51fd\u6570 \u5728\u8bad\u7ec3\u96c6\u4e0a\u8bad\u7ec3\u7f51\u7edc \u5728\u6d4b\u8bd5\u96c6\u4e0a\u6d4b\u8bd5\u7f51\u7edc","title":"\u8bad\u7ec3\u4e00\u4e2a\u56fe\u50cf\u5206\u7c7b\u5668"},{"location":"tutorial/chapter01_getting-started/1_3_4_cifar10_tutorial/#1-cifar10","text":"\u4f7f\u7528 torchvision \u53ef\u4ee5\u975e\u5e38\u5bb9\u6613\u5730\u52a0\u8f7dCIFAR10\u3002 import torch import torchvision import torchvision.transforms as transforms torchvision\u7684\u8f93\u51fa\u662f[0,1]\u7684PILImage\u56fe\u50cf\uff0c\u6211\u4eec\u628a\u5b83\u8f6c\u6362\u4e3a\u5f52\u4e00\u5316\u8303\u56f4\u4e3a[-1, 1]\u7684\u5f20\u91cf\u3002 transform = transforms . Compose ( [ transforms . ToTensor (), transforms . Normalize (( 0.5 , 0.5 , 0.5 ), ( 0.5 , 0.5 , 0.5 ))]) trainset = torchvision . datasets . CIFAR10 ( root = './data' , train = True , download = True , transform = transform ) trainloader = torch . utils . data . DataLoader ( trainset , batch_size = 4 , shuffle = True , num_workers = 2 ) testset = torchvision . datasets . CIFAR10 ( root = './data' , train = False , download = True , transform = transform ) testloader = torch . utils . data . DataLoader ( testset , batch_size = 4 , shuffle = False , num_workers = 2 ) classes = ( 'plane' , 'car' , 'bird' , 'cat' , 'deer' , 'dog' , 'frog' , 'horse' , 'ship' , 'truck' ) Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 170M/170M [20:39<00:00, 155kB/s] Files already downloaded and verified \u6211\u4eec\u5c55\u793a\u4e00\u4e9b\u8bad\u7ec3\u56fe\u50cf\u3002 import matplotlib.pyplot as plt import numpy as np # \u5c55\u793a\u56fe\u50cf\u7684\u51fd\u6570 def imshow ( img ): img = img / 2 + 0.5 # unnormalize npimg = img . numpy () plt . imshow ( np . transpose ( npimg , ( 1 , 2 , 0 ))) # \u83b7\u53d6\u968f\u673a\u6570\u636e dataiter = iter ( trainloader ) images , labels = dataiter . next () # \u5c55\u793a\u56fe\u50cf imshow ( torchvision . utils . make_grid ( images )) # \u663e\u793a\u56fe\u50cf\u6807\u7b7e print ( ' ' . join ( ' %5s ' % classes [ labels [ j ]] for j in range ( 4 ))) 171MB [20:51, 155kB/s] cat car cat ship","title":"1. \u8bfb\u53d6\u548c\u5f52\u4e00\u5316 CIFAR10"},{"location":"tutorial/chapter01_getting-started/1_3_4_cifar10_tutorial/#2","text":"\u4ece\u4e4b\u524d\u7684\u795e\u7ecf\u7f51\u7edc\u4e00\u8282\u590d\u5236\u795e\u7ecf\u7f51\u7edc\u4ee3\u7801\uff0c\u5e76\u4fee\u6539\u4e3a\u8f93\u51653\u901a\u9053\u56fe\u50cf\u3002 import torch.nn as nn import torch.nn.functional as F class Net ( nn . Module ): def __init__ ( self ): super ( Net , self ) . __init__ () self . conv1 = nn . Conv2d ( 3 , 6 , 5 ) self . pool = nn . MaxPool2d ( 2 , 2 ) self . conv2 = nn . Conv2d ( 6 , 16 , 5 ) self . fc1 = nn . Linear ( 16 * 5 * 5 , 120 ) self . fc2 = nn . Linear ( 120 , 84 ) self . fc3 = nn . Linear ( 84 , 10 ) def forward ( self , x ): x = self . pool ( F . relu ( self . conv1 ( x ))) x = self . pool ( F . relu ( self . conv2 ( x ))) x = x . view ( - 1 , 16 * 5 * 5 ) x = F . relu ( self . fc1 ( x )) x = F . relu ( self . fc2 ( x )) x = self . fc3 ( x ) return x net = Net ()","title":"2. \u5b9a\u4e49\u4e00\u4e2a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc"},{"location":"tutorial/chapter01_getting-started/1_3_4_cifar10_tutorial/#3","text":"\u6211\u4eec\u4f7f\u7528\u4ea4\u53c9\u71b5\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\uff0c\u4f7f\u7528\u5e26\u52a8\u91cf\u7684\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u3002 import torch.optim as optim criterion = nn . CrossEntropyLoss () optimizer = optim . SGD ( net . parameters (), lr = 0.001 , momentum = 0.9 )","title":"3. \u5b9a\u4e49\u635f\u5931\u51fd\u6570\u548c\u4f18\u5316\u5668"},{"location":"tutorial/chapter01_getting-started/1_3_4_cifar10_tutorial/#4","text":"\u6709\u8da3\u7684\u65f6\u523b\u5f00\u59cb\u4e86\u3002 \u6211\u4eec\u53ea\u9700\u5728\u6570\u636e\u8fed\u4ee3\u5668\u4e0a\u5faa\u73af\uff0c\u5c06\u6570\u636e\u8f93\u5165\u7ed9\u7f51\u7edc\uff0c\u5e76\u4f18\u5316\u3002 for epoch in range ( 2 ): # \u591a\u6279\u6b21\u5faa\u73af running_loss = 0.0 for i , data in enumerate ( trainloader , 0 ): # \u83b7\u53d6\u8f93\u5165 inputs , labels = data # \u68af\u5ea6\u7f6e0 optimizer . zero_grad () # \u6b63\u5411\u4f20\u64ad\uff0c\u53cd\u5411\u4f20\u64ad\uff0c\u4f18\u5316 outputs = net ( inputs ) loss = criterion ( outputs , labels ) loss . backward () optimizer . step () # \u6253\u5370\u72b6\u6001\u4fe1\u606f running_loss += loss . item () if i % 2000 == 1999 : # \u6bcf2000\u6279\u6b21\u6253\u5370\u4e00\u6b21 print ( '[ %d , %5d ] loss: %.3f ' % ( epoch + 1 , i + 1 , running_loss / 2000 )) running_loss = 0.0 print ( 'Finished Training' )","title":"4. \u8bad\u7ec3\u7f51\u8def"},{"location":"tutorial/chapter01_getting-started/1_3_4_cifar10_tutorial/#5","text":"\u6211\u4eec\u5728\u6574\u4e2a\u8bad\u7ec3\u96c6\u4e0a\u8fdb\u884c\u4e862\u6b21\u8bad\u7ec3\uff0c\u4f46\u662f\u6211\u4eec\u9700\u8981\u68c0\u67e5\u7f51\u7edc\u662f\u5426\u4ece\u6570\u636e\u96c6\u4e2d\u5b66\u4e60\u5230\u6709\u7528\u7684\u4e1c\u897f\u3002 \u901a\u8fc7\u9884\u6d4b\u795e\u7ecf\u7f51\u7edc\u8f93\u51fa\u7684\u7c7b\u522b\u6807\u7b7e\u4e0e\u5b9e\u9645\u60c5\u51b5\u6807\u7b7e\u8fdb\u884c\u5bf9\u6bd4\u6765\u8fdb\u884c\u68c0\u6d4b\u3002 \u5982\u679c\u9884\u6d4b\u6b63\u786e\uff0c\u6211\u4eec\u628a\u8be5\u6837\u672c\u6dfb\u52a0\u5230\u6b63\u786e\u9884\u6d4b\u5217\u8868\u3002 \u7b2c\u4e00\u6b65\uff0c\u663e\u793a\u6d4b\u8bd5\u96c6\u4e2d\u7684\u56fe\u7247\u5e76\u719f\u6089\u56fe\u7247\u5185\u5bb9\u3002 dataiter = iter ( testloader ) images , labels = dataiter . next () # \u663e\u793a\u56fe\u7247 imshow ( torchvision . utils . make_grid ( images )) print ( 'GroundTruth: ' , ' ' . join ( ' %5s ' % classes [ labels [ j ]] for j in range ( 4 ))) GroundTruth: cat ship ship plane \u8ba9\u6211\u4eec\u770b\u770b\u795e\u7ecf\u7f51\u7edc\u8ba4\u4e3a\u4ee5\u4e0a\u56fe\u7247\u662f\u4ec0\u4e48\u3002 outputs = net ( images ) \u8f93\u51fa\u662f10\u4e2a\u6807\u7b7e\u7684\u80fd\u91cf\u3002 \u4e00\u4e2a\u7c7b\u522b\u7684\u80fd\u91cf\u8d8a\u5927\uff0c\u795e\u7ecf\u7f51\u7edc\u8d8a\u8ba4\u4e3a\u5b83\u662f\u8fd9\u4e2a\u7c7b\u522b\u3002\u6240\u4ee5\u8ba9\u6211\u4eec\u5f97\u5230\u6700\u9ad8\u80fd\u91cf\u7684\u6807\u7b7e\u3002 _ , predicted = torch . max ( outputs , 1 ) print ( 'Predicted: ' , ' ' . join ( ' %5s ' % classes [ predicted [ j ]] for j in range ( 4 ))) Predicted: plane plane plane plane \u7ed3\u679c\u770b\u6765\u4e0d\u9519\u3002 \u63a5\u4e0b\u6765\u8ba9\u770b\u770b\u7f51\u7edc\u5728\u6574\u4e2a\u6d4b\u8bd5\u96c6\u4e0a\u7684\u7ed3\u679c\u5982\u4f55\u3002 correct = 0 total = 0 with torch . no_grad (): for data in testloader : images , labels = data outputs = net ( images ) _ , predicted = torch . max ( outputs . data , 1 ) total += labels . size ( 0 ) correct += ( predicted == labels ) . sum () . item () print ( 'Accuracy of the network on the 10000 test images: %d %% ' % ( 100 * correct / total )) Accuracy of the network on the 10000 test images: 9 % \u7ed3\u679c\u770b\u8d77\u6765\u4e0d\u9519\uff0c\u81f3\u5c11\u6bd4\u968f\u673a\u9009\u62e9\u8981\u597d\uff0c\u968f\u673a\u9009\u62e9\u7684\u6b63\u786e\u7387\u4e3a10%\u3002 \u4f3c\u4e4e\u7f51\u7edc\u5b66\u4e60\u5230\u4e86\u4e00\u4e9b\u4e1c\u897f\u3002 \u5728\u8bc6\u522b\u54ea\u4e00\u4e2a\u7c7b\u7684\u65f6\u5019\u597d\uff0c\u54ea\u4e00\u4e2a\u4e0d\u597d\u5462\uff1f class_correct = list ( 0. for i in range ( 10 )) class_total = list ( 0. for i in range ( 10 )) with torch . no_grad (): for data in testloader : images , labels = data outputs = net ( images ) _ , predicted = torch . max ( outputs , 1 ) c = ( predicted == labels ) . squeeze () for i in range ( 4 ): label = labels [ i ] class_correct [ label ] += c [ i ] . item () class_total [ label ] += 1 for i in range ( 10 ): print ( 'Accuracy of %5s : %2d %% ' % ( classes [ i ], 100 * class_correct [ i ] / class_total [ i ])) Accuracy of plane : 99 % Accuracy of car : 0 % Accuracy of bird : 0 % Accuracy of cat : 0 % Accuracy of deer : 0 % Accuracy of dog : 0 % Accuracy of frog : 0 % Accuracy of horse : 0 % Accuracy of ship : 0 % Accuracy of truck : 0 % \u4e0b\u4e00\u6b65? \u6211\u4eec\u5982\u4f55\u5728GPU\u4e0a\u8fd0\u884c\u795e\u7ecf\u7f51\u7edc\u5462\uff1f","title":"5. \u5728\u6d4b\u8bd5\u96c6\u4e0a\u6d4b\u8bd5\u7f51\u7edc"},{"location":"tutorial/chapter01_getting-started/1_3_4_cifar10_tutorial/#gpu","text":"\u628a\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u79fb\u52a8\u5230GPU\u4e0a\u8bad\u7ec3\u5c31\u50cf\u628a\u4e00\u4e2aTensor\u8f6c\u6362GPU\u4e0a\u4e00\u6837\u7b80\u5355\u3002\u5e76\u4e14\u8fd9\u4e2a\u64cd\u4f5c\u4f1a\u9012\u5f52\u904d\u5386\u6709\u6240\u6a21\u5757\uff0c\u5e76\u5c06\u5176\u53c2\u6570\u548c\u7f13\u51b2\u533a\u8f6c\u6362\u4e3aCUDA\u5f20\u91cf\u3002 device = torch . device ( \"cuda:0\" if torch . cuda . is_available () else \"cpu\" ) # \u786e\u8ba4\u6211\u4eec\u7684\u7535\u8111\u652f\u6301CUDA\uff0c\u7136\u540e\u663e\u793aCUDA\u4fe1\u606f\uff1a print ( device ) \u672c\u8282\u7684\u5176\u4f59\u90e8\u5206\u5047\u5b9a device \u662fCUDA\u8bbe\u5907\u3002 \u7136\u540e\u8fd9\u4e9b\u65b9\u6cd5\u5c06\u9012\u5f52\u904d\u5386\u6240\u6709\u6a21\u5757\u5e76\u5c06\u6a21\u5757\u7684\u53c2\u6570\u548c\u7f13\u51b2\u533a \u8f6c\u6362\u6210CUDA\u5f20\u91cf\uff1a net . to ( device ) \u8bb0\u4f4f\uff1ainputs \u548c targets \u4e5f\u8981\u8f6c\u6362\u3002 inputs , labels = inputs . to ( device ), labels . to ( device ) \u4e3a\u4ec0\u4e48\u6211\u4eec\u6ca1\u6ce8\u610f\u5230GPU\u7684\u901f\u5ea6\u63d0\u5347\u5f88\u591a\uff1f\u90a3\u662f\u56e0\u4e3a\u7f51\u7edc\u975e\u5e38\u7684\u5c0f\u3002 \u5b9e\u8df5: \u5c1d\u8bd5\u589e\u52a0\u4f60\u7684\u7f51\u7edc\u7684\u5bbd\u5ea6\uff08\u7b2c\u4e00\u4e2a nn.Conv2d \u7684\u7b2c2\u4e2a\u53c2\u6570\uff0c\u7b2c\u4e8c\u4e2a nn.Conv2d \u7684\u7b2c\u4e00\u4e2a\u53c2\u6570\uff0c\u5b83\u4eec\u9700\u8981\u662f\u76f8\u540c\u7684\u6570\u5b57\uff09\uff0c\u770b\u770b\u4f60\u5f97\u5230\u4e86\u4ec0\u4e48\u6837\u7684\u52a0\u901f\u3002 \u5b9e\u73b0\u7684\u76ee\u6807 : \u6df1\u5165\u4e86\u89e3\u4e86PyTorch\u7684\u5f20\u91cf\u5e93\u548c\u795e\u7ecf\u7f51\u7edc \u8bad\u7ec3\u4e86\u4e00\u4e2a\u5c0f\u7f51\u7edc\u6765\u5206\u7c7b\u56fe\u7247 \u8bd1\u8005\u6ce8\uff1a\u540e\u9762\u6211\u4eec\u6559\u7a0b\u4f1a\u8bad\u7ec3\u4e00\u4e2a\u771f\u6b63\u7684\u7f51\u7edc\uff0c\u4f7f\u8bc6\u522b\u7387\u8fbe\u523090%\u4ee5\u4e0a\u3002","title":"\u5728GPU\u4e0a\u8bad\u7ec3"},{"location":"tutorial/chapter01_getting-started/1_3_4_cifar10_tutorial/#gpu_1","text":"\u5982\u679c\u4f60\u60f3\u4f7f\u7528\u6240\u6709\u7684GPU\u5f97\u5230\u66f4\u5927\u7684\u52a0\u901f\uff0c \u8bf7\u67e5\u770b \u6570\u636e\u5e76\u884c\u5904\u7406 \u3002","title":"\u591aGPU\u8bad\u7ec3"},{"location":"tutorial/chapter01_getting-started/1_3_4_cifar10_tutorial/#_4","text":":doc: \u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u73a9\u7535\u5b50\u6e38\u620f </intermediate/reinforcement_q_learning> \u5728ImageNet\u4e0a\u8bad\u7ec3\u6700\u597d\u7684ResNet \u4f7f\u7528\u5bf9\u6297\u751f\u6210\u7f51\u7edc\u6765\u8bad\u7ec3\u4e00\u4e2a\u4eba\u8138\u751f\u6210\u5668 \u4f7f\u7528LSTM\u7f51\u7edc\u8bad\u7ec3\u4e00\u4e2a\u5b57\u7b26\u7ea7\u7684\u8bed\u8a00\u6a21\u578b \u66f4\u591a\u793a\u4f8b \u66f4\u591a\u6559\u7a0b \u5728\u8bba\u575b\u4e0a\u8ba8\u8bbaPyTorch Slack\u4e0a\u4e0e\u5176\u4ed6\u7528\u6237\u8ba8\u8bba","title":"\u4e0b\u4e00\u6b65\uff1f"},{"location":"tutorial/chapter01_getting-started/1_3_5_data_parallel_tutorial/","text":"% matplotlib inline \u6570\u636e\u5e76\u884c\uff08\u9009\u8bfb\uff09 \u00b6 Authors : Sung Kim and Jenny Kang \u5728\u8fd9\u4e2a\u6559\u7a0b\u91cc\uff0c\u6211\u4eec\u5c06\u5b66\u4e60\u5982\u4f55\u4f7f\u7528 DataParallel \u6765\u4f7f\u7528\u591aGPU\u3002 PyTorch\u975e\u5e38\u5bb9\u6613\u5c31\u53ef\u4ee5\u4f7f\u7528\u591aGPU\uff0c\u7528\u5982\u4e0b\u65b9\u5f0f\u628a\u4e00\u4e2a\u6a21\u578b\u653e\u5230GPU\u4e0a\uff1a device = torch . device ( \"cuda:0\" ) model . to ( device ) GPU: \u7136\u540e\u590d\u5236\u6240\u6709\u7684\u5f20\u91cf\u5230GPU\u4e0a\uff1a mytensor = my_tensor . to ( device ) \u8bf7\u6ce8\u610f\uff0c\u53ea\u8c03\u7528 my_tensor.to(device) \u5e76\u6ca1\u6709\u590d\u5236\u5f20\u91cf\u5230GPU\u4e0a\uff0c\u800c\u662f\u8fd4\u56de\u4e86\u4e00\u4e2acopy\u3002\u6240\u4ee5\u4f60\u9700\u8981\u628a\u5b83\u8d4b\u503c\u7ed9\u4e00\u4e2a\u65b0\u7684\u5f20\u91cf\u5e76\u5728GPU\u4e0a\u4f7f\u7528\u8fd9\u4e2a\u5f20\u91cf\u3002 \u5728\u591aGPU\u4e0a\u6267\u884c\u524d\u5411\u548c\u53cd\u5411\u4f20\u64ad\u662f\u81ea\u7136\u800c\u7136\u7684\u4e8b\u3002 \u4f46\u662fPyTorch\u9ed8\u8ba4\u5c06\u53ea\u4f7f\u7528\u4e00\u4e2aGPU\u3002 \u4f7f\u7528 DataParallel \u53ef\u4ee5\u8f7b\u6613\u7684\u8ba9\u6a21\u578b\u5e76\u884c\u8fd0\u884c\u5728\u591a\u4e2aGPU\u4e0a\u3002 model = nn . DataParallel ( model ) \u8fd9\u624d\u662f\u8fd9\u7bc7\u6559\u7a0b\u7684\u6838\u5fc3\uff0c\u63a5\u4e0b\u6765\u6211\u4eec\u5c06\u66f4\u8be6\u7ec6\u7684\u4ecb\u7ecd\u5b83\u3002 \u5bfc\u5165\u548c\u53c2\u6570 \u00b6 \u5bfc\u5165PyTorch\u6a21\u5757\u548c\u5b9a\u4e49\u53c2\u6570\u3002 import torch import torch.nn as nn from torch.utils.data import Dataset , DataLoader # Parameters and DataLoaders input_size = 5 output_size = 2 batch_size = 30 data_size = 100 Device device = torch . device ( \"cuda:0\" if torch . cuda . is_available () else \"cpu\" ) \u865a\u62df\u6570\u636e\u96c6 \u00b6 \u5236\u4f5c\u4e00\u4e2a\u865a\u62df\uff08\u968f\u673a\uff09\u6570\u636e\u96c6\uff0c \u4f60\u53ea\u9700\u5b9e\u73b0 __getitem__ class RandomDataset ( Dataset ): def __init__ ( self , size , length ): self . len = length self . data = torch . randn ( length , size ) def __getitem__ ( self , index ): return self . data [ index ] def __len__ ( self ): return self . len rand_loader = DataLoader ( dataset = RandomDataset ( input_size , data_size ), batch_size = batch_size , shuffle = True ) \u7b80\u5355\u6a21\u578b \u00b6 \u4f5c\u4e3a\u6f14\u793a\uff0c\u6211\u4eec\u7684\u6a21\u578b\u53ea\u63a5\u53d7\u4e00\u4e2a\u8f93\u5165\uff0c\u6267\u884c\u4e00\u4e2a\u7ebf\u6027\u64cd\u4f5c\uff0c\u7136\u540e\u5f97\u5230\u7ed3\u679c\u3002 \u8bf4\u660e\uff1a DataParallel \u80fd\u5728\u4efb\u4f55\u6a21\u578b\uff08CNN\uff0cRNN\uff0cCapsule Net\u7b49\uff09\u4e0a\u4f7f\u7528\u3002 \u6211\u4eec\u5728\u6a21\u578b\u5185\u90e8\u653e\u7f6e\u4e86\u4e00\u6761\u6253\u5370\u8bed\u53e5\u6765\u6253\u5370\u8f93\u5165\u548c\u8f93\u51fa\u5411\u91cf\u7684\u5927\u5c0f\u3002 \u8bf7\u6ce8\u610f\u6279\u6b21\u7684\u79e9\u4e3a0\u65f6\u6253\u5370\u7684\u5185\u5bb9\u3002 class Model ( nn . Module ): # Our model def __init__ ( self , input_size , output_size ): super ( Model , self ) . __init__ () self . fc = nn . Linear ( input_size , output_size ) def forward ( self , input ): output = self . fc ( input ) print ( \" \\t In Model: input size\" , input . size (), \"output size\" , output . size ()) return output \u521b\u5efa\u4e00\u4e2a\u6a21\u578b\u548c\u6570\u636e\u5e76\u884c \u00b6 \u8fd9\u662f\u672c\u6559\u7a0b\u7684\u6838\u5fc3\u90e8\u5206\u3002 \u9996\u5148\uff0c\u6211\u4eec\u9700\u8981\u521b\u5efa\u4e00\u4e2a\u6a21\u578b\u5b9e\u4f8b\u548c\u68c0\u6d4b\u6211\u4eec\u662f\u5426\u6709\u591a\u4e2aGPU\u3002 \u5982\u679c\u6709\u591a\u4e2aGPU\uff0c\u4f7f\u7528 nn.DataParallel \u6765\u5305\u88c5\u6211\u4eec\u7684\u6a21\u578b\u3002 \u7136\u540e\u901a\u8fc7m model.to(device) \u628a\u6a21\u578b\u653e\u5230GPU\u4e0a\u3002 model = Model ( input_size , output_size ) if torch . cuda . device_count () > 1 : print ( \"Let's use\" , torch . cuda . device_count (), \"GPUs!\" ) # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs model = nn . DataParallel ( model ) model . to ( device ) Model( (fc): Linear(in_features=5, out_features=2, bias=True) ) \u8fd0\u884c\u6a21\u578b \u00b6 \u73b0\u5728\u53ef\u4ee5\u770b\u5230\u8f93\u5165\u548c\u8f93\u51fa\u5f20\u91cf\u7684\u5927\u5c0f\u3002 for data in rand_loader : input = data . to ( device ) output = model ( input ) print ( \"Outside: input size\" , input . size (), \"output_size\" , output . size ()) In Model: input size torch.Size([30, 5]) output size torch.Size([30, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([30, 5]) output size torch.Size([30, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([30, 5]) output size torch.Size([30, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2]) \u7ed3\u679c \u00b6 \u5f53\u6ca1\u6709\u6216\u8005\u53ea\u6709\u4e00\u4e2aGPU\u65f6\uff0c\u5bf930\u4e2a\u8f93\u5165\u548c\u8f93\u51fa\u8fdb\u884c\u6279\u5904\u7406\uff0c\u5f97\u5230\u4e86\u671f\u671b\u7684\u4e00\u6837\u5f97\u523030\u4e2a\u8f93\u5165\u548c\u8f93\u51fa\uff0c\u4f46\u662f\u5982\u679c\u4f60\u6709\u591a\u4e2aGPU\uff0c\u4f60\u5f97\u5230\u5982\u4e0b\u7684\u7ed3\u679c\u3002 2 GPUs ~ If you have 2, you will see: .. code:: bash # on 2 GPUs Let's use 2 GPUs! In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2]) In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2]) In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2]) In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([5, 5]) output size torch.Size([5, 2]) In Model: input size torch.Size([5, 5]) output size torch.Size([5, 2]) Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2]) 3 GPUs ~ If you have 3 GPUs, you will see: .. code:: bash Let's use 3 GPUs! In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2]) 8 GPUs ~~ If you have 8, you will see: .. code:: bash Let's use 8 GPUs! In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2]) \u603b\u7ed3 \u00b6 DataParallel\u4f1a\u81ea\u52a8\u7684\u5212\u5206\u6570\u636e\uff0c\u5e76\u5c06\u4f5c\u4e1a\u53d1\u9001\u5230\u591a\u4e2aGPU\u4e0a\u7684\u591a\u4e2a\u6a21\u578b\u3002 \u5e76\u5728\u6bcf\u4e2a\u6a21\u578b\u5b8c\u6210\u4f5c\u4e1a\u540e\uff0c\u6536\u96c6\u5408\u5e76\u7ed3\u679c\u5e76\u8fd4\u56de\u3002 \u66f4\u591a\u4fe1\u606f\u8bf7\u770b\u8fd9\u91cc\uff1a https://pytorch.org/tutorials/beginner/former _torchies/parallelism_tutorial.html.","title":"1.3.5 Data Parallelism"},{"location":"tutorial/chapter01_getting-started/1_3_5_data_parallel_tutorial/#_1","text":"Authors : Sung Kim and Jenny Kang \u5728\u8fd9\u4e2a\u6559\u7a0b\u91cc\uff0c\u6211\u4eec\u5c06\u5b66\u4e60\u5982\u4f55\u4f7f\u7528 DataParallel \u6765\u4f7f\u7528\u591aGPU\u3002 PyTorch\u975e\u5e38\u5bb9\u6613\u5c31\u53ef\u4ee5\u4f7f\u7528\u591aGPU\uff0c\u7528\u5982\u4e0b\u65b9\u5f0f\u628a\u4e00\u4e2a\u6a21\u578b\u653e\u5230GPU\u4e0a\uff1a device = torch . device ( \"cuda:0\" ) model . to ( device ) GPU: \u7136\u540e\u590d\u5236\u6240\u6709\u7684\u5f20\u91cf\u5230GPU\u4e0a\uff1a mytensor = my_tensor . to ( device ) \u8bf7\u6ce8\u610f\uff0c\u53ea\u8c03\u7528 my_tensor.to(device) \u5e76\u6ca1\u6709\u590d\u5236\u5f20\u91cf\u5230GPU\u4e0a\uff0c\u800c\u662f\u8fd4\u56de\u4e86\u4e00\u4e2acopy\u3002\u6240\u4ee5\u4f60\u9700\u8981\u628a\u5b83\u8d4b\u503c\u7ed9\u4e00\u4e2a\u65b0\u7684\u5f20\u91cf\u5e76\u5728GPU\u4e0a\u4f7f\u7528\u8fd9\u4e2a\u5f20\u91cf\u3002 \u5728\u591aGPU\u4e0a\u6267\u884c\u524d\u5411\u548c\u53cd\u5411\u4f20\u64ad\u662f\u81ea\u7136\u800c\u7136\u7684\u4e8b\u3002 \u4f46\u662fPyTorch\u9ed8\u8ba4\u5c06\u53ea\u4f7f\u7528\u4e00\u4e2aGPU\u3002 \u4f7f\u7528 DataParallel \u53ef\u4ee5\u8f7b\u6613\u7684\u8ba9\u6a21\u578b\u5e76\u884c\u8fd0\u884c\u5728\u591a\u4e2aGPU\u4e0a\u3002 model = nn . DataParallel ( model ) \u8fd9\u624d\u662f\u8fd9\u7bc7\u6559\u7a0b\u7684\u6838\u5fc3\uff0c\u63a5\u4e0b\u6765\u6211\u4eec\u5c06\u66f4\u8be6\u7ec6\u7684\u4ecb\u7ecd\u5b83\u3002","title":"\u6570\u636e\u5e76\u884c\uff08\u9009\u8bfb\uff09"},{"location":"tutorial/chapter01_getting-started/1_3_5_data_parallel_tutorial/#_2","text":"\u5bfc\u5165PyTorch\u6a21\u5757\u548c\u5b9a\u4e49\u53c2\u6570\u3002 import torch import torch.nn as nn from torch.utils.data import Dataset , DataLoader # Parameters and DataLoaders input_size = 5 output_size = 2 batch_size = 30 data_size = 100 Device device = torch . device ( \"cuda:0\" if torch . cuda . is_available () else \"cpu\" )","title":"\u5bfc\u5165\u548c\u53c2\u6570"},{"location":"tutorial/chapter01_getting-started/1_3_5_data_parallel_tutorial/#_3","text":"\u5236\u4f5c\u4e00\u4e2a\u865a\u62df\uff08\u968f\u673a\uff09\u6570\u636e\u96c6\uff0c \u4f60\u53ea\u9700\u5b9e\u73b0 __getitem__ class RandomDataset ( Dataset ): def __init__ ( self , size , length ): self . len = length self . data = torch . randn ( length , size ) def __getitem__ ( self , index ): return self . data [ index ] def __len__ ( self ): return self . len rand_loader = DataLoader ( dataset = RandomDataset ( input_size , data_size ), batch_size = batch_size , shuffle = True )","title":"\u865a\u62df\u6570\u636e\u96c6"},{"location":"tutorial/chapter01_getting-started/1_3_5_data_parallel_tutorial/#_4","text":"\u4f5c\u4e3a\u6f14\u793a\uff0c\u6211\u4eec\u7684\u6a21\u578b\u53ea\u63a5\u53d7\u4e00\u4e2a\u8f93\u5165\uff0c\u6267\u884c\u4e00\u4e2a\u7ebf\u6027\u64cd\u4f5c\uff0c\u7136\u540e\u5f97\u5230\u7ed3\u679c\u3002 \u8bf4\u660e\uff1a DataParallel \u80fd\u5728\u4efb\u4f55\u6a21\u578b\uff08CNN\uff0cRNN\uff0cCapsule Net\u7b49\uff09\u4e0a\u4f7f\u7528\u3002 \u6211\u4eec\u5728\u6a21\u578b\u5185\u90e8\u653e\u7f6e\u4e86\u4e00\u6761\u6253\u5370\u8bed\u53e5\u6765\u6253\u5370\u8f93\u5165\u548c\u8f93\u51fa\u5411\u91cf\u7684\u5927\u5c0f\u3002 \u8bf7\u6ce8\u610f\u6279\u6b21\u7684\u79e9\u4e3a0\u65f6\u6253\u5370\u7684\u5185\u5bb9\u3002 class Model ( nn . Module ): # Our model def __init__ ( self , input_size , output_size ): super ( Model , self ) . __init__ () self . fc = nn . Linear ( input_size , output_size ) def forward ( self , input ): output = self . fc ( input ) print ( \" \\t In Model: input size\" , input . size (), \"output size\" , output . size ()) return output","title":"\u7b80\u5355\u6a21\u578b"},{"location":"tutorial/chapter01_getting-started/1_3_5_data_parallel_tutorial/#_5","text":"\u8fd9\u662f\u672c\u6559\u7a0b\u7684\u6838\u5fc3\u90e8\u5206\u3002 \u9996\u5148\uff0c\u6211\u4eec\u9700\u8981\u521b\u5efa\u4e00\u4e2a\u6a21\u578b\u5b9e\u4f8b\u548c\u68c0\u6d4b\u6211\u4eec\u662f\u5426\u6709\u591a\u4e2aGPU\u3002 \u5982\u679c\u6709\u591a\u4e2aGPU\uff0c\u4f7f\u7528 nn.DataParallel \u6765\u5305\u88c5\u6211\u4eec\u7684\u6a21\u578b\u3002 \u7136\u540e\u901a\u8fc7m model.to(device) \u628a\u6a21\u578b\u653e\u5230GPU\u4e0a\u3002 model = Model ( input_size , output_size ) if torch . cuda . device_count () > 1 : print ( \"Let's use\" , torch . cuda . device_count (), \"GPUs!\" ) # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs model = nn . DataParallel ( model ) model . to ( device ) Model( (fc): Linear(in_features=5, out_features=2, bias=True) )","title":"\u521b\u5efa\u4e00\u4e2a\u6a21\u578b\u548c\u6570\u636e\u5e76\u884c"},{"location":"tutorial/chapter01_getting-started/1_3_5_data_parallel_tutorial/#_6","text":"\u73b0\u5728\u53ef\u4ee5\u770b\u5230\u8f93\u5165\u548c\u8f93\u51fa\u5f20\u91cf\u7684\u5927\u5c0f\u3002 for data in rand_loader : input = data . to ( device ) output = model ( input ) print ( \"Outside: input size\" , input . size (), \"output_size\" , output . size ()) In Model: input size torch.Size([30, 5]) output size torch.Size([30, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([30, 5]) output size torch.Size([30, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([30, 5]) output size torch.Size([30, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2])","title":"\u8fd0\u884c\u6a21\u578b"},{"location":"tutorial/chapter01_getting-started/1_3_5_data_parallel_tutorial/#_7","text":"\u5f53\u6ca1\u6709\u6216\u8005\u53ea\u6709\u4e00\u4e2aGPU\u65f6\uff0c\u5bf930\u4e2a\u8f93\u5165\u548c\u8f93\u51fa\u8fdb\u884c\u6279\u5904\u7406\uff0c\u5f97\u5230\u4e86\u671f\u671b\u7684\u4e00\u6837\u5f97\u523030\u4e2a\u8f93\u5165\u548c\u8f93\u51fa\uff0c\u4f46\u662f\u5982\u679c\u4f60\u6709\u591a\u4e2aGPU\uff0c\u4f60\u5f97\u5230\u5982\u4e0b\u7684\u7ed3\u679c\u3002 2 GPUs ~ If you have 2, you will see: .. code:: bash # on 2 GPUs Let's use 2 GPUs! In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2]) In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2]) In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2]) In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([5, 5]) output size torch.Size([5, 2]) In Model: input size torch.Size([5, 5]) output size torch.Size([5, 2]) Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2]) 3 GPUs ~ If you have 3 GPUs, you will see: .. code:: bash Let's use 3 GPUs! In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2]) 8 GPUs ~~ If you have 8, you will see: .. code:: bash Let's use 8 GPUs! In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2])","title":"\u7ed3\u679c"},{"location":"tutorial/chapter01_getting-started/1_3_5_data_parallel_tutorial/#_8","text":"DataParallel\u4f1a\u81ea\u52a8\u7684\u5212\u5206\u6570\u636e\uff0c\u5e76\u5c06\u4f5c\u4e1a\u53d1\u9001\u5230\u591a\u4e2aGPU\u4e0a\u7684\u591a\u4e2a\u6a21\u578b\u3002 \u5e76\u5728\u6bcf\u4e2a\u6a21\u578b\u5b8c\u6210\u4f5c\u4e1a\u540e\uff0c\u6536\u96c6\u5408\u5e76\u7ed3\u679c\u5e76\u8fd4\u56de\u3002 \u66f4\u591a\u4fe1\u606f\u8bf7\u770b\u8fd9\u91cc\uff1a https://pytorch.org/tutorials/beginner/former _torchies/parallelism_tutorial.html.","title":"\u603b\u7ed3"},{"location":"tutorial/chapter01_getting-started/1_3_deep-learning-with-pytorch-60-minute-blitz/","text":"PyTorch \u6df1\u5ea6\u5b66\u4e60\uff1a60\u5206\u949f\u5feb\u901f\u5165\u95e8 \uff08\u5b98\u65b9\u4e2d\u6587\u7248\uff09 \u00b6 \u5b98\u65b9\u8fde\u63a5 Deep Learning with PyTorch: A 60 Minute Blitz \u76ee\u5f55 \u00b6 \u5f20\u91cf Tensor \u81ea\u52a8\u6c42\u5bfc Autograd \u795e\u7ecf\u7f51\u7edc Neural Networks \u8bad\u7ec3\u4e00\u4e2a\u5206\u7c7b\u5668 Classifier \u6570\u636e\u5e76\u884c Data Parallelism","title":"PyTorch \u6df1\u5ea6\u5b66\u4e60\uff1a60\u5206\u949f\u5feb\u901f\u5165\u95e8 \uff08\u5b98\u65b9\u4e2d\u6587\u7248\uff09"},{"location":"tutorial/chapter01_getting-started/1_3_deep-learning-with-pytorch-60-minute-blitz/#pytorch-60","text":"\u5b98\u65b9\u8fde\u63a5 Deep Learning with PyTorch: A 60 Minute Blitz","title":"PyTorch \u6df1\u5ea6\u5b66\u4e60\uff1a60\u5206\u949f\u5feb\u901f\u5165\u95e8 \uff08\u5b98\u65b9\u4e2d\u6587\u7248\uff09"},{"location":"tutorial/chapter01_getting-started/1_3_deep-learning-with-pytorch-60-minute-blitz/#_1","text":"\u5f20\u91cf Tensor \u81ea\u52a8\u6c42\u5bfc Autograd \u795e\u7ecf\u7f51\u7edc Neural Networks \u8bad\u7ec3\u4e00\u4e2a\u5206\u7c7b\u5668 Classifier \u6570\u636e\u5e76\u884c Data Parallelism","title":"\u76ee\u5f55"},{"location":"tutorial/chapter02_basics/","text":"Pytorch \u624b\u518c\u7b2c\u4e8c\u7ae0 \uff1a \u57fa\u7840 \u00b6 \u76ee\u5f55 \u00b6 \u7b2c\u4e00\u8282 PyTorch \u57fa\u7840 \u00b6 \u5f20\u91cf \u81ea\u52a8\u6c42\u5bfc \u795e\u7ecf\u7f51\u7edc\u5305nn\u548c\u4f18\u5316\u5668optm \u6570\u636e\u7684\u52a0\u8f7d\u548c\u9884\u5904\u7406 \u7b2c\u4e8c\u8282 \u6df1\u5ea6\u5b66\u4e60\u57fa\u7840\u53ca\u6570\u5b66\u539f\u7406 \u00b6 \u6df1\u5ea6\u5b66\u4e60\u57fa\u7840\u53ca\u6570\u5b66\u539f\u7406 \u7b2c\u4e09\u8282 \u795e\u7ecf\u7f51\u7edc\u7b80\u4ecb \u00b6 \u795e\u7ecf\u7f51\u7edc\u7b80\u4ecb \u7b2c\u56db\u8282 \u5377\u79ef\u795e\u7ecf\u7f51\u7edc \u00b6 \u5377\u79ef\u795e\u7ecf\u7f51\u7edc \u7b2c\u4e94\u8282 \u5faa\u73af\u795e\u7ecf\u7f51\u7edc \u00b6 \u5faa\u73af\u795e\u7ecf\u7f51\u7edc","title":"Pytorch \u624b\u518c\u7b2c\u4e8c\u7ae0 \uff1a \u57fa\u7840"},{"location":"tutorial/chapter02_basics/#pytorch","text":"","title":"Pytorch \u624b\u518c\u7b2c\u4e8c\u7ae0 \uff1a \u57fa\u7840"},{"location":"tutorial/chapter02_basics/#_1","text":"","title":"\u76ee\u5f55"},{"location":"tutorial/chapter02_basics/#pytorch_1","text":"\u5f20\u91cf \u81ea\u52a8\u6c42\u5bfc \u795e\u7ecf\u7f51\u7edc\u5305nn\u548c\u4f18\u5316\u5668optm \u6570\u636e\u7684\u52a0\u8f7d\u548c\u9884\u5904\u7406","title":"\u7b2c\u4e00\u8282 PyTorch \u57fa\u7840"},{"location":"tutorial/chapter02_basics/#_2","text":"\u6df1\u5ea6\u5b66\u4e60\u57fa\u7840\u53ca\u6570\u5b66\u539f\u7406","title":"\u7b2c\u4e8c\u8282 \u6df1\u5ea6\u5b66\u4e60\u57fa\u7840\u53ca\u6570\u5b66\u539f\u7406"},{"location":"tutorial/chapter02_basics/#_3","text":"\u795e\u7ecf\u7f51\u7edc\u7b80\u4ecb","title":"\u7b2c\u4e09\u8282 \u795e\u7ecf\u7f51\u7edc\u7b80\u4ecb"},{"location":"tutorial/chapter02_basics/#_4","text":"\u5377\u79ef\u795e\u7ecf\u7f51\u7edc","title":"\u7b2c\u56db\u8282 \u5377\u79ef\u795e\u7ecf\u7f51\u7edc"},{"location":"tutorial/chapter02_basics/#_5","text":"\u5faa\u73af\u795e\u7ecf\u7f51\u7edc","title":"\u7b2c\u4e94\u8282 \u5faa\u73af\u795e\u7ecf\u7f51\u7edc"},{"location":"tutorial/chapter02_basics/2_1_1_pytorch-basics-tensor/","text":"PyTorch \u57fa\u7840 : \u5f20\u91cf \u00b6 \u5728\u7b2c\u4e00\u7ae0\u4e2d\u6211\u4eec\u5df2\u7ecf\u901a\u8fc7\u5b98\u65b9\u7684\u5165\u95e8\u6559\u7a0b\u5bf9PyTorch\u6709\u4e86\u4e00\u5b9a\u7684\u4e86\u89e3\uff0c\u8fd9\u4e00\u7ae0\u4f1a\u8be6\u7ec6\u4ecb\u7ecdPyTorch \u91cc\u9762\u7684\u57fa\u7840\u77e5\u8bc6\u3002 \u5168\u90e8\u638c\u63e1\u4e86\u8fd9\u4e9b\u57fa\u7840\u77e5\u8bc6\uff0c\u5728\u540e\u9762\u7684\u5e94\u7528\u4e2d\u624d\u80fd\u66f4\u52a0\u5feb\u901f\u8fdb\u9636\uff0c\u5982\u679c\u4f60\u5df2\u7ecf\u5bf9PyTorch\u6709\u4e00\u5b9a\u7684\u4e86\u89e3\uff0c\u53ef\u4ee5\u8df3\u8fc7\u6b64\u7ae0 # \u9996\u5148\u8981\u5f15\u5165\u76f8\u5173\u7684\u5305 import torch import numpy as np #\u6253\u5370\u4e00\u4e0b\u7248\u672c torch . __version__ '1.0.0' \u5f20\u91cf(Tensor) \u00b6 \u5f20\u91cf\u7684\u82f1\u6587\u662fTensor\uff0c\u5b83\u662fPyTorch\u91cc\u9762\u57fa\u7840\u7684\u8fd0\u7b97\u5355\u4f4d,\u4e0eNumpy\u7684ndarray\u76f8\u540c\u90fd\u8868\u793a\u7684\u662f\u4e00\u4e2a\u591a\u7ef4\u7684\u77e9\u9635\u3002 \u4e0endarray\u7684\u6700\u5927\u533a\u522b\u5c31\u662f\uff0cPyTorch\u7684Tensor\u53ef\u4ee5\u5728 GPU \u4e0a\u8fd0\u884c\uff0c\u800c numpy \u7684 ndarray \u53ea\u80fd\u5728 CPU \u4e0a\u8fd0\u884c\uff0c\u5728GPU\u4e0a\u8fd0\u884c\u5927\u5927\u52a0\u5feb\u4e86\u8fd0\u7b97\u901f\u5ea6\u3002 \u4e0b\u9762\u6211\u4eec\u751f\u6210\u4e00\u4e2a\u7b80\u5355\u7684\u5f20\u91cf x = torch . rand ( 2 , 3 ) x tensor([[0.6904, 0.7419, 0.8010], [0.1722, 0.2442, 0.8181]]) \u4ee5\u4e0a\u751f\u6210\u4e86\u4e00\u4e2a\uff0c2\u884c3\u5217\u7684\u7684\u77e9\u9635\uff0c\u6211\u4eec\u770b\u4e00\u4e0b\u4ed6\u7684\u5927\u5c0f\uff1a # \u53ef\u4ee5\u4f7f\u7528\u4e0enumpy\u76f8\u540c\u7684shape\u5c5e\u6027\u67e5\u770b print ( x . shape ) # \u4e5f\u53ef\u4ee5\u4f7f\u7528size()\u51fd\u6570\uff0c\u8fd4\u56de\u7684\u7ed3\u679c\u90fd\u662f\u76f8\u540c\u7684 print ( x . size ()) torch.Size([2, 3]) torch.Size([2, 3]) \u5f20\u91cf\uff08Tensor\uff09\u662f\u4e00\u4e2a\u5b9a\u4e49\u5728\u4e00\u4e9b\u5411\u91cf\u7a7a\u95f4\u548c\u4e00\u4e9b\u5bf9\u5076\u7a7a\u95f4\u7684\u7b1b\u5361\u513f\u79ef\u4e0a\u7684\u591a\u91cd\u7ebf\u6027\u6620\u5c04\uff0c\u5176\u5750\u6807\u662f|n|\u7ef4\u7a7a\u95f4\u5185\uff0c\u6709|n|\u4e2a\u5206\u91cf\u7684\u4e00\u79cd\u91cf\uff0c \u5176\u4e2d\u6bcf\u4e2a\u5206\u91cf\u90fd\u662f\u5750\u6807\u7684\u51fd\u6570\uff0c \u800c\u5728\u5750\u6807\u53d8\u6362\u65f6\uff0c\u8fd9\u4e9b\u5206\u91cf\u4e5f\u4f9d\u7167\u67d0\u4e9b\u89c4\u5219\u4f5c\u7ebf\u6027\u53d8\u6362\u3002r\u79f0\u4e3a\u8be5\u5f20\u91cf\u7684\u79e9\u6216\u9636\uff08\u4e0e\u77e9\u9635\u7684\u79e9\u548c\u9636\u5747\u65e0\u5173\u7cfb\uff09\u3002 (\u6765\u81ea\u767e\u5ea6\u767e\u79d1) \u4e0b\u9762\u6211\u4eec\u6765\u751f\u6210\u4e00\u4e9b\u591a\u7ef4\u7684\u5f20\u91cf\uff1a y = torch . rand ( 2 , 3 , 4 , 5 ) print ( y . size ()) y torch.Size([2, 3, 4, 5]) tensor([[[[0.9071, 0.0616, 0.0006, 0.6031, 0.0714], [0.6592, 0.9700, 0.0253, 0.0726, 0.5360], [0.5416, 0.1138, 0.9592, 0.6779, 0.6501], [0.0546, 0.8287, 0.7748, 0.4352, 0.9232]], [[0.0730, 0.4228, 0.7407, 0.4099, 0.1482], [0.5408, 0.9156, 0.6554, 0.5787, 0.9775], [0.4262, 0.3644, 0.1993, 0.4143, 0.5757], [0.9307, 0.8839, 0.8462, 0.0933, 0.6688]], [[0.4447, 0.0929, 0.9882, 0.5392, 0.1159], [0.4790, 0.5115, 0.4005, 0.9486, 0.0054], [0.8955, 0.8097, 0.1227, 0.2250, 0.5830], [0.8483, 0.2070, 0.1067, 0.4727, 0.5095]]], [[[0.9438, 0.2601, 0.2885, 0.5457, 0.7528], [0.2971, 0.2171, 0.3910, 0.1924, 0.2570], [0.7491, 0.9749, 0.2703, 0.2198, 0.9472], [0.1216, 0.6647, 0.8809, 0.0125, 0.5513]], [[0.0870, 0.6622, 0.7252, 0.4783, 0.0160], [0.7832, 0.6050, 0.7469, 0.7947, 0.8052], [0.1755, 0.4489, 0.0602, 0.8073, 0.3028], [0.9937, 0.6780, 0.9425, 0.0059, 0.0451]], [[0.3851, 0.8742, 0.5932, 0.4899, 0.8354], [0.8577, 0.3705, 0.0229, 0.7097, 0.7557], [0.1505, 0.3527, 0.0843, 0.0088, 0.8741], [0.6041, 0.8797, 0.6189, 0.9495, 0.1479]]]]) \u5728\u540c\u6784\u7684\u610f\u4e49\u4e0b\uff0c\u7b2c\u96f6\u9636\u5f20\u91cf \uff08r = 0\uff09 \u4e3a\u6807\u91cf \uff08Scalar\uff09\uff0c\u7b2c\u4e00\u9636\u5f20\u91cf \uff08r = 1\uff09 \u4e3a\u5411\u91cf \uff08Vector\uff09\uff0c \u7b2c\u4e8c\u9636\u5f20\u91cf \uff08r = 2\uff09 \u5219\u6210\u4e3a\u77e9\u9635 \uff08Matrix\uff09\uff0c\u7b2c\u4e09\u9636\u4ee5\u4e0a\u7684\u7edf\u79f0\u4e3a\u591a\u7ef4\u5f20\u91cf\u3002 \u5176\u4e2d\u8981\u7279\u522b\u6ce8\u610f\u7684\u5c31\u662f\u6807\u91cf\uff0c\u6211\u4eec\u5148\u751f\u6210\u4e00\u4e2a\u6807\u91cf\uff1a #\u6211\u4eec\u76f4\u63a5\u4f7f\u7528\u73b0\u6709\u6570\u5b57\u751f\u6210 scalar = torch . tensor ( 3.1433223 ) print ( scalar ) #\u6253\u5370\u6807\u91cf\u7684\u5927\u5c0f scalar . size () tensor(3.1433) torch.Size([]) \u5bf9\u4e8e\u6807\u91cf\uff0c\u6211\u4eec\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528 .item() \u4ece\u4e2d\u53d6\u51fa\u5176\u5bf9\u5e94\u7684python\u5bf9\u8c61\u7684\u6570\u503c scalar . item () 3.143322229385376 \u7279\u522b\u7684\uff1a\u5982\u679c\u5f20\u91cf\u4e2d\u53ea\u6709\u4e00\u4e2a\u5143\u7d20\u7684tensor\u4e5f\u53ef\u4ee5\u8c03\u7528 tensor.item \u65b9\u6cd5 tensor = torch . tensor ([ 3.1433223 ]) print ( tensor ) tensor . size () tensor([3.1433]) torch.Size([1]) tensor . item () 3.143322229385376 \u57fa\u672c\u7c7b\u578b \u00b6 Tensor\u7684\u57fa\u672c\u6570\u636e\u7c7b\u578b\u6709\u4e94\u79cd\uff1a - 32\u4f4d\u6d6e\u70b9\u578b\uff1atorch.FloatTensor\u3002 (\u9ed8\u8ba4) - 64\u4f4d\u6574\u578b\uff1atorch.LongTensor\u3002 - 32\u4f4d\u6574\u578b\uff1atorch.IntTensor\u3002 - 16\u4f4d\u6574\u578b\uff1atorch.ShortTensor\u3002 - 64\u4f4d\u6d6e\u70b9\u578b\uff1atorch.DoubleTensor\u3002 \u9664\u4ee5\u4e0a\u6570\u5b57\u7c7b\u578b\u5916\uff0c\u8fd8\u6709 byte\u548cchart\u578b long = tensor . long () long tensor([3]) half = tensor . half () half tensor([3.1426], dtype=torch.float16) int_t = tensor . int () int_t tensor([3], dtype=torch.int32) flo = tensor . float () flo tensor([3.1433]) short = tensor . short () short tensor([3], dtype=torch.int16) ch = tensor . char () ch tensor([3], dtype=torch.int8) bt = tensor . byte () bt tensor([3], dtype=torch.uint8) Numpy\u8f6c\u6362 \u00b6 \u4f7f\u7528numpy\u65b9\u6cd5\u5c06Tensor\u8f6c\u4e3andarray a = torch . randn (( 3 , 2 )) # tensor\u8f6c\u5316\u4e3anumpy numpy_a = a . numpy () print ( numpy_a ) [[ 0.46819344 1.3774964 ] [ 0.9491934 1.4543315 ] [-0.42792308 0.99790514]] numpy\u8f6c\u5316\u4e3aTensor torch_a = torch . from_numpy ( numpy_a ) torch_a tensor([[ 0.4682, 1.3775], [ 0.9492, 1.4543], [-0.4279, 0.9979]]) Tensor\u548cnumpy\u5bf9\u8c61\u5171\u4eab\u5185\u5b58\uff0c\u6240\u4ee5\u4ed6\u4eec\u4e4b\u95f4\u7684\u8f6c\u6362\u5f88\u5feb\uff0c\u800c\u4e14\u51e0\u4e4e\u4e0d\u4f1a\u6d88\u8017\u4ec0\u4e48\u8d44\u6e90\u3002\u4f46\u8fd9\u4e5f\u610f\u5473\u7740\uff0c\u5982\u679c\u5176\u4e2d\u4e00\u4e2a\u53d8\u4e86\uff0c\u53e6\u5916\u4e00\u4e2a\u4e5f\u4f1a\u968f\u4e4b\u6539\u53d8\u3002 \u8bbe\u5907\u95f4\u8f6c\u6362 \u00b6 \u4e00\u822c\u60c5\u51b5\u4e0b\u53ef\u4ee5\u4f7f\u7528.cuda\u65b9\u6cd5\u5c06tensor\u79fb\u52a8\u5230gpu\uff0c\u8fd9\u6b65\u64cd\u4f5c\u9700\u8981cuda\u8bbe\u5907\u652f\u6301 cpu_a = torch . rand ( 4 , 3 ) cpu_a . type () 'torch.FloatTensor' gpu_a = cpu_a . cuda () gpu_a . type () 'torch.cuda.FloatTensor' \u4f7f\u7528.cpu\u65b9\u6cd5\u5c06tensor\u79fb\u52a8\u5230cpu cpu_b = gpu_a . cpu () cpu_b . type () 'torch.FloatTensor' \u5982\u679c\u6211\u4eec\u6709\u591aGPU\u7684\u60c5\u51b5\uff0c\u53ef\u4ee5\u4f7f\u7528to\u65b9\u6cd5\u6765\u786e\u5b9a\u4f7f\u7528\u90a3\u4e2a\u8bbe\u5907\uff0c\u8fd9\u91cc\u53ea\u505a\u4e2a\u7b80\u5355\u7684\u5b9e\u4f8b\uff1a #\u4f7f\u7528torch.cuda.is_available()\u6765\u786e\u5b9a\u662f\u5426\u6709cuda\u8bbe\u5907 device = torch . device ( \"cuda\" if torch . cuda . is_available () else \"cpu\" ) print ( device ) #\u5c06tensor\u4f20\u9001\u5230\u8bbe\u5907 gpu_b = cpu_b . to ( device ) gpu_b . type () cuda 'torch.cuda.FloatTensor' \u521d\u59cb\u5316 \u00b6 Pytorch\u4e2d\u6709\u8bb8\u591a\u9ed8\u8ba4\u7684\u521d\u59cb\u5316\u65b9\u6cd5\u53ef\u4ee5\u4f7f\u7528 # \u4f7f\u7528[0,1]\u5747\u5300\u5206\u5e03\u968f\u673a\u521d\u59cb\u5316\u4e8c\u7ef4\u6570\u7ec4 rnd = torch . rand ( 5 , 3 ) rnd tensor([[0.3804, 0.0297, 0.5241], [0.4111, 0.8887, 0.4642], [0.7302, 0.5913, 0.7182], [0.3048, 0.8055, 0.2176], [0.6195, 0.1620, 0.7726]]) ##\u521d\u59cb\u5316\uff0c\u4f7f\u75281\u586b\u5145 one = torch . ones ( 2 , 2 ) one tensor([[1., 1.], [1., 1.]]) ##\u521d\u59cb\u5316\uff0c\u4f7f\u75280\u586b\u5145 zero = torch . zeros ( 2 , 2 ) zero tensor([[0., 0.], [0., 0.]]) #\u521d\u59cb\u5316\u4e00\u4e2a\u5355\u4f4d\u77e9\u9635\uff0c\u5373\u5bf9\u89d2\u7ebf\u4e3a1 \u5176\u4ed6\u4e3a0 eye = torch . eye ( 2 , 2 ) eye tensor([[1., 0.], [0., 1.]]) \u5e38\u7528\u65b9\u6cd5 \u00b6 PyTorch\u4e2d\u5bf9\u5f20\u91cf\u7684\u64cd\u4f5capi \u548c NumPy \u975e\u5e38\u76f8\u4f3c\uff0c\u5982\u679c\u719f\u6089 NumPy \u4e2d\u7684\u64cd\u4f5c\uff0c\u90a3\u4e48 \u4ed6\u4eec\u4e8c\u8005 \u57fa\u672c\u662f\u4e00\u81f4\u7684\uff1a x = torch . randn ( 3 , 3 ) print ( x ) tensor([[ 0.6922, -0.4824, 0.8594], [ 0.4509, -0.8155, -0.0368], [ 1.3533, 0.5545, -0.0509]]) # \u6cbf\u7740\u884c\u53d6\u6700\u5927\u503c max_value , max_idx = torch . max ( x , dim = 1 ) print ( max_value , max_idx ) tensor([0.8594, 0.4509, 1.3533]) tensor([2, 0, 0]) # \u6bcf\u884c x \u6c42\u548c sum_x = torch . sum ( x , dim = 1 ) print ( sum_x ) tensor([ 1.0692, -0.4014, 1.8568]) y = torch . randn ( 3 , 3 ) z = x + y print ( z ) tensor([[-0.3821, -2.6932, -1.3884], [ 0.7468, -0.7697, -0.0883], [ 0.7688, -1.3485, 0.7517]]) \u6b63\u5982\u5b98\u65b960\u5206\u949f\u6559\u7a0b\u4e2d\u6240\u8bf4\uff0c\u4ee5_\u4e3a\u7ed3\u5c3e\u7684\uff0c\u5747\u4f1a\u6539\u53d8\u8c03\u7528\u503c # add \u5b8c\u6210\u540ex\u7684\u503c\u6539\u53d8\u4e86 x . add_ ( y ) print ( x ) tensor([[-0.3821, -2.6932, -1.3884], [ 0.7468, -0.7697, -0.0883], [ 0.7688, -1.3485, 0.7517]]) \u5f20\u91cf\u7684\u57fa\u672c\u64cd\u4f5c\u90fd\u4ecb\u7ecd\u7684\u7684\u5dee\u4e0d\u591a\u4e86\uff0c\u4e0b\u4e00\u7ae0\u4ecb\u7ecdPyTorch\u7684\u81ea\u52a8\u6c42\u5bfc\u673a\u5236","title":"2.1.1 Tensor"},{"location":"tutorial/chapter02_basics/2_1_1_pytorch-basics-tensor/#pytorch","text":"\u5728\u7b2c\u4e00\u7ae0\u4e2d\u6211\u4eec\u5df2\u7ecf\u901a\u8fc7\u5b98\u65b9\u7684\u5165\u95e8\u6559\u7a0b\u5bf9PyTorch\u6709\u4e86\u4e00\u5b9a\u7684\u4e86\u89e3\uff0c\u8fd9\u4e00\u7ae0\u4f1a\u8be6\u7ec6\u4ecb\u7ecdPyTorch \u91cc\u9762\u7684\u57fa\u7840\u77e5\u8bc6\u3002 \u5168\u90e8\u638c\u63e1\u4e86\u8fd9\u4e9b\u57fa\u7840\u77e5\u8bc6\uff0c\u5728\u540e\u9762\u7684\u5e94\u7528\u4e2d\u624d\u80fd\u66f4\u52a0\u5feb\u901f\u8fdb\u9636\uff0c\u5982\u679c\u4f60\u5df2\u7ecf\u5bf9PyTorch\u6709\u4e00\u5b9a\u7684\u4e86\u89e3\uff0c\u53ef\u4ee5\u8df3\u8fc7\u6b64\u7ae0 # \u9996\u5148\u8981\u5f15\u5165\u76f8\u5173\u7684\u5305 import torch import numpy as np #\u6253\u5370\u4e00\u4e0b\u7248\u672c torch . __version__ '1.0.0'","title":"PyTorch \u57fa\u7840 : \u5f20\u91cf"},{"location":"tutorial/chapter02_basics/2_1_1_pytorch-basics-tensor/#tensor","text":"\u5f20\u91cf\u7684\u82f1\u6587\u662fTensor\uff0c\u5b83\u662fPyTorch\u91cc\u9762\u57fa\u7840\u7684\u8fd0\u7b97\u5355\u4f4d,\u4e0eNumpy\u7684ndarray\u76f8\u540c\u90fd\u8868\u793a\u7684\u662f\u4e00\u4e2a\u591a\u7ef4\u7684\u77e9\u9635\u3002 \u4e0endarray\u7684\u6700\u5927\u533a\u522b\u5c31\u662f\uff0cPyTorch\u7684Tensor\u53ef\u4ee5\u5728 GPU \u4e0a\u8fd0\u884c\uff0c\u800c numpy \u7684 ndarray \u53ea\u80fd\u5728 CPU \u4e0a\u8fd0\u884c\uff0c\u5728GPU\u4e0a\u8fd0\u884c\u5927\u5927\u52a0\u5feb\u4e86\u8fd0\u7b97\u901f\u5ea6\u3002 \u4e0b\u9762\u6211\u4eec\u751f\u6210\u4e00\u4e2a\u7b80\u5355\u7684\u5f20\u91cf x = torch . rand ( 2 , 3 ) x tensor([[0.6904, 0.7419, 0.8010], [0.1722, 0.2442, 0.8181]]) \u4ee5\u4e0a\u751f\u6210\u4e86\u4e00\u4e2a\uff0c2\u884c3\u5217\u7684\u7684\u77e9\u9635\uff0c\u6211\u4eec\u770b\u4e00\u4e0b\u4ed6\u7684\u5927\u5c0f\uff1a # \u53ef\u4ee5\u4f7f\u7528\u4e0enumpy\u76f8\u540c\u7684shape\u5c5e\u6027\u67e5\u770b print ( x . shape ) # \u4e5f\u53ef\u4ee5\u4f7f\u7528size()\u51fd\u6570\uff0c\u8fd4\u56de\u7684\u7ed3\u679c\u90fd\u662f\u76f8\u540c\u7684 print ( x . size ()) torch.Size([2, 3]) torch.Size([2, 3]) \u5f20\u91cf\uff08Tensor\uff09\u662f\u4e00\u4e2a\u5b9a\u4e49\u5728\u4e00\u4e9b\u5411\u91cf\u7a7a\u95f4\u548c\u4e00\u4e9b\u5bf9\u5076\u7a7a\u95f4\u7684\u7b1b\u5361\u513f\u79ef\u4e0a\u7684\u591a\u91cd\u7ebf\u6027\u6620\u5c04\uff0c\u5176\u5750\u6807\u662f|n|\u7ef4\u7a7a\u95f4\u5185\uff0c\u6709|n|\u4e2a\u5206\u91cf\u7684\u4e00\u79cd\u91cf\uff0c \u5176\u4e2d\u6bcf\u4e2a\u5206\u91cf\u90fd\u662f\u5750\u6807\u7684\u51fd\u6570\uff0c \u800c\u5728\u5750\u6807\u53d8\u6362\u65f6\uff0c\u8fd9\u4e9b\u5206\u91cf\u4e5f\u4f9d\u7167\u67d0\u4e9b\u89c4\u5219\u4f5c\u7ebf\u6027\u53d8\u6362\u3002r\u79f0\u4e3a\u8be5\u5f20\u91cf\u7684\u79e9\u6216\u9636\uff08\u4e0e\u77e9\u9635\u7684\u79e9\u548c\u9636\u5747\u65e0\u5173\u7cfb\uff09\u3002 (\u6765\u81ea\u767e\u5ea6\u767e\u79d1) \u4e0b\u9762\u6211\u4eec\u6765\u751f\u6210\u4e00\u4e9b\u591a\u7ef4\u7684\u5f20\u91cf\uff1a y = torch . rand ( 2 , 3 , 4 , 5 ) print ( y . size ()) y torch.Size([2, 3, 4, 5]) tensor([[[[0.9071, 0.0616, 0.0006, 0.6031, 0.0714], [0.6592, 0.9700, 0.0253, 0.0726, 0.5360], [0.5416, 0.1138, 0.9592, 0.6779, 0.6501], [0.0546, 0.8287, 0.7748, 0.4352, 0.9232]], [[0.0730, 0.4228, 0.7407, 0.4099, 0.1482], [0.5408, 0.9156, 0.6554, 0.5787, 0.9775], [0.4262, 0.3644, 0.1993, 0.4143, 0.5757], [0.9307, 0.8839, 0.8462, 0.0933, 0.6688]], [[0.4447, 0.0929, 0.9882, 0.5392, 0.1159], [0.4790, 0.5115, 0.4005, 0.9486, 0.0054], [0.8955, 0.8097, 0.1227, 0.2250, 0.5830], [0.8483, 0.2070, 0.1067, 0.4727, 0.5095]]], [[[0.9438, 0.2601, 0.2885, 0.5457, 0.7528], [0.2971, 0.2171, 0.3910, 0.1924, 0.2570], [0.7491, 0.9749, 0.2703, 0.2198, 0.9472], [0.1216, 0.6647, 0.8809, 0.0125, 0.5513]], [[0.0870, 0.6622, 0.7252, 0.4783, 0.0160], [0.7832, 0.6050, 0.7469, 0.7947, 0.8052], [0.1755, 0.4489, 0.0602, 0.8073, 0.3028], [0.9937, 0.6780, 0.9425, 0.0059, 0.0451]], [[0.3851, 0.8742, 0.5932, 0.4899, 0.8354], [0.8577, 0.3705, 0.0229, 0.7097, 0.7557], [0.1505, 0.3527, 0.0843, 0.0088, 0.8741], [0.6041, 0.8797, 0.6189, 0.9495, 0.1479]]]]) \u5728\u540c\u6784\u7684\u610f\u4e49\u4e0b\uff0c\u7b2c\u96f6\u9636\u5f20\u91cf \uff08r = 0\uff09 \u4e3a\u6807\u91cf \uff08Scalar\uff09\uff0c\u7b2c\u4e00\u9636\u5f20\u91cf \uff08r = 1\uff09 \u4e3a\u5411\u91cf \uff08Vector\uff09\uff0c \u7b2c\u4e8c\u9636\u5f20\u91cf \uff08r = 2\uff09 \u5219\u6210\u4e3a\u77e9\u9635 \uff08Matrix\uff09\uff0c\u7b2c\u4e09\u9636\u4ee5\u4e0a\u7684\u7edf\u79f0\u4e3a\u591a\u7ef4\u5f20\u91cf\u3002 \u5176\u4e2d\u8981\u7279\u522b\u6ce8\u610f\u7684\u5c31\u662f\u6807\u91cf\uff0c\u6211\u4eec\u5148\u751f\u6210\u4e00\u4e2a\u6807\u91cf\uff1a #\u6211\u4eec\u76f4\u63a5\u4f7f\u7528\u73b0\u6709\u6570\u5b57\u751f\u6210 scalar = torch . tensor ( 3.1433223 ) print ( scalar ) #\u6253\u5370\u6807\u91cf\u7684\u5927\u5c0f scalar . size () tensor(3.1433) torch.Size([]) \u5bf9\u4e8e\u6807\u91cf\uff0c\u6211\u4eec\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528 .item() \u4ece\u4e2d\u53d6\u51fa\u5176\u5bf9\u5e94\u7684python\u5bf9\u8c61\u7684\u6570\u503c scalar . item () 3.143322229385376 \u7279\u522b\u7684\uff1a\u5982\u679c\u5f20\u91cf\u4e2d\u53ea\u6709\u4e00\u4e2a\u5143\u7d20\u7684tensor\u4e5f\u53ef\u4ee5\u8c03\u7528 tensor.item \u65b9\u6cd5 tensor = torch . tensor ([ 3.1433223 ]) print ( tensor ) tensor . size () tensor([3.1433]) torch.Size([1]) tensor . item () 3.143322229385376","title":"\u5f20\u91cf(Tensor)"},{"location":"tutorial/chapter02_basics/2_1_1_pytorch-basics-tensor/#_1","text":"Tensor\u7684\u57fa\u672c\u6570\u636e\u7c7b\u578b\u6709\u4e94\u79cd\uff1a - 32\u4f4d\u6d6e\u70b9\u578b\uff1atorch.FloatTensor\u3002 (\u9ed8\u8ba4) - 64\u4f4d\u6574\u578b\uff1atorch.LongTensor\u3002 - 32\u4f4d\u6574\u578b\uff1atorch.IntTensor\u3002 - 16\u4f4d\u6574\u578b\uff1atorch.ShortTensor\u3002 - 64\u4f4d\u6d6e\u70b9\u578b\uff1atorch.DoubleTensor\u3002 \u9664\u4ee5\u4e0a\u6570\u5b57\u7c7b\u578b\u5916\uff0c\u8fd8\u6709 byte\u548cchart\u578b long = tensor . long () long tensor([3]) half = tensor . half () half tensor([3.1426], dtype=torch.float16) int_t = tensor . int () int_t tensor([3], dtype=torch.int32) flo = tensor . float () flo tensor([3.1433]) short = tensor . short () short tensor([3], dtype=torch.int16) ch = tensor . char () ch tensor([3], dtype=torch.int8) bt = tensor . byte () bt tensor([3], dtype=torch.uint8)","title":"\u57fa\u672c\u7c7b\u578b"},{"location":"tutorial/chapter02_basics/2_1_1_pytorch-basics-tensor/#numpy","text":"\u4f7f\u7528numpy\u65b9\u6cd5\u5c06Tensor\u8f6c\u4e3andarray a = torch . randn (( 3 , 2 )) # tensor\u8f6c\u5316\u4e3anumpy numpy_a = a . numpy () print ( numpy_a ) [[ 0.46819344 1.3774964 ] [ 0.9491934 1.4543315 ] [-0.42792308 0.99790514]] numpy\u8f6c\u5316\u4e3aTensor torch_a = torch . from_numpy ( numpy_a ) torch_a tensor([[ 0.4682, 1.3775], [ 0.9492, 1.4543], [-0.4279, 0.9979]]) Tensor\u548cnumpy\u5bf9\u8c61\u5171\u4eab\u5185\u5b58\uff0c\u6240\u4ee5\u4ed6\u4eec\u4e4b\u95f4\u7684\u8f6c\u6362\u5f88\u5feb\uff0c\u800c\u4e14\u51e0\u4e4e\u4e0d\u4f1a\u6d88\u8017\u4ec0\u4e48\u8d44\u6e90\u3002\u4f46\u8fd9\u4e5f\u610f\u5473\u7740\uff0c\u5982\u679c\u5176\u4e2d\u4e00\u4e2a\u53d8\u4e86\uff0c\u53e6\u5916\u4e00\u4e2a\u4e5f\u4f1a\u968f\u4e4b\u6539\u53d8\u3002","title":"Numpy\u8f6c\u6362"},{"location":"tutorial/chapter02_basics/2_1_1_pytorch-basics-tensor/#_2","text":"\u4e00\u822c\u60c5\u51b5\u4e0b\u53ef\u4ee5\u4f7f\u7528.cuda\u65b9\u6cd5\u5c06tensor\u79fb\u52a8\u5230gpu\uff0c\u8fd9\u6b65\u64cd\u4f5c\u9700\u8981cuda\u8bbe\u5907\u652f\u6301 cpu_a = torch . rand ( 4 , 3 ) cpu_a . type () 'torch.FloatTensor' gpu_a = cpu_a . cuda () gpu_a . type () 'torch.cuda.FloatTensor' \u4f7f\u7528.cpu\u65b9\u6cd5\u5c06tensor\u79fb\u52a8\u5230cpu cpu_b = gpu_a . cpu () cpu_b . type () 'torch.FloatTensor' \u5982\u679c\u6211\u4eec\u6709\u591aGPU\u7684\u60c5\u51b5\uff0c\u53ef\u4ee5\u4f7f\u7528to\u65b9\u6cd5\u6765\u786e\u5b9a\u4f7f\u7528\u90a3\u4e2a\u8bbe\u5907\uff0c\u8fd9\u91cc\u53ea\u505a\u4e2a\u7b80\u5355\u7684\u5b9e\u4f8b\uff1a #\u4f7f\u7528torch.cuda.is_available()\u6765\u786e\u5b9a\u662f\u5426\u6709cuda\u8bbe\u5907 device = torch . device ( \"cuda\" if torch . cuda . is_available () else \"cpu\" ) print ( device ) #\u5c06tensor\u4f20\u9001\u5230\u8bbe\u5907 gpu_b = cpu_b . to ( device ) gpu_b . type () cuda 'torch.cuda.FloatTensor'","title":"\u8bbe\u5907\u95f4\u8f6c\u6362"},{"location":"tutorial/chapter02_basics/2_1_1_pytorch-basics-tensor/#_3","text":"Pytorch\u4e2d\u6709\u8bb8\u591a\u9ed8\u8ba4\u7684\u521d\u59cb\u5316\u65b9\u6cd5\u53ef\u4ee5\u4f7f\u7528 # \u4f7f\u7528[0,1]\u5747\u5300\u5206\u5e03\u968f\u673a\u521d\u59cb\u5316\u4e8c\u7ef4\u6570\u7ec4 rnd = torch . rand ( 5 , 3 ) rnd tensor([[0.3804, 0.0297, 0.5241], [0.4111, 0.8887, 0.4642], [0.7302, 0.5913, 0.7182], [0.3048, 0.8055, 0.2176], [0.6195, 0.1620, 0.7726]]) ##\u521d\u59cb\u5316\uff0c\u4f7f\u75281\u586b\u5145 one = torch . ones ( 2 , 2 ) one tensor([[1., 1.], [1., 1.]]) ##\u521d\u59cb\u5316\uff0c\u4f7f\u75280\u586b\u5145 zero = torch . zeros ( 2 , 2 ) zero tensor([[0., 0.], [0., 0.]]) #\u521d\u59cb\u5316\u4e00\u4e2a\u5355\u4f4d\u77e9\u9635\uff0c\u5373\u5bf9\u89d2\u7ebf\u4e3a1 \u5176\u4ed6\u4e3a0 eye = torch . eye ( 2 , 2 ) eye tensor([[1., 0.], [0., 1.]])","title":"\u521d\u59cb\u5316"},{"location":"tutorial/chapter02_basics/2_1_1_pytorch-basics-tensor/#_4","text":"PyTorch\u4e2d\u5bf9\u5f20\u91cf\u7684\u64cd\u4f5capi \u548c NumPy \u975e\u5e38\u76f8\u4f3c\uff0c\u5982\u679c\u719f\u6089 NumPy \u4e2d\u7684\u64cd\u4f5c\uff0c\u90a3\u4e48 \u4ed6\u4eec\u4e8c\u8005 \u57fa\u672c\u662f\u4e00\u81f4\u7684\uff1a x = torch . randn ( 3 , 3 ) print ( x ) tensor([[ 0.6922, -0.4824, 0.8594], [ 0.4509, -0.8155, -0.0368], [ 1.3533, 0.5545, -0.0509]]) # \u6cbf\u7740\u884c\u53d6\u6700\u5927\u503c max_value , max_idx = torch . max ( x , dim = 1 ) print ( max_value , max_idx ) tensor([0.8594, 0.4509, 1.3533]) tensor([2, 0, 0]) # \u6bcf\u884c x \u6c42\u548c sum_x = torch . sum ( x , dim = 1 ) print ( sum_x ) tensor([ 1.0692, -0.4014, 1.8568]) y = torch . randn ( 3 , 3 ) z = x + y print ( z ) tensor([[-0.3821, -2.6932, -1.3884], [ 0.7468, -0.7697, -0.0883], [ 0.7688, -1.3485, 0.7517]]) \u6b63\u5982\u5b98\u65b960\u5206\u949f\u6559\u7a0b\u4e2d\u6240\u8bf4\uff0c\u4ee5_\u4e3a\u7ed3\u5c3e\u7684\uff0c\u5747\u4f1a\u6539\u53d8\u8c03\u7528\u503c # add \u5b8c\u6210\u540ex\u7684\u503c\u6539\u53d8\u4e86 x . add_ ( y ) print ( x ) tensor([[-0.3821, -2.6932, -1.3884], [ 0.7468, -0.7697, -0.0883], [ 0.7688, -1.3485, 0.7517]]) \u5f20\u91cf\u7684\u57fa\u672c\u64cd\u4f5c\u90fd\u4ecb\u7ecd\u7684\u7684\u5dee\u4e0d\u591a\u4e86\uff0c\u4e0b\u4e00\u7ae0\u4ecb\u7ecdPyTorch\u7684\u81ea\u52a8\u6c42\u5bfc\u673a\u5236","title":"\u5e38\u7528\u65b9\u6cd5"},{"location":"tutorial/chapter02_basics/2_1_2_pytorch-basics-autograd/","text":"import torch torch . __version__ '1.0.1.post2' \u4f7f\u7528PyTorch\u8ba1\u7b97\u68af\u5ea6\u6570\u503c \u00b6 PyTorch\u7684Autograd\u6a21\u5757\u5b9e\u73b0\u4e86\u6df1\u5ea6\u5b66\u4e60\u7684\u7b97\u6cd5\u4e2d\u7684\u5411\u4f20\u64ad\u6c42\u5bfc\u6570\uff0c\u5728\u5f20\u91cf\uff08Tensor\u7c7b\uff09\u4e0a\u7684\u6240\u6709\u64cd\u4f5c\uff0cAutograd\u90fd\u80fd\u4e3a\u4ed6\u4eec\u81ea\u52a8\u63d0\u4f9b\u5fae\u5206\uff0c\u7b80\u5316\u4e86\u624b\u52a8\u8ba1\u7b97\u5bfc\u6570\u7684\u590d\u6742\u8fc7\u7a0b\u3002 \u57280.4\u4ee5\u524d\u7684\u7248\u672c\u4e2d\uff0cPytorch\u4f7f\u7528Variable\u7c7b\u6765\u81ea\u52a8\u8ba1\u7b97\u6240\u6709\u7684\u68af\u5ea6Variable\u7c7b\u4e3b\u8981\u5305\u542b\u4e09\u4e2a\u5c5e\u6027\uff1a data\uff1a\u4fdd\u5b58Variable\u6240\u5305\u542b\u7684Tensor\uff1bgrad\uff1a\u4fdd\u5b58data\u5bf9\u5e94\u7684\u68af\u5ea6\uff0cgrad\u4e5f\u662f\u4e2aVariable\uff0c\u800c\u4e0d\u662fTensor\uff0c\u5b83\u548cdata\u7684\u5f62\u72b6\u4e00\u6837\uff1bgrad_fn\uff1a\u6307\u5411\u4e00\u4e2aFunction\u5bf9\u8c61\uff0c\u8fd9\u4e2aFunction\u7528\u6765\u53cd\u5411\u4f20\u64ad\u8ba1\u7b97\u8f93\u5165\u7684\u68af\u5ea6\u3002 \u4ece0.4\u8d77, Variable \u6b63\u5f0f\u5408\u5e76\u5165Tensor\u7c7b, \u901a\u8fc7Variable\u5d4c\u5957\u5b9e\u73b0\u7684\u81ea\u52a8\u5fae\u5206\u529f\u80fd\u5df2\u7ecf\u6574\u5408\u8fdb\u5165\u4e86Tensor\u7c7b\u4e2d\u3002\u867d\u7136\u4e3a\u4e86\u4ee3\u7801\u7684\u517c\u5bb9\u6027\u8fd8\u662f\u53ef\u4ee5\u4f7f\u7528Variable(tensor)\u8fd9\u79cd\u65b9\u5f0f\u8fdb\u884c\u5d4c\u5957, \u4f46\u662f\u8fd9\u4e2a\u64cd\u4f5c\u5176\u5b9e\u4ec0\u4e48\u90fd\u6ca1\u505a\u3002 \u6240\u4ee5\uff0c\u4ee5\u540e\u7684\u4ee3\u7801\u5efa\u8bae\u76f4\u63a5\u4f7f\u7528Tensor\u7c7b\u8fdb\u884c\u64cd\u4f5c\uff0c\u56e0\u4e3a\u5b98\u65b9\u6587\u6863\u4e2d\u5df2\u7ecf\u5c06Variable\u8bbe\u7f6e\u6210\u8fc7\u671f\u6a21\u5757\u3002 \u8981\u60f3\u901a\u8fc7Tensor\u7c7b\u672c\u8eab\u5c31\u652f\u6301\u4e86\u4f7f\u7528autograd\u529f\u80fd\uff0c\u53ea\u9700\u8981\u8bbe\u7f6e.requries_grad=True Variable\u7c7b\u4e2d\u7684\u7684grad\u548cgrad_fn\u5c5e\u6027\u5df2\u7ecf\u6574\u5408\u8fdb\u5165\u4e86Tensor\u7c7b\u4e2d Autograd \u00b6 \u5728\u5f20\u91cf\u521b\u5efa\u65f6\uff0c\u901a\u8fc7\u8bbe\u7f6e requires_grad \u6807\u8bc6\u4e3aTure\u6765\u544a\u8bc9Pytorch\u9700\u8981\u5bf9\u8be5\u5f20\u91cf\u8fdb\u884c\u81ea\u52a8\u6c42\u5bfc\uff0cPyTorch\u4f1a\u8bb0\u5f55\u8be5\u5f20\u91cf\u7684\u6bcf\u4e00\u6b65\u64cd\u4f5c\u5386\u53f2\u5e76\u81ea\u52a8\u8ba1\u7b97 x = torch . rand ( 5 , 5 , requires_grad = True ) x tensor([[0.0403, 0.5633, 0.2561, 0.4064, 0.9596], [0.6928, 0.1832, 0.5380, 0.6386, 0.8710], [0.5332, 0.8216, 0.8139, 0.1925, 0.4993], [0.2650, 0.6230, 0.5945, 0.3230, 0.0752], [0.0919, 0.4770, 0.4622, 0.6185, 0.2761]], requires_grad=True) y = torch . rand ( 5 , 5 , requires_grad = True ) y tensor([[0.2269, 0.7673, 0.8179, 0.5558, 0.0493], [0.7762, 0.9242, 0.2872, 0.0035, 0.4197], [0.4322, 0.5281, 0.9001, 0.7276, 0.3218], [0.5123, 0.6567, 0.9465, 0.0475, 0.9172], [0.9899, 0.9284, 0.5303, 0.1718, 0.3937]], requires_grad=True) PyTorch\u4f1a\u81ea\u52a8\u8ffd\u8e2a\u548c\u8bb0\u5f55\u5bf9\u4e0e\u5f20\u91cf\u7684\u6240\u6709\u64cd\u4f5c\uff0c\u5f53\u8ba1\u7b97\u5b8c\u6210\u540e\u8c03\u7528.backward()\u65b9\u6cd5\u81ea\u52a8\u8ba1\u7b97\u68af\u5ea6\u5e76\u4e14\u5c06\u8ba1\u7b97\u7ed3\u679c\u4fdd\u5b58\u5230grad\u5c5e\u6027\u4e2d\u3002 z = torch . sum ( x + y ) z tensor(25.6487, grad_fn=<SumBackward0>) \u5728\u5f20\u91cf\u8fdb\u884c\u64cd\u4f5c\u540e\uff0cgrad_fn\u5df2\u7ecf\u88ab\u8d4b\u4e88\u4e86\u4e00\u4e2a\u65b0\u7684\u51fd\u6570\uff0c\u8fd9\u4e2a\u51fd\u6570\u5f15\u7528\u4e86\u4e00\u4e2a\u521b\u5efa\u4e86\u8fd9\u4e2aTensor\u7c7b\u7684Function\u5bf9\u8c61\u3002 Tensor\u548cFunction\u4e92\u76f8\u8fde\u63a5\u751f\u6210\u4e86\u4e00\u4e2a\u975e\u5faa\u73af\u56fe\uff0c\u5b83\u8bb0\u5f55\u5e76\u4e14\u7f16\u7801\u4e86\u5b8c\u6574\u7684\u8ba1\u7b97\u5386\u53f2\u3002\u6bcf\u4e2a\u5f20\u91cf\u90fd\u6709\u4e00\u4e2a.grad_fn\u5c5e\u6027\uff0c\u5982\u679c\u8fd9\u4e2a\u5f20\u91cf\u662f\u7528\u6237\u624b\u52a8\u521b\u5efa\u7684\u90a3\u4e48\u8fd9\u4e2a\u5f20\u91cf\u7684grad_fn\u662fNone\u3002 \u4e0b\u9762\u6211\u4eec\u6765\u8c03\u7528\u53cd\u5411\u4f20\u64ad\u51fd\u6570\uff0c\u8ba1\u7b97\u5176\u68af\u5ea6 \u7b80\u5355\u7684\u81ea\u52a8\u6c42\u5bfc \u00b6 z . backward () print ( x . grad , y . grad ) tensor([[1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.]]) tensor([[1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.]]) \u5982\u679cTensor\u7c7b\u8868\u793a\u7684\u662f\u4e00\u4e2a\u6807\u91cf\uff08\u5373\u5b83\u5305\u542b\u4e00\u4e2a\u5143\u7d20\u7684\u5f20\u91cf\uff09\uff0c\u5219\u4e0d\u9700\u8981\u4e3abackward()\u6307\u5b9a\u4efb\u4f55\u53c2\u6570\uff0c\u4f46\u662f\u5982\u679c\u5b83\u6709\u66f4\u591a\u7684\u5143\u7d20\uff0c\u5219\u9700\u8981\u6307\u5b9a\u4e00\u4e2agradient\u53c2\u6570\uff0c\u5b83\u662f\u5f62\u72b6\u5339\u914d\u7684\u5f20\u91cf\u3002 \u4ee5\u4e0a\u7684 z.backward() \u76f8\u5f53\u4e8e\u662f z.backward(torch.tensor(1.)) \u7684\u7b80\u5199\u3002 \u8fd9\u79cd\u53c2\u6570\u5e38\u51fa\u73b0\u5728\u56fe\u50cf\u5206\u7c7b\u4e2d\u7684\u5355\u6807\u7b7e\u5206\u7c7b\uff0c\u8f93\u51fa\u4e00\u4e2a\u6807\u91cf\u4ee3\u8868\u56fe\u50cf\u7684\u6807\u7b7e\u3002 \u590d\u6742\u7684\u81ea\u52a8\u6c42\u5bfc \u00b6 x = torch . rand ( 5 , 5 , requires_grad = True ) y = torch . rand ( 5 , 5 , requires_grad = True ) z = x ** 2 + y ** 3 z tensor([[3.3891e-01, 4.9468e-01, 8.0797e-02, 2.5656e-01, 2.9529e-01], [7.1946e-01, 1.6977e-02, 1.7965e-01, 3.2656e-01, 1.7665e-01], [3.1353e-01, 2.2096e-01, 1.2251e+00, 5.5087e-01, 5.9572e-02], [1.3015e+00, 3.8029e-01, 1.1103e+00, 4.0392e-01, 2.2055e-01], [8.8726e-02, 6.9701e-01, 8.0164e-01, 9.7221e-01, 4.2239e-04]], grad_fn=<AddBackward0>) #\u6211\u4eec\u7684\u8fd4\u56de\u503c\u4e0d\u662f\u4e00\u4e2a\u6807\u91cf\uff0c\u6240\u4ee5\u9700\u8981\u8f93\u5165\u4e00\u4e2a\u5927\u5c0f\u76f8\u540c\u7684\u5f20\u91cf\u4f5c\u4e3a\u53c2\u6570\uff0c\u8fd9\u91cc\u6211\u4eec\u7528ones_like\u51fd\u6570\u6839\u636ex\u751f\u6210\u4e00\u4e2a\u5f20\u91cf z . backward ( torch . ones_like ( x )) print ( x . grad ) tensor([[0.2087, 1.3554, 0.5560, 1.0009, 0.9931], [1.2655, 0.1223, 0.8008, 1.1127, 0.7261], [1.1052, 0.2579, 1.8006, 0.1544, 0.3646], [1.8855, 1.2296, 1.9061, 0.9313, 0.0648], [0.5952, 1.6190, 0.8430, 1.9213, 0.0322]]) \u6211\u4eec\u53ef\u4ee5\u4f7f\u7528with torch.no_grad()\u4e0a\u4e0b\u6587\u7ba1\u7406\u5668\u4e34\u65f6\u7981\u6b62\u5bf9\u5df2\u8bbe\u7f6erequires_grad=True\u7684\u5f20\u91cf\u8fdb\u884c\u81ea\u52a8\u6c42\u5bfc\u3002\u8fd9\u4e2a\u65b9\u6cd5\u5728\u6d4b\u8bd5\u96c6\u8ba1\u7b97\u51c6\u786e\u7387\u7684\u65f6\u5019\u4f1a\u7ecf\u5e38\u7528\u5230\uff0c\u4f8b\u5982\uff1a with torch . no_grad (): print (( x + y * 2 ) . requires_grad ) False \u4f7f\u7528.no_grad()\u8fdb\u884c\u5d4c\u5957\u540e\uff0c\u4ee3\u7801\u4e0d\u4f1a\u8ddf\u8e2a\u5386\u53f2\u8bb0\u5f55\u4e5f\u5c31\u662f\u8bf4\u4fdd\u5b58\u8fd9\u90e8\u5206\u8bb0\u5f55\u7684\u5185\u5b58\u4e0d\u7cca\u4f1a\u51cf\u5c11\u5185\u5b58\u7684\u4f7f\u7528\u91cf\u5e76\u4e14\u4f1a\u52a0\u5feb\u5c11\u8bb8\u7684\u8fd0\u7b97\u901f\u5ea6\u3002 Autograd \u8fc7\u7a0b\u89e3\u6790 \u00b6 \u4e3a\u4e86\u8bf4\u660ePytorch\u7684\u81ea\u52a8\u6c42\u5bfc\u539f\u7406\uff0c\u6211\u4eec\u6765\u5c1d\u8bd5\u5206\u6790\u4e00\u4e0bPyTorch\u7684\u6e90\u4ee3\u7801\uff0c\u867d\u7136Pytorch\u7684 Tensor\u548c TensorBase\u90fd\u662f\u4f7f\u7528CPP\u6765\u5b9e\u73b0\u7684\uff0c\u4f46\u662f\u53ef\u4ee5\u4f7f\u7528\u4e00\u4e9bPython\u7684\u4e00\u4e9b\u65b9\u6cd5\u67e5\u770b\u8fd9\u4e9b\u5bf9\u8c61\u5728Python\u7684\u5c5e\u6027\u548c\u72b6\u6001\u3002 Python\u7684 dir() \u8fd4\u56de\u53c2\u6570\u7684\u5c5e\u6027\u3001\u65b9\u6cd5\u5217\u8868\u3002 z \u662f\u4e00\u4e2aTensor\u53d8\u91cf\uff0c\u770b\u770b\u91cc\u9762\u6709\u54ea\u4e9b\u6210\u5458\u53d8\u91cf\u3002 dir ( z ) ['__abs__', '__add__', '__and__', '__array__', '__array_priority__', '__array_wrap__', '__bool__', '__class__', '__deepcopy__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__div__', '__doc__', '__eq__', '__float__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__iand__', '__idiv__', '__ilshift__', '__imul__', '__index__', '__init__', '__init_subclass__', '__int__', '__invert__', '__ior__', '__ipow__', '__irshift__', '__isub__', '__iter__', '__itruediv__', '__ixor__', '__le__', '__len__', '__long__', '__lshift__', '__lt__', '__matmul__', '__mod__', '__module__', '__mul__', '__ne__', '__neg__', '__new__', '__nonzero__', '__or__', '__pow__', '__radd__', '__rdiv__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rfloordiv__', '__rmul__', '__rpow__', '__rshift__', '__rsub__', '__rtruediv__', '__setattr__', '__setitem__', '__setstate__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__weakref__', '__xor__', '_backward_hooks', '_base', '_cdata', '_coalesced_', '_dimI', '_dimV', '_grad', '_grad_fn', '_indices', '_make_subclass', '_nnz', '_values', '_version', 'abs', 'abs_', 'acos', 'acos_', 'add', 'add_', 'addbmm', 'addbmm_', 'addcdiv', 'addcdiv_', 'addcmul', 'addcmul_', 'addmm', 'addmm_', 'addmv', 'addmv_', 'addr', 'addr_', 'all', 'allclose', 'any', 'apply_', 'argmax', 'argmin', 'argsort', 'as_strided', 'as_strided_', 'asin', 'asin_', 'atan', 'atan2', 'atan2_', 'atan_', 'backward', 'baddbmm', 'baddbmm_', 'bernoulli', 'bernoulli_', 'bincount', 'bmm', 'btrifact', 'btrifact_with_info', 'btrisolve', 'byte', 'cauchy_', 'ceil', 'ceil_', 'char', 'cholesky', 'chunk', 'clamp', 'clamp_', 'clamp_max', 'clamp_max_', 'clamp_min', 'clamp_min_', 'clone', 'coalesce', 'contiguous', 'copy_', 'cos', 'cos_', 'cosh', 'cosh_', 'cpu', 'cross', 'cuda', 'cumprod', 'cumsum', 'data', 'data_ptr', 'dense_dim', 'det', 'detach', 'detach_', 'device', 'diag', 'diag_embed', 'diagflat', 'diagonal', 'digamma', 'digamma_', 'dim', 'dist', 'div', 'div_', 'dot', 'double', 'dtype', 'eig', 'element_size', 'eq', 'eq_', 'equal', 'erf', 'erf_', 'erfc', 'erfc_', 'erfinv', 'erfinv_', 'exp', 'exp_', 'expand', 'expand_as', 'expm1', 'expm1_', 'exponential_', 'fft', 'fill_', 'flatten', 'flip', 'float', 'floor', 'floor_', 'fmod', 'fmod_', 'frac', 'frac_', 'gather', 'ge', 'ge_', 'gels', 'geometric_', 'geqrf', 'ger', 'gesv', 'get_device', 'grad', 'grad_fn', 'gt', 'gt_', 'half', 'hardshrink', 'histc', 'ifft', 'index_add', 'index_add_', 'index_copy', 'index_copy_', 'index_fill', 'index_fill_', 'index_put', 'index_put_', 'index_select', 'indices', 'int', 'inverse', 'irfft', 'is_coalesced', 'is_complex', 'is_contiguous', 'is_cuda', 'is_distributed', 'is_floating_point', 'is_leaf', 'is_nonzero', 'is_pinned', 'is_same_size', 'is_set_to', 'is_shared', 'is_signed', 'is_sparse', 'isclose', 'item', 'kthvalue', 'layout', 'le', 'le_', 'lerp', 'lerp_', 'lgamma', 'lgamma_', 'log', 'log10', 'log10_', 'log1p', 'log1p_', 'log2', 'log2_', 'log_', 'log_normal_', 'log_softmax', 'logdet', 'logsumexp', 'long', 'lt', 'lt_', 'map2_', 'map_', 'masked_fill', 'masked_fill_', 'masked_scatter', 'masked_scatter_', 'masked_select', 'matmul', 'matrix_power', 'max', 'mean', 'median', 'min', 'mm', 'mode', 'mul', 'mul_', 'multinomial', 'mv', 'mvlgamma', 'mvlgamma_', 'name', 'narrow', 'narrow_copy', 'ndimension', 'ne', 'ne_', 'neg', 'neg_', 'nelement', 'new', 'new_empty', 'new_full', 'new_ones', 'new_tensor', 'new_zeros', 'nonzero', 'norm', 'normal_', 'numel', 'numpy', 'orgqr', 'ormqr', 'output_nr', 'permute', 'pin_memory', 'pinverse', 'polygamma', 'polygamma_', 'potrf', 'potri', 'potrs', 'pow', 'pow_', 'prelu', 'prod', 'pstrf', 'put_', 'qr', 'random_', 'reciprocal', 'reciprocal_', 'record_stream', 'register_hook', 'reinforce', 'relu', 'relu_', 'remainder', 'remainder_', 'renorm', 'renorm_', 'repeat', 'requires_grad', 'requires_grad_', 'reshape', 'reshape_as', 'resize', 'resize_', 'resize_as', 'resize_as_', 'retain_grad', 'rfft', 'roll', 'rot90', 'round', 'round_', 'rsqrt', 'rsqrt_', 'scatter', 'scatter_', 'scatter_add', 'scatter_add_', 'select', 'set_', 'shape', 'share_memory_', 'short', 'sigmoid', 'sigmoid_', 'sign', 'sign_', 'sin', 'sin_', 'sinh', 'sinh_', 'size', 'slogdet', 'smm', 'softmax', 'sort', 'sparse_dim', 'sparse_mask', 'sparse_resize_', 'sparse_resize_and_clear_', 'split', 'split_with_sizes', 'sqrt', 'sqrt_', 'squeeze', 'squeeze_', 'sspaddmm', 'std', 'stft', 'storage', 'storage_offset', 'storage_type', 'stride', 'sub', 'sub_', 'sum', 'svd', 'symeig', 't', 't_', 'take', 'tan', 'tan_', 'tanh', 'tanh_', 'to', 'to_dense', 'to_sparse', 'tolist', 'topk', 'trace', 'transpose', 'transpose_', 'tril', 'tril_', 'triu', 'triu_', 'trtrs', 'trunc', 'trunc_', 'type', 'type_as', 'unbind', 'unfold', 'uniform_', 'unique', 'unsqueeze', 'unsqueeze_', 'values', 'var', 'view', 'view_as', 'where', 'zero_'] \u8fd4\u56de\u5f88\u591a\uff0c\u6211\u4eec\u76f4\u63a5\u6392\u9664\u6389\u4e00\u4e9bPython\u4e2d\u7279\u6b8a\u65b9\u6cd5\uff08\u4ee5__\u5f00\u5934\u548c\u7ed3\u675f\u7684\uff09\u548c\u79c1\u6709\u65b9\u6cd5\uff08\u4ee5_\u5f00\u5934\u7684\uff0c\u76f4\u63a5\u770b\u51e0\u4e2a\u6bd4\u8f83\u4e3b\u8981\u7684\u5c5e\u6027\uff1a .is_leaf \uff1a\u8bb0\u5f55\u662f\u5426\u662f\u53f6\u5b50\u8282\u70b9\u3002\u901a\u8fc7\u8fd9\u4e2a\u5c5e\u6027\u6765\u786e\u5b9a\u8fd9\u4e2a\u53d8\u91cf\u7684\u7c7b\u578b \u5728\u5b98\u65b9\u6587\u6863\u4e2d\u6240\u8bf4\u7684\u201cgraph leaves\u201d,\u201cleaf variables\u201d\uff0c\u90fd\u662f\u6307\u50cf x , y \u8fd9\u6837\u7684\u624b\u52a8\u521b\u5efa\u7684\u3001\u800c\u975e\u8fd0\u7b97\u5f97\u5230\u7684\u53d8\u91cf\uff0c\u8fd9\u4e9b\u53d8\u91cf\u6210\u4e3a\u521b\u5efa\u53d8\u91cf\u3002 \u50cf z \u8fd9\u6837\u7684\uff0c\u662f\u901a\u8fc7\u8ba1\u7b97\u540e\u5f97\u5230\u7684\u7ed3\u679c\u79f0\u4e3a\u7ed3\u679c\u53d8\u91cf\u3002 \u4e00\u4e2a\u53d8\u91cf\u662f\u521b\u5efa\u53d8\u91cf\u8fd8\u662f\u7ed3\u679c\u53d8\u91cf\u662f\u901a\u8fc7 .is_leaf \u6765\u83b7\u53d6\u7684\u3002 print ( \"x.is_leaf=\" + str ( x . is_leaf )) print ( \"z.is_leaf=\" + str ( z . is_leaf )) x.is_leaf=True z.is_leaf=False x \u662f\u624b\u52a8\u521b\u5efa\u7684\u6ca1\u6709\u901a\u8fc7\u8ba1\u7b97\uff0c\u6240\u4ee5\u4ed6\u88ab\u8ba4\u4e3a\u662f\u4e00\u4e2a\u53f6\u5b50\u8282\u70b9\u4e5f\u5c31\u662f\u4e00\u4e2a\u521b\u5efa\u53d8\u91cf\uff0c\u800c z \u662f\u901a\u8fc7 x \u4e0e y \u7684\u4e00\u7cfb\u5217\u8ba1\u7b97\u5f97\u5230\u7684\uff0c\u6240\u4ee5\u4e0d\u662f\u53f6\u5b50\u7ed3\u70b9\u4e5f\u5c31\u662f\u7ed3\u679c\u53d8\u91cf\u3002 \u4e3a\u4ec0\u4e48\u6211\u4eec\u6267\u884c z.backward() \u65b9\u6cd5\u4f1a\u66f4\u65b0 x.grad \u548c y.grad \u5462\uff1f .grad_fn \u5c5e\u6027\u8bb0\u5f55\u7684\u5c31\u662f\u8fd9\u90e8\u5206\u7684\u64cd\u4f5c\uff0c\u867d\u7136 .backward() \u65b9\u6cd5\u4e5f\u662fCPP\u5b9e\u73b0\u7684\uff0c\u4f46\u662f\u53ef\u4ee5\u901a\u8fc7Python\u6765\u8fdb\u884c\u7b80\u5355\u7684\u63a2\u7d22\u3002 grad_fn \uff1a\u8bb0\u5f55\u5e76\u4e14\u7f16\u7801\u4e86\u5b8c\u6574\u7684\u8ba1\u7b97\u5386\u53f2 z . grad_fn <AddBackward0 at 0x120840a90> grad_fn \u662f\u4e00\u4e2a AddBackward0 \u7c7b\u578b\u7684\u53d8\u91cf AddBackward0 \u8fd9\u4e2a\u7c7b\u4e5f\u662f\u7528Cpp\u6765\u5199\u7684,\u4f46\u662f\u6211\u4eec\u4ece\u540d\u5b57\u91cc\u5c31\u80fd\u591f\u5927\u6982\u77e5\u9053\uff0c\u4ed6\u662f\u52a0\u6cd5(ADD)\u7684\u53cd\u53cd\u5411\u4f20\u64ad\uff08Backward\uff09\uff0c\u770b\u770b\u91cc\u9762\u6709\u4e9b\u4ec0\u4e48\u4e1c\u897f dir ( z . grad_fn ) ['__call__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '_register_hook_dict', 'metadata', 'name', 'next_functions', 'register_hook', 'requires_grad'] next_functions \u5c31\u662f grad_fn \u7684\u7cbe\u534e z . grad_fn . next_functions ((<PowBackward0 at 0x1208409b0>, 0), (<PowBackward0 at 0x1208408d0>, 0)) next_functions \u662f\u4e00\u4e2atuple of tuple of PowBackward0 and int\u3002 \u4e3a\u4ec0\u4e48\u662f2\u4e2atuple \uff1f \u56e0\u4e3a\u6211\u4eec\u7684\u64cd\u4f5c\u662f z= x**2+y**3 \u521a\u624d\u7684 AddBackward0 \u662f\u76f8\u52a0\uff0c\u800c\u524d\u9762\u7684\u64cd\u4f5c\u662f\u4e58\u65b9 PowBackward0 \u3002tuple\u7b2c\u4e00\u4e2a\u5143\u7d20\u5c31\u662fx\u76f8\u5173\u7684\u64cd\u4f5c\u8bb0\u5f55 xg = z . grad_fn . next_functions [ 0 ][ 0 ] dir ( xg ) ['__call__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '_register_hook_dict', 'metadata', 'name', 'next_functions', 'register_hook', 'requires_grad'] \u7ee7\u7eed\u6df1\u6316 x_leaf = xg . next_functions [ 0 ][ 0 ] type ( x_leaf ) AccumulateGrad \u5728PyTorch\u7684\u53cd\u5411\u56fe\u8ba1\u7b97\u4e2d\uff0c AccumulateGrad \u7c7b\u578b\u4ee3\u8868\u7684\u5c31\u662f\u53f6\u5b50\u8282\u70b9\u7c7b\u578b\uff0c\u4e5f\u5c31\u662f\u8ba1\u7b97\u56fe\u7ec8\u6b62\u8282\u70b9\u3002 AccumulateGrad \u7c7b\u4e2d\u6709\u4e00\u4e2a .variable \u5c5e\u6027\u6307\u5411\u53f6\u5b50\u8282\u70b9\u3002 x_leaf . variable tensor([[0.1044, 0.6777, 0.2780, 0.5005, 0.4966], [0.6328, 0.0611, 0.4004, 0.5564, 0.3631], [0.5526, 0.1290, 0.9003, 0.0772, 0.1823], [0.9428, 0.6148, 0.9530, 0.4657, 0.0324], [0.2976, 0.8095, 0.4215, 0.9606, 0.0161]], requires_grad=True) \u8fd9\u4e2a .variable \u7684\u5c5e\u6027\u5c31\u662f\u6211\u4eec\u7684\u751f\u6210\u7684\u53d8\u91cf x print ( \"x_leaf.variable\u7684id:\" + str ( id ( x_leaf . variable ))) print ( \"x\u7684id:\" + str ( id ( x ))) x_leaf.variable\u7684id:4840553424 x\u7684id:4840553424 assert ( id ( x_leaf . variable ) == id ( x )) \u8fd9\u6837\u6574\u4e2a\u89c4\u7a0b\u5c31\u5f88\u6e05\u6670\u4e86\uff1a \u5f53\u6211\u4eec\u6267\u884cz.backward()\u7684\u65f6\u5019\u3002\u8fd9\u4e2a\u64cd\u4f5c\u5c06\u8c03\u7528z\u91cc\u9762\u7684grad_fn\u8fd9\u4e2a\u5c5e\u6027\uff0c\u6267\u884c\u6c42\u5bfc\u7684\u64cd\u4f5c\u3002 \u8fd9\u4e2a\u64cd\u4f5c\u5c06\u904d\u5386grad_fn\u7684next_functions\uff0c\u7136\u540e\u5206\u522b\u53d6\u51fa\u91cc\u9762\u7684Function\uff08AccumulateGrad\uff09\uff0c\u6267\u884c\u6c42\u5bfc\u64cd\u4f5c\u3002\u8fd9\u90e8\u5206\u662f\u4e00\u4e2a\u9012\u5f52\u7684\u8fc7\u7a0b\u76f4\u5230\u6700\u540e\u7c7b\u578b\u4e3a\u53f6\u5b50\u8282\u70b9\u3002 \u8ba1\u7b97\u51fa\u7ed3\u679c\u4ee5\u540e\uff0c\u5c06\u7ed3\u679c\u4fdd\u5b58\u5230\u4ed6\u4eec\u5bf9\u5e94\u7684variable \u8fd9\u4e2a\u53d8\u91cf\u6240\u5f15\u7528\u7684\u5bf9\u8c61\uff08x\u548cy\uff09\u7684 grad\u8fd9\u4e2a\u5c5e\u6027\u91cc\u9762\u3002 \u6c42\u5bfc\u7ed3\u675f\u3002\u6240\u6709\u7684\u53f6\u8282\u70b9\u7684grad\u53d8\u91cf\u90fd\u5f97\u5230\u4e86\u76f8\u5e94\u7684\u66f4\u65b0 \u6700\u7ec8\u5f53\u6211\u4eec\u6267\u884c\u5b8cc.backward()\u4e4b\u540e\uff0ca\u548cb\u91cc\u9762\u7684grad\u503c\u5c31\u5f97\u5230\u4e86\u66f4\u65b0\u3002 \u6269\u5c55Autograd \u00b6 \u5982\u679c\u9700\u8981\u81ea\u5b9a\u4e49autograd\u6269\u5c55\u65b0\u7684\u529f\u80fd\uff0c\u5c31\u9700\u8981\u6269\u5c55Function\u7c7b\u3002\u56e0\u4e3aFunction\u4f7f\u7528autograd\u6765\u8ba1\u7b97\u7ed3\u679c\u548c\u68af\u5ea6\uff0c\u5e76\u5bf9\u64cd\u4f5c\u5386\u53f2\u8fdb\u884c\u7f16\u7801\u3002 \u5728Function\u7c7b\u4e2d\u6700\u4e3b\u8981\u7684\u65b9\u6cd5\u5c31\u662f forward() \u548c backward() \u4ed6\u4eec\u5206\u522b\u4ee3\u8868\u4e86\u524d\u5411\u4f20\u64ad\u548c\u53cd\u5411\u4f20\u64ad\u3002 \u4e00\u4e2a\u81ea\u5b9a\u4e49\u7684Function\u9700\u8981\u4e00\u4e0b\u4e09\u4e2a\u65b9\u6cd5\uff1a __init__ (optional)\uff1a\u5982\u679c\u8fd9\u4e2a\u64cd\u4f5c\u9700\u8981\u989d\u5916\u7684\u53c2\u6570\u5219\u9700\u8981\u5b9a\u4e49\u8fd9\u4e2aFunction\u7684\u6784\u9020\u51fd\u6570\uff0c\u4e0d\u9700\u8981\u7684\u8bdd\u53ef\u4ee5\u5ffd\u7565\u3002 forward()\uff1a\u6267\u884c\u524d\u5411\u4f20\u64ad\u7684\u8ba1\u7b97\u4ee3\u7801 backward()\uff1a\u53cd\u5411\u4f20\u64ad\u65f6\u68af\u5ea6\u8ba1\u7b97\u7684\u4ee3\u7801\u3002 \u53c2\u6570\u7684\u4e2a\u6570\u548cforward\u8fd4\u56de\u503c\u7684\u4e2a\u6570\u4e00\u6837\uff0c\u6bcf\u4e2a\u53c2\u6570\u4ee3\u8868\u4f20\u56de\u5230\u6b64\u64cd\u4f5c\u7684\u68af\u5ea6\u3002 # \u5f15\u5165Function\u4fbf\u4e8e\u6269\u5c55 from torch.autograd.function import Function # \u5b9a\u4e49\u4e00\u4e2a\u4e58\u4ee5\u5e38\u6570\u7684\u64cd\u4f5c(\u8f93\u5165\u53c2\u6570\u662f\u5f20\u91cf) # \u65b9\u6cd5\u5fc5\u987b\u662f\u9759\u6001\u65b9\u6cd5\uff0c\u6240\u4ee5\u8981\u52a0\u4e0a@staticmethod class MulConstant ( Function ): @staticmethod def forward ( ctx , tensor , constant ): # ctx \u7528\u6765\u4fdd\u5b58\u4fe1\u606f\u8fd9\u91cc\u7c7b\u4f3cself\uff0c\u5e76\u4e14ctx\u7684\u5c5e\u6027\u53ef\u4ee5\u5728backward\u4e2d\u8c03\u7528 ctx . constant = constant return tensor * constant @staticmethod def backward ( ctx , grad_output ): # \u8fd4\u56de\u7684\u53c2\u6570\u8981\u4e0e\u8f93\u5165\u7684\u53c2\u6570\u4e00\u6837. # \u7b2c\u4e00\u4e2a\u8f93\u5165\u4e3a3x3\u7684\u5f20\u91cf\uff0c\u7b2c\u4e8c\u4e2a\u4e3a\u4e00\u4e2a\u5e38\u6570 # \u5e38\u6570\u7684\u68af\u5ea6\u5fc5\u987b\u662f None. return grad_output , None \u5b9a\u4e49\u5b8c\u6211\u4eec\u7684\u65b0\u64cd\u4f5c\u540e\uff0c\u6211\u4eec\u6765\u8fdb\u884c\u6d4b\u8bd5 a = torch . rand ( 3 , 3 , requires_grad = True ) b = MulConstant . apply ( a , 5 ) print ( \"a:\" + str ( a )) print ( \"b:\" + str ( b )) # b\u4e3aa\u7684\u5143\u7d20\u4e58\u4ee55 a:tensor([[0.0118, 0.1434, 0.8669], [0.1817, 0.8904, 0.5852], [0.7364, 0.5234, 0.9677]], requires_grad=True) b:tensor([[0.0588, 0.7169, 4.3347], [0.9084, 4.4520, 2.9259], [3.6820, 2.6171, 4.8386]], grad_fn=<MulConstantBackward>) \u53cd\u5411\u4f20\u64ad\uff0c\u8fd4\u56de\u503c\u4e0d\u662f\u6807\u91cf\uff0c\u6240\u4ee5 backward \u65b9\u6cd5\u9700\u8981\u53c2\u6570 b . backward ( torch . ones_like ( a )) a . grad tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.]]) \u68af\u5ea6\u56e0\u4e3a1","title":"2.1.2 AutoGrad"},{"location":"tutorial/chapter02_basics/2_1_2_pytorch-basics-autograd/#pytorch","text":"PyTorch\u7684Autograd\u6a21\u5757\u5b9e\u73b0\u4e86\u6df1\u5ea6\u5b66\u4e60\u7684\u7b97\u6cd5\u4e2d\u7684\u5411\u4f20\u64ad\u6c42\u5bfc\u6570\uff0c\u5728\u5f20\u91cf\uff08Tensor\u7c7b\uff09\u4e0a\u7684\u6240\u6709\u64cd\u4f5c\uff0cAutograd\u90fd\u80fd\u4e3a\u4ed6\u4eec\u81ea\u52a8\u63d0\u4f9b\u5fae\u5206\uff0c\u7b80\u5316\u4e86\u624b\u52a8\u8ba1\u7b97\u5bfc\u6570\u7684\u590d\u6742\u8fc7\u7a0b\u3002 \u57280.4\u4ee5\u524d\u7684\u7248\u672c\u4e2d\uff0cPytorch\u4f7f\u7528Variable\u7c7b\u6765\u81ea\u52a8\u8ba1\u7b97\u6240\u6709\u7684\u68af\u5ea6Variable\u7c7b\u4e3b\u8981\u5305\u542b\u4e09\u4e2a\u5c5e\u6027\uff1a data\uff1a\u4fdd\u5b58Variable\u6240\u5305\u542b\u7684Tensor\uff1bgrad\uff1a\u4fdd\u5b58data\u5bf9\u5e94\u7684\u68af\u5ea6\uff0cgrad\u4e5f\u662f\u4e2aVariable\uff0c\u800c\u4e0d\u662fTensor\uff0c\u5b83\u548cdata\u7684\u5f62\u72b6\u4e00\u6837\uff1bgrad_fn\uff1a\u6307\u5411\u4e00\u4e2aFunction\u5bf9\u8c61\uff0c\u8fd9\u4e2aFunction\u7528\u6765\u53cd\u5411\u4f20\u64ad\u8ba1\u7b97\u8f93\u5165\u7684\u68af\u5ea6\u3002 \u4ece0.4\u8d77, Variable \u6b63\u5f0f\u5408\u5e76\u5165Tensor\u7c7b, \u901a\u8fc7Variable\u5d4c\u5957\u5b9e\u73b0\u7684\u81ea\u52a8\u5fae\u5206\u529f\u80fd\u5df2\u7ecf\u6574\u5408\u8fdb\u5165\u4e86Tensor\u7c7b\u4e2d\u3002\u867d\u7136\u4e3a\u4e86\u4ee3\u7801\u7684\u517c\u5bb9\u6027\u8fd8\u662f\u53ef\u4ee5\u4f7f\u7528Variable(tensor)\u8fd9\u79cd\u65b9\u5f0f\u8fdb\u884c\u5d4c\u5957, \u4f46\u662f\u8fd9\u4e2a\u64cd\u4f5c\u5176\u5b9e\u4ec0\u4e48\u90fd\u6ca1\u505a\u3002 \u6240\u4ee5\uff0c\u4ee5\u540e\u7684\u4ee3\u7801\u5efa\u8bae\u76f4\u63a5\u4f7f\u7528Tensor\u7c7b\u8fdb\u884c\u64cd\u4f5c\uff0c\u56e0\u4e3a\u5b98\u65b9\u6587\u6863\u4e2d\u5df2\u7ecf\u5c06Variable\u8bbe\u7f6e\u6210\u8fc7\u671f\u6a21\u5757\u3002 \u8981\u60f3\u901a\u8fc7Tensor\u7c7b\u672c\u8eab\u5c31\u652f\u6301\u4e86\u4f7f\u7528autograd\u529f\u80fd\uff0c\u53ea\u9700\u8981\u8bbe\u7f6e.requries_grad=True Variable\u7c7b\u4e2d\u7684\u7684grad\u548cgrad_fn\u5c5e\u6027\u5df2\u7ecf\u6574\u5408\u8fdb\u5165\u4e86Tensor\u7c7b\u4e2d","title":"\u4f7f\u7528PyTorch\u8ba1\u7b97\u68af\u5ea6\u6570\u503c"},{"location":"tutorial/chapter02_basics/2_1_2_pytorch-basics-autograd/#autograd","text":"\u5728\u5f20\u91cf\u521b\u5efa\u65f6\uff0c\u901a\u8fc7\u8bbe\u7f6e requires_grad \u6807\u8bc6\u4e3aTure\u6765\u544a\u8bc9Pytorch\u9700\u8981\u5bf9\u8be5\u5f20\u91cf\u8fdb\u884c\u81ea\u52a8\u6c42\u5bfc\uff0cPyTorch\u4f1a\u8bb0\u5f55\u8be5\u5f20\u91cf\u7684\u6bcf\u4e00\u6b65\u64cd\u4f5c\u5386\u53f2\u5e76\u81ea\u52a8\u8ba1\u7b97 x = torch . rand ( 5 , 5 , requires_grad = True ) x tensor([[0.0403, 0.5633, 0.2561, 0.4064, 0.9596], [0.6928, 0.1832, 0.5380, 0.6386, 0.8710], [0.5332, 0.8216, 0.8139, 0.1925, 0.4993], [0.2650, 0.6230, 0.5945, 0.3230, 0.0752], [0.0919, 0.4770, 0.4622, 0.6185, 0.2761]], requires_grad=True) y = torch . rand ( 5 , 5 , requires_grad = True ) y tensor([[0.2269, 0.7673, 0.8179, 0.5558, 0.0493], [0.7762, 0.9242, 0.2872, 0.0035, 0.4197], [0.4322, 0.5281, 0.9001, 0.7276, 0.3218], [0.5123, 0.6567, 0.9465, 0.0475, 0.9172], [0.9899, 0.9284, 0.5303, 0.1718, 0.3937]], requires_grad=True) PyTorch\u4f1a\u81ea\u52a8\u8ffd\u8e2a\u548c\u8bb0\u5f55\u5bf9\u4e0e\u5f20\u91cf\u7684\u6240\u6709\u64cd\u4f5c\uff0c\u5f53\u8ba1\u7b97\u5b8c\u6210\u540e\u8c03\u7528.backward()\u65b9\u6cd5\u81ea\u52a8\u8ba1\u7b97\u68af\u5ea6\u5e76\u4e14\u5c06\u8ba1\u7b97\u7ed3\u679c\u4fdd\u5b58\u5230grad\u5c5e\u6027\u4e2d\u3002 z = torch . sum ( x + y ) z tensor(25.6487, grad_fn=<SumBackward0>) \u5728\u5f20\u91cf\u8fdb\u884c\u64cd\u4f5c\u540e\uff0cgrad_fn\u5df2\u7ecf\u88ab\u8d4b\u4e88\u4e86\u4e00\u4e2a\u65b0\u7684\u51fd\u6570\uff0c\u8fd9\u4e2a\u51fd\u6570\u5f15\u7528\u4e86\u4e00\u4e2a\u521b\u5efa\u4e86\u8fd9\u4e2aTensor\u7c7b\u7684Function\u5bf9\u8c61\u3002 Tensor\u548cFunction\u4e92\u76f8\u8fde\u63a5\u751f\u6210\u4e86\u4e00\u4e2a\u975e\u5faa\u73af\u56fe\uff0c\u5b83\u8bb0\u5f55\u5e76\u4e14\u7f16\u7801\u4e86\u5b8c\u6574\u7684\u8ba1\u7b97\u5386\u53f2\u3002\u6bcf\u4e2a\u5f20\u91cf\u90fd\u6709\u4e00\u4e2a.grad_fn\u5c5e\u6027\uff0c\u5982\u679c\u8fd9\u4e2a\u5f20\u91cf\u662f\u7528\u6237\u624b\u52a8\u521b\u5efa\u7684\u90a3\u4e48\u8fd9\u4e2a\u5f20\u91cf\u7684grad_fn\u662fNone\u3002 \u4e0b\u9762\u6211\u4eec\u6765\u8c03\u7528\u53cd\u5411\u4f20\u64ad\u51fd\u6570\uff0c\u8ba1\u7b97\u5176\u68af\u5ea6","title":"Autograd"},{"location":"tutorial/chapter02_basics/2_1_2_pytorch-basics-autograd/#_1","text":"z . backward () print ( x . grad , y . grad ) tensor([[1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.]]) tensor([[1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.]]) \u5982\u679cTensor\u7c7b\u8868\u793a\u7684\u662f\u4e00\u4e2a\u6807\u91cf\uff08\u5373\u5b83\u5305\u542b\u4e00\u4e2a\u5143\u7d20\u7684\u5f20\u91cf\uff09\uff0c\u5219\u4e0d\u9700\u8981\u4e3abackward()\u6307\u5b9a\u4efb\u4f55\u53c2\u6570\uff0c\u4f46\u662f\u5982\u679c\u5b83\u6709\u66f4\u591a\u7684\u5143\u7d20\uff0c\u5219\u9700\u8981\u6307\u5b9a\u4e00\u4e2agradient\u53c2\u6570\uff0c\u5b83\u662f\u5f62\u72b6\u5339\u914d\u7684\u5f20\u91cf\u3002 \u4ee5\u4e0a\u7684 z.backward() \u76f8\u5f53\u4e8e\u662f z.backward(torch.tensor(1.)) \u7684\u7b80\u5199\u3002 \u8fd9\u79cd\u53c2\u6570\u5e38\u51fa\u73b0\u5728\u56fe\u50cf\u5206\u7c7b\u4e2d\u7684\u5355\u6807\u7b7e\u5206\u7c7b\uff0c\u8f93\u51fa\u4e00\u4e2a\u6807\u91cf\u4ee3\u8868\u56fe\u50cf\u7684\u6807\u7b7e\u3002","title":"\u7b80\u5355\u7684\u81ea\u52a8\u6c42\u5bfc"},{"location":"tutorial/chapter02_basics/2_1_2_pytorch-basics-autograd/#_2","text":"x = torch . rand ( 5 , 5 , requires_grad = True ) y = torch . rand ( 5 , 5 , requires_grad = True ) z = x ** 2 + y ** 3 z tensor([[3.3891e-01, 4.9468e-01, 8.0797e-02, 2.5656e-01, 2.9529e-01], [7.1946e-01, 1.6977e-02, 1.7965e-01, 3.2656e-01, 1.7665e-01], [3.1353e-01, 2.2096e-01, 1.2251e+00, 5.5087e-01, 5.9572e-02], [1.3015e+00, 3.8029e-01, 1.1103e+00, 4.0392e-01, 2.2055e-01], [8.8726e-02, 6.9701e-01, 8.0164e-01, 9.7221e-01, 4.2239e-04]], grad_fn=<AddBackward0>) #\u6211\u4eec\u7684\u8fd4\u56de\u503c\u4e0d\u662f\u4e00\u4e2a\u6807\u91cf\uff0c\u6240\u4ee5\u9700\u8981\u8f93\u5165\u4e00\u4e2a\u5927\u5c0f\u76f8\u540c\u7684\u5f20\u91cf\u4f5c\u4e3a\u53c2\u6570\uff0c\u8fd9\u91cc\u6211\u4eec\u7528ones_like\u51fd\u6570\u6839\u636ex\u751f\u6210\u4e00\u4e2a\u5f20\u91cf z . backward ( torch . ones_like ( x )) print ( x . grad ) tensor([[0.2087, 1.3554, 0.5560, 1.0009, 0.9931], [1.2655, 0.1223, 0.8008, 1.1127, 0.7261], [1.1052, 0.2579, 1.8006, 0.1544, 0.3646], [1.8855, 1.2296, 1.9061, 0.9313, 0.0648], [0.5952, 1.6190, 0.8430, 1.9213, 0.0322]]) \u6211\u4eec\u53ef\u4ee5\u4f7f\u7528with torch.no_grad()\u4e0a\u4e0b\u6587\u7ba1\u7406\u5668\u4e34\u65f6\u7981\u6b62\u5bf9\u5df2\u8bbe\u7f6erequires_grad=True\u7684\u5f20\u91cf\u8fdb\u884c\u81ea\u52a8\u6c42\u5bfc\u3002\u8fd9\u4e2a\u65b9\u6cd5\u5728\u6d4b\u8bd5\u96c6\u8ba1\u7b97\u51c6\u786e\u7387\u7684\u65f6\u5019\u4f1a\u7ecf\u5e38\u7528\u5230\uff0c\u4f8b\u5982\uff1a with torch . no_grad (): print (( x + y * 2 ) . requires_grad ) False \u4f7f\u7528.no_grad()\u8fdb\u884c\u5d4c\u5957\u540e\uff0c\u4ee3\u7801\u4e0d\u4f1a\u8ddf\u8e2a\u5386\u53f2\u8bb0\u5f55\u4e5f\u5c31\u662f\u8bf4\u4fdd\u5b58\u8fd9\u90e8\u5206\u8bb0\u5f55\u7684\u5185\u5b58\u4e0d\u7cca\u4f1a\u51cf\u5c11\u5185\u5b58\u7684\u4f7f\u7528\u91cf\u5e76\u4e14\u4f1a\u52a0\u5feb\u5c11\u8bb8\u7684\u8fd0\u7b97\u901f\u5ea6\u3002","title":"\u590d\u6742\u7684\u81ea\u52a8\u6c42\u5bfc"},{"location":"tutorial/chapter02_basics/2_1_2_pytorch-basics-autograd/#autograd_1","text":"\u4e3a\u4e86\u8bf4\u660ePytorch\u7684\u81ea\u52a8\u6c42\u5bfc\u539f\u7406\uff0c\u6211\u4eec\u6765\u5c1d\u8bd5\u5206\u6790\u4e00\u4e0bPyTorch\u7684\u6e90\u4ee3\u7801\uff0c\u867d\u7136Pytorch\u7684 Tensor\u548c TensorBase\u90fd\u662f\u4f7f\u7528CPP\u6765\u5b9e\u73b0\u7684\uff0c\u4f46\u662f\u53ef\u4ee5\u4f7f\u7528\u4e00\u4e9bPython\u7684\u4e00\u4e9b\u65b9\u6cd5\u67e5\u770b\u8fd9\u4e9b\u5bf9\u8c61\u5728Python\u7684\u5c5e\u6027\u548c\u72b6\u6001\u3002 Python\u7684 dir() \u8fd4\u56de\u53c2\u6570\u7684\u5c5e\u6027\u3001\u65b9\u6cd5\u5217\u8868\u3002 z \u662f\u4e00\u4e2aTensor\u53d8\u91cf\uff0c\u770b\u770b\u91cc\u9762\u6709\u54ea\u4e9b\u6210\u5458\u53d8\u91cf\u3002 dir ( z ) ['__abs__', '__add__', '__and__', '__array__', '__array_priority__', '__array_wrap__', '__bool__', '__class__', '__deepcopy__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__div__', '__doc__', '__eq__', '__float__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__iand__', '__idiv__', '__ilshift__', '__imul__', '__index__', '__init__', '__init_subclass__', '__int__', '__invert__', '__ior__', '__ipow__', '__irshift__', '__isub__', '__iter__', '__itruediv__', '__ixor__', '__le__', '__len__', '__long__', '__lshift__', '__lt__', '__matmul__', '__mod__', '__module__', '__mul__', '__ne__', '__neg__', '__new__', '__nonzero__', '__or__', '__pow__', '__radd__', '__rdiv__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rfloordiv__', '__rmul__', '__rpow__', '__rshift__', '__rsub__', '__rtruediv__', '__setattr__', '__setitem__', '__setstate__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__weakref__', '__xor__', '_backward_hooks', '_base', '_cdata', '_coalesced_', '_dimI', '_dimV', '_grad', '_grad_fn', '_indices', '_make_subclass', '_nnz', '_values', '_version', 'abs', 'abs_', 'acos', 'acos_', 'add', 'add_', 'addbmm', 'addbmm_', 'addcdiv', 'addcdiv_', 'addcmul', 'addcmul_', 'addmm', 'addmm_', 'addmv', 'addmv_', 'addr', 'addr_', 'all', 'allclose', 'any', 'apply_', 'argmax', 'argmin', 'argsort', 'as_strided', 'as_strided_', 'asin', 'asin_', 'atan', 'atan2', 'atan2_', 'atan_', 'backward', 'baddbmm', 'baddbmm_', 'bernoulli', 'bernoulli_', 'bincount', 'bmm', 'btrifact', 'btrifact_with_info', 'btrisolve', 'byte', 'cauchy_', 'ceil', 'ceil_', 'char', 'cholesky', 'chunk', 'clamp', 'clamp_', 'clamp_max', 'clamp_max_', 'clamp_min', 'clamp_min_', 'clone', 'coalesce', 'contiguous', 'copy_', 'cos', 'cos_', 'cosh', 'cosh_', 'cpu', 'cross', 'cuda', 'cumprod', 'cumsum', 'data', 'data_ptr', 'dense_dim', 'det', 'detach', 'detach_', 'device', 'diag', 'diag_embed', 'diagflat', 'diagonal', 'digamma', 'digamma_', 'dim', 'dist', 'div', 'div_', 'dot', 'double', 'dtype', 'eig', 'element_size', 'eq', 'eq_', 'equal', 'erf', 'erf_', 'erfc', 'erfc_', 'erfinv', 'erfinv_', 'exp', 'exp_', 'expand', 'expand_as', 'expm1', 'expm1_', 'exponential_', 'fft', 'fill_', 'flatten', 'flip', 'float', 'floor', 'floor_', 'fmod', 'fmod_', 'frac', 'frac_', 'gather', 'ge', 'ge_', 'gels', 'geometric_', 'geqrf', 'ger', 'gesv', 'get_device', 'grad', 'grad_fn', 'gt', 'gt_', 'half', 'hardshrink', 'histc', 'ifft', 'index_add', 'index_add_', 'index_copy', 'index_copy_', 'index_fill', 'index_fill_', 'index_put', 'index_put_', 'index_select', 'indices', 'int', 'inverse', 'irfft', 'is_coalesced', 'is_complex', 'is_contiguous', 'is_cuda', 'is_distributed', 'is_floating_point', 'is_leaf', 'is_nonzero', 'is_pinned', 'is_same_size', 'is_set_to', 'is_shared', 'is_signed', 'is_sparse', 'isclose', 'item', 'kthvalue', 'layout', 'le', 'le_', 'lerp', 'lerp_', 'lgamma', 'lgamma_', 'log', 'log10', 'log10_', 'log1p', 'log1p_', 'log2', 'log2_', 'log_', 'log_normal_', 'log_softmax', 'logdet', 'logsumexp', 'long', 'lt', 'lt_', 'map2_', 'map_', 'masked_fill', 'masked_fill_', 'masked_scatter', 'masked_scatter_', 'masked_select', 'matmul', 'matrix_power', 'max', 'mean', 'median', 'min', 'mm', 'mode', 'mul', 'mul_', 'multinomial', 'mv', 'mvlgamma', 'mvlgamma_', 'name', 'narrow', 'narrow_copy', 'ndimension', 'ne', 'ne_', 'neg', 'neg_', 'nelement', 'new', 'new_empty', 'new_full', 'new_ones', 'new_tensor', 'new_zeros', 'nonzero', 'norm', 'normal_', 'numel', 'numpy', 'orgqr', 'ormqr', 'output_nr', 'permute', 'pin_memory', 'pinverse', 'polygamma', 'polygamma_', 'potrf', 'potri', 'potrs', 'pow', 'pow_', 'prelu', 'prod', 'pstrf', 'put_', 'qr', 'random_', 'reciprocal', 'reciprocal_', 'record_stream', 'register_hook', 'reinforce', 'relu', 'relu_', 'remainder', 'remainder_', 'renorm', 'renorm_', 'repeat', 'requires_grad', 'requires_grad_', 'reshape', 'reshape_as', 'resize', 'resize_', 'resize_as', 'resize_as_', 'retain_grad', 'rfft', 'roll', 'rot90', 'round', 'round_', 'rsqrt', 'rsqrt_', 'scatter', 'scatter_', 'scatter_add', 'scatter_add_', 'select', 'set_', 'shape', 'share_memory_', 'short', 'sigmoid', 'sigmoid_', 'sign', 'sign_', 'sin', 'sin_', 'sinh', 'sinh_', 'size', 'slogdet', 'smm', 'softmax', 'sort', 'sparse_dim', 'sparse_mask', 'sparse_resize_', 'sparse_resize_and_clear_', 'split', 'split_with_sizes', 'sqrt', 'sqrt_', 'squeeze', 'squeeze_', 'sspaddmm', 'std', 'stft', 'storage', 'storage_offset', 'storage_type', 'stride', 'sub', 'sub_', 'sum', 'svd', 'symeig', 't', 't_', 'take', 'tan', 'tan_', 'tanh', 'tanh_', 'to', 'to_dense', 'to_sparse', 'tolist', 'topk', 'trace', 'transpose', 'transpose_', 'tril', 'tril_', 'triu', 'triu_', 'trtrs', 'trunc', 'trunc_', 'type', 'type_as', 'unbind', 'unfold', 'uniform_', 'unique', 'unsqueeze', 'unsqueeze_', 'values', 'var', 'view', 'view_as', 'where', 'zero_'] \u8fd4\u56de\u5f88\u591a\uff0c\u6211\u4eec\u76f4\u63a5\u6392\u9664\u6389\u4e00\u4e9bPython\u4e2d\u7279\u6b8a\u65b9\u6cd5\uff08\u4ee5__\u5f00\u5934\u548c\u7ed3\u675f\u7684\uff09\u548c\u79c1\u6709\u65b9\u6cd5\uff08\u4ee5_\u5f00\u5934\u7684\uff0c\u76f4\u63a5\u770b\u51e0\u4e2a\u6bd4\u8f83\u4e3b\u8981\u7684\u5c5e\u6027\uff1a .is_leaf \uff1a\u8bb0\u5f55\u662f\u5426\u662f\u53f6\u5b50\u8282\u70b9\u3002\u901a\u8fc7\u8fd9\u4e2a\u5c5e\u6027\u6765\u786e\u5b9a\u8fd9\u4e2a\u53d8\u91cf\u7684\u7c7b\u578b \u5728\u5b98\u65b9\u6587\u6863\u4e2d\u6240\u8bf4\u7684\u201cgraph leaves\u201d,\u201cleaf variables\u201d\uff0c\u90fd\u662f\u6307\u50cf x , y \u8fd9\u6837\u7684\u624b\u52a8\u521b\u5efa\u7684\u3001\u800c\u975e\u8fd0\u7b97\u5f97\u5230\u7684\u53d8\u91cf\uff0c\u8fd9\u4e9b\u53d8\u91cf\u6210\u4e3a\u521b\u5efa\u53d8\u91cf\u3002 \u50cf z \u8fd9\u6837\u7684\uff0c\u662f\u901a\u8fc7\u8ba1\u7b97\u540e\u5f97\u5230\u7684\u7ed3\u679c\u79f0\u4e3a\u7ed3\u679c\u53d8\u91cf\u3002 \u4e00\u4e2a\u53d8\u91cf\u662f\u521b\u5efa\u53d8\u91cf\u8fd8\u662f\u7ed3\u679c\u53d8\u91cf\u662f\u901a\u8fc7 .is_leaf \u6765\u83b7\u53d6\u7684\u3002 print ( \"x.is_leaf=\" + str ( x . is_leaf )) print ( \"z.is_leaf=\" + str ( z . is_leaf )) x.is_leaf=True z.is_leaf=False x \u662f\u624b\u52a8\u521b\u5efa\u7684\u6ca1\u6709\u901a\u8fc7\u8ba1\u7b97\uff0c\u6240\u4ee5\u4ed6\u88ab\u8ba4\u4e3a\u662f\u4e00\u4e2a\u53f6\u5b50\u8282\u70b9\u4e5f\u5c31\u662f\u4e00\u4e2a\u521b\u5efa\u53d8\u91cf\uff0c\u800c z \u662f\u901a\u8fc7 x \u4e0e y \u7684\u4e00\u7cfb\u5217\u8ba1\u7b97\u5f97\u5230\u7684\uff0c\u6240\u4ee5\u4e0d\u662f\u53f6\u5b50\u7ed3\u70b9\u4e5f\u5c31\u662f\u7ed3\u679c\u53d8\u91cf\u3002 \u4e3a\u4ec0\u4e48\u6211\u4eec\u6267\u884c z.backward() \u65b9\u6cd5\u4f1a\u66f4\u65b0 x.grad \u548c y.grad \u5462\uff1f .grad_fn \u5c5e\u6027\u8bb0\u5f55\u7684\u5c31\u662f\u8fd9\u90e8\u5206\u7684\u64cd\u4f5c\uff0c\u867d\u7136 .backward() \u65b9\u6cd5\u4e5f\u662fCPP\u5b9e\u73b0\u7684\uff0c\u4f46\u662f\u53ef\u4ee5\u901a\u8fc7Python\u6765\u8fdb\u884c\u7b80\u5355\u7684\u63a2\u7d22\u3002 grad_fn \uff1a\u8bb0\u5f55\u5e76\u4e14\u7f16\u7801\u4e86\u5b8c\u6574\u7684\u8ba1\u7b97\u5386\u53f2 z . grad_fn <AddBackward0 at 0x120840a90> grad_fn \u662f\u4e00\u4e2a AddBackward0 \u7c7b\u578b\u7684\u53d8\u91cf AddBackward0 \u8fd9\u4e2a\u7c7b\u4e5f\u662f\u7528Cpp\u6765\u5199\u7684,\u4f46\u662f\u6211\u4eec\u4ece\u540d\u5b57\u91cc\u5c31\u80fd\u591f\u5927\u6982\u77e5\u9053\uff0c\u4ed6\u662f\u52a0\u6cd5(ADD)\u7684\u53cd\u53cd\u5411\u4f20\u64ad\uff08Backward\uff09\uff0c\u770b\u770b\u91cc\u9762\u6709\u4e9b\u4ec0\u4e48\u4e1c\u897f dir ( z . grad_fn ) ['__call__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '_register_hook_dict', 'metadata', 'name', 'next_functions', 'register_hook', 'requires_grad'] next_functions \u5c31\u662f grad_fn \u7684\u7cbe\u534e z . grad_fn . next_functions ((<PowBackward0 at 0x1208409b0>, 0), (<PowBackward0 at 0x1208408d0>, 0)) next_functions \u662f\u4e00\u4e2atuple of tuple of PowBackward0 and int\u3002 \u4e3a\u4ec0\u4e48\u662f2\u4e2atuple \uff1f \u56e0\u4e3a\u6211\u4eec\u7684\u64cd\u4f5c\u662f z= x**2+y**3 \u521a\u624d\u7684 AddBackward0 \u662f\u76f8\u52a0\uff0c\u800c\u524d\u9762\u7684\u64cd\u4f5c\u662f\u4e58\u65b9 PowBackward0 \u3002tuple\u7b2c\u4e00\u4e2a\u5143\u7d20\u5c31\u662fx\u76f8\u5173\u7684\u64cd\u4f5c\u8bb0\u5f55 xg = z . grad_fn . next_functions [ 0 ][ 0 ] dir ( xg ) ['__call__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '_register_hook_dict', 'metadata', 'name', 'next_functions', 'register_hook', 'requires_grad'] \u7ee7\u7eed\u6df1\u6316 x_leaf = xg . next_functions [ 0 ][ 0 ] type ( x_leaf ) AccumulateGrad \u5728PyTorch\u7684\u53cd\u5411\u56fe\u8ba1\u7b97\u4e2d\uff0c AccumulateGrad \u7c7b\u578b\u4ee3\u8868\u7684\u5c31\u662f\u53f6\u5b50\u8282\u70b9\u7c7b\u578b\uff0c\u4e5f\u5c31\u662f\u8ba1\u7b97\u56fe\u7ec8\u6b62\u8282\u70b9\u3002 AccumulateGrad \u7c7b\u4e2d\u6709\u4e00\u4e2a .variable \u5c5e\u6027\u6307\u5411\u53f6\u5b50\u8282\u70b9\u3002 x_leaf . variable tensor([[0.1044, 0.6777, 0.2780, 0.5005, 0.4966], [0.6328, 0.0611, 0.4004, 0.5564, 0.3631], [0.5526, 0.1290, 0.9003, 0.0772, 0.1823], [0.9428, 0.6148, 0.9530, 0.4657, 0.0324], [0.2976, 0.8095, 0.4215, 0.9606, 0.0161]], requires_grad=True) \u8fd9\u4e2a .variable \u7684\u5c5e\u6027\u5c31\u662f\u6211\u4eec\u7684\u751f\u6210\u7684\u53d8\u91cf x print ( \"x_leaf.variable\u7684id:\" + str ( id ( x_leaf . variable ))) print ( \"x\u7684id:\" + str ( id ( x ))) x_leaf.variable\u7684id:4840553424 x\u7684id:4840553424 assert ( id ( x_leaf . variable ) == id ( x )) \u8fd9\u6837\u6574\u4e2a\u89c4\u7a0b\u5c31\u5f88\u6e05\u6670\u4e86\uff1a \u5f53\u6211\u4eec\u6267\u884cz.backward()\u7684\u65f6\u5019\u3002\u8fd9\u4e2a\u64cd\u4f5c\u5c06\u8c03\u7528z\u91cc\u9762\u7684grad_fn\u8fd9\u4e2a\u5c5e\u6027\uff0c\u6267\u884c\u6c42\u5bfc\u7684\u64cd\u4f5c\u3002 \u8fd9\u4e2a\u64cd\u4f5c\u5c06\u904d\u5386grad_fn\u7684next_functions\uff0c\u7136\u540e\u5206\u522b\u53d6\u51fa\u91cc\u9762\u7684Function\uff08AccumulateGrad\uff09\uff0c\u6267\u884c\u6c42\u5bfc\u64cd\u4f5c\u3002\u8fd9\u90e8\u5206\u662f\u4e00\u4e2a\u9012\u5f52\u7684\u8fc7\u7a0b\u76f4\u5230\u6700\u540e\u7c7b\u578b\u4e3a\u53f6\u5b50\u8282\u70b9\u3002 \u8ba1\u7b97\u51fa\u7ed3\u679c\u4ee5\u540e\uff0c\u5c06\u7ed3\u679c\u4fdd\u5b58\u5230\u4ed6\u4eec\u5bf9\u5e94\u7684variable \u8fd9\u4e2a\u53d8\u91cf\u6240\u5f15\u7528\u7684\u5bf9\u8c61\uff08x\u548cy\uff09\u7684 grad\u8fd9\u4e2a\u5c5e\u6027\u91cc\u9762\u3002 \u6c42\u5bfc\u7ed3\u675f\u3002\u6240\u6709\u7684\u53f6\u8282\u70b9\u7684grad\u53d8\u91cf\u90fd\u5f97\u5230\u4e86\u76f8\u5e94\u7684\u66f4\u65b0 \u6700\u7ec8\u5f53\u6211\u4eec\u6267\u884c\u5b8cc.backward()\u4e4b\u540e\uff0ca\u548cb\u91cc\u9762\u7684grad\u503c\u5c31\u5f97\u5230\u4e86\u66f4\u65b0\u3002","title":"Autograd \u8fc7\u7a0b\u89e3\u6790"},{"location":"tutorial/chapter02_basics/2_1_2_pytorch-basics-autograd/#autograd_2","text":"\u5982\u679c\u9700\u8981\u81ea\u5b9a\u4e49autograd\u6269\u5c55\u65b0\u7684\u529f\u80fd\uff0c\u5c31\u9700\u8981\u6269\u5c55Function\u7c7b\u3002\u56e0\u4e3aFunction\u4f7f\u7528autograd\u6765\u8ba1\u7b97\u7ed3\u679c\u548c\u68af\u5ea6\uff0c\u5e76\u5bf9\u64cd\u4f5c\u5386\u53f2\u8fdb\u884c\u7f16\u7801\u3002 \u5728Function\u7c7b\u4e2d\u6700\u4e3b\u8981\u7684\u65b9\u6cd5\u5c31\u662f forward() \u548c backward() \u4ed6\u4eec\u5206\u522b\u4ee3\u8868\u4e86\u524d\u5411\u4f20\u64ad\u548c\u53cd\u5411\u4f20\u64ad\u3002 \u4e00\u4e2a\u81ea\u5b9a\u4e49\u7684Function\u9700\u8981\u4e00\u4e0b\u4e09\u4e2a\u65b9\u6cd5\uff1a __init__ (optional)\uff1a\u5982\u679c\u8fd9\u4e2a\u64cd\u4f5c\u9700\u8981\u989d\u5916\u7684\u53c2\u6570\u5219\u9700\u8981\u5b9a\u4e49\u8fd9\u4e2aFunction\u7684\u6784\u9020\u51fd\u6570\uff0c\u4e0d\u9700\u8981\u7684\u8bdd\u53ef\u4ee5\u5ffd\u7565\u3002 forward()\uff1a\u6267\u884c\u524d\u5411\u4f20\u64ad\u7684\u8ba1\u7b97\u4ee3\u7801 backward()\uff1a\u53cd\u5411\u4f20\u64ad\u65f6\u68af\u5ea6\u8ba1\u7b97\u7684\u4ee3\u7801\u3002 \u53c2\u6570\u7684\u4e2a\u6570\u548cforward\u8fd4\u56de\u503c\u7684\u4e2a\u6570\u4e00\u6837\uff0c\u6bcf\u4e2a\u53c2\u6570\u4ee3\u8868\u4f20\u56de\u5230\u6b64\u64cd\u4f5c\u7684\u68af\u5ea6\u3002 # \u5f15\u5165Function\u4fbf\u4e8e\u6269\u5c55 from torch.autograd.function import Function # \u5b9a\u4e49\u4e00\u4e2a\u4e58\u4ee5\u5e38\u6570\u7684\u64cd\u4f5c(\u8f93\u5165\u53c2\u6570\u662f\u5f20\u91cf) # \u65b9\u6cd5\u5fc5\u987b\u662f\u9759\u6001\u65b9\u6cd5\uff0c\u6240\u4ee5\u8981\u52a0\u4e0a@staticmethod class MulConstant ( Function ): @staticmethod def forward ( ctx , tensor , constant ): # ctx \u7528\u6765\u4fdd\u5b58\u4fe1\u606f\u8fd9\u91cc\u7c7b\u4f3cself\uff0c\u5e76\u4e14ctx\u7684\u5c5e\u6027\u53ef\u4ee5\u5728backward\u4e2d\u8c03\u7528 ctx . constant = constant return tensor * constant @staticmethod def backward ( ctx , grad_output ): # \u8fd4\u56de\u7684\u53c2\u6570\u8981\u4e0e\u8f93\u5165\u7684\u53c2\u6570\u4e00\u6837. # \u7b2c\u4e00\u4e2a\u8f93\u5165\u4e3a3x3\u7684\u5f20\u91cf\uff0c\u7b2c\u4e8c\u4e2a\u4e3a\u4e00\u4e2a\u5e38\u6570 # \u5e38\u6570\u7684\u68af\u5ea6\u5fc5\u987b\u662f None. return grad_output , None \u5b9a\u4e49\u5b8c\u6211\u4eec\u7684\u65b0\u64cd\u4f5c\u540e\uff0c\u6211\u4eec\u6765\u8fdb\u884c\u6d4b\u8bd5 a = torch . rand ( 3 , 3 , requires_grad = True ) b = MulConstant . apply ( a , 5 ) print ( \"a:\" + str ( a )) print ( \"b:\" + str ( b )) # b\u4e3aa\u7684\u5143\u7d20\u4e58\u4ee55 a:tensor([[0.0118, 0.1434, 0.8669], [0.1817, 0.8904, 0.5852], [0.7364, 0.5234, 0.9677]], requires_grad=True) b:tensor([[0.0588, 0.7169, 4.3347], [0.9084, 4.4520, 2.9259], [3.6820, 2.6171, 4.8386]], grad_fn=<MulConstantBackward>) \u53cd\u5411\u4f20\u64ad\uff0c\u8fd4\u56de\u503c\u4e0d\u662f\u6807\u91cf\uff0c\u6240\u4ee5 backward \u65b9\u6cd5\u9700\u8981\u53c2\u6570 b . backward ( torch . ones_like ( a )) a . grad tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.]]) \u68af\u5ea6\u56e0\u4e3a1","title":"\u6269\u5c55Autograd"},{"location":"tutorial/chapter02_basics/2_1_3_pytorch-basics-nerual-network/","text":"PyTorch \u57fa\u7840 : \u795e\u7ecf\u7f51\u7edc\u5305nn\u548c\u4f18\u5316\u5668optm \u00b6 torch.nn\u662f\u4e13\u95e8\u4e3a\u795e\u7ecf\u7f51\u7edc\u8bbe\u8ba1\u7684\u6a21\u5757\u5316\u63a5\u53e3\u3002nn\u6784\u5efa\u4e8e Autograd\u4e4b\u4e0a\uff0c\u53ef\u7528\u6765\u5b9a\u4e49\u548c\u8fd0\u884c\u795e\u7ecf\u7f51\u7edc\u3002 \u8fd9\u91cc\u6211\u4eec\u4e3b\u8981\u4ecb\u7ecd\u51e0\u4e2a\u4e00\u4e9b\u5e38\u7528\u7684\u7c7b \u7ea6\u5b9a\uff1atorch.nn \u6211\u4eec\u4e3a\u4e86\u65b9\u4fbf\u4f7f\u7528\uff0c\u4f1a\u4e3a\u4ed6\u8bbe\u7f6e\u522b\u540d\u4e3ann,\u672c\u7ae0\u9664nn\u4ee5\u5916\u8fd8\u6709\u5176\u4ed6\u7684\u547d\u540d\u7ea6\u5b9a # \u9996\u5148\u8981\u5f15\u5165\u76f8\u5173\u7684\u5305 import torch # \u5f15\u5165torch.nn\u5e76\u6307\u5b9a\u522b\u540d import torch.nn as nn #\u6253\u5370\u4e00\u4e0b\u7248\u672c torch . __version__ '1.0.0' \u9664\u4e86nn\u522b\u540d\u4ee5\u5916\uff0c\u6211\u4eec\u8fd8\u5f15\u7528\u4e86nn.functional\uff0c\u8fd9\u4e2a\u5305\u4e2d\u5305\u542b\u4e86\u795e\u7ecf\u7f51\u7edc\u4e2d\u4f7f\u7528\u7684\u4e00\u4e9b\u5e38\u7528\u51fd\u6570\uff0c\u8fd9\u4e9b\u51fd\u6570\u7684\u7279\u70b9\u662f\uff0c\u4e0d\u5177\u6709\u53ef\u5b66\u4e60\u7684\u53c2\u6570(\u5982ReLU\uff0cpool\uff0cDropOut\u7b49)\uff0c\u8fd9\u4e9b\u51fd\u6570\u53ef\u4ee5\u653e\u5728\u6784\u9020\u51fd\u6570\u4e2d\uff0c\u4e5f\u53ef\u4ee5\u4e0d\u653e\uff0c\u4f46\u662f\u8fd9\u91cc\u5efa\u8bae\u4e0d\u653e\u3002 \u4e00\u822c\u60c5\u51b5\u4e0b\u6211\u4eec\u4f1a**\u5c06nn.functional \u8bbe\u7f6e\u4e3a\u5927\u5199\u7684F**\uff0c\u8fd9\u6837\u7f29\u5199\u65b9\u4fbf\u8c03\u7528 import torch.nn.functional as F \u5b9a\u4e49\u4e00\u4e2a\u7f51\u7edc \u00b6 PyTorch\u4e2d\u5df2\u7ecf\u4e3a\u6211\u4eec\u51c6\u5907\u597d\u4e86\u73b0\u6210\u7684\u7f51\u7edc\u6a21\u578b\uff0c\u53ea\u8981\u7ee7\u627fnn.Module\uff0c\u5e76\u5b9e\u73b0\u5b83\u7684forward\u65b9\u6cd5\uff0cPyTorch\u4f1a\u6839\u636eautograd\uff0c\u81ea\u52a8\u5b9e\u73b0backward\u51fd\u6570\uff0c\u5728forward\u51fd\u6570\u4e2d\u53ef\u4f7f\u7528\u4efb\u4f55tensor\u652f\u6301\u7684\u51fd\u6570\uff0c\u8fd8\u53ef\u4ee5\u4f7f\u7528if\u3001for\u5faa\u73af\u3001print\u3001log\u7b49Python\u8bed\u6cd5\uff0c\u5199\u6cd5\u548c\u6807\u51c6\u7684Python\u5199\u6cd5\u4e00\u81f4\u3002 class Net ( nn . Module ): def __init__ ( self ): # nn.Module\u5b50\u7c7b\u7684\u51fd\u6570\u5fc5\u987b\u5728\u6784\u9020\u51fd\u6570\u4e2d\u6267\u884c\u7236\u7c7b\u7684\u6784\u9020\u51fd\u6570 super ( Net , self ) . __init__ () # \u5377\u79ef\u5c42 '1'\u8868\u793a\u8f93\u5165\u56fe\u7247\u4e3a\u5355\u901a\u9053, '6'\u8868\u793a\u8f93\u51fa\u901a\u9053\u6570\uff0c'3'\u8868\u793a\u5377\u79ef\u6838\u4e3a3*3 self . conv1 = nn . Conv2d ( 1 , 6 , 3 ) #\u7ebf\u6027\u5c42\uff0c\u8f93\u51651350\u4e2a\u7279\u5f81\uff0c\u8f93\u51fa10\u4e2a\u7279\u5f81 self . fc1 = nn . Linear ( 1350 , 10 ) #\u8fd9\u91cc\u76841350\u662f\u5982\u4f55\u8ba1\u7b97\u7684\u5462\uff1f\u8fd9\u5c31\u8981\u770b\u540e\u9762\u7684forward\u51fd\u6570 #\u6b63\u5411\u4f20\u64ad def forward ( self , x ): print ( x . size ()) # \u7ed3\u679c\uff1a[1, 1, 32, 32] # \u5377\u79ef -> \u6fc0\u6d3b -> \u6c60\u5316 x = self . conv1 ( x ) #\u6839\u636e\u5377\u79ef\u7684\u5c3a\u5bf8\u8ba1\u7b97\u516c\u5f0f\uff0c\u8ba1\u7b97\u7ed3\u679c\u662f30\uff0c\u5177\u4f53\u8ba1\u7b97\u516c\u5f0f\u540e\u9762\u7b2c\u4e8c\u7ae0\u7b2c\u56db\u8282 \u5377\u79ef\u795e\u7ecf\u7f51\u7edc \u6709\u8be6\u7ec6\u4ecb\u7ecd\u3002 x = F . relu ( x ) print ( x . size ()) # \u7ed3\u679c\uff1a[1, 6, 30, 30] x = F . max_pool2d ( x , ( 2 , 2 )) #\u6211\u4eec\u4f7f\u7528\u6c60\u5316\u5c42\uff0c\u8ba1\u7b97\u7ed3\u679c\u662f15 x = F . relu ( x ) print ( x . size ()) # \u7ed3\u679c\uff1a[1, 6, 15, 15] # reshape\uff0c\u2018-1\u2019\u8868\u793a\u81ea\u9002\u5e94 #\u8fd9\u91cc\u505a\u7684\u5c31\u662f\u538b\u6241\u7684\u64cd\u4f5c \u5c31\u662f\u628a\u540e\u9762\u7684[1, 6, 15, 15]\u538b\u6241\uff0c\u53d8\u4e3a [1, 1350] x = x . view ( x . size ()[ 0 ], - 1 ) print ( x . size ()) # \u8fd9\u91cc\u5c31\u662ffc1\u5c42\u7684\u7684\u8f93\u51651350 x = self . fc1 ( x ) return x net = Net () print ( net ) Net( (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1)) (fc1): Linear(in_features=1350, out_features=10, bias=True) ) \u7f51\u7edc\u7684\u53ef\u5b66\u4e60\u53c2\u6570\u901a\u8fc7net.parameters()\u8fd4\u56de for parameters in net . parameters (): print ( parameters ) Parameter containing: tensor([[[[ 0.2745, 0.2594, 0.0171], [ 0.0429, 0.3013, -0.0208], [ 0.1459, -0.3223, 0.1797]]], [[[ 0.1847, 0.0227, -0.1919], [-0.0210, -0.1336, -0.2176], [-0.2164, -0.1244, -0.2428]]], [[[ 0.1042, -0.0055, -0.2171], [ 0.3306, -0.2808, 0.2058], [ 0.2492, 0.2971, 0.2277]]], [[[ 0.2134, -0.0644, -0.3044], [ 0.0040, 0.0828, -0.2093], [ 0.0204, 0.1065, 0.1168]]], [[[ 0.1651, -0.2244, 0.3072], [-0.2301, 0.2443, -0.2340], [ 0.0685, 0.1026, 0.1754]]], [[[ 0.1691, -0.0790, 0.2617], [ 0.1956, 0.1477, 0.0877], [ 0.0538, -0.3091, 0.2030]]]], requires_grad=True) Parameter containing: tensor([ 0.2355, 0.2949, -0.1283, -0.0848, 0.2027, -0.3331], requires_grad=True) Parameter containing: tensor([[ 2.0555e-02, -2.1445e-02, -1.7981e-02, ..., -2.3864e-02, 8.5149e-03, -6.2071e-04], [-1.1755e-02, 1.0010e-02, 2.1978e-02, ..., 1.8433e-02, 7.1362e-03, -4.0951e-03], [ 1.6187e-02, 2.1623e-02, 1.1840e-02, ..., 5.7059e-03, -2.7165e-02, 1.3463e-03], ..., [-3.2552e-03, 1.7277e-02, -1.4907e-02, ..., 7.4232e-03, -2.7188e-02, -4.6431e-03], [-1.9786e-02, -3.7382e-03, 1.2259e-02, ..., 3.2471e-03, -1.2375e-02, -1.6372e-02], [-8.2350e-03, 4.1301e-03, -1.9192e-03, ..., -2.3119e-05, 2.0167e-03, 1.9528e-02]], requires_grad=True) Parameter containing: tensor([ 0.0162, -0.0146, -0.0218, 0.0212, -0.0119, -0.0142, -0.0079, 0.0171, 0.0205, 0.0164], requires_grad=True) net.named_parameters\u53ef\u540c\u65f6\u8fd4\u56de\u53ef\u5b66\u4e60\u7684\u53c2\u6570\u53ca\u540d\u79f0\u3002 for name , parameters in net . named_parameters (): print ( name , ':' , parameters . size ()) conv1.weight : torch.Size([6, 1, 3, 3]) conv1.bias : torch.Size([6]) fc1.weight : torch.Size([10, 1350]) fc1.bias : torch.Size([10]) forward\u51fd\u6570\u7684\u8f93\u5165\u548c\u8f93\u51fa\u90fd\u662fTensor input = torch . randn ( 1 , 1 , 32 , 32 ) # \u8fd9\u91cc\u7684\u5bf9\u5e94\u524d\u9762fforward\u7684\u8f93\u5165\u662f32 out = net ( input ) out . size () torch.Size([1, 1, 32, 32]) torch.Size([1, 6, 30, 30]) torch.Size([1, 6, 15, 15]) torch.Size([1, 1350]) torch.Size([1, 10]) input . size () torch.Size([1, 1, 32, 32]) \u5728\u53cd\u5411\u4f20\u64ad\u524d\uff0c\u5148\u8981\u5c06\u6240\u6709\u53c2\u6570\u7684\u68af\u5ea6\u6e05\u96f6 net . zero_grad () out . backward ( torch . ones ( 1 , 10 )) # \u53cd\u5411\u4f20\u64ad\u7684\u5b9e\u73b0\u662fPyTorch\u81ea\u52a8\u5b9e\u73b0\u7684\uff0c\u6211\u4eec\u53ea\u8981\u8c03\u7528\u8fd9\u4e2a\u51fd\u6570\u5373\u53ef \u6ce8\u610f :torch.nn\u53ea\u652f\u6301mini-batches\uff0c\u4e0d\u652f\u6301\u4e00\u6b21\u53ea\u8f93\u5165\u4e00\u4e2a\u6837\u672c\uff0c\u5373\u4e00\u6b21\u5fc5\u987b\u662f\u4e00\u4e2abatch\u3002 \u4e5f\u5c31\u662f\u8bf4\uff0c\u5c31\u7b97\u6211\u4eec\u8f93\u5165\u4e00\u4e2a\u6837\u672c\uff0c\u4e5f\u4f1a\u5bf9\u6837\u672c\u8fdb\u884c\u5206\u6279\uff0c\u6240\u4ee5\uff0c\u6240\u6709\u7684\u8f93\u5165\u90fd\u4f1a\u589e\u52a0\u4e00\u4e2a\u7ef4\u5ea6\uff0c\u6211\u4eec\u5bf9\u6bd4\u4e0b\u521a\u624d\u7684input\uff0cnn\u4e2d\u5b9a\u4e49\u4e3a3\u7ef4\uff0c\u4f46\u662f\u6211\u4eec\u4eba\u5de5\u521b\u5efa\u65f6\u591a\u589e\u52a0\u4e86\u4e00\u4e2a\u7ef4\u5ea6\uff0c\u53d8\u4e3a\u4e864\u7ef4\uff0c\u6700\u524d\u9762\u76841\u5373\u4e3abatch-size \u635f\u5931\u51fd\u6570 \u00b6 \u5728nn\u4e2dPyTorch\u8fd8\u9884\u5236\u4e86\u5e38\u7528\u7684\u635f\u5931\u51fd\u6570\uff0c\u4e0b\u9762\u6211\u4eec\u7528MSELoss\u7528\u6765\u8ba1\u7b97\u5747\u65b9\u8bef\u5dee y = torch . arange ( 0 , 10 ) . view ( 1 , 10 ) . float () criterion = nn . MSELoss () loss = criterion ( out , y ) #loss\u662f\u4e2ascalar\uff0c\u6211\u4eec\u53ef\u4ee5\u76f4\u63a5\u7528item\u83b7\u53d6\u5230\u4ed6\u7684python\u7c7b\u578b\u7684\u6570\u503c print ( loss . item ()) 28.92203712463379 \u4f18\u5316\u5668 \u00b6 \u5728\u53cd\u5411\u4f20\u64ad\u8ba1\u7b97\u5b8c\u6240\u6709\u53c2\u6570\u7684\u68af\u5ea6\u540e\uff0c\u8fd8\u9700\u8981\u4f7f\u7528\u4f18\u5316\u65b9\u6cd5\u6765\u66f4\u65b0\u7f51\u7edc\u7684\u6743\u91cd\u548c\u53c2\u6570\uff0c\u4f8b\u5982\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u6cd5(SGD)\u7684\u66f4\u65b0\u7b56\u7565\u5982\u4e0b\uff1a weight = weight - learning_rate * gradient \u5728torch.optim\u4e2d\u5b9e\u73b0\u5927\u591a\u6570\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u4f8b\u5982RMSProp\u3001Adam\u3001SGD\u7b49\uff0c\u4e0b\u9762\u6211\u4eec\u4f7f\u7528SGD\u505a\u4e2a\u7b80\u5355\u7684\u6837\u4f8b import torch.optim out = net ( input ) # \u8fd9\u91cc\u8c03\u7528\u7684\u65f6\u5019\u4f1a\u6253\u5370\u51fa\u6211\u4eec\u5728forword\u51fd\u6570\u4e2d\u6253\u5370\u7684x\u7684\u5927\u5c0f criterion = nn . MSELoss () loss = criterion ( out , y ) #\u65b0\u5efa\u4e00\u4e2a\u4f18\u5316\u5668\uff0cSGD\u53ea\u9700\u8981\u8981\u8c03\u6574\u7684\u53c2\u6570\u548c\u5b66\u4e60\u7387 optimizer = torch . optim . SGD ( net . parameters (), lr = 0.01 ) # \u5148\u68af\u5ea6\u6e05\u96f6(\u4e0enet.zero_grad()\u6548\u679c\u4e00\u6837) optimizer . zero_grad () loss . backward () #\u66f4\u65b0\u53c2\u6570 optimizer . step () torch.Size([1, 1, 32, 32]) torch.Size([1, 6, 30, 30]) torch.Size([1, 6, 15, 15]) torch.Size([1, 1350]) \u8fd9\u6837\uff0c\u795e\u7ecf\u7f51\u7edc\u7684\u6570\u636e\u7684\u4e00\u4e2a\u5b8c\u6574\u7684\u4f20\u64ad\u5c31\u5df2\u7ecf\u901a\u8fc7PyTorch\u5b9e\u73b0\u4e86\uff0c\u4e0b\u9762\u4e00\u7ae0\u5c06\u4ecb\u7ecdPyTorch\u63d0\u4f9b\u7684\u6570\u636e\u52a0\u8f7d\u548c\u5904\u7406\u5de5\u5177\uff0c\u4f7f\u7528\u8fd9\u4e9b\u5de5\u5177\u53ef\u4ee5\u65b9\u4fbf\u7684\u5904\u7406\u6240\u9700\u8981\u7684\u6570\u636e\u3002 \u770b\u5b8c\u8fd9\u8282\uff0c\u5927\u5bb6\u53ef\u80fd\u5bf9\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u91cc\u9762\u7684\u4e00\u4e9b\u53c2\u6570\u7684\u8ba1\u7b97\u65b9\u5f0f\u8fd8\u6709\u7591\u60d1\uff0c\u8fd9\u90e8\u5206\u4f1a\u5728\u7b2c\u4e8c\u7ae0\u7b2c\u56db\u8282 \u5377\u79ef\u795e\u7ecf\u7f51\u7edc \u6709\u8be6\u7ec6\u4ecb\u7ecd\uff0c\u5e76\u4e14\u5728\u7b2c\u4e09\u7ae0 \u7b2c\u4e8c\u8282 MNIST\u6570\u636e\u96c6\u624b\u5199\u6570\u5b57\u8bc6\u522b \u7684\u5b9e\u8df5\u4ee3\u7801\u4e2d\u6709\u8be6\u7ec6\u7684\u6ce8\u91ca\u8bf4\u660e\u3002","title":"2.1.3 Nerual Network"},{"location":"tutorial/chapter02_basics/2_1_3_pytorch-basics-nerual-network/#pytorch-nnoptm","text":"torch.nn\u662f\u4e13\u95e8\u4e3a\u795e\u7ecf\u7f51\u7edc\u8bbe\u8ba1\u7684\u6a21\u5757\u5316\u63a5\u53e3\u3002nn\u6784\u5efa\u4e8e Autograd\u4e4b\u4e0a\uff0c\u53ef\u7528\u6765\u5b9a\u4e49\u548c\u8fd0\u884c\u795e\u7ecf\u7f51\u7edc\u3002 \u8fd9\u91cc\u6211\u4eec\u4e3b\u8981\u4ecb\u7ecd\u51e0\u4e2a\u4e00\u4e9b\u5e38\u7528\u7684\u7c7b \u7ea6\u5b9a\uff1atorch.nn \u6211\u4eec\u4e3a\u4e86\u65b9\u4fbf\u4f7f\u7528\uff0c\u4f1a\u4e3a\u4ed6\u8bbe\u7f6e\u522b\u540d\u4e3ann,\u672c\u7ae0\u9664nn\u4ee5\u5916\u8fd8\u6709\u5176\u4ed6\u7684\u547d\u540d\u7ea6\u5b9a # \u9996\u5148\u8981\u5f15\u5165\u76f8\u5173\u7684\u5305 import torch # \u5f15\u5165torch.nn\u5e76\u6307\u5b9a\u522b\u540d import torch.nn as nn #\u6253\u5370\u4e00\u4e0b\u7248\u672c torch . __version__ '1.0.0' \u9664\u4e86nn\u522b\u540d\u4ee5\u5916\uff0c\u6211\u4eec\u8fd8\u5f15\u7528\u4e86nn.functional\uff0c\u8fd9\u4e2a\u5305\u4e2d\u5305\u542b\u4e86\u795e\u7ecf\u7f51\u7edc\u4e2d\u4f7f\u7528\u7684\u4e00\u4e9b\u5e38\u7528\u51fd\u6570\uff0c\u8fd9\u4e9b\u51fd\u6570\u7684\u7279\u70b9\u662f\uff0c\u4e0d\u5177\u6709\u53ef\u5b66\u4e60\u7684\u53c2\u6570(\u5982ReLU\uff0cpool\uff0cDropOut\u7b49)\uff0c\u8fd9\u4e9b\u51fd\u6570\u53ef\u4ee5\u653e\u5728\u6784\u9020\u51fd\u6570\u4e2d\uff0c\u4e5f\u53ef\u4ee5\u4e0d\u653e\uff0c\u4f46\u662f\u8fd9\u91cc\u5efa\u8bae\u4e0d\u653e\u3002 \u4e00\u822c\u60c5\u51b5\u4e0b\u6211\u4eec\u4f1a**\u5c06nn.functional \u8bbe\u7f6e\u4e3a\u5927\u5199\u7684F**\uff0c\u8fd9\u6837\u7f29\u5199\u65b9\u4fbf\u8c03\u7528 import torch.nn.functional as F","title":"PyTorch \u57fa\u7840 : \u795e\u7ecf\u7f51\u7edc\u5305nn\u548c\u4f18\u5316\u5668optm"},{"location":"tutorial/chapter02_basics/2_1_3_pytorch-basics-nerual-network/#_1","text":"PyTorch\u4e2d\u5df2\u7ecf\u4e3a\u6211\u4eec\u51c6\u5907\u597d\u4e86\u73b0\u6210\u7684\u7f51\u7edc\u6a21\u578b\uff0c\u53ea\u8981\u7ee7\u627fnn.Module\uff0c\u5e76\u5b9e\u73b0\u5b83\u7684forward\u65b9\u6cd5\uff0cPyTorch\u4f1a\u6839\u636eautograd\uff0c\u81ea\u52a8\u5b9e\u73b0backward\u51fd\u6570\uff0c\u5728forward\u51fd\u6570\u4e2d\u53ef\u4f7f\u7528\u4efb\u4f55tensor\u652f\u6301\u7684\u51fd\u6570\uff0c\u8fd8\u53ef\u4ee5\u4f7f\u7528if\u3001for\u5faa\u73af\u3001print\u3001log\u7b49Python\u8bed\u6cd5\uff0c\u5199\u6cd5\u548c\u6807\u51c6\u7684Python\u5199\u6cd5\u4e00\u81f4\u3002 class Net ( nn . Module ): def __init__ ( self ): # nn.Module\u5b50\u7c7b\u7684\u51fd\u6570\u5fc5\u987b\u5728\u6784\u9020\u51fd\u6570\u4e2d\u6267\u884c\u7236\u7c7b\u7684\u6784\u9020\u51fd\u6570 super ( Net , self ) . __init__ () # \u5377\u79ef\u5c42 '1'\u8868\u793a\u8f93\u5165\u56fe\u7247\u4e3a\u5355\u901a\u9053, '6'\u8868\u793a\u8f93\u51fa\u901a\u9053\u6570\uff0c'3'\u8868\u793a\u5377\u79ef\u6838\u4e3a3*3 self . conv1 = nn . Conv2d ( 1 , 6 , 3 ) #\u7ebf\u6027\u5c42\uff0c\u8f93\u51651350\u4e2a\u7279\u5f81\uff0c\u8f93\u51fa10\u4e2a\u7279\u5f81 self . fc1 = nn . Linear ( 1350 , 10 ) #\u8fd9\u91cc\u76841350\u662f\u5982\u4f55\u8ba1\u7b97\u7684\u5462\uff1f\u8fd9\u5c31\u8981\u770b\u540e\u9762\u7684forward\u51fd\u6570 #\u6b63\u5411\u4f20\u64ad def forward ( self , x ): print ( x . size ()) # \u7ed3\u679c\uff1a[1, 1, 32, 32] # \u5377\u79ef -> \u6fc0\u6d3b -> \u6c60\u5316 x = self . conv1 ( x ) #\u6839\u636e\u5377\u79ef\u7684\u5c3a\u5bf8\u8ba1\u7b97\u516c\u5f0f\uff0c\u8ba1\u7b97\u7ed3\u679c\u662f30\uff0c\u5177\u4f53\u8ba1\u7b97\u516c\u5f0f\u540e\u9762\u7b2c\u4e8c\u7ae0\u7b2c\u56db\u8282 \u5377\u79ef\u795e\u7ecf\u7f51\u7edc \u6709\u8be6\u7ec6\u4ecb\u7ecd\u3002 x = F . relu ( x ) print ( x . size ()) # \u7ed3\u679c\uff1a[1, 6, 30, 30] x = F . max_pool2d ( x , ( 2 , 2 )) #\u6211\u4eec\u4f7f\u7528\u6c60\u5316\u5c42\uff0c\u8ba1\u7b97\u7ed3\u679c\u662f15 x = F . relu ( x ) print ( x . size ()) # \u7ed3\u679c\uff1a[1, 6, 15, 15] # reshape\uff0c\u2018-1\u2019\u8868\u793a\u81ea\u9002\u5e94 #\u8fd9\u91cc\u505a\u7684\u5c31\u662f\u538b\u6241\u7684\u64cd\u4f5c \u5c31\u662f\u628a\u540e\u9762\u7684[1, 6, 15, 15]\u538b\u6241\uff0c\u53d8\u4e3a [1, 1350] x = x . view ( x . size ()[ 0 ], - 1 ) print ( x . size ()) # \u8fd9\u91cc\u5c31\u662ffc1\u5c42\u7684\u7684\u8f93\u51651350 x = self . fc1 ( x ) return x net = Net () print ( net ) Net( (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1)) (fc1): Linear(in_features=1350, out_features=10, bias=True) ) \u7f51\u7edc\u7684\u53ef\u5b66\u4e60\u53c2\u6570\u901a\u8fc7net.parameters()\u8fd4\u56de for parameters in net . parameters (): print ( parameters ) Parameter containing: tensor([[[[ 0.2745, 0.2594, 0.0171], [ 0.0429, 0.3013, -0.0208], [ 0.1459, -0.3223, 0.1797]]], [[[ 0.1847, 0.0227, -0.1919], [-0.0210, -0.1336, -0.2176], [-0.2164, -0.1244, -0.2428]]], [[[ 0.1042, -0.0055, -0.2171], [ 0.3306, -0.2808, 0.2058], [ 0.2492, 0.2971, 0.2277]]], [[[ 0.2134, -0.0644, -0.3044], [ 0.0040, 0.0828, -0.2093], [ 0.0204, 0.1065, 0.1168]]], [[[ 0.1651, -0.2244, 0.3072], [-0.2301, 0.2443, -0.2340], [ 0.0685, 0.1026, 0.1754]]], [[[ 0.1691, -0.0790, 0.2617], [ 0.1956, 0.1477, 0.0877], [ 0.0538, -0.3091, 0.2030]]]], requires_grad=True) Parameter containing: tensor([ 0.2355, 0.2949, -0.1283, -0.0848, 0.2027, -0.3331], requires_grad=True) Parameter containing: tensor([[ 2.0555e-02, -2.1445e-02, -1.7981e-02, ..., -2.3864e-02, 8.5149e-03, -6.2071e-04], [-1.1755e-02, 1.0010e-02, 2.1978e-02, ..., 1.8433e-02, 7.1362e-03, -4.0951e-03], [ 1.6187e-02, 2.1623e-02, 1.1840e-02, ..., 5.7059e-03, -2.7165e-02, 1.3463e-03], ..., [-3.2552e-03, 1.7277e-02, -1.4907e-02, ..., 7.4232e-03, -2.7188e-02, -4.6431e-03], [-1.9786e-02, -3.7382e-03, 1.2259e-02, ..., 3.2471e-03, -1.2375e-02, -1.6372e-02], [-8.2350e-03, 4.1301e-03, -1.9192e-03, ..., -2.3119e-05, 2.0167e-03, 1.9528e-02]], requires_grad=True) Parameter containing: tensor([ 0.0162, -0.0146, -0.0218, 0.0212, -0.0119, -0.0142, -0.0079, 0.0171, 0.0205, 0.0164], requires_grad=True) net.named_parameters\u53ef\u540c\u65f6\u8fd4\u56de\u53ef\u5b66\u4e60\u7684\u53c2\u6570\u53ca\u540d\u79f0\u3002 for name , parameters in net . named_parameters (): print ( name , ':' , parameters . size ()) conv1.weight : torch.Size([6, 1, 3, 3]) conv1.bias : torch.Size([6]) fc1.weight : torch.Size([10, 1350]) fc1.bias : torch.Size([10]) forward\u51fd\u6570\u7684\u8f93\u5165\u548c\u8f93\u51fa\u90fd\u662fTensor input = torch . randn ( 1 , 1 , 32 , 32 ) # \u8fd9\u91cc\u7684\u5bf9\u5e94\u524d\u9762fforward\u7684\u8f93\u5165\u662f32 out = net ( input ) out . size () torch.Size([1, 1, 32, 32]) torch.Size([1, 6, 30, 30]) torch.Size([1, 6, 15, 15]) torch.Size([1, 1350]) torch.Size([1, 10]) input . size () torch.Size([1, 1, 32, 32]) \u5728\u53cd\u5411\u4f20\u64ad\u524d\uff0c\u5148\u8981\u5c06\u6240\u6709\u53c2\u6570\u7684\u68af\u5ea6\u6e05\u96f6 net . zero_grad () out . backward ( torch . ones ( 1 , 10 )) # \u53cd\u5411\u4f20\u64ad\u7684\u5b9e\u73b0\u662fPyTorch\u81ea\u52a8\u5b9e\u73b0\u7684\uff0c\u6211\u4eec\u53ea\u8981\u8c03\u7528\u8fd9\u4e2a\u51fd\u6570\u5373\u53ef \u6ce8\u610f :torch.nn\u53ea\u652f\u6301mini-batches\uff0c\u4e0d\u652f\u6301\u4e00\u6b21\u53ea\u8f93\u5165\u4e00\u4e2a\u6837\u672c\uff0c\u5373\u4e00\u6b21\u5fc5\u987b\u662f\u4e00\u4e2abatch\u3002 \u4e5f\u5c31\u662f\u8bf4\uff0c\u5c31\u7b97\u6211\u4eec\u8f93\u5165\u4e00\u4e2a\u6837\u672c\uff0c\u4e5f\u4f1a\u5bf9\u6837\u672c\u8fdb\u884c\u5206\u6279\uff0c\u6240\u4ee5\uff0c\u6240\u6709\u7684\u8f93\u5165\u90fd\u4f1a\u589e\u52a0\u4e00\u4e2a\u7ef4\u5ea6\uff0c\u6211\u4eec\u5bf9\u6bd4\u4e0b\u521a\u624d\u7684input\uff0cnn\u4e2d\u5b9a\u4e49\u4e3a3\u7ef4\uff0c\u4f46\u662f\u6211\u4eec\u4eba\u5de5\u521b\u5efa\u65f6\u591a\u589e\u52a0\u4e86\u4e00\u4e2a\u7ef4\u5ea6\uff0c\u53d8\u4e3a\u4e864\u7ef4\uff0c\u6700\u524d\u9762\u76841\u5373\u4e3abatch-size","title":"\u5b9a\u4e49\u4e00\u4e2a\u7f51\u7edc"},{"location":"tutorial/chapter02_basics/2_1_3_pytorch-basics-nerual-network/#_2","text":"\u5728nn\u4e2dPyTorch\u8fd8\u9884\u5236\u4e86\u5e38\u7528\u7684\u635f\u5931\u51fd\u6570\uff0c\u4e0b\u9762\u6211\u4eec\u7528MSELoss\u7528\u6765\u8ba1\u7b97\u5747\u65b9\u8bef\u5dee y = torch . arange ( 0 , 10 ) . view ( 1 , 10 ) . float () criterion = nn . MSELoss () loss = criterion ( out , y ) #loss\u662f\u4e2ascalar\uff0c\u6211\u4eec\u53ef\u4ee5\u76f4\u63a5\u7528item\u83b7\u53d6\u5230\u4ed6\u7684python\u7c7b\u578b\u7684\u6570\u503c print ( loss . item ()) 28.92203712463379","title":"\u635f\u5931\u51fd\u6570"},{"location":"tutorial/chapter02_basics/2_1_3_pytorch-basics-nerual-network/#_3","text":"\u5728\u53cd\u5411\u4f20\u64ad\u8ba1\u7b97\u5b8c\u6240\u6709\u53c2\u6570\u7684\u68af\u5ea6\u540e\uff0c\u8fd8\u9700\u8981\u4f7f\u7528\u4f18\u5316\u65b9\u6cd5\u6765\u66f4\u65b0\u7f51\u7edc\u7684\u6743\u91cd\u548c\u53c2\u6570\uff0c\u4f8b\u5982\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u6cd5(SGD)\u7684\u66f4\u65b0\u7b56\u7565\u5982\u4e0b\uff1a weight = weight - learning_rate * gradient \u5728torch.optim\u4e2d\u5b9e\u73b0\u5927\u591a\u6570\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u4f8b\u5982RMSProp\u3001Adam\u3001SGD\u7b49\uff0c\u4e0b\u9762\u6211\u4eec\u4f7f\u7528SGD\u505a\u4e2a\u7b80\u5355\u7684\u6837\u4f8b import torch.optim out = net ( input ) # \u8fd9\u91cc\u8c03\u7528\u7684\u65f6\u5019\u4f1a\u6253\u5370\u51fa\u6211\u4eec\u5728forword\u51fd\u6570\u4e2d\u6253\u5370\u7684x\u7684\u5927\u5c0f criterion = nn . MSELoss () loss = criterion ( out , y ) #\u65b0\u5efa\u4e00\u4e2a\u4f18\u5316\u5668\uff0cSGD\u53ea\u9700\u8981\u8981\u8c03\u6574\u7684\u53c2\u6570\u548c\u5b66\u4e60\u7387 optimizer = torch . optim . SGD ( net . parameters (), lr = 0.01 ) # \u5148\u68af\u5ea6\u6e05\u96f6(\u4e0enet.zero_grad()\u6548\u679c\u4e00\u6837) optimizer . zero_grad () loss . backward () #\u66f4\u65b0\u53c2\u6570 optimizer . step () torch.Size([1, 1, 32, 32]) torch.Size([1, 6, 30, 30]) torch.Size([1, 6, 15, 15]) torch.Size([1, 1350]) \u8fd9\u6837\uff0c\u795e\u7ecf\u7f51\u7edc\u7684\u6570\u636e\u7684\u4e00\u4e2a\u5b8c\u6574\u7684\u4f20\u64ad\u5c31\u5df2\u7ecf\u901a\u8fc7PyTorch\u5b9e\u73b0\u4e86\uff0c\u4e0b\u9762\u4e00\u7ae0\u5c06\u4ecb\u7ecdPyTorch\u63d0\u4f9b\u7684\u6570\u636e\u52a0\u8f7d\u548c\u5904\u7406\u5de5\u5177\uff0c\u4f7f\u7528\u8fd9\u4e9b\u5de5\u5177\u53ef\u4ee5\u65b9\u4fbf\u7684\u5904\u7406\u6240\u9700\u8981\u7684\u6570\u636e\u3002 \u770b\u5b8c\u8fd9\u8282\uff0c\u5927\u5bb6\u53ef\u80fd\u5bf9\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u91cc\u9762\u7684\u4e00\u4e9b\u53c2\u6570\u7684\u8ba1\u7b97\u65b9\u5f0f\u8fd8\u6709\u7591\u60d1\uff0c\u8fd9\u90e8\u5206\u4f1a\u5728\u7b2c\u4e8c\u7ae0\u7b2c\u56db\u8282 \u5377\u79ef\u795e\u7ecf\u7f51\u7edc \u6709\u8be6\u7ec6\u4ecb\u7ecd\uff0c\u5e76\u4e14\u5728\u7b2c\u4e09\u7ae0 \u7b2c\u4e8c\u8282 MNIST\u6570\u636e\u96c6\u624b\u5199\u6570\u5b57\u8bc6\u522b \u7684\u5b9e\u8df5\u4ee3\u7801\u4e2d\u6709\u8be6\u7ec6\u7684\u6ce8\u91ca\u8bf4\u660e\u3002","title":"\u4f18\u5316\u5668"},{"location":"tutorial/chapter02_basics/2_1_4_pytorch-basics-data-loader/","text":"PyTorch \u57fa\u7840 :\u6570\u636e\u7684\u52a0\u8f7d\u548c\u9884\u5904\u7406 \u00b6 PyTorch\u901a\u8fc7torch.utils.data\u5bf9\u4e00\u822c\u5e38\u7528\u7684\u6570\u636e\u52a0\u8f7d\u8fdb\u884c\u4e86\u5c01\u88c5\uff0c\u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u5b9e\u73b0\u591a\u7ebf\u7a0b\u6570\u636e\u9884\u8bfb\u548c\u6279\u91cf\u52a0\u8f7d\u3002 \u5e76\u4e14torchvision\u5df2\u7ecf\u9884\u5148\u5b9e\u73b0\u4e86\u5e38\u7528\u56fe\u50cf\u6570\u636e\u96c6\uff0c\u5305\u62ec\u524d\u9762\u4f7f\u7528\u8fc7\u7684CIFAR-10\uff0cImageNet\u3001COCO\u3001MNIST\u3001LSUN\u7b49\u6570\u636e\u96c6\uff0c\u53ef\u901a\u8fc7torchvision.datasets\u65b9\u4fbf\u7684\u8c03\u7528 # \u9996\u5148\u8981\u5f15\u5165\u76f8\u5173\u7684\u5305 import torch #\u6253\u5370\u4e00\u4e0b\u7248\u672c torch . __version__ '1.0.1.post2' Dataset \u00b6 Dataset\u662f\u4e00\u4e2a\u62bd\u8c61\u7c7b, \u4e3a\u4e86\u80fd\u591f\u65b9\u4fbf\u7684\u8bfb\u53d6\uff0c\u9700\u8981\u5c06\u8981\u4f7f\u7528\u7684\u6570\u636e\u5305\u88c5\u4e3aDataset\u7c7b\u3002 \u81ea\u5b9a\u4e49\u7684Dataset\u9700\u8981\u7ee7\u627f\u5b83\u5e76\u4e14\u5b9e\u73b0\u4e24\u4e2a\u6210\u5458\u65b9\u6cd5\uff1a 1. __getitem__() \u8be5\u65b9\u6cd5\u5b9a\u4e49\u7528\u7d22\u5f15( 0 \u5230 len(self) )\u83b7\u53d6\u4e00\u6761\u6570\u636e\u6216\u4e00\u4e2a\u6837\u672c 2. __len__() \u8be5\u65b9\u6cd5\u8fd4\u56de\u6570\u636e\u96c6\u7684\u603b\u957f\u5ea6 \u4e0b\u9762\u6211\u4eec\u4f7f\u7528kaggle\u4e0a\u7684\u4e00\u4e2a\u7ade\u8d5b bluebook for bulldozers \u81ea\u5b9a\u4e49\u4e00\u4e2a\u6570\u636e\u96c6\uff0c\u4e3a\u4e86\u65b9\u4fbf\u4ecb\u7ecd\uff0c\u6211\u4eec\u4f7f\u7528\u91cc\u9762\u7684\u6570\u636e\u5b57\u5178\u6765\u505a\u8bf4\u660e\uff08\u56e0\u4e3a\u6761\u6570\u5c11\uff09 #\u5f15\u7528 from torch.utils.data import Dataset import pandas as pd #\u5b9a\u4e49\u4e00\u4e2a\u6570\u636e\u96c6 class BulldozerDataset ( Dataset ): \"\"\" \u6570\u636e\u96c6\u6f14\u793a \"\"\" def __init__ ( self , csv_file ): \"\"\"\u5b9e\u73b0\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u5728\u521d\u59cb\u5316\u7684\u65f6\u5019\u5c06\u6570\u636e\u8bfb\u8f7d\u5165\"\"\" self . df = pd . read_csv ( csv_file ) def __len__ ( self ): ''' \u8fd4\u56dedf\u7684\u957f\u5ea6 ''' return len ( self . df ) def __getitem__ ( self , idx ): ''' \u6839\u636e idx \u8fd4\u56de\u4e00\u884c\u6570\u636e ''' return self . df . iloc [ idx ] . SalePrice \u81f3\u6b64\uff0c\u6211\u4eec\u7684\u6570\u636e\u96c6\u5df2\u7ecf\u5b9a\u4e49\u5b8c\u6210\u4e86\uff0c\u6211\u4eec\u53ef\u4ee5\u5b9e\u4f8b\u8bdd\u4e00\u4e2a\u5bf9\u8c61\u8bbf\u95ee\u4ed6 ds_demo = BulldozerDataset ( 'median_benchmark.csv' ) \u6211\u4eec\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528\u5982\u4e0b\u547d\u4ee4\u67e5\u770b\u6570\u636e\u96c6\u6570\u636e #\u5b9e\u73b0\u4e86 __len__ \u65b9\u6cd5\u6240\u4ee5\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528len\u83b7\u53d6\u6570\u636e\u603b\u6570 len ( ds_demo ) 11573 #\u7528\u7d22\u5f15\u53ef\u4ee5\u76f4\u63a5\u8bbf\u95ee\u5bf9\u5e94\u7684\u6570\u636e, \u5bf9\u5e94 __getitem__ \u65b9\u6cd5 ds_demo [ 0 ] 24000.0 \u81ea\u5b9a\u4e49\u7684\u6570\u636e\u96c6\u5df2\u7ecf\u521b\u5efa\u597d\u4e86\uff0c\u4e0b\u9762\u6211\u4eec\u4f7f\u7528\u5b98\u65b9\u63d0\u4f9b\u7684\u6570\u636e\u8f7d\u5165\u5668\uff0c\u8bfb\u53d6\u6570\u636e Dataloader \u00b6 DataLoader\u4e3a\u6211\u4eec\u63d0\u4f9b\u4e86\u5bf9Dataset\u7684\u8bfb\u53d6\u64cd\u4f5c\uff0c\u5e38\u7528\u53c2\u6570\u6709\uff1abatch_size(\u6bcf\u4e2abatch\u7684\u5927\u5c0f), shuffle(\u662f\u5426\u8fdb\u884cshuffle\u64cd\u4f5c), num_workers(\u52a0\u8f7d\u6570\u636e\u7684\u65f6\u5019\u4f7f\u7528\u51e0\u4e2a\u5b50\u8fdb\u7a0b)\uff0c\u4e0b\u9762\u505a\u4e00\u4e2a\u7b80\u5355\u7684\u64cd\u4f5c dl = torch . utils . data . DataLoader ( ds_demo , batch_size = 10 , shuffle = True , num_workers = 0 ) DataLoader\u8fd4\u56de\u7684\u662f\u4e00\u4e2a\u53ef\u8fed\u4ee3\u5bf9\u8c61\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u8fed\u4ee3\u5668\u5206\u6b21\u83b7\u53d6\u6570\u636e idata = iter ( dl ) print ( next ( idata )) tensor([24000., 24000., 24000., 24000., 24000., 24000., 24000., 24000., 24000., 24000.], dtype=torch.float64) \u5e38\u89c1\u7684\u7528\u6cd5\u662f\u4f7f\u7528for\u5faa\u73af\u5bf9\u5176\u8fdb\u884c\u904d\u5386 for i , data in enumerate ( dl ): print ( i , data ) # \u4e3a\u4e86\u8282\u7ea6\u7a7a\u95f4, \u8fd9\u91cc\u53ea\u5faa\u73af\u4e00\u904d break 0 tensor([24000., 24000., 24000., 24000., 24000., 24000., 24000., 24000., 24000., 24000.], dtype=torch.float64) \u6211\u4eec\u5df2\u7ecf\u53ef\u4ee5\u901a\u8fc7dataset\u5b9a\u4e49\u6570\u636e\u96c6\uff0c\u5e76\u4f7f\u7528Datalorder\u8f7d\u5165\u548c\u904d\u5386\u6570\u636e\u96c6\uff0c\u9664\u4e86\u8fd9\u4e9b\u4ee5\u5916\uff0cPyTorch\u8fd8\u63d0\u4f9b\u80fdtorcvision\u7684\u8ba1\u7b97\u673a\u89c6\u89c9\u6269\u5c55\u5305\uff0c\u91cc\u9762\u5c01\u88c5\u4e86 torchvision \u5305 \u00b6 torchvision \u662fPyTorch\u4e2d\u4e13\u95e8\u7528\u6765\u5904\u7406\u56fe\u50cf\u7684\u5e93\uff0cPyTorch\u5b98\u7f51\u7684\u5b89\u88c5\u6559\u7a0b\u4e2d\u6700\u540e\u7684pip install torchvision \u5c31\u662f\u5b89\u88c5\u8fd9\u4e2a\u5305\u3002 torchvision.datasets \u00b6 torchvision.datasets \u53ef\u4ee5\u7406\u89e3\u4e3aPyTorch\u56e2\u961f\u81ea\u5b9a\u4e49\u7684dataset\uff0c\u8fd9\u4e9bdataset\u5e2e\u6211\u4eec\u63d0\u524d\u5904\u7406\u597d\u4e86\u5f88\u591a\u7684\u56fe\u7247\u6570\u636e\u96c6\uff0c\u6211\u4eec\u62ff\u6765\u5c31\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528\uff1a - MNIST - COCO - Captions - Detection - LSUN - ImageFolder - Imagenet-12 - CIFAR - STL10 - SVHN - PhotoTour \u6211\u4eec\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528\uff0c\u793a\u4f8b\u5982\u4e0b\uff1a import torchvision.datasets as datasets trainset = datasets . MNIST ( root = './data' , # \u8868\u793a MNIST \u6570\u636e\u7684\u52a0\u8f7d\u7684\u76ee\u5f55 train = True , # \u8868\u793a\u662f\u5426\u52a0\u8f7d\u6570\u636e\u5e93\u7684\u8bad\u7ec3\u96c6\uff0cfalse\u7684\u65f6\u5019\u52a0\u8f7d\u6d4b\u8bd5\u96c6 download = True , # \u8868\u793a\u662f\u5426\u81ea\u52a8\u4e0b\u8f7d MNIST \u6570\u636e\u96c6 transform = None ) # \u8868\u793a\u662f\u5426\u9700\u8981\u5bf9\u6570\u636e\u8fdb\u884c\u9884\u5904\u7406\uff0cnone\u4e3a\u4e0d\u8fdb\u884c\u9884\u5904\u7406 torchvision.models \u00b6 torchvision\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u5e38\u7528\u56fe\u7247\u6570\u636e\u96c6\uff0c\u8fd8\u63d0\u4f9b\u4e86\u8bad\u7ec3\u597d\u7684\u6a21\u578b\uff0c\u53ef\u4ee5\u52a0\u8f7d\u4e4b\u540e\uff0c\u76f4\u63a5\u4f7f\u7528\uff0c\u6216\u8005\u5728\u8fdb\u884c\u8fc1\u79fb\u5b66\u4e60 torchvision.models\u6a21\u5757\u7684 \u5b50\u6a21\u5757\u4e2d\u5305\u542b\u4ee5\u4e0b\u6a21\u578b\u7ed3\u6784\u3002 - AlexNet - VGG - ResNet - SqueezeNet - DenseNet #\u6211\u4eec\u76f4\u63a5\u53ef\u4ee5\u4f7f\u7528\u8bad\u7ec3\u597d\u7684\u6a21\u578b\uff0c\u5f53\u7136\u8fd9\u4e2a\u4e0edatasets\u76f8\u540c\uff0c\u90fd\u662f\u9700\u8981\u4ece\u670d\u52a1\u5668\u4e0b\u8f7d\u7684 import torchvision.models as models resnet18 = models . resnet18 ( pretrained = True ) torchvision.transforms \u00b6 transforms \u6a21\u5757\u63d0\u4f9b\u4e86\u4e00\u822c\u7684\u56fe\u50cf\u8f6c\u6362\u64cd\u4f5c\u7c7b\uff0c\u7528\u4f5c\u6570\u636e\u5904\u7406\u548c\u6570\u636e\u589e\u5f3a from torchvision import transforms as transforms transform = transforms . Compose ([ transforms . RandomCrop ( 32 , padding = 4 ), #\u5148\u56db\u5468\u586b\u51450\uff0c\u5728\u628a\u56fe\u50cf\u968f\u673a\u88c1\u526a\u621032*32 transforms . RandomHorizontalFlip (), #\u56fe\u50cf\u4e00\u534a\u7684\u6982\u7387\u7ffb\u8f6c\uff0c\u4e00\u534a\u7684\u6982\u7387\u4e0d\u7ffb\u8f6c transforms . RandomRotation (( - 45 , 45 )), #\u968f\u673a\u65cb\u8f6c transforms . ToTensor (), transforms . Normalize (( 0.4914 , 0.4822 , 0.4465 ), ( 0.229 , 0.224 , 0.225 )), #R,G,B\u6bcf\u5c42\u7684\u5f52\u4e00\u5316\u7528\u5230\u7684\u5747\u503c\u548c\u65b9\u5dee ]) \u80af\u5b9a\u6709\u4eba\u4f1a\u95ee\uff1a(0.485, 0.456, 0.406), (0.2023, 0.1994, 0.2010) \u8fd9\u51e0\u4e2a\u6570\u5b57\u662f\u4ec0\u4e48\u610f\u601d\uff1f \u5b98\u65b9\u7684\u8fd9\u4e2a\u5e16\u5b50\u6709\u8be6\u7ec6\u7684\u8bf4\u660e: https://discuss.pytorch.org/t/normalization-in-the-mnist-example/457/21 \u8fd9\u4e9b\u90fd\u662f\u6839\u636eImageNet\u8bad\u7ec3\u7684\u5f52\u4e00\u5316\u53c2\u6570\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528\uff0c\u6211\u4eec\u8ba4\u4e3a\u8fd9\u4e2a\u662f\u56fa\u5b9a\u503c\u5c31\u53ef\u4ee5 \u6211\u4eec\u5df2\u7ecf\u5b8c\u6210\u4e86Python\u7684\u57fa\u672c\u5185\u5bb9\u7684\u4ecb\u7ecd\uff0c\u4e0b\u9762\u6211\u4eec\u8981\u4ecb\u7ecd\u795e\u7ecf\u7f51\u7edc\u7684\u7406\u8bba\u57fa\u7840\uff0c\u91cc\u9762\u7684\u516c\u5f0f\u7b49\u5185\u5bb9\u6211\u4eec\u90fd\u4f7f\u7528PyTorch\u6765\u5b9e\u73b0","title":"2.1.4 Data Loader"},{"location":"tutorial/chapter02_basics/2_1_4_pytorch-basics-data-loader/#pytorch","text":"PyTorch\u901a\u8fc7torch.utils.data\u5bf9\u4e00\u822c\u5e38\u7528\u7684\u6570\u636e\u52a0\u8f7d\u8fdb\u884c\u4e86\u5c01\u88c5\uff0c\u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u5b9e\u73b0\u591a\u7ebf\u7a0b\u6570\u636e\u9884\u8bfb\u548c\u6279\u91cf\u52a0\u8f7d\u3002 \u5e76\u4e14torchvision\u5df2\u7ecf\u9884\u5148\u5b9e\u73b0\u4e86\u5e38\u7528\u56fe\u50cf\u6570\u636e\u96c6\uff0c\u5305\u62ec\u524d\u9762\u4f7f\u7528\u8fc7\u7684CIFAR-10\uff0cImageNet\u3001COCO\u3001MNIST\u3001LSUN\u7b49\u6570\u636e\u96c6\uff0c\u53ef\u901a\u8fc7torchvision.datasets\u65b9\u4fbf\u7684\u8c03\u7528 # \u9996\u5148\u8981\u5f15\u5165\u76f8\u5173\u7684\u5305 import torch #\u6253\u5370\u4e00\u4e0b\u7248\u672c torch . __version__ '1.0.1.post2'","title":"PyTorch \u57fa\u7840 :\u6570\u636e\u7684\u52a0\u8f7d\u548c\u9884\u5904\u7406"},{"location":"tutorial/chapter02_basics/2_1_4_pytorch-basics-data-loader/#dataset","text":"Dataset\u662f\u4e00\u4e2a\u62bd\u8c61\u7c7b, \u4e3a\u4e86\u80fd\u591f\u65b9\u4fbf\u7684\u8bfb\u53d6\uff0c\u9700\u8981\u5c06\u8981\u4f7f\u7528\u7684\u6570\u636e\u5305\u88c5\u4e3aDataset\u7c7b\u3002 \u81ea\u5b9a\u4e49\u7684Dataset\u9700\u8981\u7ee7\u627f\u5b83\u5e76\u4e14\u5b9e\u73b0\u4e24\u4e2a\u6210\u5458\u65b9\u6cd5\uff1a 1. __getitem__() \u8be5\u65b9\u6cd5\u5b9a\u4e49\u7528\u7d22\u5f15( 0 \u5230 len(self) )\u83b7\u53d6\u4e00\u6761\u6570\u636e\u6216\u4e00\u4e2a\u6837\u672c 2. __len__() \u8be5\u65b9\u6cd5\u8fd4\u56de\u6570\u636e\u96c6\u7684\u603b\u957f\u5ea6 \u4e0b\u9762\u6211\u4eec\u4f7f\u7528kaggle\u4e0a\u7684\u4e00\u4e2a\u7ade\u8d5b bluebook for bulldozers \u81ea\u5b9a\u4e49\u4e00\u4e2a\u6570\u636e\u96c6\uff0c\u4e3a\u4e86\u65b9\u4fbf\u4ecb\u7ecd\uff0c\u6211\u4eec\u4f7f\u7528\u91cc\u9762\u7684\u6570\u636e\u5b57\u5178\u6765\u505a\u8bf4\u660e\uff08\u56e0\u4e3a\u6761\u6570\u5c11\uff09 #\u5f15\u7528 from torch.utils.data import Dataset import pandas as pd #\u5b9a\u4e49\u4e00\u4e2a\u6570\u636e\u96c6 class BulldozerDataset ( Dataset ): \"\"\" \u6570\u636e\u96c6\u6f14\u793a \"\"\" def __init__ ( self , csv_file ): \"\"\"\u5b9e\u73b0\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u5728\u521d\u59cb\u5316\u7684\u65f6\u5019\u5c06\u6570\u636e\u8bfb\u8f7d\u5165\"\"\" self . df = pd . read_csv ( csv_file ) def __len__ ( self ): ''' \u8fd4\u56dedf\u7684\u957f\u5ea6 ''' return len ( self . df ) def __getitem__ ( self , idx ): ''' \u6839\u636e idx \u8fd4\u56de\u4e00\u884c\u6570\u636e ''' return self . df . iloc [ idx ] . SalePrice \u81f3\u6b64\uff0c\u6211\u4eec\u7684\u6570\u636e\u96c6\u5df2\u7ecf\u5b9a\u4e49\u5b8c\u6210\u4e86\uff0c\u6211\u4eec\u53ef\u4ee5\u5b9e\u4f8b\u8bdd\u4e00\u4e2a\u5bf9\u8c61\u8bbf\u95ee\u4ed6 ds_demo = BulldozerDataset ( 'median_benchmark.csv' ) \u6211\u4eec\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528\u5982\u4e0b\u547d\u4ee4\u67e5\u770b\u6570\u636e\u96c6\u6570\u636e #\u5b9e\u73b0\u4e86 __len__ \u65b9\u6cd5\u6240\u4ee5\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528len\u83b7\u53d6\u6570\u636e\u603b\u6570 len ( ds_demo ) 11573 #\u7528\u7d22\u5f15\u53ef\u4ee5\u76f4\u63a5\u8bbf\u95ee\u5bf9\u5e94\u7684\u6570\u636e, \u5bf9\u5e94 __getitem__ \u65b9\u6cd5 ds_demo [ 0 ] 24000.0 \u81ea\u5b9a\u4e49\u7684\u6570\u636e\u96c6\u5df2\u7ecf\u521b\u5efa\u597d\u4e86\uff0c\u4e0b\u9762\u6211\u4eec\u4f7f\u7528\u5b98\u65b9\u63d0\u4f9b\u7684\u6570\u636e\u8f7d\u5165\u5668\uff0c\u8bfb\u53d6\u6570\u636e","title":"Dataset"},{"location":"tutorial/chapter02_basics/2_1_4_pytorch-basics-data-loader/#dataloader","text":"DataLoader\u4e3a\u6211\u4eec\u63d0\u4f9b\u4e86\u5bf9Dataset\u7684\u8bfb\u53d6\u64cd\u4f5c\uff0c\u5e38\u7528\u53c2\u6570\u6709\uff1abatch_size(\u6bcf\u4e2abatch\u7684\u5927\u5c0f), shuffle(\u662f\u5426\u8fdb\u884cshuffle\u64cd\u4f5c), num_workers(\u52a0\u8f7d\u6570\u636e\u7684\u65f6\u5019\u4f7f\u7528\u51e0\u4e2a\u5b50\u8fdb\u7a0b)\uff0c\u4e0b\u9762\u505a\u4e00\u4e2a\u7b80\u5355\u7684\u64cd\u4f5c dl = torch . utils . data . DataLoader ( ds_demo , batch_size = 10 , shuffle = True , num_workers = 0 ) DataLoader\u8fd4\u56de\u7684\u662f\u4e00\u4e2a\u53ef\u8fed\u4ee3\u5bf9\u8c61\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u8fed\u4ee3\u5668\u5206\u6b21\u83b7\u53d6\u6570\u636e idata = iter ( dl ) print ( next ( idata )) tensor([24000., 24000., 24000., 24000., 24000., 24000., 24000., 24000., 24000., 24000.], dtype=torch.float64) \u5e38\u89c1\u7684\u7528\u6cd5\u662f\u4f7f\u7528for\u5faa\u73af\u5bf9\u5176\u8fdb\u884c\u904d\u5386 for i , data in enumerate ( dl ): print ( i , data ) # \u4e3a\u4e86\u8282\u7ea6\u7a7a\u95f4, \u8fd9\u91cc\u53ea\u5faa\u73af\u4e00\u904d break 0 tensor([24000., 24000., 24000., 24000., 24000., 24000., 24000., 24000., 24000., 24000.], dtype=torch.float64) \u6211\u4eec\u5df2\u7ecf\u53ef\u4ee5\u901a\u8fc7dataset\u5b9a\u4e49\u6570\u636e\u96c6\uff0c\u5e76\u4f7f\u7528Datalorder\u8f7d\u5165\u548c\u904d\u5386\u6570\u636e\u96c6\uff0c\u9664\u4e86\u8fd9\u4e9b\u4ee5\u5916\uff0cPyTorch\u8fd8\u63d0\u4f9b\u80fdtorcvision\u7684\u8ba1\u7b97\u673a\u89c6\u89c9\u6269\u5c55\u5305\uff0c\u91cc\u9762\u5c01\u88c5\u4e86","title":"Dataloader"},{"location":"tutorial/chapter02_basics/2_1_4_pytorch-basics-data-loader/#torchvision","text":"torchvision \u662fPyTorch\u4e2d\u4e13\u95e8\u7528\u6765\u5904\u7406\u56fe\u50cf\u7684\u5e93\uff0cPyTorch\u5b98\u7f51\u7684\u5b89\u88c5\u6559\u7a0b\u4e2d\u6700\u540e\u7684pip install torchvision \u5c31\u662f\u5b89\u88c5\u8fd9\u4e2a\u5305\u3002","title":"torchvision \u5305"},{"location":"tutorial/chapter02_basics/2_1_4_pytorch-basics-data-loader/#torchvisiondatasets","text":"torchvision.datasets \u53ef\u4ee5\u7406\u89e3\u4e3aPyTorch\u56e2\u961f\u81ea\u5b9a\u4e49\u7684dataset\uff0c\u8fd9\u4e9bdataset\u5e2e\u6211\u4eec\u63d0\u524d\u5904\u7406\u597d\u4e86\u5f88\u591a\u7684\u56fe\u7247\u6570\u636e\u96c6\uff0c\u6211\u4eec\u62ff\u6765\u5c31\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528\uff1a - MNIST - COCO - Captions - Detection - LSUN - ImageFolder - Imagenet-12 - CIFAR - STL10 - SVHN - PhotoTour \u6211\u4eec\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528\uff0c\u793a\u4f8b\u5982\u4e0b\uff1a import torchvision.datasets as datasets trainset = datasets . MNIST ( root = './data' , # \u8868\u793a MNIST \u6570\u636e\u7684\u52a0\u8f7d\u7684\u76ee\u5f55 train = True , # \u8868\u793a\u662f\u5426\u52a0\u8f7d\u6570\u636e\u5e93\u7684\u8bad\u7ec3\u96c6\uff0cfalse\u7684\u65f6\u5019\u52a0\u8f7d\u6d4b\u8bd5\u96c6 download = True , # \u8868\u793a\u662f\u5426\u81ea\u52a8\u4e0b\u8f7d MNIST \u6570\u636e\u96c6 transform = None ) # \u8868\u793a\u662f\u5426\u9700\u8981\u5bf9\u6570\u636e\u8fdb\u884c\u9884\u5904\u7406\uff0cnone\u4e3a\u4e0d\u8fdb\u884c\u9884\u5904\u7406","title":"torchvision.datasets"},{"location":"tutorial/chapter02_basics/2_1_4_pytorch-basics-data-loader/#torchvisionmodels","text":"torchvision\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u5e38\u7528\u56fe\u7247\u6570\u636e\u96c6\uff0c\u8fd8\u63d0\u4f9b\u4e86\u8bad\u7ec3\u597d\u7684\u6a21\u578b\uff0c\u53ef\u4ee5\u52a0\u8f7d\u4e4b\u540e\uff0c\u76f4\u63a5\u4f7f\u7528\uff0c\u6216\u8005\u5728\u8fdb\u884c\u8fc1\u79fb\u5b66\u4e60 torchvision.models\u6a21\u5757\u7684 \u5b50\u6a21\u5757\u4e2d\u5305\u542b\u4ee5\u4e0b\u6a21\u578b\u7ed3\u6784\u3002 - AlexNet - VGG - ResNet - SqueezeNet - DenseNet #\u6211\u4eec\u76f4\u63a5\u53ef\u4ee5\u4f7f\u7528\u8bad\u7ec3\u597d\u7684\u6a21\u578b\uff0c\u5f53\u7136\u8fd9\u4e2a\u4e0edatasets\u76f8\u540c\uff0c\u90fd\u662f\u9700\u8981\u4ece\u670d\u52a1\u5668\u4e0b\u8f7d\u7684 import torchvision.models as models resnet18 = models . resnet18 ( pretrained = True )","title":"torchvision.models"},{"location":"tutorial/chapter02_basics/2_1_4_pytorch-basics-data-loader/#torchvisiontransforms","text":"transforms \u6a21\u5757\u63d0\u4f9b\u4e86\u4e00\u822c\u7684\u56fe\u50cf\u8f6c\u6362\u64cd\u4f5c\u7c7b\uff0c\u7528\u4f5c\u6570\u636e\u5904\u7406\u548c\u6570\u636e\u589e\u5f3a from torchvision import transforms as transforms transform = transforms . Compose ([ transforms . RandomCrop ( 32 , padding = 4 ), #\u5148\u56db\u5468\u586b\u51450\uff0c\u5728\u628a\u56fe\u50cf\u968f\u673a\u88c1\u526a\u621032*32 transforms . RandomHorizontalFlip (), #\u56fe\u50cf\u4e00\u534a\u7684\u6982\u7387\u7ffb\u8f6c\uff0c\u4e00\u534a\u7684\u6982\u7387\u4e0d\u7ffb\u8f6c transforms . RandomRotation (( - 45 , 45 )), #\u968f\u673a\u65cb\u8f6c transforms . ToTensor (), transforms . Normalize (( 0.4914 , 0.4822 , 0.4465 ), ( 0.229 , 0.224 , 0.225 )), #R,G,B\u6bcf\u5c42\u7684\u5f52\u4e00\u5316\u7528\u5230\u7684\u5747\u503c\u548c\u65b9\u5dee ]) \u80af\u5b9a\u6709\u4eba\u4f1a\u95ee\uff1a(0.485, 0.456, 0.406), (0.2023, 0.1994, 0.2010) \u8fd9\u51e0\u4e2a\u6570\u5b57\u662f\u4ec0\u4e48\u610f\u601d\uff1f \u5b98\u65b9\u7684\u8fd9\u4e2a\u5e16\u5b50\u6709\u8be6\u7ec6\u7684\u8bf4\u660e: https://discuss.pytorch.org/t/normalization-in-the-mnist-example/457/21 \u8fd9\u4e9b\u90fd\u662f\u6839\u636eImageNet\u8bad\u7ec3\u7684\u5f52\u4e00\u5316\u53c2\u6570\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528\uff0c\u6211\u4eec\u8ba4\u4e3a\u8fd9\u4e2a\u662f\u56fa\u5b9a\u503c\u5c31\u53ef\u4ee5 \u6211\u4eec\u5df2\u7ecf\u5b8c\u6210\u4e86Python\u7684\u57fa\u672c\u5185\u5bb9\u7684\u4ecb\u7ecd\uff0c\u4e0b\u9762\u6211\u4eec\u8981\u4ecb\u7ecd\u795e\u7ecf\u7f51\u7edc\u7684\u7406\u8bba\u57fa\u7840\uff0c\u91cc\u9762\u7684\u516c\u5f0f\u7b49\u5185\u5bb9\u6211\u4eec\u90fd\u4f7f\u7528PyTorch\u6765\u5b9e\u73b0","title":"torchvision.transforms"},{"location":"tutorial/chapter02_basics/2_2_deep-learning-mathematics-basic/","text":"2.2 \u6df1\u5ea6\u5b66\u4e60\u57fa\u7840\u53ca\u6570\u5b66\u539f\u7406 \u00b6 \u6df1\u5ea6\u5b66\u4e60\u5e76\u6ca1\u6709\u60f3\u8c61\u7684\u90a3\u4e48\u96be\uff0c\u751a\u81f3\u6bd4\u6709\u4e9b\u4f20\u7edf\u7684\u673a\u5668\u5b66\u4e60\u66f4\u7b80\u5355\u3002\u6240\u7528\u5230\u7684\u6570\u5b66\u77e5\u8bc6\u4e5f\u4e0d\u9700\u8981\u7279\u522b\u7684\u9ad8\u6df1\uff0c\u672c\u7ae0\u5c06\u4f1a\u4e00\u8fb9\u8bb2\u89e3\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u57fa\u672c\u7406\u8bba\uff0c\u4e00\u8fb9\u901a\u8fc7\u52a8\u624b\u4f7f\u7528PyTorch\u5b9e\u73b0\u4e00\u4e9b\u7b80\u5355\u7684\u7406\u8bba\uff0c\u672c\u7ae0\u5185\u5bb9\u5f88\u591a\uff0c\u6240\u4ee5\u53ea\u505a\u4e00\u4e2a\u7b80\u77ed\u7684\u4ecb\u7ecd 2.2.1 \u76d1\u7763\u5b66\u4e60\u548c\u65e0\u76d1\u7763\u5b66\u4e60 \u00b6 \u76d1\u7763\u5b66\u4e60\u3001\u65e0\u76d1\u7763\u5b66\u4e60\u3001\u534a\u76d1\u7763\u5b66\u4e60\u3001\u5f3a\u5316\u5b66\u4e60\u662f\u6211\u4eec\u65e5\u5e38\u63a5\u89e6\u5230\u7684\u5e38\u89c1\u7684\u56db\u4e2a\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff1a \u76d1\u7763\u5b66\u4e60\uff1a\u901a\u8fc7\u5df2\u6709\u7684\u8bad\u7ec3\u6837\u672c\uff08\u5373\u5df2\u77e5\u6570\u636e\u4ee5\u53ca\u5176\u5bf9\u5e94\u7684\u8f93\u51fa\uff09\u53bb\u8bad\u7ec3\u5f97\u5230\u4e00\u4e2a\u6700\u4f18\u6a21\u578b\uff08\u8fd9\u4e2a\u6a21\u578b\u5c5e\u4e8e\u67d0\u4e2a\u51fd\u6570\u7684\u96c6\u5408\uff0c\u6700\u4f18\u5219\u8868\u793a\u5728\u67d0\u4e2a\u8bc4\u4ef7\u51c6\u5219\u4e0b\u662f\u6700\u4f73\u7684\uff09\uff0c\u518d\u5229\u7528\u8fd9\u4e2a\u6a21\u578b\u5c06\u6240\u6709\u7684\u8f93\u5165\u6620\u5c04\u4e3a\u76f8\u5e94\u7684\u8f93\u51fa\u3002 \u65e0\u76d1\u7763\u5b66\u4e60\uff1a\u5b83\u4e0e\u76d1\u7763\u5b66\u4e60\u7684\u4e0d\u540c\u4e4b\u5904\uff0c\u5728\u4e8e\u6211\u4eec\u4e8b\u5148\u6ca1\u6709\u4efb\u4f55\u8bad\u7ec3\u6837\u672c\uff0c\u800c\u9700\u8981\u76f4\u63a5\u5bf9\u6570\u636e\u8fdb\u884c\u5efa\u6a21\u3002 \u534a\u76d1\u7763\u5b66\u4e60 \uff1a\u5728\u8bad\u7ec3\u9636\u6bb5\u7ed3\u5408\u4e86\u5927\u91cf\u672a\u6807\u8bb0\u7684\u6570\u636e\u548c\u5c11\u91cf\u6807\u7b7e\u6570\u636e\u3002\u4e0e\u4f7f\u7528\u6240\u6709\u6807\u7b7e\u6570\u636e\u7684\u6a21\u578b\u76f8\u6bd4\uff0c\u4f7f\u7528\u8bad\u7ec3\u96c6\u7684\u8bad\u7ec3\u6a21\u578b\u5728\u8bad\u7ec3\u65f6\u53ef\u4ee5\u66f4\u4e3a\u51c6\u786e\u3002 \u5f3a\u5316\u5b66\u4e60\uff1a\u6211\u4eec\u8bbe\u5b9a\u4e00\u4e2a\u56de\u62a5\u51fd\u6570\uff08reward function\uff09\uff0c\u901a\u8fc7\u8fd9\u4e2a\u51fd\u6570\u6765\u786e\u8ba4\u5426\u8d8a\u6765\u8d8a\u63a5\u8fd1\u76ee\u6807\uff0c\u7c7b\u4f3c\u6211\u4eec\u8bad\u7ec3\u5ba0\u7269\uff0c\u5982\u679c\u505a\u5bf9\u4e86\u5c31\u7ed9\u4ed6\u5956\u52b1\uff0c\u505a\u9519\u4e86\u5c31\u7ed9\u4e88\u60e9\u7f5a\uff0c\u6700\u540e\u6765\u8fbe\u5230\u6211\u4eec\u7684\u8bad\u7ec3\u76ee\u7684\u3002 \u8fd9\u91cc\u6211\u4eec\u53ea\u7740\u91cd\u4ecb\u7ecd\u76d1\u7763\u5b66\u4e60\uff0c\u56e0\u4e3a\u6211\u4eec\u540e\u9762\u7684\u7edd\u5927\u90e8\u4eec\u8bfe\u7a0b\u90fd\u662f\u4f7f\u7528\u7684\u76d1\u7763\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u5728\u8bad\u7ec3\u548c\u9a8c\u8bc1\u65f6\u8f93\u5165\u7684\u6570\u636e\u65e2\u5305\u542b\u8f93\u5165x,\u53c8\u5305\u542bx\u5bf9\u5e94\u7684\u8f93\u51fay\uff0c\u5373\u5b66\u4e60\u6570\u636e\u5df2\u7ecf\u4e8b\u5148\u7ed9\u51fa\u4e86\u6b63\u786e\u7b54\u6848\u3002 2.2.2 \u7ebf\u6027\u56de\u5f52 \uff08Linear Regreesion\uff09 \u00b6 \u7ebf\u6027\u56de\u5f52\u662f\u5229\u7528\u6570\u7406\u7edf\u8ba1\u4e2d\u56de\u5f52\u5206\u6790\uff0c\u6765\u786e\u5b9a\u4e24\u79cd\u6216\u4e24\u79cd\u4ee5\u4e0a\u53d8\u91cf\u95f4\u76f8\u4e92\u4f9d\u8d56\u7684\u5b9a\u91cf\u5173\u7cfb\u7684\u4e00\u79cd\u7edf\u8ba1\u5206\u6790\u65b9\u6cd5\uff0c\u8fd0\u7528\u5341\u5206\u5e7f\u6cdb\u3002\u5176\u8868\u8fbe\u5f62\u5f0f\u4e3ay = w'x+e\uff0ce\u4e3a\u8bef\u5dee\u670d\u4ece\u5747\u503c\u4e3a0\u7684\u6b63\u6001\u5206\u5e03\u3002 \u56de\u5f52\u5206\u6790\u4e2d\uff0c\u53ea\u5305\u62ec\u4e00\u4e2a\u81ea\u53d8\u91cf\u548c\u4e00\u4e2a\u56e0\u53d8\u91cf\uff0c\u4e14\u4e8c\u8005\u7684\u5173\u7cfb\u53ef\u7528\u4e00\u6761\u76f4\u7ebf\u8fd1\u4f3c\u8868\u793a\uff0c\u8fd9\u79cd\u56de\u5f52\u5206\u6790\u79f0\u4e3a\u4e00\u5143\u7ebf\u6027\u56de\u5f52\u5206\u6790\u3002\u5982\u679c\u56de\u5f52\u5206\u6790\u4e2d\u5305\u62ec\u4e24\u4e2a\u6216\u4e24\u4e2a\u4ee5\u4e0a\u7684\u81ea\u53d8\u91cf\uff0c\u4e14\u56e0\u53d8\u91cf\u548c\u81ea\u53d8\u91cf\u4e4b\u95f4\u662f\u7ebf\u6027\u5173\u7cfb\uff0c\u5219\u79f0\u4e3a\u591a\u5143\u7ebf\u6027\u56de\u5f52\u5206\u6790\u3002 \u6458\u81ea \u767e\u5ea6\u767e\u79d1 \u7b80\u5355\u7684\u8bf4\uff1a \u7ebf\u6027\u56de\u5f52\u5bf9\u4e8e\u8f93\u5165x\u4e0e\u8f93\u51fay\u6709\u4e00\u4e2a\u6620\u5c04f\uff0cy=f(x),\u800cf\u7684\u5f62\u5f0f\u4e3aaX+b\u3002\u5176\u4e2da\u548cb\u662f\u4e24\u4e2a\u53ef\u8c03\u7684\u53c2\u6570\uff0c\u6211\u4eec\u8bad\u7ec3\u7684\u65f6\u5019\u5c31\u662f\u8bad\u7ec3a\uff0cb\u8fd9\u4e24\u4e2a\u53c2\u6570\u3002 \u4e0b\u9762\u6211\u4eec\u6765\u7528pyTorch\u7684\u4ee3\u7801\u6765\u505a\u4e00\u4e2a\u8be6\u7ec6\u7684\u89e3\u91ca: # \u5f15\u7528 # \u6ce8\u610f\uff0c\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528\u4e86\u4e00\u4e2a\u65b0\u5e93\u53eb seaborn \u5982\u679c\u62a5\u9519\u627e\u4e0d\u5230\u5305\u7684\u8bdd\u8bf7\u4f7f\u7528pip install seaborn \u6765\u8fdb\u884c\u5b89\u88c5 import torch from torch.nn import Linear , Module , MSELoss from torch.optim import SGD import numpy as np import pandas as pd import matplotlib import matplotlib.pyplot as plt import seaborn as sns torch . __version__ '1.0.1.post2' \u4e0b\u9762\u5b9a\u4e49\u4e00\u4e2a\u7ebf\u6027\u51fd\u6570\uff0c\u8fd9\u91cc\u4f7f\u7528 y = 5x + 7 y = 5x + 7 \uff0c\u8fd9\u91cc\u76845\u548c7\u5c31\u662f\u4e0a\u9762\u8bf4\u5230\u7684\u53c2\u6570a\u548cb\uff0c\u6211\u4eec\u5148\u4f7f\u7528matplot\u53ef\u89c6\u5316\u4e00\u4e0b\u8fd9\u4e2a\u51fd\u6570 x = np . linspace ( 0 , 20 , 500 ) y = 5 * x + 7 plt . plot ( x , y ) [<matplotlib.lines.Line2D at 0x7fd40bbe57f0>] \u4e0b\u9762\u6211\u751f\u6210\u4e00\u4e9b\u968f\u673a\u7684\u70b9\uff0c\u6765\u4f5c\u4e3a\u6211\u4eec\u7684\u8bad\u7ec3\u6570\u636e x = np . random . rand ( 256 ) noise = np . random . randn ( 256 ) / 4 y = x * 5 + 7 + noise df = pd . DataFrame () df [ 'x' ] = x df [ 'y' ] = y \u5728\u56fe\u4e0a\u663e\u793a\u4e0b\u6211\u4eec\u751f\u6210\u7684\u6570\u636e sns . lmplot ( x = 'x' , y = 'y' , data = df ); \u6211\u4eec\u968f\u673a\u751f\u6210\u4e86\u4e00\u4e9b\u70b9\uff0c\u4e0b\u9762\u5c06\u4f7f\u7528PyTorch\u5efa\u7acb\u4e00\u4e2a\u7ebf\u6027\u7684\u6a21\u578b\u6765\u5bf9\u5176\u8fdb\u884c\u62df\u5408\uff0c\u8fd9\u5c31\u662f\u6240\u8bf4\u7684\u8bad\u7ec3\u7684\u8fc7\u7a0b\uff0c\u7531\u4e8e\u53ea\u6709\u4e00\u5c42\u7ebf\u6027\u6a21\u578b\uff0c\u6240\u4ee5\u6211\u4eec\u5c31\u76f4\u63a5\u4f7f\u7528\u4e86\u3002 model = Linear ( 1 , 1 ) \u5176\u4e2d\u53c2\u6570(1, 1)\u4ee3\u8868\u8f93\u5165\u8f93\u51fa\u7684\u7279\u5f81(feature)\u6570\u91cf\u90fd\u662f1. Linear \u6a21\u578b\u7684\u8868\u8fbe\u5f0f\u662f y=w \\cdot x+b y=w \\cdot x+b , \u5176\u4e2d w w \u4ee3\u8868\u6743\u91cd, b b \u4ee3\u8868\u504f\u7f6e\u3002 \u635f\u5931\u51fd\u6570\u6211\u4eec\u4f7f\u7528\u5747\u65b9\u635f\u5931\u51fd\u6570\uff1a MSELoss \uff0c\u8fd9\u4e2a\u540e\u9762\u4f1a\u8be6\u7ec6\u4ecb\u7ecd\u3002 criterion = MSELoss () \u4f18\u5316\u5668\u6211\u4eec\u9009\u62e9\u6700\u5e38\u89c1\u7684\u4f18\u5316\u65b9\u6cd5 SGD \uff0c\u5c31\u662f\u6bcf\u4e00\u6b21\u8fed\u4ee3\u8ba1\u7b97 mini-batch \u7684\u68af\u5ea6\uff0c\u7136\u540e\u5bf9\u53c2\u6570\u8fdb\u884c\u66f4\u65b0\uff0c\u5b66\u4e60\u7387 0.01 \uff0c\u4f18\u5316\u5668\u672c\u7ae0\u540e\u9762\u4e5f\u4f1a\u8fdb\u884c\u4ecb\u7ecd\u3002 optim = SGD ( model . parameters (), lr = 0.01 ) \u8bad\u7ec33000\u6b21 epochs = 3000 \u51c6\u5907\u8bad\u7ec3\u6570\u636e: x_train , y_train \u7684\u5f62\u72b6\u662f (256, 1), \u4ee3\u8868 mini-batch \u5927\u5c0f\u4e3a256, feature \u4e3a1. astype('float32') \u662f\u4e3a\u4e86\u4e0b\u4e00\u6b65\u53ef\u4ee5\u76f4\u63a5\u8f6c\u6362\u4e3a torch.float . x_train = x . reshape ( - 1 , 1 ) . astype ( 'float32' ) y_train = y . reshape ( - 1 , 1 ) . astype ( 'float32' ) \u5f00\u59cb\u8bad\u7ec3\uff1a for i in range ( epochs ): # \u6574\u7406\u8f93\u5165\u548c\u8f93\u51fa\u7684\u6570\u636e\uff0c\u8fd9\u91cc\u8f93\u5165\u548c\u8f93\u51fa\u4e00\u5b9a\u8981\u662ftorch\u7684Tensor\u7c7b\u578b inputs = torch . from_numpy ( x_train ) labels = torch . from_numpy ( y_train ) #\u4f7f\u7528\u6a21\u578b\u8fdb\u884c\u9884\u6d4b outputs = model ( inputs ) #\u68af\u5ea6\u7f6e0\uff0c\u5426\u5219\u4f1a\u7d2f\u52a0 optim . zero_grad () # \u8ba1\u7b97\u635f\u5931 loss = criterion ( outputs , labels ) # \u53cd\u5411\u4f20\u64ad loss . backward () # \u4f7f\u7528\u4f18\u5316\u5668\u9ed8\u8ba4\u65b9\u6cd5\u4f18\u5316 optim . step () if ( i % 100 == 0 ): #\u6bcf 100\u6b21\u6253\u5370\u4e00\u4e0b\u635f\u5931\u51fd\u6570\uff0c\u770b\u770b\u6548\u679c print ( 'epoch {}, loss {:1.4f}' . format ( i , loss . data . item ())) epoch 0, loss 105.8649 epoch 100, loss 0.7534 epoch 200, loss 0.1216 epoch 300, loss 0.1029 epoch 400, loss 0.0915 epoch 500, loss 0.0828 epoch 600, loss 0.0763 epoch 700, loss 0.0713 epoch 800, loss 0.0675 epoch 900, loss 0.0647 epoch 1000, loss 0.0625 epoch 1100, loss 0.0608 epoch 1200, loss 0.0596 epoch 1300, loss 0.0586 epoch 1400, loss 0.0579 epoch 1500, loss 0.0574 epoch 1600, loss 0.0570 epoch 1700, loss 0.0566 epoch 1800, loss 0.0564 epoch 1900, loss 0.0562 epoch 2000, loss 0.0561 epoch 2100, loss 0.0560 epoch 2200, loss 0.0559 epoch 2300, loss 0.0558 epoch 2400, loss 0.0558 epoch 2500, loss 0.0558 epoch 2600, loss 0.0557 epoch 2700, loss 0.0557 epoch 2800, loss 0.0557 epoch 2900, loss 0.0557 \u8bad\u7ec3\u5b8c\u6210\u4e86\uff0c\u770b\u4e00\u4e0b\u8bad\u7ec3\u7684\u6210\u679c\u662f\u591a\u5c11\u3002 \u7528 model.parameters() \u63d0\u53d6\u6a21\u578b\u53c2\u6570\u3002 w w , b b \u662f\u6211\u4eec\u6240\u9700\u8981\u8bad\u7ec3\u7684\u6a21\u578b\u53c2\u6570\u3002 \u6211\u4eec\u671f\u671b\u7684\u6570\u636e w=5 w=5 \uff0c b=7 b=7 \u53ef\u4ee5\u505a\u4e00\u4e0b\u5bf9\u6bd4\uff1a [ w , b ] = model . parameters () print ( w . item (), b . item ()) 4.994358062744141 7.0252156257629395 \u518d\u6b21\u53ef\u89c6\u5316\u4e00\u4e0b\u6211\u4eec\u7684\u6a21\u578b\uff0c\u770b\u770b\u6211\u4eec\u8bad\u7ec3\u7684\u6570\u636e\uff0c\u5982\u679c\u4f60\u4e0d\u559c\u6b22seaborn\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528matplot\uff1a predicted = model . forward ( torch . from_numpy ( x_train )) . data . numpy () plt . plot ( x_train , y_train , 'go' , label = 'data' , alpha = 0.3 ) plt . plot ( x_train , predicted , label = 'predicted' , alpha = 1 ) plt . legend () plt . show () \u4ee5\u4e0a\u5c31\u662f\u4e00\u4e2a\u4f7f\u7528PyTorch\u505a\u7ebf\u6027\u56de\u5f52\u7684\u7b80\u5355\u6837\u4f8b\u4e86\uff0c\u4e0b\u9762\u6211\u4eec\u4f1a\u5bf9\u4e0a\u9762\u7684\u5185\u5bb9\u505a\u8be6\u7ec6\u7684\u4ecb\u7ecd 2.2.3 \u635f\u5931\u51fd\u6570(Loss Function) \u00b6 \u635f\u5931\u51fd\u6570\uff08loss function\uff09\u662f\u7528\u6765\u4f30\u91cf\u6a21\u578b\u7684\u9884\u6d4b\u503c(\u6211\u4eec\u4f8b\u5b50\u4e2d\u7684output)\u4e0e\u771f\u5b9e\u503c\uff08\u4f8b\u5b50\u4e2d\u7684y_train\uff09\u7684\u4e0d\u4e00\u81f4\u7a0b\u5ea6\uff0c\u5b83\u662f\u4e00\u4e2a\u975e\u8d1f\u5b9e\u503c\u51fd\u6570,\u635f\u5931\u51fd\u6570\u8d8a\u5c0f\uff0c\u6a21\u578b\u7684\u9c81\u68d2\u6027\u5c31\u8d8a\u597d\u3002 \u6211\u4eec\u8bad\u7ec3\u6a21\u578b\u7684\u8fc7\u7a0b\uff0c\u5c31\u662f\u901a\u8fc7\u4e0d\u65ad\u7684\u8fed\u4ee3\u8ba1\u7b97\uff0c\u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u7684\u4f18\u5316\u7b97\u6cd5\uff0c\u4f7f\u5f97\u635f\u5931\u51fd\u6570\u8d8a\u6765\u8d8a\u5c0f\u3002\u635f\u5931\u51fd\u6570\u8d8a\u5c0f\u5c31\u8868\u793a\u7b97\u6cd5\u8fbe\u5230\u610f\u4e49\u4e0a\u7684\u6700\u4f18\u3002 \u8fd9\u91cc\u6709\u4e00\u4e2a\u91cd\u70b9\uff1a\u56e0\u4e3aPyTorch\u662f\u4f7f\u7528mini-batch\u6765\u8fdb\u884c\u8ba1\u7b97\u7684\uff0c\u6240\u4ee5\u635f\u5931\u51fd\u6570\u7684\u8ba1\u7b97\u51fa\u6765\u7684\u7ed3\u679c\u5df2\u7ecf\u5bf9mini-batch\u53d6\u4e86\u5e73\u5747 \u5e38\u89c1\uff08PyTorch\u5185\u7f6e\uff09\u7684\u635f\u5931\u51fd\u6570\u6709\u4ee5\u4e0b\u51e0\u4e2a\uff1a nn.L1Loss: \u00b6 \u8f93\u5165x\u548c\u76ee\u6807y\u4e4b\u95f4\u5dee\u7684\u7edd\u5bf9\u503c\uff0c\u8981\u6c42 x \u548c y \u7684\u7ef4\u5ea6\u8981\u4e00\u6837\uff08\u53ef\u4ee5\u662f\u5411\u91cf\u6216\u8005\u77e9\u9635\uff09\uff0c\u5f97\u5230\u7684 loss \u7ef4\u5ea6\u4e5f\u662f\u5bf9\u5e94\u4e00\u6837\u7684 loss(x,y)=1/n\\sum|x_i-y_i| loss(x,y)=1/n\\sum|x_i-y_i| nn.NLLLoss: \u00b6 \u7528\u4e8e\u591a\u5206\u7c7b\u7684\u8d1f\u5bf9\u6570\u4f3c\u7136\u635f\u5931\u51fd\u6570 loss(x, class) = -x[class] loss(x, class) = -x[class] NLLLoss\u4e2d\u5982\u679c\u4f20\u9012\u4e86weights\u53c2\u6570\uff0c\u4f1a\u5bf9\u635f\u5931\u8fdb\u884c\u52a0\u6743\uff0c\u516c\u5f0f\u5c31\u53d8\u6210\u4e86 loss(x, class) = -weights[class] * x[class] loss(x, class) = -weights[class] * x[class] nn.MSELoss: \u00b6 \u5747\u65b9\u635f\u5931\u51fd\u6570 \uff0c\u8f93\u5165x\u548c\u76ee\u6807y\u4e4b\u95f4\u5747\u65b9\u5dee loss(x,y)=1/n\\sum(x_i-y_i)^2 loss(x,y)=1/n\\sum(x_i-y_i)^2 nn.CrossEntropyLoss: \u00b6 \u591a\u5206\u7c7b\u7528\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0cLogSoftMax\u548cNLLLoss\u96c6\u6210\u5230\u4e00\u4e2a\u7c7b\u4e2d\uff0c\u4f1a\u8c03\u7528nn.NLLLoss\u51fd\u6570,\u6211\u4eec\u53ef\u4ee5\u7406\u89e3\u4e3aCrossEntropyLoss() = log_softmax() + NLLLoss() $$ \\begin{aligned} loss(x, class) &= -\\text{log}\\frac{exp(x[class])}{\\sum_j exp(x[j]))} &= -x[class] + log(\\sum_j exp(x[j])) \\end{aligned} $$ \u56e0\u4e3a\u4f7f\u7528\u4e86NLLLoss\uff0c\u6240\u4ee5\u4e5f\u53ef\u4ee5\u4f20\u5165weight\u53c2\u6570\uff0c\u8fd9\u65f6loss\u7684\u8ba1\u7b97\u516c\u5f0f\u53d8\u4e3a\uff1a $$ loss(x, class) = weights[class] * (-x[class] + log(\\sum_j exp(x[j]))) $$ \u6240\u4ee5\u4e00\u822c\u591a\u5206\u7c7b\u7684\u60c5\u51b5\u4f1a\u4f7f\u7528\u8fd9\u4e2a\u635f\u5931\u51fd\u6570\u3002 nn.BCELoss: \u00b6 \u8ba1\u7b97 x \u4e0e y \u4e4b\u95f4\u7684\u4e8c\u8fdb\u5236\u4ea4\u53c9\u71b5\u3002 loss(o,t) = -\\frac{1}{n}\\sum_i(t[i] * log(o[i])+(1-t[i]) * log(1-o[i])) loss(o,t) = -\\frac{1}{n}\\sum_i(t[i] * log(o[i])+(1-t[i]) * log(1-o[i])) \u4e0eNLLLoss\u7c7b\u4f3c\uff0c\u4e5f\u53ef\u4ee5\u6dfb\u52a0\u6743\u91cd\u53c2\u6570\uff1a loss(o,t)=-\\frac{1}{n}\\sum_iweights[i] * (t[i] * log(o[i])+(1-t[i]) * log(1-o[i])) loss(o,t)=-\\frac{1}{n}\\sum_iweights[i] * (t[i] * log(o[i])+(1-t[i]) * log(1-o[i])) \u7528\u7684\u65f6\u5019\u9700\u8981\u5728\u8be5\u5c42\u524d\u9762\u52a0\u4e0a Sigmoid \u51fd\u6570\u3002 2.2.4 \u68af\u5ea6\u4e0b\u964d \u00b6 \u5728\u4ecb\u7ecd\u635f\u5931\u51fd\u6570\u7684\u65f6\u5019\u6211\u4eec\u5df2\u7ecf\u8bf4\u4e86\uff0c\u68af\u5ea6\u4e0b\u964d\u662f\u4e00\u4e2a\u4f7f\u635f\u5931\u51fd\u6570\u8d8a\u6765\u8d8a\u5c0f\u7684\u4f18\u5316\u7b97\u6cd5\uff0c\u5728\u65e0\u6c42\u89e3\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u6a21\u578b\u53c2\u6570\uff0c\u5373\u7ea6\u675f\u4f18\u5316\u95ee\u9898\u65f6\uff0c\u68af\u5ea6\u4e0b\u964d\uff08Gradient Descent\uff09\u662f\u6700\u5e38\u91c7\u7528\u7684\u65b9\u6cd5\u4e4b\u4e00\u3002\u6240\u4ee5\u68af\u5ea6\u4e0b\u964d\u662f\u6211\u4eec\u76ee\u524d\u6240\u8bf4\u7684\u673a\u5668\u5b66\u4e60\u7684\u6838\u5fc3\uff0c\u4e86\u89e3\u4e86\u5b83\u7684\u542b\u4e49\uff0c\u4e5f\u5c31\u4e86\u89e3\u4e86\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u542b\u4e49\u3002 \u68af\u5ea6 \u00b6 \u5728\u5fae\u79ef\u5206\u91cc\u9762\uff0c\u5bf9\u591a\u5143\u51fd\u6570\u7684\u53c2\u6570\u6c42\u2202\u504f\u5bfc\u6570\uff0c\u628a\u6c42\u5f97\u7684\u5404\u4e2a\u53c2\u6570\u7684\u504f\u5bfc\u6570\u4ee5\u5411\u91cf\u7684\u5f62\u5f0f\u5199\u51fa\u6765\uff0c\u5c31\u662f\u68af\u5ea6\u3002 \u4f8b\u5982\u51fd\u6570f(x,y), \u5206\u522b\u5bf9x,y\u6c42\u504f\u5bfc\u6570\uff0c\u6c42\u5f97\u7684\u68af\u5ea6\u5411\u91cf\u5c31\u662f(\u2202f/\u2202x, \u2202f/\u2202y)T,\u7b80\u79f0grad f(x,y)\u6216\u8005\u25bdf(x,y)\u3002 \u51e0\u4f55\u4e0a\u8bb2\uff0c\u68af\u5ea6\u5c31\u662f\u51fd\u6570\u53d8\u5316\u589e\u52a0\u6700\u5feb\u7684\u5730\u65b9\uff0c\u6cbf\u7740\u68af\u5ea6\u5411\u91cf\u7684\u65b9\u5411\uff0c\u66f4\u52a0\u5bb9\u6613\u627e\u5230\u51fd\u6570\u7684\u6700\u5927\u503c\u3002\u53cd\u8fc7\u6765\u8bf4\uff0c\u6cbf\u7740\u68af\u5ea6\u5411\u91cf\u76f8\u53cd\u7684\u65b9\u5411\u68af\u5ea6\u51cf\u5c11\u6700\u5feb\uff0c\u4e5f\u5c31\u662f\u66f4\u52a0\u5bb9\u6613\u627e\u5230\u51fd\u6570\u7684\u6700\u5c0f\u503c\u3002 \u6211\u4eec\u9700\u8981\u6700\u5c0f\u5316\u635f\u5931\u51fd\u6570\uff0c\u53ef\u4ee5\u901a\u8fc7\u68af\u5ea6\u4e0b\u964d\u6cd5\u6765\u4e00\u6b65\u6b65\u7684\u8fed\u4ee3\u6c42\u89e3\uff0c\u5f97\u5230\u6700\u5c0f\u5316\u7684\u635f\u5931\u51fd\u6570\uff0c\u548c\u6a21\u578b\u53c2\u6570\u503c\u3002 \u68af\u5ea6\u4e0b\u964d\u6cd5\u76f4\u89c2\u89e3\u91ca \u00b6 \u68af\u5ea6\u4e0b\u964d\u6cd5\u5c31\u597d\u6bd4\u4e0b\u5c71\uff0c\u6211\u4eec\u5e76\u4e0d\u77e5\u9053\u4e0b\u5c71\u7684\u8def\uff0c\u4e8e\u662f\u51b3\u5b9a\u8d70\u4e00\u6b65\u7b97\u4e00\u6b65\uff0c\u6bcf\u8d70\u5230\u4e00\u4e2a\u4f4d\u7f6e\u7684\u65f6\u5019\uff0c\u6c42\u89e3\u5f53\u524d\u4f4d\u7f6e\u7684\u68af\u5ea6\uff0c\u6cbf\u7740\u68af\u5ea6\u7684\u8d1f\u65b9\u5411\uff0c\u4e5f\u5c31\u662f\u5f53\u524d\u6700\u9661\u5ced\u7684\u4f4d\u7f6e\u5411\u4e0b\u8d70\u4e00\u6b65\uff0c\u7136\u540e\u7ee7\u7eed\u6c42\u89e3\u5f53\u524d\u4f4d\u7f6e\u68af\u5ea6\uff0c\u5411\u8fd9\u4e00\u6b65\u6240\u5728\u4f4d\u7f6e\u6cbf\u7740\u6700\u9661\u5ced\u6700\u6613\u4e0b\u5c71\u7684\u4f4d\u7f6e\u8d70\u4e00\u6b65\u3002\u8fd9\u6837\u4e00\u6b65\u6b65\u7684\u8d70\u4e0b\u53bb\uff0c\u4e00\u76f4\u8d70\u5230\u89c9\u5f97\u6211\u4eec\u5df2\u7ecf\u5230\u4e86\u5c71\u811a\u3002 \u5982\u4e0b\u56fe\u6240\u793a\uff0c\uff08\u6b64\u56fe\u6458\u81ea\u767e\u5ea6\u767e\u79d1\uff09 \u8fd9\u6837\u8d70\u4e0b\u53bb\uff0c\u6709\u53ef\u80fd\u6211\u4eec\u4e0d\u80fd\u8d70\u5230\u5c71\u811a\uff0c\u800c\u662f\u5230\u4e86\u67d0\u4e00\u4e2a\u5c40\u90e8\u7684\u5c71\u5cf0\u4f4e\u5904\uff08\u5c40\u90e8\u6700\u4f18\u89e3\uff09\u3002 \u8fd9\u4e2a\u95ee\u9898\u5728\u4ee5\u524d\u7684\u673a\u5668\u5b66\u4e60\u4e2d\u53ef\u80fd\u4f1a\u9047\u5230\uff0c\u56e0\u4e3a\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u7279\u5f81\u6bd4\u8f83\u5c11\uff0c\u6240\u4ee5\u5bfc\u81f4\u5f88\u53ef\u80fd\u9677\u5165\u5230\u4e00\u4e2a\u5c40\u90e8\u6700\u4f18\u89e3\u4e2d\u51fa\u4e0d\u6765\uff0c\u4f46\u662f\u5230\u4e86\u6df1\u5ea6\u5b66\u4e60\uff0c\u52a8\u8f84\u767e\u4e07\u751a\u81f3\u4e0a\u4ebf\u7684\u7279\u5f81\uff0c\u51fa\u73b0\u8fd9\u79cd\u60c5\u51b5\u7684\u6982\u7387\u51e0\u4e4e\u4e3a0\uff0c\u6240\u4ee5\u6211\u4eec\u53ef\u4ee5\u4e0d\u7528\u8003\u8651\u8fd9\u4e2a\u95ee\u9898\u3002 Mini-batch\u7684\u68af\u5ea6\u4e0b\u964d\u6cd5 \u00b6 \u5bf9\u6574\u4e2a\u8bad\u7ec3\u96c6\u8fdb\u884c\u68af\u5ea6\u4e0b\u964d\u6cd5\u7684\u65f6\u5019\uff0c\u6211\u4eec\u5fc5\u987b\u5904\u7406\u6574\u4e2a\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u7136\u540e\u624d\u80fd\u8fdb\u884c\u4e00\u6b65\u68af\u5ea6\u4e0b\u964d\uff0c\u5373\u6bcf\u4e00\u6b65\u68af\u5ea6\u4e0b\u964d\u6cd5\u9700\u8981\u5bf9\u6574\u4e2a\u8bad\u7ec3\u96c6\u8fdb\u884c\u4e00\u6b21\u5904\u7406\uff0c\u5982\u679c\u8bad\u7ec3\u6570\u636e\u96c6\u5f88\u5927\u7684\u65f6\u5019\u5904\u7406\u901f\u5ea6\u4f1a\u5f88\u6162\uff0c\u800c\u4e14\u4e5f\u4e0d\u53ef\u80fd\u4e00\u6b21\u7684\u8f7d\u5165\u5230\u5185\u5b58\u6216\u8005\u663e\u5b58\u4e2d\uff0c\u6240\u4ee5\u6211\u4eec\u4f1a\u628a\u5927\u6570\u636e\u96c6\u5206\u6210\u5c0f\u6570\u636e\u96c6\uff0c\u4e00\u90e8\u5206\u4e00\u90e8\u5206\u7684\u8bad\u7ec3\uff0c\u8fd9\u4e2a\u8bad\u7ec3\u5b50\u96c6\u5373\u79f0\u4e3aMini-batch\u3002 \u5728PyTorch\u4e2d\u5c31\u662f\u4f7f\u7528\u8fd9\u79cd\u65b9\u6cd5\u8fdb\u884c\u7684\u8bad\u7ec3\uff0c\u53ef\u4ee5\u770b\u770b\u4e0a\u4e00\u7ae0\u4e2d\u5173\u4e8edataloader\u7684\u4ecb\u7ecd\u91cc\u9762\u7684batch_size\u5c31\u662f\u6211\u4eec\u4e00\u4e2aMini-batch\u7684\u5927\u5c0f\u3002 \u4e3a\u4e86\u4ecb\u7ecd\u7684\u66f4\u7b80\u6d01\uff0c\u4f7f\u7528 \u5434\u6069\u8fbe\u8001\u5e08\u7684 deeplearning.ai \u8bfe\u7a0b\u677f\u4e66\u3002 \u5bf9\u4e8e\u666e\u901a\u7684\u68af\u5ea6\u4e0b\u964d\u6cd5\uff0c\u4e00\u4e2aepoch\u53ea\u80fd\u8fdb\u884c\u4e00\u6b21\u68af\u5ea6\u4e0b\u964d\uff1b\u800c\u5bf9\u4e8eMini-batch\u68af\u5ea6\u4e0b\u964d\u6cd5\uff0c\u4e00\u4e2aepoch\u53ef\u4ee5\u8fdb\u884cMini-batch\u7684\u4e2a\u6570\u6b21\u68af\u5ea6\u4e0b\u964d\u3002 \u666e\u901a\u7684batch\u68af\u5ea6\u4e0b\u964d\u6cd5\u548cMini-batch\u68af\u5ea6\u4e0b\u964d\u6cd5\u4ee3\u4ef7\u51fd\u6570\u7684\u53d8\u5316\u8d8b\u52bf\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5982\u679c\u8bad\u7ec3\u6837\u672c\u7684\u5927\u5c0f\u6bd4\u8f83\u5c0f\u65f6,\u80fd\u591f\u4e00\u6b21\u6027\u7684\u8bfb\u53d6\u5230\u5185\u5b58\u4e2d\uff0c\u90a3\u6211\u4eec\u5c31\u4e0d\u9700\u8981\u4f7f\u7528Mini-batch\uff0c \u5982\u679c\u8bad\u7ec3\u6837\u672c\u7684\u5927\u5c0f\u6bd4\u8f83\u5927\u65f6\uff0c\u4e00\u6b21\u8bfb\u5165\u4e0d\u5230\u5185\u5b58\u6216\u8005\u73b0\u5b58\u4e2d\uff0c\u90a3\u6211\u4eec\u5fc5\u987b\u8981\u4f7f\u7528 Mini-batch\u6765\u5206\u6279\u7684\u8ba1\u7b97 Mini-batch size\u7684\u8ba1\u7b97\u89c4\u5219\u5982\u4e0b\uff0c\u5728\u5185\u5b58\u5141\u8bb8\u7684\u6700\u5927\u60c5\u51b5\u4e0b\u4f7f\u75282\u7684N\u6b21\u65b9\u4e2asize torch.optim \u662f\u4e00\u4e2a\u5b9e\u73b0\u4e86\u5404\u79cd\u4f18\u5316\u7b97\u6cd5\u7684\u5e93\u3002\u5927\u90e8\u5206\u5e38\u7528\u4f18\u5316\u7b97\u6cd5\u90fd\u6709\u5b9e\u73b0\uff0c\u6211\u4eec\u76f4\u63a5\u8c03\u7528\u5373\u53ef\u3002 torch.optim.SGD \u00b6 \u968f\u673a\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5,\u5e26\u6709\u52a8\u91cf\uff08momentum\uff09\u7684\u7b97\u6cd5\u4f5c\u4e3a\u4e00\u4e2a\u53ef\u9009\u53c2\u6570\u53ef\u4ee5\u8fdb\u884c\u8bbe\u7f6e\uff0c\u6837\u4f8b\u5982\u4e0b\uff1a #lr\u53c2\u6570\u4e3a\u5b66\u4e60\u7387\uff0c\u5bf9\u4e8eSGD\u6765\u8bf4\u4e00\u822c\u9009\u62e90.1 0.01.0.001\uff0c\u5982\u4f55\u8bbe\u7f6e\u4f1a\u5728\u540e\u9762\u5b9e\u6218\u7684\u7ae0\u8282\u4e2d\u8be6\u7ec6\u8bf4\u660e ##\u5982\u679c\u8bbe\u7f6e\u4e86momentum\uff0c\u5c31\u662f\u5e26\u6709\u52a8\u91cf\u7684SGD\uff0c\u53ef\u4ee5\u4e0d\u8bbe\u7f6e optimizer = torch . optim . SGD ( model . parameters (), lr = 0.1 , momentum = 0.9 ) torch.optim.RMSprop \u00b6 \u9664\u4e86\u4ee5\u4e0a\u7684\u5e26\u6709\u52a8\u91cfMomentum\u68af\u5ea6\u4e0b\u964d\u6cd5\u5916\uff0cRMSprop\uff08root mean square prop\uff09\u4e5f\u662f\u4e00\u79cd\u53ef\u4ee5\u52a0\u5feb\u68af\u5ea6\u4e0b\u964d\u7684\u7b97\u6cd5\uff0c\u5229\u7528RMSprop\u7b97\u6cd5\uff0c\u53ef\u4ee5\u51cf\u5c0f\u67d0\u4e9b\u7ef4\u5ea6\u68af\u5ea6\u66f4\u65b0\u6ce2\u52a8\u8f83\u5927\u7684\u60c5\u51b5\uff0c\u4f7f\u5176\u68af\u5ea6\u4e0b\u964d\u7684\u901f\u5ea6\u53d8\u5f97\u66f4\u5feb #\u6211\u4eec\u7684\u8bfe\u7a0b\u57fa\u672c\u4e0d\u4f1a\u4f7f\u7528\u5230RMSprop\u6240\u4ee5\u8fd9\u91cc\u53ea\u7ed9\u4e00\u4e2a\u5b9e\u4f8b optimizer = torch . optim . RMSprop ( model . parameters (), lr = 0.01 , alpha = 0.99 ) torch.optim.Adam \u00b6 Adam \u4f18\u5316\u7b97\u6cd5\u7684\u57fa\u672c\u601d\u60f3\u5c31\u662f\u5c06 Momentum \u548c RMSprop \u7ed3\u5408\u8d77\u6765\u5f62\u6210\u7684\u4e00\u79cd\u9002\u7528\u4e8e\u4e0d\u540c\u6df1\u5ea6\u5b66\u4e60\u7ed3\u6784\u7684\u4f18\u5316\u7b97\u6cd5 # \u8fd9\u91cc\u7684lr\uff0cbetas\uff0c\u8fd8\u6709eps\u90fd\u662f\u7528\u9ed8\u8ba4\u503c\u5373\u53ef\uff0c\u6240\u4ee5Adam\u662f\u4e00\u4e2a\u4f7f\u7528\u8d77\u6765\u6700\u7b80\u5355\u7684\u4f18\u5316\u65b9\u6cd5 optimizer = torch . optim . Adam ( model . parameters (), lr = 0.001 , betas = ( 0.9 , 0.999 ), eps = 1e-08 ) 2.2.5 \u65b9\u5dee/\u504f\u5dee \u00b6 \u504f\u5dee\u5ea6\u91cf\u4e86\u5b66\u4e60\u7b97\u6cd5\u7684\u671f\u671b\u9884\u6d4b\u4e0e\u771f\u5b9e\u7ed3\u679c\u7684\u504f\u79bb\u7a0b\u5e8f, \u5373 \u523b\u753b\u4e86\u5b66\u4e60\u7b97\u6cd5\u672c\u8eab\u7684\u62df\u5408\u80fd\u529b \u65b9\u5dee\u5ea6\u91cf\u4e86\u540c\u6837\u5927\u5c0f\u7684\u8bad\u7ec3\u96c6\u7684\u53d8\u52a8\u6240\u5bfc\u81f4\u7684\u5b66\u4e60\u6027\u80fd\u7684\u53d8\u5316, \u5373**\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b**\uff1a \u4ece\u56fe\u4e2d\u6211\u4eec\u53ef\u4ee5\u770b\u51fa\uff1a - \u9ad8\u504f\u5dee\uff08high bias\uff09\u7684\u60c5\u51b5\uff0c\u4e00\u822c\u79f0\u4e3a\u6b20\u62df\u5408\uff08underfitting\uff09,\u5373\u6211\u4eec\u7684\u6a21\u578b\u5e76\u6ca1\u6709\u5f88\u597d\u7684\u53bb\u9002\u914d\u73b0\u6709\u7684\u6570\u636e\uff0c\u62df\u5408\u5ea6\u4e0d\u591f\u3002 - \u9ad8\u65b9\u5dee\uff08high variance\uff09\u7684\u60c5\u51b5\u4e00\u822c\u79f0\u4f5c\u8fc7\u62df\u5408\uff08overfitting\uff09\uff0c\u5373\u6a21\u578b\u5bf9\u4e8e\u8bad\u7ec3\u6570\u636e\u62df\u5408\u5ea6\u592a\u9ad8\u4e86\uff0c\u5931\u53bb\u4e86\u6cdb\u5316\u7684\u80fd\u529b\u3002 \u5982\u4f55\u89e3\u51b3\u8fd9\u4e24\u79cd\u60c5\u51b5\u5462\uff1f \u6b20\u62df\u5408\uff1a - \u589e\u52a0\u7f51\u7edc\u7ed3\u6784\uff0c\u5982\u589e\u52a0\u9690\u85cf\u5c42\u6570\u76ee\uff1b - \u8bad\u7ec3\u66f4\u957f\u65f6\u95f4\uff1b - \u5bfb\u627e\u5408\u9002\u7684\u7f51\u7edc\u67b6\u6784\uff0c\u4f7f\u7528\u66f4\u5927\u7684NN\u7ed3\u6784\uff1b \u8fc7\u62df\u5408 \uff1a - \u4f7f\u7528\u66f4\u591a\u7684\u6570\u636e\uff1b - \u6b63\u5219\u5316\uff08 regularization\uff09\uff1b - \u5bfb\u627e\u5408\u9002\u7684\u7f51\u7edc\u7ed3\u6784\uff1b \u4f8b\u5982\u6211\u4eec\u4e0a\u9762\u7684\u4f8b\u5b50\uff0c\u53ef\u4ee5\u8ba1\u7b97\u51fa\u6211\u4eec\u7684\u504f\u5dee: print ( 5 - w . data . item (), 7 - b . data . item ()) 0.005641937255859375 -0.025215625762939453 2.2.6 \u6b63\u5219\u5316 \u00b6 \u5229\u7528\u6b63\u5219\u5316\u6765\u89e3\u51b3High variance \u7684\u95ee\u9898\uff0c\u6b63\u5219\u5316\u662f\u5728 Cost function \u4e2d\u52a0\u5165\u4e00\u9879\u6b63\u5219\u5316\u9879\uff0c\u60e9\u7f5a\u6a21\u578b\u7684\u590d\u6742\u5ea6,\u8fd9\u91cc\u6211\u4eec\u7b80\u5355\u7684\u4ecb\u7ecd\u4e00\u4e0b\u6b63\u5219\u5316\u7684\u6982\u5ff5 L1\u6b63\u5219\u5316 \u00b6 \u635f\u5931\u51fd\u6570\u57fa\u7840\u4e0a\u52a0\u4e0a\u6743\u91cd\u53c2\u6570\u7684\u7edd\u5bf9\u503c L=E_{in}+\\lambda{\\sum_j} \\left|w_j\\right| L=E_{in}+\\lambda{\\sum_j} \\left|w_j\\right| L2\u6b63\u5219\u5316 \u00b6 \u635f\u5931\u51fd\u6570\u57fa\u7840\u4e0a\u52a0\u4e0a\u6743\u91cd\u53c2\u6570\u7684\u5e73\u65b9\u548c L=E_{in}+\\lambda{\\sum_j} w^2_j L=E_{in}+\\lambda{\\sum_j} w^2_j \u9700\u8981\u8bf4\u660e\u7684\u662f\uff1al1 \u76f8\u6bd4\u4e8e l2 \u4f1a\u66f4\u5bb9\u6613\u83b7\u5f97\u7a00\u758f\u89e3\uff0c\u53ef\u67e5\u770b \u77e5\u4e4e \u89e3\u7b54\u3002","title":"2.2 Deep Learning Mathematics Basic"},{"location":"tutorial/chapter02_basics/2_2_deep-learning-mathematics-basic/#22","text":"\u6df1\u5ea6\u5b66\u4e60\u5e76\u6ca1\u6709\u60f3\u8c61\u7684\u90a3\u4e48\u96be\uff0c\u751a\u81f3\u6bd4\u6709\u4e9b\u4f20\u7edf\u7684\u673a\u5668\u5b66\u4e60\u66f4\u7b80\u5355\u3002\u6240\u7528\u5230\u7684\u6570\u5b66\u77e5\u8bc6\u4e5f\u4e0d\u9700\u8981\u7279\u522b\u7684\u9ad8\u6df1\uff0c\u672c\u7ae0\u5c06\u4f1a\u4e00\u8fb9\u8bb2\u89e3\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u57fa\u672c\u7406\u8bba\uff0c\u4e00\u8fb9\u901a\u8fc7\u52a8\u624b\u4f7f\u7528PyTorch\u5b9e\u73b0\u4e00\u4e9b\u7b80\u5355\u7684\u7406\u8bba\uff0c\u672c\u7ae0\u5185\u5bb9\u5f88\u591a\uff0c\u6240\u4ee5\u53ea\u505a\u4e00\u4e2a\u7b80\u77ed\u7684\u4ecb\u7ecd","title":"2.2 \u6df1\u5ea6\u5b66\u4e60\u57fa\u7840\u53ca\u6570\u5b66\u539f\u7406"},{"location":"tutorial/chapter02_basics/2_2_deep-learning-mathematics-basic/#221","text":"\u76d1\u7763\u5b66\u4e60\u3001\u65e0\u76d1\u7763\u5b66\u4e60\u3001\u534a\u76d1\u7763\u5b66\u4e60\u3001\u5f3a\u5316\u5b66\u4e60\u662f\u6211\u4eec\u65e5\u5e38\u63a5\u89e6\u5230\u7684\u5e38\u89c1\u7684\u56db\u4e2a\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff1a \u76d1\u7763\u5b66\u4e60\uff1a\u901a\u8fc7\u5df2\u6709\u7684\u8bad\u7ec3\u6837\u672c\uff08\u5373\u5df2\u77e5\u6570\u636e\u4ee5\u53ca\u5176\u5bf9\u5e94\u7684\u8f93\u51fa\uff09\u53bb\u8bad\u7ec3\u5f97\u5230\u4e00\u4e2a\u6700\u4f18\u6a21\u578b\uff08\u8fd9\u4e2a\u6a21\u578b\u5c5e\u4e8e\u67d0\u4e2a\u51fd\u6570\u7684\u96c6\u5408\uff0c\u6700\u4f18\u5219\u8868\u793a\u5728\u67d0\u4e2a\u8bc4\u4ef7\u51c6\u5219\u4e0b\u662f\u6700\u4f73\u7684\uff09\uff0c\u518d\u5229\u7528\u8fd9\u4e2a\u6a21\u578b\u5c06\u6240\u6709\u7684\u8f93\u5165\u6620\u5c04\u4e3a\u76f8\u5e94\u7684\u8f93\u51fa\u3002 \u65e0\u76d1\u7763\u5b66\u4e60\uff1a\u5b83\u4e0e\u76d1\u7763\u5b66\u4e60\u7684\u4e0d\u540c\u4e4b\u5904\uff0c\u5728\u4e8e\u6211\u4eec\u4e8b\u5148\u6ca1\u6709\u4efb\u4f55\u8bad\u7ec3\u6837\u672c\uff0c\u800c\u9700\u8981\u76f4\u63a5\u5bf9\u6570\u636e\u8fdb\u884c\u5efa\u6a21\u3002 \u534a\u76d1\u7763\u5b66\u4e60 \uff1a\u5728\u8bad\u7ec3\u9636\u6bb5\u7ed3\u5408\u4e86\u5927\u91cf\u672a\u6807\u8bb0\u7684\u6570\u636e\u548c\u5c11\u91cf\u6807\u7b7e\u6570\u636e\u3002\u4e0e\u4f7f\u7528\u6240\u6709\u6807\u7b7e\u6570\u636e\u7684\u6a21\u578b\u76f8\u6bd4\uff0c\u4f7f\u7528\u8bad\u7ec3\u96c6\u7684\u8bad\u7ec3\u6a21\u578b\u5728\u8bad\u7ec3\u65f6\u53ef\u4ee5\u66f4\u4e3a\u51c6\u786e\u3002 \u5f3a\u5316\u5b66\u4e60\uff1a\u6211\u4eec\u8bbe\u5b9a\u4e00\u4e2a\u56de\u62a5\u51fd\u6570\uff08reward function\uff09\uff0c\u901a\u8fc7\u8fd9\u4e2a\u51fd\u6570\u6765\u786e\u8ba4\u5426\u8d8a\u6765\u8d8a\u63a5\u8fd1\u76ee\u6807\uff0c\u7c7b\u4f3c\u6211\u4eec\u8bad\u7ec3\u5ba0\u7269\uff0c\u5982\u679c\u505a\u5bf9\u4e86\u5c31\u7ed9\u4ed6\u5956\u52b1\uff0c\u505a\u9519\u4e86\u5c31\u7ed9\u4e88\u60e9\u7f5a\uff0c\u6700\u540e\u6765\u8fbe\u5230\u6211\u4eec\u7684\u8bad\u7ec3\u76ee\u7684\u3002 \u8fd9\u91cc\u6211\u4eec\u53ea\u7740\u91cd\u4ecb\u7ecd\u76d1\u7763\u5b66\u4e60\uff0c\u56e0\u4e3a\u6211\u4eec\u540e\u9762\u7684\u7edd\u5927\u90e8\u4eec\u8bfe\u7a0b\u90fd\u662f\u4f7f\u7528\u7684\u76d1\u7763\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u5728\u8bad\u7ec3\u548c\u9a8c\u8bc1\u65f6\u8f93\u5165\u7684\u6570\u636e\u65e2\u5305\u542b\u8f93\u5165x,\u53c8\u5305\u542bx\u5bf9\u5e94\u7684\u8f93\u51fay\uff0c\u5373\u5b66\u4e60\u6570\u636e\u5df2\u7ecf\u4e8b\u5148\u7ed9\u51fa\u4e86\u6b63\u786e\u7b54\u6848\u3002","title":"2.2.1 \u76d1\u7763\u5b66\u4e60\u548c\u65e0\u76d1\u7763\u5b66\u4e60"},{"location":"tutorial/chapter02_basics/2_2_deep-learning-mathematics-basic/#222-linear-regreesion","text":"\u7ebf\u6027\u56de\u5f52\u662f\u5229\u7528\u6570\u7406\u7edf\u8ba1\u4e2d\u56de\u5f52\u5206\u6790\uff0c\u6765\u786e\u5b9a\u4e24\u79cd\u6216\u4e24\u79cd\u4ee5\u4e0a\u53d8\u91cf\u95f4\u76f8\u4e92\u4f9d\u8d56\u7684\u5b9a\u91cf\u5173\u7cfb\u7684\u4e00\u79cd\u7edf\u8ba1\u5206\u6790\u65b9\u6cd5\uff0c\u8fd0\u7528\u5341\u5206\u5e7f\u6cdb\u3002\u5176\u8868\u8fbe\u5f62\u5f0f\u4e3ay = w'x+e\uff0ce\u4e3a\u8bef\u5dee\u670d\u4ece\u5747\u503c\u4e3a0\u7684\u6b63\u6001\u5206\u5e03\u3002 \u56de\u5f52\u5206\u6790\u4e2d\uff0c\u53ea\u5305\u62ec\u4e00\u4e2a\u81ea\u53d8\u91cf\u548c\u4e00\u4e2a\u56e0\u53d8\u91cf\uff0c\u4e14\u4e8c\u8005\u7684\u5173\u7cfb\u53ef\u7528\u4e00\u6761\u76f4\u7ebf\u8fd1\u4f3c\u8868\u793a\uff0c\u8fd9\u79cd\u56de\u5f52\u5206\u6790\u79f0\u4e3a\u4e00\u5143\u7ebf\u6027\u56de\u5f52\u5206\u6790\u3002\u5982\u679c\u56de\u5f52\u5206\u6790\u4e2d\u5305\u62ec\u4e24\u4e2a\u6216\u4e24\u4e2a\u4ee5\u4e0a\u7684\u81ea\u53d8\u91cf\uff0c\u4e14\u56e0\u53d8\u91cf\u548c\u81ea\u53d8\u91cf\u4e4b\u95f4\u662f\u7ebf\u6027\u5173\u7cfb\uff0c\u5219\u79f0\u4e3a\u591a\u5143\u7ebf\u6027\u56de\u5f52\u5206\u6790\u3002 \u6458\u81ea \u767e\u5ea6\u767e\u79d1 \u7b80\u5355\u7684\u8bf4\uff1a \u7ebf\u6027\u56de\u5f52\u5bf9\u4e8e\u8f93\u5165x\u4e0e\u8f93\u51fay\u6709\u4e00\u4e2a\u6620\u5c04f\uff0cy=f(x),\u800cf\u7684\u5f62\u5f0f\u4e3aaX+b\u3002\u5176\u4e2da\u548cb\u662f\u4e24\u4e2a\u53ef\u8c03\u7684\u53c2\u6570\uff0c\u6211\u4eec\u8bad\u7ec3\u7684\u65f6\u5019\u5c31\u662f\u8bad\u7ec3a\uff0cb\u8fd9\u4e24\u4e2a\u53c2\u6570\u3002 \u4e0b\u9762\u6211\u4eec\u6765\u7528pyTorch\u7684\u4ee3\u7801\u6765\u505a\u4e00\u4e2a\u8be6\u7ec6\u7684\u89e3\u91ca: # \u5f15\u7528 # \u6ce8\u610f\uff0c\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528\u4e86\u4e00\u4e2a\u65b0\u5e93\u53eb seaborn \u5982\u679c\u62a5\u9519\u627e\u4e0d\u5230\u5305\u7684\u8bdd\u8bf7\u4f7f\u7528pip install seaborn \u6765\u8fdb\u884c\u5b89\u88c5 import torch from torch.nn import Linear , Module , MSELoss from torch.optim import SGD import numpy as np import pandas as pd import matplotlib import matplotlib.pyplot as plt import seaborn as sns torch . __version__ '1.0.1.post2' \u4e0b\u9762\u5b9a\u4e49\u4e00\u4e2a\u7ebf\u6027\u51fd\u6570\uff0c\u8fd9\u91cc\u4f7f\u7528 y = 5x + 7 y = 5x + 7 \uff0c\u8fd9\u91cc\u76845\u548c7\u5c31\u662f\u4e0a\u9762\u8bf4\u5230\u7684\u53c2\u6570a\u548cb\uff0c\u6211\u4eec\u5148\u4f7f\u7528matplot\u53ef\u89c6\u5316\u4e00\u4e0b\u8fd9\u4e2a\u51fd\u6570 x = np . linspace ( 0 , 20 , 500 ) y = 5 * x + 7 plt . plot ( x , y ) [<matplotlib.lines.Line2D at 0x7fd40bbe57f0>] \u4e0b\u9762\u6211\u751f\u6210\u4e00\u4e9b\u968f\u673a\u7684\u70b9\uff0c\u6765\u4f5c\u4e3a\u6211\u4eec\u7684\u8bad\u7ec3\u6570\u636e x = np . random . rand ( 256 ) noise = np . random . randn ( 256 ) / 4 y = x * 5 + 7 + noise df = pd . DataFrame () df [ 'x' ] = x df [ 'y' ] = y \u5728\u56fe\u4e0a\u663e\u793a\u4e0b\u6211\u4eec\u751f\u6210\u7684\u6570\u636e sns . lmplot ( x = 'x' , y = 'y' , data = df ); \u6211\u4eec\u968f\u673a\u751f\u6210\u4e86\u4e00\u4e9b\u70b9\uff0c\u4e0b\u9762\u5c06\u4f7f\u7528PyTorch\u5efa\u7acb\u4e00\u4e2a\u7ebf\u6027\u7684\u6a21\u578b\u6765\u5bf9\u5176\u8fdb\u884c\u62df\u5408\uff0c\u8fd9\u5c31\u662f\u6240\u8bf4\u7684\u8bad\u7ec3\u7684\u8fc7\u7a0b\uff0c\u7531\u4e8e\u53ea\u6709\u4e00\u5c42\u7ebf\u6027\u6a21\u578b\uff0c\u6240\u4ee5\u6211\u4eec\u5c31\u76f4\u63a5\u4f7f\u7528\u4e86\u3002 model = Linear ( 1 , 1 ) \u5176\u4e2d\u53c2\u6570(1, 1)\u4ee3\u8868\u8f93\u5165\u8f93\u51fa\u7684\u7279\u5f81(feature)\u6570\u91cf\u90fd\u662f1. Linear \u6a21\u578b\u7684\u8868\u8fbe\u5f0f\u662f y=w \\cdot x+b y=w \\cdot x+b , \u5176\u4e2d w w \u4ee3\u8868\u6743\u91cd, b b \u4ee3\u8868\u504f\u7f6e\u3002 \u635f\u5931\u51fd\u6570\u6211\u4eec\u4f7f\u7528\u5747\u65b9\u635f\u5931\u51fd\u6570\uff1a MSELoss \uff0c\u8fd9\u4e2a\u540e\u9762\u4f1a\u8be6\u7ec6\u4ecb\u7ecd\u3002 criterion = MSELoss () \u4f18\u5316\u5668\u6211\u4eec\u9009\u62e9\u6700\u5e38\u89c1\u7684\u4f18\u5316\u65b9\u6cd5 SGD \uff0c\u5c31\u662f\u6bcf\u4e00\u6b21\u8fed\u4ee3\u8ba1\u7b97 mini-batch \u7684\u68af\u5ea6\uff0c\u7136\u540e\u5bf9\u53c2\u6570\u8fdb\u884c\u66f4\u65b0\uff0c\u5b66\u4e60\u7387 0.01 \uff0c\u4f18\u5316\u5668\u672c\u7ae0\u540e\u9762\u4e5f\u4f1a\u8fdb\u884c\u4ecb\u7ecd\u3002 optim = SGD ( model . parameters (), lr = 0.01 ) \u8bad\u7ec33000\u6b21 epochs = 3000 \u51c6\u5907\u8bad\u7ec3\u6570\u636e: x_train , y_train \u7684\u5f62\u72b6\u662f (256, 1), \u4ee3\u8868 mini-batch \u5927\u5c0f\u4e3a256, feature \u4e3a1. astype('float32') \u662f\u4e3a\u4e86\u4e0b\u4e00\u6b65\u53ef\u4ee5\u76f4\u63a5\u8f6c\u6362\u4e3a torch.float . x_train = x . reshape ( - 1 , 1 ) . astype ( 'float32' ) y_train = y . reshape ( - 1 , 1 ) . astype ( 'float32' ) \u5f00\u59cb\u8bad\u7ec3\uff1a for i in range ( epochs ): # \u6574\u7406\u8f93\u5165\u548c\u8f93\u51fa\u7684\u6570\u636e\uff0c\u8fd9\u91cc\u8f93\u5165\u548c\u8f93\u51fa\u4e00\u5b9a\u8981\u662ftorch\u7684Tensor\u7c7b\u578b inputs = torch . from_numpy ( x_train ) labels = torch . from_numpy ( y_train ) #\u4f7f\u7528\u6a21\u578b\u8fdb\u884c\u9884\u6d4b outputs = model ( inputs ) #\u68af\u5ea6\u7f6e0\uff0c\u5426\u5219\u4f1a\u7d2f\u52a0 optim . zero_grad () # \u8ba1\u7b97\u635f\u5931 loss = criterion ( outputs , labels ) # \u53cd\u5411\u4f20\u64ad loss . backward () # \u4f7f\u7528\u4f18\u5316\u5668\u9ed8\u8ba4\u65b9\u6cd5\u4f18\u5316 optim . step () if ( i % 100 == 0 ): #\u6bcf 100\u6b21\u6253\u5370\u4e00\u4e0b\u635f\u5931\u51fd\u6570\uff0c\u770b\u770b\u6548\u679c print ( 'epoch {}, loss {:1.4f}' . format ( i , loss . data . item ())) epoch 0, loss 105.8649 epoch 100, loss 0.7534 epoch 200, loss 0.1216 epoch 300, loss 0.1029 epoch 400, loss 0.0915 epoch 500, loss 0.0828 epoch 600, loss 0.0763 epoch 700, loss 0.0713 epoch 800, loss 0.0675 epoch 900, loss 0.0647 epoch 1000, loss 0.0625 epoch 1100, loss 0.0608 epoch 1200, loss 0.0596 epoch 1300, loss 0.0586 epoch 1400, loss 0.0579 epoch 1500, loss 0.0574 epoch 1600, loss 0.0570 epoch 1700, loss 0.0566 epoch 1800, loss 0.0564 epoch 1900, loss 0.0562 epoch 2000, loss 0.0561 epoch 2100, loss 0.0560 epoch 2200, loss 0.0559 epoch 2300, loss 0.0558 epoch 2400, loss 0.0558 epoch 2500, loss 0.0558 epoch 2600, loss 0.0557 epoch 2700, loss 0.0557 epoch 2800, loss 0.0557 epoch 2900, loss 0.0557 \u8bad\u7ec3\u5b8c\u6210\u4e86\uff0c\u770b\u4e00\u4e0b\u8bad\u7ec3\u7684\u6210\u679c\u662f\u591a\u5c11\u3002 \u7528 model.parameters() \u63d0\u53d6\u6a21\u578b\u53c2\u6570\u3002 w w , b b \u662f\u6211\u4eec\u6240\u9700\u8981\u8bad\u7ec3\u7684\u6a21\u578b\u53c2\u6570\u3002 \u6211\u4eec\u671f\u671b\u7684\u6570\u636e w=5 w=5 \uff0c b=7 b=7 \u53ef\u4ee5\u505a\u4e00\u4e0b\u5bf9\u6bd4\uff1a [ w , b ] = model . parameters () print ( w . item (), b . item ()) 4.994358062744141 7.0252156257629395 \u518d\u6b21\u53ef\u89c6\u5316\u4e00\u4e0b\u6211\u4eec\u7684\u6a21\u578b\uff0c\u770b\u770b\u6211\u4eec\u8bad\u7ec3\u7684\u6570\u636e\uff0c\u5982\u679c\u4f60\u4e0d\u559c\u6b22seaborn\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528matplot\uff1a predicted = model . forward ( torch . from_numpy ( x_train )) . data . numpy () plt . plot ( x_train , y_train , 'go' , label = 'data' , alpha = 0.3 ) plt . plot ( x_train , predicted , label = 'predicted' , alpha = 1 ) plt . legend () plt . show () \u4ee5\u4e0a\u5c31\u662f\u4e00\u4e2a\u4f7f\u7528PyTorch\u505a\u7ebf\u6027\u56de\u5f52\u7684\u7b80\u5355\u6837\u4f8b\u4e86\uff0c\u4e0b\u9762\u6211\u4eec\u4f1a\u5bf9\u4e0a\u9762\u7684\u5185\u5bb9\u505a\u8be6\u7ec6\u7684\u4ecb\u7ecd","title":"2.2.2 \u7ebf\u6027\u56de\u5f52 \uff08Linear Regreesion\uff09"},{"location":"tutorial/chapter02_basics/2_2_deep-learning-mathematics-basic/#223-loss-function","text":"\u635f\u5931\u51fd\u6570\uff08loss function\uff09\u662f\u7528\u6765\u4f30\u91cf\u6a21\u578b\u7684\u9884\u6d4b\u503c(\u6211\u4eec\u4f8b\u5b50\u4e2d\u7684output)\u4e0e\u771f\u5b9e\u503c\uff08\u4f8b\u5b50\u4e2d\u7684y_train\uff09\u7684\u4e0d\u4e00\u81f4\u7a0b\u5ea6\uff0c\u5b83\u662f\u4e00\u4e2a\u975e\u8d1f\u5b9e\u503c\u51fd\u6570,\u635f\u5931\u51fd\u6570\u8d8a\u5c0f\uff0c\u6a21\u578b\u7684\u9c81\u68d2\u6027\u5c31\u8d8a\u597d\u3002 \u6211\u4eec\u8bad\u7ec3\u6a21\u578b\u7684\u8fc7\u7a0b\uff0c\u5c31\u662f\u901a\u8fc7\u4e0d\u65ad\u7684\u8fed\u4ee3\u8ba1\u7b97\uff0c\u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u7684\u4f18\u5316\u7b97\u6cd5\uff0c\u4f7f\u5f97\u635f\u5931\u51fd\u6570\u8d8a\u6765\u8d8a\u5c0f\u3002\u635f\u5931\u51fd\u6570\u8d8a\u5c0f\u5c31\u8868\u793a\u7b97\u6cd5\u8fbe\u5230\u610f\u4e49\u4e0a\u7684\u6700\u4f18\u3002 \u8fd9\u91cc\u6709\u4e00\u4e2a\u91cd\u70b9\uff1a\u56e0\u4e3aPyTorch\u662f\u4f7f\u7528mini-batch\u6765\u8fdb\u884c\u8ba1\u7b97\u7684\uff0c\u6240\u4ee5\u635f\u5931\u51fd\u6570\u7684\u8ba1\u7b97\u51fa\u6765\u7684\u7ed3\u679c\u5df2\u7ecf\u5bf9mini-batch\u53d6\u4e86\u5e73\u5747 \u5e38\u89c1\uff08PyTorch\u5185\u7f6e\uff09\u7684\u635f\u5931\u51fd\u6570\u6709\u4ee5\u4e0b\u51e0\u4e2a\uff1a","title":"2.2.3 \u635f\u5931\u51fd\u6570(Loss Function)"},{"location":"tutorial/chapter02_basics/2_2_deep-learning-mathematics-basic/#nnl1loss","text":"\u8f93\u5165x\u548c\u76ee\u6807y\u4e4b\u95f4\u5dee\u7684\u7edd\u5bf9\u503c\uff0c\u8981\u6c42 x \u548c y \u7684\u7ef4\u5ea6\u8981\u4e00\u6837\uff08\u53ef\u4ee5\u662f\u5411\u91cf\u6216\u8005\u77e9\u9635\uff09\uff0c\u5f97\u5230\u7684 loss \u7ef4\u5ea6\u4e5f\u662f\u5bf9\u5e94\u4e00\u6837\u7684 loss(x,y)=1/n\\sum|x_i-y_i| loss(x,y)=1/n\\sum|x_i-y_i|","title":"nn.L1Loss:"},{"location":"tutorial/chapter02_basics/2_2_deep-learning-mathematics-basic/#nnnllloss","text":"\u7528\u4e8e\u591a\u5206\u7c7b\u7684\u8d1f\u5bf9\u6570\u4f3c\u7136\u635f\u5931\u51fd\u6570 loss(x, class) = -x[class] loss(x, class) = -x[class] NLLLoss\u4e2d\u5982\u679c\u4f20\u9012\u4e86weights\u53c2\u6570\uff0c\u4f1a\u5bf9\u635f\u5931\u8fdb\u884c\u52a0\u6743\uff0c\u516c\u5f0f\u5c31\u53d8\u6210\u4e86 loss(x, class) = -weights[class] * x[class] loss(x, class) = -weights[class] * x[class]","title":"nn.NLLLoss:"},{"location":"tutorial/chapter02_basics/2_2_deep-learning-mathematics-basic/#nnmseloss","text":"\u5747\u65b9\u635f\u5931\u51fd\u6570 \uff0c\u8f93\u5165x\u548c\u76ee\u6807y\u4e4b\u95f4\u5747\u65b9\u5dee loss(x,y)=1/n\\sum(x_i-y_i)^2 loss(x,y)=1/n\\sum(x_i-y_i)^2","title":"nn.MSELoss:"},{"location":"tutorial/chapter02_basics/2_2_deep-learning-mathematics-basic/#nncrossentropyloss","text":"\u591a\u5206\u7c7b\u7528\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0cLogSoftMax\u548cNLLLoss\u96c6\u6210\u5230\u4e00\u4e2a\u7c7b\u4e2d\uff0c\u4f1a\u8c03\u7528nn.NLLLoss\u51fd\u6570,\u6211\u4eec\u53ef\u4ee5\u7406\u89e3\u4e3aCrossEntropyLoss() = log_softmax() + NLLLoss() $$ \\begin{aligned} loss(x, class) &= -\\text{log}\\frac{exp(x[class])}{\\sum_j exp(x[j]))} &= -x[class] + log(\\sum_j exp(x[j])) \\end{aligned} $$ \u56e0\u4e3a\u4f7f\u7528\u4e86NLLLoss\uff0c\u6240\u4ee5\u4e5f\u53ef\u4ee5\u4f20\u5165weight\u53c2\u6570\uff0c\u8fd9\u65f6loss\u7684\u8ba1\u7b97\u516c\u5f0f\u53d8\u4e3a\uff1a $$ loss(x, class) = weights[class] * (-x[class] + log(\\sum_j exp(x[j]))) $$ \u6240\u4ee5\u4e00\u822c\u591a\u5206\u7c7b\u7684\u60c5\u51b5\u4f1a\u4f7f\u7528\u8fd9\u4e2a\u635f\u5931\u51fd\u6570\u3002","title":"nn.CrossEntropyLoss:"},{"location":"tutorial/chapter02_basics/2_2_deep-learning-mathematics-basic/#nnbceloss","text":"\u8ba1\u7b97 x \u4e0e y \u4e4b\u95f4\u7684\u4e8c\u8fdb\u5236\u4ea4\u53c9\u71b5\u3002 loss(o,t) = -\\frac{1}{n}\\sum_i(t[i] * log(o[i])+(1-t[i]) * log(1-o[i])) loss(o,t) = -\\frac{1}{n}\\sum_i(t[i] * log(o[i])+(1-t[i]) * log(1-o[i])) \u4e0eNLLLoss\u7c7b\u4f3c\uff0c\u4e5f\u53ef\u4ee5\u6dfb\u52a0\u6743\u91cd\u53c2\u6570\uff1a loss(o,t)=-\\frac{1}{n}\\sum_iweights[i] * (t[i] * log(o[i])+(1-t[i]) * log(1-o[i])) loss(o,t)=-\\frac{1}{n}\\sum_iweights[i] * (t[i] * log(o[i])+(1-t[i]) * log(1-o[i])) \u7528\u7684\u65f6\u5019\u9700\u8981\u5728\u8be5\u5c42\u524d\u9762\u52a0\u4e0a Sigmoid \u51fd\u6570\u3002","title":"nn.BCELoss:"},{"location":"tutorial/chapter02_basics/2_2_deep-learning-mathematics-basic/#224","text":"\u5728\u4ecb\u7ecd\u635f\u5931\u51fd\u6570\u7684\u65f6\u5019\u6211\u4eec\u5df2\u7ecf\u8bf4\u4e86\uff0c\u68af\u5ea6\u4e0b\u964d\u662f\u4e00\u4e2a\u4f7f\u635f\u5931\u51fd\u6570\u8d8a\u6765\u8d8a\u5c0f\u7684\u4f18\u5316\u7b97\u6cd5\uff0c\u5728\u65e0\u6c42\u89e3\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u6a21\u578b\u53c2\u6570\uff0c\u5373\u7ea6\u675f\u4f18\u5316\u95ee\u9898\u65f6\uff0c\u68af\u5ea6\u4e0b\u964d\uff08Gradient Descent\uff09\u662f\u6700\u5e38\u91c7\u7528\u7684\u65b9\u6cd5\u4e4b\u4e00\u3002\u6240\u4ee5\u68af\u5ea6\u4e0b\u964d\u662f\u6211\u4eec\u76ee\u524d\u6240\u8bf4\u7684\u673a\u5668\u5b66\u4e60\u7684\u6838\u5fc3\uff0c\u4e86\u89e3\u4e86\u5b83\u7684\u542b\u4e49\uff0c\u4e5f\u5c31\u4e86\u89e3\u4e86\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u542b\u4e49\u3002","title":"2.2.4 \u68af\u5ea6\u4e0b\u964d"},{"location":"tutorial/chapter02_basics/2_2_deep-learning-mathematics-basic/#_1","text":"\u5728\u5fae\u79ef\u5206\u91cc\u9762\uff0c\u5bf9\u591a\u5143\u51fd\u6570\u7684\u53c2\u6570\u6c42\u2202\u504f\u5bfc\u6570\uff0c\u628a\u6c42\u5f97\u7684\u5404\u4e2a\u53c2\u6570\u7684\u504f\u5bfc\u6570\u4ee5\u5411\u91cf\u7684\u5f62\u5f0f\u5199\u51fa\u6765\uff0c\u5c31\u662f\u68af\u5ea6\u3002 \u4f8b\u5982\u51fd\u6570f(x,y), \u5206\u522b\u5bf9x,y\u6c42\u504f\u5bfc\u6570\uff0c\u6c42\u5f97\u7684\u68af\u5ea6\u5411\u91cf\u5c31\u662f(\u2202f/\u2202x, \u2202f/\u2202y)T,\u7b80\u79f0grad f(x,y)\u6216\u8005\u25bdf(x,y)\u3002 \u51e0\u4f55\u4e0a\u8bb2\uff0c\u68af\u5ea6\u5c31\u662f\u51fd\u6570\u53d8\u5316\u589e\u52a0\u6700\u5feb\u7684\u5730\u65b9\uff0c\u6cbf\u7740\u68af\u5ea6\u5411\u91cf\u7684\u65b9\u5411\uff0c\u66f4\u52a0\u5bb9\u6613\u627e\u5230\u51fd\u6570\u7684\u6700\u5927\u503c\u3002\u53cd\u8fc7\u6765\u8bf4\uff0c\u6cbf\u7740\u68af\u5ea6\u5411\u91cf\u76f8\u53cd\u7684\u65b9\u5411\u68af\u5ea6\u51cf\u5c11\u6700\u5feb\uff0c\u4e5f\u5c31\u662f\u66f4\u52a0\u5bb9\u6613\u627e\u5230\u51fd\u6570\u7684\u6700\u5c0f\u503c\u3002 \u6211\u4eec\u9700\u8981\u6700\u5c0f\u5316\u635f\u5931\u51fd\u6570\uff0c\u53ef\u4ee5\u901a\u8fc7\u68af\u5ea6\u4e0b\u964d\u6cd5\u6765\u4e00\u6b65\u6b65\u7684\u8fed\u4ee3\u6c42\u89e3\uff0c\u5f97\u5230\u6700\u5c0f\u5316\u7684\u635f\u5931\u51fd\u6570\uff0c\u548c\u6a21\u578b\u53c2\u6570\u503c\u3002","title":"\u68af\u5ea6"},{"location":"tutorial/chapter02_basics/2_2_deep-learning-mathematics-basic/#_2","text":"\u68af\u5ea6\u4e0b\u964d\u6cd5\u5c31\u597d\u6bd4\u4e0b\u5c71\uff0c\u6211\u4eec\u5e76\u4e0d\u77e5\u9053\u4e0b\u5c71\u7684\u8def\uff0c\u4e8e\u662f\u51b3\u5b9a\u8d70\u4e00\u6b65\u7b97\u4e00\u6b65\uff0c\u6bcf\u8d70\u5230\u4e00\u4e2a\u4f4d\u7f6e\u7684\u65f6\u5019\uff0c\u6c42\u89e3\u5f53\u524d\u4f4d\u7f6e\u7684\u68af\u5ea6\uff0c\u6cbf\u7740\u68af\u5ea6\u7684\u8d1f\u65b9\u5411\uff0c\u4e5f\u5c31\u662f\u5f53\u524d\u6700\u9661\u5ced\u7684\u4f4d\u7f6e\u5411\u4e0b\u8d70\u4e00\u6b65\uff0c\u7136\u540e\u7ee7\u7eed\u6c42\u89e3\u5f53\u524d\u4f4d\u7f6e\u68af\u5ea6\uff0c\u5411\u8fd9\u4e00\u6b65\u6240\u5728\u4f4d\u7f6e\u6cbf\u7740\u6700\u9661\u5ced\u6700\u6613\u4e0b\u5c71\u7684\u4f4d\u7f6e\u8d70\u4e00\u6b65\u3002\u8fd9\u6837\u4e00\u6b65\u6b65\u7684\u8d70\u4e0b\u53bb\uff0c\u4e00\u76f4\u8d70\u5230\u89c9\u5f97\u6211\u4eec\u5df2\u7ecf\u5230\u4e86\u5c71\u811a\u3002 \u5982\u4e0b\u56fe\u6240\u793a\uff0c\uff08\u6b64\u56fe\u6458\u81ea\u767e\u5ea6\u767e\u79d1\uff09 \u8fd9\u6837\u8d70\u4e0b\u53bb\uff0c\u6709\u53ef\u80fd\u6211\u4eec\u4e0d\u80fd\u8d70\u5230\u5c71\u811a\uff0c\u800c\u662f\u5230\u4e86\u67d0\u4e00\u4e2a\u5c40\u90e8\u7684\u5c71\u5cf0\u4f4e\u5904\uff08\u5c40\u90e8\u6700\u4f18\u89e3\uff09\u3002 \u8fd9\u4e2a\u95ee\u9898\u5728\u4ee5\u524d\u7684\u673a\u5668\u5b66\u4e60\u4e2d\u53ef\u80fd\u4f1a\u9047\u5230\uff0c\u56e0\u4e3a\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u7279\u5f81\u6bd4\u8f83\u5c11\uff0c\u6240\u4ee5\u5bfc\u81f4\u5f88\u53ef\u80fd\u9677\u5165\u5230\u4e00\u4e2a\u5c40\u90e8\u6700\u4f18\u89e3\u4e2d\u51fa\u4e0d\u6765\uff0c\u4f46\u662f\u5230\u4e86\u6df1\u5ea6\u5b66\u4e60\uff0c\u52a8\u8f84\u767e\u4e07\u751a\u81f3\u4e0a\u4ebf\u7684\u7279\u5f81\uff0c\u51fa\u73b0\u8fd9\u79cd\u60c5\u51b5\u7684\u6982\u7387\u51e0\u4e4e\u4e3a0\uff0c\u6240\u4ee5\u6211\u4eec\u53ef\u4ee5\u4e0d\u7528\u8003\u8651\u8fd9\u4e2a\u95ee\u9898\u3002","title":"\u68af\u5ea6\u4e0b\u964d\u6cd5\u76f4\u89c2\u89e3\u91ca"},{"location":"tutorial/chapter02_basics/2_2_deep-learning-mathematics-basic/#mini-batch","text":"\u5bf9\u6574\u4e2a\u8bad\u7ec3\u96c6\u8fdb\u884c\u68af\u5ea6\u4e0b\u964d\u6cd5\u7684\u65f6\u5019\uff0c\u6211\u4eec\u5fc5\u987b\u5904\u7406\u6574\u4e2a\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u7136\u540e\u624d\u80fd\u8fdb\u884c\u4e00\u6b65\u68af\u5ea6\u4e0b\u964d\uff0c\u5373\u6bcf\u4e00\u6b65\u68af\u5ea6\u4e0b\u964d\u6cd5\u9700\u8981\u5bf9\u6574\u4e2a\u8bad\u7ec3\u96c6\u8fdb\u884c\u4e00\u6b21\u5904\u7406\uff0c\u5982\u679c\u8bad\u7ec3\u6570\u636e\u96c6\u5f88\u5927\u7684\u65f6\u5019\u5904\u7406\u901f\u5ea6\u4f1a\u5f88\u6162\uff0c\u800c\u4e14\u4e5f\u4e0d\u53ef\u80fd\u4e00\u6b21\u7684\u8f7d\u5165\u5230\u5185\u5b58\u6216\u8005\u663e\u5b58\u4e2d\uff0c\u6240\u4ee5\u6211\u4eec\u4f1a\u628a\u5927\u6570\u636e\u96c6\u5206\u6210\u5c0f\u6570\u636e\u96c6\uff0c\u4e00\u90e8\u5206\u4e00\u90e8\u5206\u7684\u8bad\u7ec3\uff0c\u8fd9\u4e2a\u8bad\u7ec3\u5b50\u96c6\u5373\u79f0\u4e3aMini-batch\u3002 \u5728PyTorch\u4e2d\u5c31\u662f\u4f7f\u7528\u8fd9\u79cd\u65b9\u6cd5\u8fdb\u884c\u7684\u8bad\u7ec3\uff0c\u53ef\u4ee5\u770b\u770b\u4e0a\u4e00\u7ae0\u4e2d\u5173\u4e8edataloader\u7684\u4ecb\u7ecd\u91cc\u9762\u7684batch_size\u5c31\u662f\u6211\u4eec\u4e00\u4e2aMini-batch\u7684\u5927\u5c0f\u3002 \u4e3a\u4e86\u4ecb\u7ecd\u7684\u66f4\u7b80\u6d01\uff0c\u4f7f\u7528 \u5434\u6069\u8fbe\u8001\u5e08\u7684 deeplearning.ai \u8bfe\u7a0b\u677f\u4e66\u3002 \u5bf9\u4e8e\u666e\u901a\u7684\u68af\u5ea6\u4e0b\u964d\u6cd5\uff0c\u4e00\u4e2aepoch\u53ea\u80fd\u8fdb\u884c\u4e00\u6b21\u68af\u5ea6\u4e0b\u964d\uff1b\u800c\u5bf9\u4e8eMini-batch\u68af\u5ea6\u4e0b\u964d\u6cd5\uff0c\u4e00\u4e2aepoch\u53ef\u4ee5\u8fdb\u884cMini-batch\u7684\u4e2a\u6570\u6b21\u68af\u5ea6\u4e0b\u964d\u3002 \u666e\u901a\u7684batch\u68af\u5ea6\u4e0b\u964d\u6cd5\u548cMini-batch\u68af\u5ea6\u4e0b\u964d\u6cd5\u4ee3\u4ef7\u51fd\u6570\u7684\u53d8\u5316\u8d8b\u52bf\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u5982\u679c\u8bad\u7ec3\u6837\u672c\u7684\u5927\u5c0f\u6bd4\u8f83\u5c0f\u65f6,\u80fd\u591f\u4e00\u6b21\u6027\u7684\u8bfb\u53d6\u5230\u5185\u5b58\u4e2d\uff0c\u90a3\u6211\u4eec\u5c31\u4e0d\u9700\u8981\u4f7f\u7528Mini-batch\uff0c \u5982\u679c\u8bad\u7ec3\u6837\u672c\u7684\u5927\u5c0f\u6bd4\u8f83\u5927\u65f6\uff0c\u4e00\u6b21\u8bfb\u5165\u4e0d\u5230\u5185\u5b58\u6216\u8005\u73b0\u5b58\u4e2d\uff0c\u90a3\u6211\u4eec\u5fc5\u987b\u8981\u4f7f\u7528 Mini-batch\u6765\u5206\u6279\u7684\u8ba1\u7b97 Mini-batch size\u7684\u8ba1\u7b97\u89c4\u5219\u5982\u4e0b\uff0c\u5728\u5185\u5b58\u5141\u8bb8\u7684\u6700\u5927\u60c5\u51b5\u4e0b\u4f7f\u75282\u7684N\u6b21\u65b9\u4e2asize torch.optim \u662f\u4e00\u4e2a\u5b9e\u73b0\u4e86\u5404\u79cd\u4f18\u5316\u7b97\u6cd5\u7684\u5e93\u3002\u5927\u90e8\u5206\u5e38\u7528\u4f18\u5316\u7b97\u6cd5\u90fd\u6709\u5b9e\u73b0\uff0c\u6211\u4eec\u76f4\u63a5\u8c03\u7528\u5373\u53ef\u3002","title":"Mini-batch\u7684\u68af\u5ea6\u4e0b\u964d\u6cd5"},{"location":"tutorial/chapter02_basics/2_2_deep-learning-mathematics-basic/#torchoptimsgd","text":"\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5,\u5e26\u6709\u52a8\u91cf\uff08momentum\uff09\u7684\u7b97\u6cd5\u4f5c\u4e3a\u4e00\u4e2a\u53ef\u9009\u53c2\u6570\u53ef\u4ee5\u8fdb\u884c\u8bbe\u7f6e\uff0c\u6837\u4f8b\u5982\u4e0b\uff1a #lr\u53c2\u6570\u4e3a\u5b66\u4e60\u7387\uff0c\u5bf9\u4e8eSGD\u6765\u8bf4\u4e00\u822c\u9009\u62e90.1 0.01.0.001\uff0c\u5982\u4f55\u8bbe\u7f6e\u4f1a\u5728\u540e\u9762\u5b9e\u6218\u7684\u7ae0\u8282\u4e2d\u8be6\u7ec6\u8bf4\u660e ##\u5982\u679c\u8bbe\u7f6e\u4e86momentum\uff0c\u5c31\u662f\u5e26\u6709\u52a8\u91cf\u7684SGD\uff0c\u53ef\u4ee5\u4e0d\u8bbe\u7f6e optimizer = torch . optim . SGD ( model . parameters (), lr = 0.1 , momentum = 0.9 )","title":"torch.optim.SGD"},{"location":"tutorial/chapter02_basics/2_2_deep-learning-mathematics-basic/#torchoptimrmsprop","text":"\u9664\u4e86\u4ee5\u4e0a\u7684\u5e26\u6709\u52a8\u91cfMomentum\u68af\u5ea6\u4e0b\u964d\u6cd5\u5916\uff0cRMSprop\uff08root mean square prop\uff09\u4e5f\u662f\u4e00\u79cd\u53ef\u4ee5\u52a0\u5feb\u68af\u5ea6\u4e0b\u964d\u7684\u7b97\u6cd5\uff0c\u5229\u7528RMSprop\u7b97\u6cd5\uff0c\u53ef\u4ee5\u51cf\u5c0f\u67d0\u4e9b\u7ef4\u5ea6\u68af\u5ea6\u66f4\u65b0\u6ce2\u52a8\u8f83\u5927\u7684\u60c5\u51b5\uff0c\u4f7f\u5176\u68af\u5ea6\u4e0b\u964d\u7684\u901f\u5ea6\u53d8\u5f97\u66f4\u5feb #\u6211\u4eec\u7684\u8bfe\u7a0b\u57fa\u672c\u4e0d\u4f1a\u4f7f\u7528\u5230RMSprop\u6240\u4ee5\u8fd9\u91cc\u53ea\u7ed9\u4e00\u4e2a\u5b9e\u4f8b optimizer = torch . optim . RMSprop ( model . parameters (), lr = 0.01 , alpha = 0.99 )","title":"torch.optim.RMSprop"},{"location":"tutorial/chapter02_basics/2_2_deep-learning-mathematics-basic/#torchoptimadam","text":"Adam \u4f18\u5316\u7b97\u6cd5\u7684\u57fa\u672c\u601d\u60f3\u5c31\u662f\u5c06 Momentum \u548c RMSprop \u7ed3\u5408\u8d77\u6765\u5f62\u6210\u7684\u4e00\u79cd\u9002\u7528\u4e8e\u4e0d\u540c\u6df1\u5ea6\u5b66\u4e60\u7ed3\u6784\u7684\u4f18\u5316\u7b97\u6cd5 # \u8fd9\u91cc\u7684lr\uff0cbetas\uff0c\u8fd8\u6709eps\u90fd\u662f\u7528\u9ed8\u8ba4\u503c\u5373\u53ef\uff0c\u6240\u4ee5Adam\u662f\u4e00\u4e2a\u4f7f\u7528\u8d77\u6765\u6700\u7b80\u5355\u7684\u4f18\u5316\u65b9\u6cd5 optimizer = torch . optim . Adam ( model . parameters (), lr = 0.001 , betas = ( 0.9 , 0.999 ), eps = 1e-08 )","title":"torch.optim.Adam"},{"location":"tutorial/chapter02_basics/2_2_deep-learning-mathematics-basic/#225","text":"\u504f\u5dee\u5ea6\u91cf\u4e86\u5b66\u4e60\u7b97\u6cd5\u7684\u671f\u671b\u9884\u6d4b\u4e0e\u771f\u5b9e\u7ed3\u679c\u7684\u504f\u79bb\u7a0b\u5e8f, \u5373 \u523b\u753b\u4e86\u5b66\u4e60\u7b97\u6cd5\u672c\u8eab\u7684\u62df\u5408\u80fd\u529b \u65b9\u5dee\u5ea6\u91cf\u4e86\u540c\u6837\u5927\u5c0f\u7684\u8bad\u7ec3\u96c6\u7684\u53d8\u52a8\u6240\u5bfc\u81f4\u7684\u5b66\u4e60\u6027\u80fd\u7684\u53d8\u5316, \u5373**\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b**\uff1a \u4ece\u56fe\u4e2d\u6211\u4eec\u53ef\u4ee5\u770b\u51fa\uff1a - \u9ad8\u504f\u5dee\uff08high bias\uff09\u7684\u60c5\u51b5\uff0c\u4e00\u822c\u79f0\u4e3a\u6b20\u62df\u5408\uff08underfitting\uff09,\u5373\u6211\u4eec\u7684\u6a21\u578b\u5e76\u6ca1\u6709\u5f88\u597d\u7684\u53bb\u9002\u914d\u73b0\u6709\u7684\u6570\u636e\uff0c\u62df\u5408\u5ea6\u4e0d\u591f\u3002 - \u9ad8\u65b9\u5dee\uff08high variance\uff09\u7684\u60c5\u51b5\u4e00\u822c\u79f0\u4f5c\u8fc7\u62df\u5408\uff08overfitting\uff09\uff0c\u5373\u6a21\u578b\u5bf9\u4e8e\u8bad\u7ec3\u6570\u636e\u62df\u5408\u5ea6\u592a\u9ad8\u4e86\uff0c\u5931\u53bb\u4e86\u6cdb\u5316\u7684\u80fd\u529b\u3002 \u5982\u4f55\u89e3\u51b3\u8fd9\u4e24\u79cd\u60c5\u51b5\u5462\uff1f \u6b20\u62df\u5408\uff1a - \u589e\u52a0\u7f51\u7edc\u7ed3\u6784\uff0c\u5982\u589e\u52a0\u9690\u85cf\u5c42\u6570\u76ee\uff1b - \u8bad\u7ec3\u66f4\u957f\u65f6\u95f4\uff1b - \u5bfb\u627e\u5408\u9002\u7684\u7f51\u7edc\u67b6\u6784\uff0c\u4f7f\u7528\u66f4\u5927\u7684NN\u7ed3\u6784\uff1b \u8fc7\u62df\u5408 \uff1a - \u4f7f\u7528\u66f4\u591a\u7684\u6570\u636e\uff1b - \u6b63\u5219\u5316\uff08 regularization\uff09\uff1b - \u5bfb\u627e\u5408\u9002\u7684\u7f51\u7edc\u7ed3\u6784\uff1b \u4f8b\u5982\u6211\u4eec\u4e0a\u9762\u7684\u4f8b\u5b50\uff0c\u53ef\u4ee5\u8ba1\u7b97\u51fa\u6211\u4eec\u7684\u504f\u5dee: print ( 5 - w . data . item (), 7 - b . data . item ()) 0.005641937255859375 -0.025215625762939453","title":"2.2.5 \u65b9\u5dee/\u504f\u5dee"},{"location":"tutorial/chapter02_basics/2_2_deep-learning-mathematics-basic/#226","text":"\u5229\u7528\u6b63\u5219\u5316\u6765\u89e3\u51b3High variance \u7684\u95ee\u9898\uff0c\u6b63\u5219\u5316\u662f\u5728 Cost function \u4e2d\u52a0\u5165\u4e00\u9879\u6b63\u5219\u5316\u9879\uff0c\u60e9\u7f5a\u6a21\u578b\u7684\u590d\u6742\u5ea6,\u8fd9\u91cc\u6211\u4eec\u7b80\u5355\u7684\u4ecb\u7ecd\u4e00\u4e0b\u6b63\u5219\u5316\u7684\u6982\u5ff5","title":"2.2.6 \u6b63\u5219\u5316"},{"location":"tutorial/chapter02_basics/2_2_deep-learning-mathematics-basic/#l1","text":"\u635f\u5931\u51fd\u6570\u57fa\u7840\u4e0a\u52a0\u4e0a\u6743\u91cd\u53c2\u6570\u7684\u7edd\u5bf9\u503c L=E_{in}+\\lambda{\\sum_j} \\left|w_j\\right| L=E_{in}+\\lambda{\\sum_j} \\left|w_j\\right|","title":"L1\u6b63\u5219\u5316"},{"location":"tutorial/chapter02_basics/2_2_deep-learning-mathematics-basic/#l2","text":"\u635f\u5931\u51fd\u6570\u57fa\u7840\u4e0a\u52a0\u4e0a\u6743\u91cd\u53c2\u6570\u7684\u5e73\u65b9\u548c L=E_{in}+\\lambda{\\sum_j} w^2_j L=E_{in}+\\lambda{\\sum_j} w^2_j \u9700\u8981\u8bf4\u660e\u7684\u662f\uff1al1 \u76f8\u6bd4\u4e8e l2 \u4f1a\u66f4\u5bb9\u6613\u83b7\u5f97\u7a00\u758f\u89e3\uff0c\u53ef\u67e5\u770b \u77e5\u4e4e \u89e3\u7b54\u3002","title":"L2\u6b63\u5219\u5316"},{"location":"tutorial/chapter02_basics/2_3_deep-learning-neural-network-introduction/","text":"2.3 \u795e\u7ecf\u7f51\u7edc\u7b80\u4ecb \u00b6 \u76ee\u524d\u6700\u5e7f\u6cdb\u4f7f\u7528\u7684\u5b9a\u4e49\u662fKohonen\u4e8e1988\u5e74\u7684\u63cf\u8ff0\uff0c\u795e\u7ecf\u7f51\u7edc\u662f\u7531\u5177\u6709\u9002\u5e94\u6027\u7684\u7b80\u5355\u5355\u5143\u7ec4\u6210\u7684\u5e7f\u6cdb\u5e76\u884c\u4e92\u8fde\u7684\u7f51\u7edc\uff0c\u5b83\u7684\u7ec4\u7ec7\u80fd\u591f\u6a21\u62df\u751f\u7269\u795e\u7ecf\u7cfb\u7edf\u5bf9\u771f\u5b9e\u4e16\u754c\u7269\u4f53\u6240\u505a\u51fa\u7684\u4ea4\u4e92\u53cd\u5e94\u3002 \u6982\u8ff0 \u00b6 \u5728\u751f\u7269\u795e\u7ecf\u7f51\u7edc\u4e2d\uff0c\u6bcf\u4e2a\u795e\u7ecf\u5143\u4e0e\u5176\u4ed6\u795e\u7ecf\u5143\u76f8\u8fde\uff0c\u5f53\u5b83\u5174\u594b\u65f6\uff0c\u5c31\u4f1a\u5411\u76f8\u8fde\u7684\u795e\u7ecf\u5143\u53d1\u9001\u5316\u5b66\u7269\u8d28\uff0c\u4ece\u800c\u6539\u53d8\u8fd9\u4e9b\u795e\u7ecf\u5143\u5185\u7684\u7535\u4f4d\uff1b\u5982\u679c\u67d0\u795e\u7ecf\u5143\u7684\u7535\u4f4d\u8d85\u8fc7\u4e86\u4e00\u4e2a\u9608\u503c\uff0c\u90a3\u4e48\u5b83\u5c31\u4f1a\u6fc0\u6d3b\uff0c\u5373\u5174\u594b\u8d77\u6765\u5e76\u5411\u5176\u4ed6\u795e\u7ecf\u5143\u53d1\u9001\u5316\u5b66\u7269\u8d28\u3002 \u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\u4e5f\u501f\u9274\u4e86\u8fd9\u6837\u7684\u7ed3\u6784,\u6bcf\u4e00\u4e2a\u795e\u7ecf\u5143\uff08\u4e0a\u9762\u8bf4\u5230\u7684\u7b80\u5355\u5355\u5143\uff09\u63a5\u53d7\u8f93\u5165x\uff0c\u901a\u8fc7\u5e26\u6743\u91cdw\u7684\u8fde\u63a5\u8fdb\u884c\u4f20\u9012\uff0c\u5c06\u603b\u8f93\u5165\u4fe1\u53f7\u4e0e\u795e\u7ecf\u5143\u7684\u9608\u503c\u8fdb\u884c\u6bd4\u8f83\uff0c\u6700\u540e\u901a\u8fc7\u6fc0\u6d3b\u51fd\u6570\u5904\u7406\u786e\u5b9a\u662f\u5426\u6fc0\u6d3b\uff0c\u5e76\u5c06\u6fc0\u6d3b\u540e\u7684\u8ba1\u7b97\u7ed3\u679cy\u8f93\u51fa,\u800c\u6211\u4eec\u6240\u8bf4\u7684\u8bad\u7ec3\uff0c\u6240\u8bad\u7ec3\u7684\u5c31\u662f\u8fd9\u91cc\u9762\u7684\u6743\u91cdw\u3002 \u53c2\u8003 \u6bcf\u4e00\u4e2a\u795e\u7ecf\u5143\u7684\u7ed3\u6784\u5982\u4e0b\uff1a \u6765\u6e90 \u795e\u7ecf\u7f51\u7edc\u7684\u8868\u793a \u00b6 \u6211\u4eec\u53ef\u4ee5\u5c06\u795e\u7ecf\u5143\u62fc\u63a5\u8d77\u6765\uff0c\u4e24\u5c42\u795e\u7ecf\u5143\uff0c\u5373\u8f93\u5165\u5c42+\u8f93\u51fa\u5c42(M-P\u795e\u7ecf\u5143),\u6784\u6210\u611f\u77e5\u673a\u3002 \u800c\u591a\u5c42\u529f\u80fd\u795e\u7ecf\u5143\u76f8\u8fde\u6784\u6210\u795e\u7ecf\u7f51\u7edc\uff0c\u8f93\u5165\u5c42\u4e0e\u8f93\u51fa\u5c42\u4e4b\u95f4\u7684\u6240\u6709\u5c42\u795e\u7ecf\u5143\uff0c\u79f0\u4e3a\u9690\u85cf\u5c42\uff1a \u5982\u4e0a\u56fe\u6240\u793a\uff0c\u8f93\u5165\u5c42\u548c\u8f93\u51fa\u5c42\u53ea\u6709\u4e00\u4e2a\uff0c\u4e2d\u95f4\u7684\u9690\u85cf\u5c42\u53ef\u4ee5\u6709\u5f88\u591a\u5c42\uff08\u8f93\u51fa\u5c42\u4e5f\u53ef\u4ee5\u591a\u4e2a\uff0c\u4f8b\u5982\u7ecf\u5178\u7684GoogleNet\uff0c\u540e\u9762\u4f1a\u8be6\u7ec6\u4ecb\u7ecd\uff09 \u6fc0\u6d3b\u51fd\u6570 \u00b6 \u4ecb\u7ecd\u795e\u7ecf\u7f51\u7edc\u7684\u65f6\u5019\u5df2\u7ecf\u8bf4\u5230\uff0c\u795e\u7ecf\u5143\u4f1a\u5bf9\u5316\u5b66\u7269\u8d28\u7684\u523a\u6fc0\u8fdb\u884c\uff0c\u5f53\u8fbe\u5230\u4e00\u5b9a\u7a0b\u5ea6\u7684\u65f6\u5019\uff0c\u795e\u7ecf\u5143\u624d\u4f1a\u5174\u594b\uff0c\u5e76\u5411\u5176\u4ed6\u795e\u7ecf\u5143\u53d1\u9001\u4fe1\u606f\u3002\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u6fc0\u6d3b\u51fd\u6570\u5c31\u662f\u7528\u6765\u5224\u65ad\u6211\u4eec\u6240\u8ba1\u7b97\u7684\u4fe1\u606f\u662f\u5426\u8fbe\u5230\u4e86\u5f80\u540e\u9762\u4f20\u8f93\u7684\u6761\u4ef6\u3002 \u4e3a\u4ec0\u4e48\u6fc0\u6d3b\u51fd\u6570\u90fd\u662f\u975e\u7ebf\u6027\u7684 \u00b6 \u5728\u795e\u7ecf\u7f51\u7edc\u7684\u8ba1\u7b97\u8fc7\u7a0b\u4e2d\uff0c\u6bcf\u5c42\u90fd\u76f8\u5f53\u4e8e\u77e9\u9635\u76f8\u4e58\uff0c\u65e0\u8bba\u795e\u7ecf\u7f51\u7edc\u6709\u591a\u5c11\u5c42\u8f93\u51fa\u90fd\u662f\u8f93\u5165\u7684\u7ebf\u6027\u7ec4\u5408\uff0c\u5c31\u7b97\u6211\u4eec\u6709\u51e0\u5343\u5c42\u7684\u8ba1\u7b97\uff0c\u65e0\u975e\u8fd8\u662f\u4e2a\u77e9\u9635\u76f8\u4e58\uff0c\u548c\u4e00\u5c42\u77e9\u9635\u76f8\u4e58\u6240\u83b7\u5f97\u7684\u4fe1\u606f\u5dee\u8ddd\u4e0d\u5927\uff0c\u6240\u4ee5\u9700\u8981\u6fc0\u6d3b\u51fd\u6570\u6765\u5f15\u5165\u975e\u7ebf\u6027\u56e0\u7d20\uff0c\u4f7f\u5f97\u795e\u7ecf\u7f51\u7edc\u53ef\u4ee5\u4efb\u610f\u903c\u8fd1\u4efb\u4f55\u975e\u7ebf\u6027\u51fd\u6570\uff0c\u8fd9\u6837\u795e\u7ecf\u7f51\u7edc\u5c31\u53ef\u4ee5\u5e94\u7528\u5230\u4f17\u591a\u7684\u975e\u7ebf\u6027\u6a21\u578b\u4e2d\uff0c\u589e\u52a0\u4e86\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u6cdb\u5316\u7684\u7279\u6027\u3002 \u65e9\u671f\u7814\u7a76\u795e\u7ecf\u7f51\u7edc\u4e3b\u8981\u91c7\u7528sigmoid\u51fd\u6570\u6216\u8005tanh\u51fd\u6570\uff0c\u8f93\u51fa\u6709\u754c\uff0c\u5f88\u5bb9\u6613\u5145\u5f53\u4e0b\u4e00\u5c42\u7684\u8f93\u5165\u3002 \u8fd1\u4e9b\u5e74Relu\u51fd\u6570\u53ca\u5176\u6539\u8fdb\u578b\uff08\u5982Leaky-ReLU\u3001P-ReLU\u3001R-ReLU\u7b49\uff09\uff0c\u7531\u4e8e\u8ba1\u7b97\u7b80\u5355\u3001\u6548\u679c\u597d\u6240\u4ee5\u5728\u591a\u5c42\u795e\u7ecf\u7f51\u7edc\u4e2d\u5e94\u7528\u6bd4\u8f83\u591a\u3002 \u4e0b\u9762\u6765\u603b\u7ed3\u4e0b\u8f83\u5e38\u89c1\u7684\u6fc0\u6d3b\u51fd\u6570\uff1a # \u521d\u59cb\u5316\u4e00\u4e9b\u4fe1\u606f import torch import torch.nn.functional as F import matplotlib.pyplot as plt import numpy as np x = torch . linspace ( - 10 , 10 , 60 ) sigmod \u51fd\u6570 \u00b6 a=\\frac{1}{1+e^{-z}} a=\\frac{1}{1+e^{-z}} \u5bfc\u6570 \uff1a$$ a^\\prime =a(1 - a) $$ \u5728sigmod\u51fd\u6570\u4e2d\u6211\u4eec\u53ef\u4ee5\u770b\u5230\uff0c\u5176\u8f93\u51fa\u662f\u5728(0,1)\u8fd9\u4e2a\u5f00\u533a\u95f4,\u5b83\u80fd\u591f\u628a\u8f93\u5165\u7684\u8fde\u7eed\u5b9e\u503c\u53d8\u6362\u4e3a0\u548c1\u4e4b\u95f4\u7684\u8f93\u51fa\uff0c\u5982\u679c\u662f\u975e\u5e38\u5927\u7684\u8d1f\u6570\uff0c\u90a3\u4e48\u8f93\u51fa\u5c31\u662f0\uff1b\u5982\u679c\u662f\u975e\u5e38\u5927\u7684\u6b63\u6570\u8f93\u51fa\u5c31\u662f1\uff0c\u8d77\u5230\u4e86\u6291\u5236\u7684\u4f5c\u7528\u3002 ax = plt . gca () ax . spines [ 'right' ] . set_color ( 'none' ) ax . spines [ 'top' ] . set_color ( 'none' ) ax . xaxis . set_ticks_position ( 'bottom' ) ax . spines [ 'bottom' ] . set_position (( 'data' , 0 )) ax . yaxis . set_ticks_position ( 'left' ) ax . spines [ 'left' ] . set_position (( 'data' , 0 )) plt . ylim (( 0 , 1 )) sigmod = torch . sigmoid ( x ) plt . plot ( x . numpy (), sigmod . numpy ()) [<matplotlib.lines.Line2D at 0x2ad8aa2b9b0>] \u4f46\u662fsigmod\u7531\u4e8e\u9700\u8981\u8fdb\u884c\u6307\u6570\u8fd0\u7b97\uff08\u8fd9\u4e2a\u5bf9\u4e8e\u8ba1\u7b97\u673a\u6765\u8bf4\u662f\u6bd4\u8f83\u6162\uff0c\u76f8\u6bd4relu\uff09\uff0c\u518d\u52a0\u4e0a\u51fd\u6570\u8f93\u51fa\u4e0d\u662f\u4ee50\u4e3a\u4e2d\u5fc3\u7684\uff08\u8fd9\u6837\u4f1a\u4f7f\u6743\u91cd\u66f4\u65b0\u6548\u7387\u964d\u4f4e\uff09\uff0c\u5f53\u8f93\u5165\u7a0d\u5fae\u8fdc\u79bb\u4e86\u5750\u6807\u539f\u70b9\uff0c\u51fd\u6570\u7684\u68af\u5ea6\u5c31\u53d8\u5f97\u5f88\u5c0f\u4e86\uff08\u51e0\u4e4e\u4e3a\u96f6\uff09\u3002\u5728\u795e\u7ecf\u7f51\u7edc\u53cd\u5411\u4f20\u64ad\u7684\u8fc7\u7a0b\u4e2d\u4e0d\u5229\u4e8e\u6743\u91cd\u7684\u4f18\u5316\uff0c\u8fd9\u4e2a\u95ee\u9898\u53eb\u505a\u68af\u5ea6\u9971\u548c\uff0c\u4e5f\u53ef\u4ee5\u53eb\u68af\u5ea6\u5f25\u6563\u3002\u8fd9\u4e9b\u4e0d\u8db3\uff0c\u6240\u4ee5\u73b0\u5728\u4f7f\u7528\u5230sigmod\u57fa\u672c\u5f88\u5c11\u4e86\uff0c\u57fa\u672c\u4e0a\u53ea\u6709\u5728\u505a\u4e8c\u5143\u5206\u7c7b\uff080\uff0c1\uff09\u65f6\u7684\u8f93\u51fa\u5c42\u624d\u4f1a\u4f7f\u7528\u3002 tanh \u51fd\u6570 \u00b6 a=\\frac{e^z-e^{-z}}{e^z+e^{-z}} a=\\frac{e^z-e^{-z}}{e^z+e^{-z}} \u5bfc\u6570\uff1a$$ a^\\prime =1 - a^2 $$ tanh\u662f\u53cc\u66f2\u6b63\u5207\u51fd\u6570,\u8f93\u51fa\u533a\u95f4\u662f\u5728(-1,1)\u4e4b\u95f4\uff0c\u800c\u4e14\u6574\u4e2a\u51fd\u6570\u662f\u4ee50\u4e3a\u4e2d\u5fc3\u7684: ax = plt . gca () ax . spines [ 'right' ] . set_color ( 'none' ) ax . spines [ 'top' ] . set_color ( 'none' ) ax . xaxis . set_ticks_position ( 'bottom' ) ax . spines [ 'bottom' ] . set_position (( 'data' , 0 )) ax . yaxis . set_ticks_position ( 'left' ) ax . spines [ 'left' ] . set_position (( 'data' , 0 )) plt . ylim (( - 1 , 1 )) tanh = torch . tanh ( x ) plt . plot ( x . numpy (), tanh . numpy ()) [<matplotlib.lines.Line2D at 0x2ad8ab67cc0>] \u4e0esigmoid\u51fd\u6570\u7c7b\u4f3c\uff0c\u5f53\u8f93\u5165\u7a0d\u5fae\u8fdc\u79bb\u4e86\u5750\u6807\u539f\u70b9\uff0c\u68af\u5ea6\u8fd8\u662f\u4f1a\u5f88\u5c0f\uff0c\u4f46\u662f\u597d\u5728tanh\u662f\u4ee50\u4e3a\u4e2d\u5fc3\u70b9\uff0c\u5982\u679c\u4f7f\u7528tanh\u4f5c\u4e3a\u6fc0\u6d3b\u51fd\u6570\uff0c\u8fd8\u80fd\u8d77\u5230\u5f52\u4e00\u5316\uff08\u5747\u503c\u4e3a0\uff09\u7684\u6548\u679c\u3002 \u4e00\u822c\u4e8c\u5206\u7c7b\u95ee\u9898\u4e2d\uff0c\u9690\u85cf\u5c42\u7528tanh\u51fd\u6570\uff0c\u8f93\u51fa\u5c42\u7528sigmod\u51fd\u6570\uff0c\u4f46\u662f\u968f\u7740Relu\u7684\u51fa\u73b0\u6240\u6709\u7684\u9690\u85cf\u5c42\u57fa\u672c\u4e0a\u90fd\u4f7f\u7528relu\u6765\u4f5c\u4e3a\u6fc0\u6d3b\u51fd\u6570\u4e86 ReLU \u51fd\u6570 \u00b6 Relu\uff08Rectified Linear Units\uff09\u4fee\u6b63\u7ebf\u6027\u5355\u5143 $$ a=max(0,z) $$ \u5bfc\u6570\u5927\u4e8e0\u65f61\uff0c\u5c0f\u4e8e0\u65f60\u3002 \u4e5f\u5c31\u662f\u8bf4\uff1a z>0\u65f6\uff0c\u68af\u5ea6\u59cb\u7ec8\u4e3a1\uff0c\u4ece\u800c\u63d0\u9ad8\u795e\u7ecf\u7f51\u7edc\u57fa\u4e8e\u68af\u5ea6\u7b97\u6cd5\u7684\u8fd0\u7b97\u901f\u5ea6\u3002\u7136\u800c\u5f53 z<0\u65f6\uff0c\u68af\u5ea6\u4e00\u76f4\u4e3a0\u3002 ReLU\u51fd\u6570\u53ea\u6709\u7ebf\u6027\u5173\u7cfb\uff08\u53ea\u9700\u8981\u5224\u65ad\u8f93\u5165\u662f\u5426\u5927\u4e8e0\uff09\u4e0d\u7ba1\u662f\u524d\u5411\u4f20\u64ad\u8fd8\u662f\u53cd\u5411\u4f20\u64ad\uff0c\u90fd\u6bd4sigmod\u548ctanh\u8981\u5feb\u5f88\u591a\uff0c ax = plt . gca () ax . spines [ 'right' ] . set_color ( 'none' ) ax . spines [ 'top' ] . set_color ( 'none' ) ax . xaxis . set_ticks_position ( 'bottom' ) ax . spines [ 'bottom' ] . set_position (( 'data' , 0 )) ax . yaxis . set_ticks_position ( 'left' ) ax . spines [ 'left' ] . set_position (( 'data' , 0 )) plt . ylim (( - 3 , 10 )) relu = F . relu ( x ) plt . plot ( x . numpy (), relu . numpy ()) [<matplotlib.lines.Line2D at 0x2ad8b097470>] \u5f53\u8f93\u5165\u662f\u8d1f\u6570\u7684\u65f6\u5019\uff0cReLU\u662f\u5b8c\u5168\u4e0d\u88ab\u6fc0\u6d3b\u7684\uff0c\u8fd9\u5c31\u8868\u660e\u4e00\u65e6\u8f93\u5165\u5230\u4e86\u8d1f\u6570\uff0cReLU\u5c31\u4f1a\u6b7b\u6389\u3002\u4f46\u662f\u5230\u4e86\u53cd\u5411\u4f20\u64ad\u8fc7\u7a0b\u4e2d\uff0c\u8f93\u5165\u8d1f\u6570\uff0c\u68af\u5ea6\u5c31\u4f1a\u5b8c\u5168\u52300\uff0c\u8fd9\u4e2a\u548csigmod\u51fd\u6570\u3001tanh\u51fd\u6570\u6709\u4e00\u6837\u7684\u95ee\u9898\u3002 \u4f46\u662f\u5b9e\u9645\u7684\u8fd0\u7528\u4e2d\uff0c\u8be5\u7f3a\u9677\u7684\u5f71\u54cd\u4e0d\u662f\u5f88\u5927\u3002 Leaky Relu \u51fd\u6570 \u00b6 \u4e3a\u4e86\u89e3\u51b3relu\u51fd\u6570z<0\u65f6\u7684\u95ee\u9898\u51fa\u73b0\u4e86 Leaky ReLU\u51fd\u6570\uff0c\u8be5\u51fd\u6570\u4fdd\u8bc1\u5728z<0\u7684\u65f6\u5019\uff0c\u68af\u5ea6\u4ecd\u7136\u4e0d\u4e3a0\u3002 ReLU\u7684\u524d\u534a\u6bb5\u8bbe\u4e3a\u03b1z\u800c\u975e0\uff0c\u901a\u5e38\u03b1=0.01 $$ a=max(\\alpha z,z) $$ ax = plt . gca () ax . spines [ 'right' ] . set_color ( 'none' ) ax . spines [ 'top' ] . set_color ( 'none' ) ax . xaxis . set_ticks_position ( 'bottom' ) ax . spines [ 'bottom' ] . set_position (( 'data' , 0 )) ax . yaxis . set_ticks_position ( 'left' ) ax . spines [ 'left' ] . set_position (( 'data' , 0 )) plt . ylim (( - 3 , 10 )) l_relu = F . leaky_relu ( x , 0.1 ) # \u8fd9\u91cc\u76840.1\u662f\u4e3a\u4e86\u65b9\u4fbf\u5c55\u793a\uff0c\u7406\u8bba\u4e0a\u5e94\u4e3a0.01\u751a\u81f3\u66f4\u5c0f\u7684\u503c plt . plot ( x . numpy (), l_relu . numpy ()) [<matplotlib.lines.Line2D at 0x2ad8b0bd3c8>] \u7406\u8bba\u4e0a\u6765\u8bb2\uff0cLeaky ReLU\u6709ReLU\u7684\u6240\u6709\u4f18\u70b9\uff0c\u4f46\u662f\u5728\u5b9e\u9645\u64cd\u4f5c\u5f53\u4e2d\uff0c\u5e76\u6ca1\u6709\u5b8c\u5168\u8bc1\u660eLeaky ReLU\u603b\u662f\u597d\u4e8eReLU\u3002 ReLU\u76ee\u524d\u4ecd\u662f\u6700\u5e38\u7528\u7684activation function\uff0c\u5728\u9690\u85cf\u5c42\u4e2d\u63a8\u8350\u4f18\u5148\u5c1d\u8bd5\uff01 \u6df1\u5165\u7406\u89e3\u524d\u5411\u4f20\u64ad\u548c\u53cd\u5411\u4f20\u64ad \u00b6 \u5728\u6700\u540e\u6211\u4eec\u518d\u8be6\u7ec6\u8bf4\u4e0b\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u524d\u5411\u4f20\u64ad\u548c\u53cd\u5411\u4f20\u64ad\uff0c\u8fd9\u91cc\u7ee7\u7eed\u4f7f\u7528\u5434\u6069\u8fbe\u8001\u5e08\u7684\u677f\u4e66: \u6b63\u5411\u4f20\u64ad \u00b6 \u5bf9\u4e8e\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u6765\u8bf4\uff0c\u628a\u8f93\u5165\u7279\u5f81 a^{[0]} a^{[0]} \u8fd9\u4e2a\u8f93\u5165\u503c\u5c31\u662f\u6211\u4eec\u7684\u8f93\u5165 x x \uff0c\u653e\u5165\u7b2c\u4e00\u5c42\u5e76\u8ba1\u7b97\u7b2c\u4e00\u5c42\u7684\u6fc0\u6d3b\u51fd\u6570\uff0c\u7528 a^{[1]} a^{[1]} \u8868\u793a\uff0c\u672c\u5c42\u4e2d\u8bad\u7ec3\u7684\u7ed3\u679c\u7528 W^{[1]} W^{[1]} \u548c b^{[l]} b^{[l]} \u6765\u8868\u793a\uff0c\u8fd9\u4e24\u4e2a\u503c\u4e0e\uff0c\u8ba1\u7b97\u7684\u7ed3\u679c z^{[1]} z^{[1]} \u503c\u90fd\u9700\u8981\u8fdb\u884c\u7f13\u5b58\uff0c\u800c\u8ba1\u7b97\u7684\u7ed3\u679c\u8fd8\u9700\u8981\u901a\u8fc7\u6fc0\u6d3b\u51fd\u6570\u751f\u6210\u6fc0\u6d3b\u540e\u7684 a^{[1]} a^{[1]} ,\u5373\u7b2c\u4e00\u5c42\u7684\u8f93\u51fa\u503c\uff0c\u8fd9\u4e2a\u503c\u4f1a\u4f5c\u4e3a\u7b2c\u4e8c\u5c42\u7684\u8f93\u5165\u4f20\u5230\u7b2c\u4e8c\u5c42\uff0c\u7b2c\u4e8c\u5c42\u91cc\uff0c\u9700\u8981\u7528\u5230 W^{[2]} W^{[2]} \u548c b^{[2]} b^{[2]} \uff0c\u8ba1\u7b97\u7ed3\u679c\u4e3a z^{[2]} z^{[2]} \uff0c\u7b2c\u4e8c\u5c42\u7684\u6fc0\u6d3b\u51fd\u6570 a^{[2]} a^{[2]} \u3002 \u540e\u9762\u51e0\u5c42\u4ee5\u6b64\u7c7b\u63a8\uff0c\u76f4\u5230\u6700\u540e\u7b97\u51fa\u4e86 a^{[L]} a^{[L]} \uff0c\u7b2c L L \u5c42\u7684\u6700\u7ec8\u8f93\u51fa\u503c \\hat{y} \\hat{y} ,\u5373\u6211\u4eec\u7f51\u7edc\u7684\u9884\u6d4b\u503c\u3002\u6b63\u5411\u4f20\u64ad\u5176\u5b9e\u5c31\u662f\u6211\u4eec\u7684\u8f93\u5165 x x \u901a\u8fc7\u4e00\u7cfb\u5217\u7684\u7f51\u7edc\u8ba1\u7b97\uff0c\u5f97\u5230 \\hat{y} \\hat{y} \u7684\u8fc7\u7a0b\u3002 \u5728\u8fd9\u4e2a\u8fc7\u7a0b\u91cc\u6211\u4eec\u7f13\u5b58\u7684\u503c,\u4f1a\u5728\u540e\u9762\u7684\u53cd\u5411\u4f20\u64ad\u4e2d\u7528\u5230\u3002 \u53cd\u5411\u4f20\u64ad \u00b6 \u5bf9\u53cd\u5411\u4f20\u64ad\u7684\u6b65\u9aa4\u800c\u8a00\uff0c\u5c31\u662f\u5bf9\u6b63\u5411\u4f20\u64ad\u7684\u4e00\u7cfb\u5217\u7684\u53cd\u5411\u8fed\u4ee3\uff0c\u901a\u8fc7\u53cd\u5411\u8ba1\u7b97\u68af\u5ea6\uff0c\u6765\u4f18\u5316\u6211\u4eec\u9700\u8981\u8bad\u7ec3\u7684 W W \u548c b b \u3002 \u628a {\\delta}a^{[l]} {\\delta}a^{[l]} \u503c\u8fdb\u884c\u6c42\u5bfc\u5f97\u5230 {\\delta}a^{[l-1]} {\\delta}a^{[l-1]} \uff0c\u4ee5\u6b64\u7c7b\u63a8\uff0c\u76f4\u5230\u6211\u4eec\u5f97\u5230 {\\delta}a^{[2]} {\\delta}a^{[2]} \u548c {\\delta}a^{[1]} {\\delta}a^{[1]} \u3002\u53cd\u5411\u4f20\u64ad\u6b65\u9aa4\u4e2d\u4e5f\u4f1a\u8f93\u51fa {\\delta}W^{[l]} {\\delta}W^{[l]} \u548c {\\delta}b^{[l]} {\\delta}b^{[l]} \u3002\u8fd9\u4e00\u6b65\u6211\u4eec\u5df2\u7ecf\u5f97\u5230\u4e86\u6743\u91cd\u7684\u53d8\u5316\u91cf\uff0c\u4e0b\u9762\u6211\u4eec\u8981\u901a\u8fc7\u5b66\u4e60\u7387\u6765\u5bf9\u8bad\u7ec3\u7684 W W \u548c b b \u8fdb\u884c\u66f4\u65b0\uff0c W=W-\\alpha{\\delta}W W=W-\\alpha{\\delta}W b=b-\\alpha{\\delta}b b=b-\\alpha{\\delta}b \u8fd9\u6837\u53cd\u5411\u4f20\u64ad\u5c31\u5c31\u7b97\u662f\u5b8c\u6210\u4e86\ud83d\ude42","title":"2.3 Deep Learning Neural Network Introduction"},{"location":"tutorial/chapter02_basics/2_3_deep-learning-neural-network-introduction/#23","text":"\u76ee\u524d\u6700\u5e7f\u6cdb\u4f7f\u7528\u7684\u5b9a\u4e49\u662fKohonen\u4e8e1988\u5e74\u7684\u63cf\u8ff0\uff0c\u795e\u7ecf\u7f51\u7edc\u662f\u7531\u5177\u6709\u9002\u5e94\u6027\u7684\u7b80\u5355\u5355\u5143\u7ec4\u6210\u7684\u5e7f\u6cdb\u5e76\u884c\u4e92\u8fde\u7684\u7f51\u7edc\uff0c\u5b83\u7684\u7ec4\u7ec7\u80fd\u591f\u6a21\u62df\u751f\u7269\u795e\u7ecf\u7cfb\u7edf\u5bf9\u771f\u5b9e\u4e16\u754c\u7269\u4f53\u6240\u505a\u51fa\u7684\u4ea4\u4e92\u53cd\u5e94\u3002","title":"2.3 \u795e\u7ecf\u7f51\u7edc\u7b80\u4ecb"},{"location":"tutorial/chapter02_basics/2_3_deep-learning-neural-network-introduction/#_1","text":"\u5728\u751f\u7269\u795e\u7ecf\u7f51\u7edc\u4e2d\uff0c\u6bcf\u4e2a\u795e\u7ecf\u5143\u4e0e\u5176\u4ed6\u795e\u7ecf\u5143\u76f8\u8fde\uff0c\u5f53\u5b83\u5174\u594b\u65f6\uff0c\u5c31\u4f1a\u5411\u76f8\u8fde\u7684\u795e\u7ecf\u5143\u53d1\u9001\u5316\u5b66\u7269\u8d28\uff0c\u4ece\u800c\u6539\u53d8\u8fd9\u4e9b\u795e\u7ecf\u5143\u5185\u7684\u7535\u4f4d\uff1b\u5982\u679c\u67d0\u795e\u7ecf\u5143\u7684\u7535\u4f4d\u8d85\u8fc7\u4e86\u4e00\u4e2a\u9608\u503c\uff0c\u90a3\u4e48\u5b83\u5c31\u4f1a\u6fc0\u6d3b\uff0c\u5373\u5174\u594b\u8d77\u6765\u5e76\u5411\u5176\u4ed6\u795e\u7ecf\u5143\u53d1\u9001\u5316\u5b66\u7269\u8d28\u3002 \u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\u4e5f\u501f\u9274\u4e86\u8fd9\u6837\u7684\u7ed3\u6784,\u6bcf\u4e00\u4e2a\u795e\u7ecf\u5143\uff08\u4e0a\u9762\u8bf4\u5230\u7684\u7b80\u5355\u5355\u5143\uff09\u63a5\u53d7\u8f93\u5165x\uff0c\u901a\u8fc7\u5e26\u6743\u91cdw\u7684\u8fde\u63a5\u8fdb\u884c\u4f20\u9012\uff0c\u5c06\u603b\u8f93\u5165\u4fe1\u53f7\u4e0e\u795e\u7ecf\u5143\u7684\u9608\u503c\u8fdb\u884c\u6bd4\u8f83\uff0c\u6700\u540e\u901a\u8fc7\u6fc0\u6d3b\u51fd\u6570\u5904\u7406\u786e\u5b9a\u662f\u5426\u6fc0\u6d3b\uff0c\u5e76\u5c06\u6fc0\u6d3b\u540e\u7684\u8ba1\u7b97\u7ed3\u679cy\u8f93\u51fa,\u800c\u6211\u4eec\u6240\u8bf4\u7684\u8bad\u7ec3\uff0c\u6240\u8bad\u7ec3\u7684\u5c31\u662f\u8fd9\u91cc\u9762\u7684\u6743\u91cdw\u3002 \u53c2\u8003 \u6bcf\u4e00\u4e2a\u795e\u7ecf\u5143\u7684\u7ed3\u6784\u5982\u4e0b\uff1a \u6765\u6e90","title":"\u6982\u8ff0"},{"location":"tutorial/chapter02_basics/2_3_deep-learning-neural-network-introduction/#_2","text":"\u6211\u4eec\u53ef\u4ee5\u5c06\u795e\u7ecf\u5143\u62fc\u63a5\u8d77\u6765\uff0c\u4e24\u5c42\u795e\u7ecf\u5143\uff0c\u5373\u8f93\u5165\u5c42+\u8f93\u51fa\u5c42(M-P\u795e\u7ecf\u5143),\u6784\u6210\u611f\u77e5\u673a\u3002 \u800c\u591a\u5c42\u529f\u80fd\u795e\u7ecf\u5143\u76f8\u8fde\u6784\u6210\u795e\u7ecf\u7f51\u7edc\uff0c\u8f93\u5165\u5c42\u4e0e\u8f93\u51fa\u5c42\u4e4b\u95f4\u7684\u6240\u6709\u5c42\u795e\u7ecf\u5143\uff0c\u79f0\u4e3a\u9690\u85cf\u5c42\uff1a \u5982\u4e0a\u56fe\u6240\u793a\uff0c\u8f93\u5165\u5c42\u548c\u8f93\u51fa\u5c42\u53ea\u6709\u4e00\u4e2a\uff0c\u4e2d\u95f4\u7684\u9690\u85cf\u5c42\u53ef\u4ee5\u6709\u5f88\u591a\u5c42\uff08\u8f93\u51fa\u5c42\u4e5f\u53ef\u4ee5\u591a\u4e2a\uff0c\u4f8b\u5982\u7ecf\u5178\u7684GoogleNet\uff0c\u540e\u9762\u4f1a\u8be6\u7ec6\u4ecb\u7ecd\uff09","title":"\u795e\u7ecf\u7f51\u7edc\u7684\u8868\u793a"},{"location":"tutorial/chapter02_basics/2_3_deep-learning-neural-network-introduction/#_3","text":"\u4ecb\u7ecd\u795e\u7ecf\u7f51\u7edc\u7684\u65f6\u5019\u5df2\u7ecf\u8bf4\u5230\uff0c\u795e\u7ecf\u5143\u4f1a\u5bf9\u5316\u5b66\u7269\u8d28\u7684\u523a\u6fc0\u8fdb\u884c\uff0c\u5f53\u8fbe\u5230\u4e00\u5b9a\u7a0b\u5ea6\u7684\u65f6\u5019\uff0c\u795e\u7ecf\u5143\u624d\u4f1a\u5174\u594b\uff0c\u5e76\u5411\u5176\u4ed6\u795e\u7ecf\u5143\u53d1\u9001\u4fe1\u606f\u3002\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u6fc0\u6d3b\u51fd\u6570\u5c31\u662f\u7528\u6765\u5224\u65ad\u6211\u4eec\u6240\u8ba1\u7b97\u7684\u4fe1\u606f\u662f\u5426\u8fbe\u5230\u4e86\u5f80\u540e\u9762\u4f20\u8f93\u7684\u6761\u4ef6\u3002","title":"\u6fc0\u6d3b\u51fd\u6570"},{"location":"tutorial/chapter02_basics/2_3_deep-learning-neural-network-introduction/#_4","text":"\u5728\u795e\u7ecf\u7f51\u7edc\u7684\u8ba1\u7b97\u8fc7\u7a0b\u4e2d\uff0c\u6bcf\u5c42\u90fd\u76f8\u5f53\u4e8e\u77e9\u9635\u76f8\u4e58\uff0c\u65e0\u8bba\u795e\u7ecf\u7f51\u7edc\u6709\u591a\u5c11\u5c42\u8f93\u51fa\u90fd\u662f\u8f93\u5165\u7684\u7ebf\u6027\u7ec4\u5408\uff0c\u5c31\u7b97\u6211\u4eec\u6709\u51e0\u5343\u5c42\u7684\u8ba1\u7b97\uff0c\u65e0\u975e\u8fd8\u662f\u4e2a\u77e9\u9635\u76f8\u4e58\uff0c\u548c\u4e00\u5c42\u77e9\u9635\u76f8\u4e58\u6240\u83b7\u5f97\u7684\u4fe1\u606f\u5dee\u8ddd\u4e0d\u5927\uff0c\u6240\u4ee5\u9700\u8981\u6fc0\u6d3b\u51fd\u6570\u6765\u5f15\u5165\u975e\u7ebf\u6027\u56e0\u7d20\uff0c\u4f7f\u5f97\u795e\u7ecf\u7f51\u7edc\u53ef\u4ee5\u4efb\u610f\u903c\u8fd1\u4efb\u4f55\u975e\u7ebf\u6027\u51fd\u6570\uff0c\u8fd9\u6837\u795e\u7ecf\u7f51\u7edc\u5c31\u53ef\u4ee5\u5e94\u7528\u5230\u4f17\u591a\u7684\u975e\u7ebf\u6027\u6a21\u578b\u4e2d\uff0c\u589e\u52a0\u4e86\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u6cdb\u5316\u7684\u7279\u6027\u3002 \u65e9\u671f\u7814\u7a76\u795e\u7ecf\u7f51\u7edc\u4e3b\u8981\u91c7\u7528sigmoid\u51fd\u6570\u6216\u8005tanh\u51fd\u6570\uff0c\u8f93\u51fa\u6709\u754c\uff0c\u5f88\u5bb9\u6613\u5145\u5f53\u4e0b\u4e00\u5c42\u7684\u8f93\u5165\u3002 \u8fd1\u4e9b\u5e74Relu\u51fd\u6570\u53ca\u5176\u6539\u8fdb\u578b\uff08\u5982Leaky-ReLU\u3001P-ReLU\u3001R-ReLU\u7b49\uff09\uff0c\u7531\u4e8e\u8ba1\u7b97\u7b80\u5355\u3001\u6548\u679c\u597d\u6240\u4ee5\u5728\u591a\u5c42\u795e\u7ecf\u7f51\u7edc\u4e2d\u5e94\u7528\u6bd4\u8f83\u591a\u3002 \u4e0b\u9762\u6765\u603b\u7ed3\u4e0b\u8f83\u5e38\u89c1\u7684\u6fc0\u6d3b\u51fd\u6570\uff1a # \u521d\u59cb\u5316\u4e00\u4e9b\u4fe1\u606f import torch import torch.nn.functional as F import matplotlib.pyplot as plt import numpy as np x = torch . linspace ( - 10 , 10 , 60 )","title":"\u4e3a\u4ec0\u4e48\u6fc0\u6d3b\u51fd\u6570\u90fd\u662f\u975e\u7ebf\u6027\u7684"},{"location":"tutorial/chapter02_basics/2_3_deep-learning-neural-network-introduction/#sigmod","text":"a=\\frac{1}{1+e^{-z}} a=\\frac{1}{1+e^{-z}} \u5bfc\u6570 \uff1a$$ a^\\prime =a(1 - a) $$ \u5728sigmod\u51fd\u6570\u4e2d\u6211\u4eec\u53ef\u4ee5\u770b\u5230\uff0c\u5176\u8f93\u51fa\u662f\u5728(0,1)\u8fd9\u4e2a\u5f00\u533a\u95f4,\u5b83\u80fd\u591f\u628a\u8f93\u5165\u7684\u8fde\u7eed\u5b9e\u503c\u53d8\u6362\u4e3a0\u548c1\u4e4b\u95f4\u7684\u8f93\u51fa\uff0c\u5982\u679c\u662f\u975e\u5e38\u5927\u7684\u8d1f\u6570\uff0c\u90a3\u4e48\u8f93\u51fa\u5c31\u662f0\uff1b\u5982\u679c\u662f\u975e\u5e38\u5927\u7684\u6b63\u6570\u8f93\u51fa\u5c31\u662f1\uff0c\u8d77\u5230\u4e86\u6291\u5236\u7684\u4f5c\u7528\u3002 ax = plt . gca () ax . spines [ 'right' ] . set_color ( 'none' ) ax . spines [ 'top' ] . set_color ( 'none' ) ax . xaxis . set_ticks_position ( 'bottom' ) ax . spines [ 'bottom' ] . set_position (( 'data' , 0 )) ax . yaxis . set_ticks_position ( 'left' ) ax . spines [ 'left' ] . set_position (( 'data' , 0 )) plt . ylim (( 0 , 1 )) sigmod = torch . sigmoid ( x ) plt . plot ( x . numpy (), sigmod . numpy ()) [<matplotlib.lines.Line2D at 0x2ad8aa2b9b0>] \u4f46\u662fsigmod\u7531\u4e8e\u9700\u8981\u8fdb\u884c\u6307\u6570\u8fd0\u7b97\uff08\u8fd9\u4e2a\u5bf9\u4e8e\u8ba1\u7b97\u673a\u6765\u8bf4\u662f\u6bd4\u8f83\u6162\uff0c\u76f8\u6bd4relu\uff09\uff0c\u518d\u52a0\u4e0a\u51fd\u6570\u8f93\u51fa\u4e0d\u662f\u4ee50\u4e3a\u4e2d\u5fc3\u7684\uff08\u8fd9\u6837\u4f1a\u4f7f\u6743\u91cd\u66f4\u65b0\u6548\u7387\u964d\u4f4e\uff09\uff0c\u5f53\u8f93\u5165\u7a0d\u5fae\u8fdc\u79bb\u4e86\u5750\u6807\u539f\u70b9\uff0c\u51fd\u6570\u7684\u68af\u5ea6\u5c31\u53d8\u5f97\u5f88\u5c0f\u4e86\uff08\u51e0\u4e4e\u4e3a\u96f6\uff09\u3002\u5728\u795e\u7ecf\u7f51\u7edc\u53cd\u5411\u4f20\u64ad\u7684\u8fc7\u7a0b\u4e2d\u4e0d\u5229\u4e8e\u6743\u91cd\u7684\u4f18\u5316\uff0c\u8fd9\u4e2a\u95ee\u9898\u53eb\u505a\u68af\u5ea6\u9971\u548c\uff0c\u4e5f\u53ef\u4ee5\u53eb\u68af\u5ea6\u5f25\u6563\u3002\u8fd9\u4e9b\u4e0d\u8db3\uff0c\u6240\u4ee5\u73b0\u5728\u4f7f\u7528\u5230sigmod\u57fa\u672c\u5f88\u5c11\u4e86\uff0c\u57fa\u672c\u4e0a\u53ea\u6709\u5728\u505a\u4e8c\u5143\u5206\u7c7b\uff080\uff0c1\uff09\u65f6\u7684\u8f93\u51fa\u5c42\u624d\u4f1a\u4f7f\u7528\u3002","title":"sigmod \u51fd\u6570"},{"location":"tutorial/chapter02_basics/2_3_deep-learning-neural-network-introduction/#tanh","text":"a=\\frac{e^z-e^{-z}}{e^z+e^{-z}} a=\\frac{e^z-e^{-z}}{e^z+e^{-z}} \u5bfc\u6570\uff1a$$ a^\\prime =1 - a^2 $$ tanh\u662f\u53cc\u66f2\u6b63\u5207\u51fd\u6570,\u8f93\u51fa\u533a\u95f4\u662f\u5728(-1,1)\u4e4b\u95f4\uff0c\u800c\u4e14\u6574\u4e2a\u51fd\u6570\u662f\u4ee50\u4e3a\u4e2d\u5fc3\u7684: ax = plt . gca () ax . spines [ 'right' ] . set_color ( 'none' ) ax . spines [ 'top' ] . set_color ( 'none' ) ax . xaxis . set_ticks_position ( 'bottom' ) ax . spines [ 'bottom' ] . set_position (( 'data' , 0 )) ax . yaxis . set_ticks_position ( 'left' ) ax . spines [ 'left' ] . set_position (( 'data' , 0 )) plt . ylim (( - 1 , 1 )) tanh = torch . tanh ( x ) plt . plot ( x . numpy (), tanh . numpy ()) [<matplotlib.lines.Line2D at 0x2ad8ab67cc0>] \u4e0esigmoid\u51fd\u6570\u7c7b\u4f3c\uff0c\u5f53\u8f93\u5165\u7a0d\u5fae\u8fdc\u79bb\u4e86\u5750\u6807\u539f\u70b9\uff0c\u68af\u5ea6\u8fd8\u662f\u4f1a\u5f88\u5c0f\uff0c\u4f46\u662f\u597d\u5728tanh\u662f\u4ee50\u4e3a\u4e2d\u5fc3\u70b9\uff0c\u5982\u679c\u4f7f\u7528tanh\u4f5c\u4e3a\u6fc0\u6d3b\u51fd\u6570\uff0c\u8fd8\u80fd\u8d77\u5230\u5f52\u4e00\u5316\uff08\u5747\u503c\u4e3a0\uff09\u7684\u6548\u679c\u3002 \u4e00\u822c\u4e8c\u5206\u7c7b\u95ee\u9898\u4e2d\uff0c\u9690\u85cf\u5c42\u7528tanh\u51fd\u6570\uff0c\u8f93\u51fa\u5c42\u7528sigmod\u51fd\u6570\uff0c\u4f46\u662f\u968f\u7740Relu\u7684\u51fa\u73b0\u6240\u6709\u7684\u9690\u85cf\u5c42\u57fa\u672c\u4e0a\u90fd\u4f7f\u7528relu\u6765\u4f5c\u4e3a\u6fc0\u6d3b\u51fd\u6570\u4e86","title":"tanh \u51fd\u6570"},{"location":"tutorial/chapter02_basics/2_3_deep-learning-neural-network-introduction/#relu","text":"Relu\uff08Rectified Linear Units\uff09\u4fee\u6b63\u7ebf\u6027\u5355\u5143 $$ a=max(0,z) $$ \u5bfc\u6570\u5927\u4e8e0\u65f61\uff0c\u5c0f\u4e8e0\u65f60\u3002 \u4e5f\u5c31\u662f\u8bf4\uff1a z>0\u65f6\uff0c\u68af\u5ea6\u59cb\u7ec8\u4e3a1\uff0c\u4ece\u800c\u63d0\u9ad8\u795e\u7ecf\u7f51\u7edc\u57fa\u4e8e\u68af\u5ea6\u7b97\u6cd5\u7684\u8fd0\u7b97\u901f\u5ea6\u3002\u7136\u800c\u5f53 z<0\u65f6\uff0c\u68af\u5ea6\u4e00\u76f4\u4e3a0\u3002 ReLU\u51fd\u6570\u53ea\u6709\u7ebf\u6027\u5173\u7cfb\uff08\u53ea\u9700\u8981\u5224\u65ad\u8f93\u5165\u662f\u5426\u5927\u4e8e0\uff09\u4e0d\u7ba1\u662f\u524d\u5411\u4f20\u64ad\u8fd8\u662f\u53cd\u5411\u4f20\u64ad\uff0c\u90fd\u6bd4sigmod\u548ctanh\u8981\u5feb\u5f88\u591a\uff0c ax = plt . gca () ax . spines [ 'right' ] . set_color ( 'none' ) ax . spines [ 'top' ] . set_color ( 'none' ) ax . xaxis . set_ticks_position ( 'bottom' ) ax . spines [ 'bottom' ] . set_position (( 'data' , 0 )) ax . yaxis . set_ticks_position ( 'left' ) ax . spines [ 'left' ] . set_position (( 'data' , 0 )) plt . ylim (( - 3 , 10 )) relu = F . relu ( x ) plt . plot ( x . numpy (), relu . numpy ()) [<matplotlib.lines.Line2D at 0x2ad8b097470>] \u5f53\u8f93\u5165\u662f\u8d1f\u6570\u7684\u65f6\u5019\uff0cReLU\u662f\u5b8c\u5168\u4e0d\u88ab\u6fc0\u6d3b\u7684\uff0c\u8fd9\u5c31\u8868\u660e\u4e00\u65e6\u8f93\u5165\u5230\u4e86\u8d1f\u6570\uff0cReLU\u5c31\u4f1a\u6b7b\u6389\u3002\u4f46\u662f\u5230\u4e86\u53cd\u5411\u4f20\u64ad\u8fc7\u7a0b\u4e2d\uff0c\u8f93\u5165\u8d1f\u6570\uff0c\u68af\u5ea6\u5c31\u4f1a\u5b8c\u5168\u52300\uff0c\u8fd9\u4e2a\u548csigmod\u51fd\u6570\u3001tanh\u51fd\u6570\u6709\u4e00\u6837\u7684\u95ee\u9898\u3002 \u4f46\u662f\u5b9e\u9645\u7684\u8fd0\u7528\u4e2d\uff0c\u8be5\u7f3a\u9677\u7684\u5f71\u54cd\u4e0d\u662f\u5f88\u5927\u3002","title":"ReLU \u51fd\u6570"},{"location":"tutorial/chapter02_basics/2_3_deep-learning-neural-network-introduction/#leaky-relu","text":"\u4e3a\u4e86\u89e3\u51b3relu\u51fd\u6570z<0\u65f6\u7684\u95ee\u9898\u51fa\u73b0\u4e86 Leaky ReLU\u51fd\u6570\uff0c\u8be5\u51fd\u6570\u4fdd\u8bc1\u5728z<0\u7684\u65f6\u5019\uff0c\u68af\u5ea6\u4ecd\u7136\u4e0d\u4e3a0\u3002 ReLU\u7684\u524d\u534a\u6bb5\u8bbe\u4e3a\u03b1z\u800c\u975e0\uff0c\u901a\u5e38\u03b1=0.01 $$ a=max(\\alpha z,z) $$ ax = plt . gca () ax . spines [ 'right' ] . set_color ( 'none' ) ax . spines [ 'top' ] . set_color ( 'none' ) ax . xaxis . set_ticks_position ( 'bottom' ) ax . spines [ 'bottom' ] . set_position (( 'data' , 0 )) ax . yaxis . set_ticks_position ( 'left' ) ax . spines [ 'left' ] . set_position (( 'data' , 0 )) plt . ylim (( - 3 , 10 )) l_relu = F . leaky_relu ( x , 0.1 ) # \u8fd9\u91cc\u76840.1\u662f\u4e3a\u4e86\u65b9\u4fbf\u5c55\u793a\uff0c\u7406\u8bba\u4e0a\u5e94\u4e3a0.01\u751a\u81f3\u66f4\u5c0f\u7684\u503c plt . plot ( x . numpy (), l_relu . numpy ()) [<matplotlib.lines.Line2D at 0x2ad8b0bd3c8>] \u7406\u8bba\u4e0a\u6765\u8bb2\uff0cLeaky ReLU\u6709ReLU\u7684\u6240\u6709\u4f18\u70b9\uff0c\u4f46\u662f\u5728\u5b9e\u9645\u64cd\u4f5c\u5f53\u4e2d\uff0c\u5e76\u6ca1\u6709\u5b8c\u5168\u8bc1\u660eLeaky ReLU\u603b\u662f\u597d\u4e8eReLU\u3002 ReLU\u76ee\u524d\u4ecd\u662f\u6700\u5e38\u7528\u7684activation function\uff0c\u5728\u9690\u85cf\u5c42\u4e2d\u63a8\u8350\u4f18\u5148\u5c1d\u8bd5\uff01","title":"Leaky Relu \u51fd\u6570"},{"location":"tutorial/chapter02_basics/2_3_deep-learning-neural-network-introduction/#_5","text":"\u5728\u6700\u540e\u6211\u4eec\u518d\u8be6\u7ec6\u8bf4\u4e0b\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u524d\u5411\u4f20\u64ad\u548c\u53cd\u5411\u4f20\u64ad\uff0c\u8fd9\u91cc\u7ee7\u7eed\u4f7f\u7528\u5434\u6069\u8fbe\u8001\u5e08\u7684\u677f\u4e66:","title":"\u6df1\u5165\u7406\u89e3\u524d\u5411\u4f20\u64ad\u548c\u53cd\u5411\u4f20\u64ad"},{"location":"tutorial/chapter02_basics/2_3_deep-learning-neural-network-introduction/#_6","text":"\u5bf9\u4e8e\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u6765\u8bf4\uff0c\u628a\u8f93\u5165\u7279\u5f81 a^{[0]} a^{[0]} \u8fd9\u4e2a\u8f93\u5165\u503c\u5c31\u662f\u6211\u4eec\u7684\u8f93\u5165 x x \uff0c\u653e\u5165\u7b2c\u4e00\u5c42\u5e76\u8ba1\u7b97\u7b2c\u4e00\u5c42\u7684\u6fc0\u6d3b\u51fd\u6570\uff0c\u7528 a^{[1]} a^{[1]} \u8868\u793a\uff0c\u672c\u5c42\u4e2d\u8bad\u7ec3\u7684\u7ed3\u679c\u7528 W^{[1]} W^{[1]} \u548c b^{[l]} b^{[l]} \u6765\u8868\u793a\uff0c\u8fd9\u4e24\u4e2a\u503c\u4e0e\uff0c\u8ba1\u7b97\u7684\u7ed3\u679c z^{[1]} z^{[1]} \u503c\u90fd\u9700\u8981\u8fdb\u884c\u7f13\u5b58\uff0c\u800c\u8ba1\u7b97\u7684\u7ed3\u679c\u8fd8\u9700\u8981\u901a\u8fc7\u6fc0\u6d3b\u51fd\u6570\u751f\u6210\u6fc0\u6d3b\u540e\u7684 a^{[1]} a^{[1]} ,\u5373\u7b2c\u4e00\u5c42\u7684\u8f93\u51fa\u503c\uff0c\u8fd9\u4e2a\u503c\u4f1a\u4f5c\u4e3a\u7b2c\u4e8c\u5c42\u7684\u8f93\u5165\u4f20\u5230\u7b2c\u4e8c\u5c42\uff0c\u7b2c\u4e8c\u5c42\u91cc\uff0c\u9700\u8981\u7528\u5230 W^{[2]} W^{[2]} \u548c b^{[2]} b^{[2]} \uff0c\u8ba1\u7b97\u7ed3\u679c\u4e3a z^{[2]} z^{[2]} \uff0c\u7b2c\u4e8c\u5c42\u7684\u6fc0\u6d3b\u51fd\u6570 a^{[2]} a^{[2]} \u3002 \u540e\u9762\u51e0\u5c42\u4ee5\u6b64\u7c7b\u63a8\uff0c\u76f4\u5230\u6700\u540e\u7b97\u51fa\u4e86 a^{[L]} a^{[L]} \uff0c\u7b2c L L \u5c42\u7684\u6700\u7ec8\u8f93\u51fa\u503c \\hat{y} \\hat{y} ,\u5373\u6211\u4eec\u7f51\u7edc\u7684\u9884\u6d4b\u503c\u3002\u6b63\u5411\u4f20\u64ad\u5176\u5b9e\u5c31\u662f\u6211\u4eec\u7684\u8f93\u5165 x x \u901a\u8fc7\u4e00\u7cfb\u5217\u7684\u7f51\u7edc\u8ba1\u7b97\uff0c\u5f97\u5230 \\hat{y} \\hat{y} \u7684\u8fc7\u7a0b\u3002 \u5728\u8fd9\u4e2a\u8fc7\u7a0b\u91cc\u6211\u4eec\u7f13\u5b58\u7684\u503c,\u4f1a\u5728\u540e\u9762\u7684\u53cd\u5411\u4f20\u64ad\u4e2d\u7528\u5230\u3002","title":"\u6b63\u5411\u4f20\u64ad"},{"location":"tutorial/chapter02_basics/2_3_deep-learning-neural-network-introduction/#_7","text":"\u5bf9\u53cd\u5411\u4f20\u64ad\u7684\u6b65\u9aa4\u800c\u8a00\uff0c\u5c31\u662f\u5bf9\u6b63\u5411\u4f20\u64ad\u7684\u4e00\u7cfb\u5217\u7684\u53cd\u5411\u8fed\u4ee3\uff0c\u901a\u8fc7\u53cd\u5411\u8ba1\u7b97\u68af\u5ea6\uff0c\u6765\u4f18\u5316\u6211\u4eec\u9700\u8981\u8bad\u7ec3\u7684 W W \u548c b b \u3002 \u628a {\\delta}a^{[l]} {\\delta}a^{[l]} \u503c\u8fdb\u884c\u6c42\u5bfc\u5f97\u5230 {\\delta}a^{[l-1]} {\\delta}a^{[l-1]} \uff0c\u4ee5\u6b64\u7c7b\u63a8\uff0c\u76f4\u5230\u6211\u4eec\u5f97\u5230 {\\delta}a^{[2]} {\\delta}a^{[2]} \u548c {\\delta}a^{[1]} {\\delta}a^{[1]} \u3002\u53cd\u5411\u4f20\u64ad\u6b65\u9aa4\u4e2d\u4e5f\u4f1a\u8f93\u51fa {\\delta}W^{[l]} {\\delta}W^{[l]} \u548c {\\delta}b^{[l]} {\\delta}b^{[l]} \u3002\u8fd9\u4e00\u6b65\u6211\u4eec\u5df2\u7ecf\u5f97\u5230\u4e86\u6743\u91cd\u7684\u53d8\u5316\u91cf\uff0c\u4e0b\u9762\u6211\u4eec\u8981\u901a\u8fc7\u5b66\u4e60\u7387\u6765\u5bf9\u8bad\u7ec3\u7684 W W \u548c b b \u8fdb\u884c\u66f4\u65b0\uff0c W=W-\\alpha{\\delta}W W=W-\\alpha{\\delta}W b=b-\\alpha{\\delta}b b=b-\\alpha{\\delta}b \u8fd9\u6837\u53cd\u5411\u4f20\u64ad\u5c31\u5c31\u7b97\u662f\u5b8c\u6210\u4e86\ud83d\ude42","title":"\u53cd\u5411\u4f20\u64ad"},{"location":"tutorial/chapter02_basics/2_4_convolutional-neural-network/","text":"import torch torch . __version__ '1.0.0' 2.4 \u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7b80\u4ecb \u00b6 \u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7531\u4e00\u4e2a\u6216\u591a\u4e2a\u5377\u79ef\u5c42\u548c\u9876\u7aef\u7684\u5168\u8fde\u901a\u5c42\uff08\u4e5f\u53ef\u4ee5\u4f7f\u75281x1\u7684\u5377\u79ef\u5c42\u4f5c\u4e3a\u6700\u7ec8\u7684\u8f93\u51fa\uff09\u7ec4\u6210\u4e00\u79cd\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u3002\u4e00\u822c\u7684\u8ba4\u4e3a\uff0c\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u662f\u7531Yann LeCun\u5927\u795e\u57281989\u5e74\u63d0\u51fa\u7684LeNet\u4e2d\u9996\u5148\u88ab\u4f7f\u7528\uff0c\u4f46\u662f\u7531\u4e8e\u5f53\u65f6\u7684\u8ba1\u7b97\u80fd\u529b\u4e0d\u591f\uff0c\u5e76\u6ca1\u6709\u5f97\u5230\u5e7f\u6cdb\u7684\u5e94\u7528\uff0c\u5230\u4e861998\u5e74Yann LeCun\u53ca\u5176\u5408\u4f5c\u8005\u6784\u5efa\u4e86\u66f4\u52a0\u5b8c\u5907\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edcLeNet-5\u5e76\u5728\u624b\u5199\u6570\u5b57\u7684\u8bc6\u522b\u95ee\u9898\u4e2d\u53d6\u5f97\u6210\u529f\uff0cLeNet-5\u7684\u6210\u529f\u4f7f\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u5e94\u7528\u5f97\u5230\u5173\u6ce8\u3002LeNet-5\u6cbf\u7528\u4e86LeCun (1989) \u7684\u5b66\u4e60\u7b56\u7565\u5e76\u5728\u539f\u6709\u8bbe\u8ba1\u4e2d\u52a0\u5165\u4e86\u6c60\u5316\u5c42\u5bf9\u8f93\u5165\u7279\u5f81\u8fdb\u884c\u7b5b\u9009 \u3002LeNet-5\u57fa\u672c\u4e0a\u5b9a\u4e49\u4e86\u73b0\u4ee3\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u57fa\u672c\u7ed3\u6784\uff0c\u5176\u6784\u7b51\u4e2d\u4ea4\u66ff\u51fa\u73b0\u7684\u5377\u79ef\u5c42-\u6c60\u5316\u5c42\u88ab\u8ba4\u4e3a\u6709\u6548\u63d0\u53d6\u4e86\u8f93\u5165\u56fe\u50cf\u7684\u5e73\u79fb\u4e0d\u53d8\u7279\u5f81\uff0c\u4f7f\u5f97\u5bf9\u4e8e\u7279\u5f81\u7684\u63d0\u53d6\u524d\u8fdb\u4e86\u4e00\u5927\u6b65\uff0c\u6240\u4ee5\u6211\u4eec\u4e00\u822c\u7684\u8ba4\u4e3a\uff0cYann LeCun\u662f\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u521b\u59cb\u4eba\u3002 2006\u5e74\u540e\uff0c\u968f\u7740\u6df1\u5ea6\u5b66\u4e60\u7406\u8bba\u7684\u5b8c\u5584\uff0c\u5c24\u5176\u662f\u8ba1\u7b97\u80fd\u529b\u7684\u63d0\u5347\u548c\u53c2\u6570\u5fae\u8c03\uff08fine-tuning\uff09\u7b49\u6280\u672f\u7684\u51fa\u73b0\uff0c\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5f00\u59cb\u5feb\u901f\u53d1\u5c55\uff0c\u5728\u7ed3\u6784\u4e0a\u4e0d\u65ad\u52a0\u6df1\uff0c\u5404\u7c7b\u5b66\u4e60\u548c\u4f18\u5316\u7406\u8bba\u5f97\u5230\u5f15\u5165\uff0c2012\u5e74\u7684AlexNet\u30012014\u5e74\u7684VGGNet\u3001GoogLeNet \u548c2015\u5e74\u7684ResNet,\u4f7f\u5f97\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u51e0\u4e4e\u6210\u4e3a\u4e86\u6df1\u5ea6\u5b66\u4e60\u4e2d\u56fe\u50cf\u5904\u7406\u65b9\u9762\u7684\u6807\u914d\u3002 2.4.1 \u4e3a\u4ec0\u4e48\u8981\u7528\u5377\u79ef\u795e\u7ecf\u7f51\u7edc \u00b6 \u5bf9\u4e8e\u8ba1\u7b97\u673a\u89c6\u89c9\u6765\u8bf4\uff0c\u6bcf\u4e00\u4e2a\u56fe\u50cf\u662f\u7531\u4e00\u4e2a\u4e2a\u50cf\u7d20\u70b9\u6784\u6210\uff0c\u6bcf\u4e2a\u50cf\u7d20\u70b9\u6709\u4e09\u4e2a\u901a\u9053\uff0c\u5206\u522b\u4ee3\u8868RGB\u4e09\u79cd\u989c\u8272(\u4e0d\u8ba1\u7b97\u900f\u660e\u5ea6)\uff0c\u6211\u4eec\u4ee5\u624b\u5199\u8bc6\u522b\u7684\u6570\u636e\u4f60MNIST\u4e3e\u4f8b\uff0c\u6bcf\u4e2a\u56fe\u50cf\u7684\u662f\u4e00\u4e2a\u957f\u5bbd\u5747\u4e3a28\uff0cchannel\u4e3a1\u7684\u5355\u8272\u56fe\u50cf\uff0c\u5982\u679c\u4f7f\u7528\u5168\u8fde\u63a5\u7684\u7f51\u7edc\u7ed3\u6784\uff0c\u5373\uff0c\u7f51\u7edc\u4e2d\u7684\u795e\u7ecf\u4e0e\u76f8\u90bb\u5c42\u4e0a\u7684\u6bcf\u4e2a\u795e\u7ecf\u5143\u5747\u8fde\u63a5\uff0c\u90a3\u5c31\u610f\u5473\u7740\u6211\u4eec\u7684\u7f51\u7edc\u670928 * 28 =784\u4e2a\u795e\u7ecf\u5143\uff08RGB3\u8272\u7684\u8bdd\u8fd8\u8981*3\uff09\uff0chidden\u5c42\u5982\u679c\u4f7f\u7528\u4e8615\u4e2a\u795e\u7ecf\u5143\uff0c\u9700\u8981\u7684\u53c2\u6570\u4e2a\u6570(w\u548cb)\u5c31\u6709\uff1a28 * 28 * 15 * 10 + 15 + 10=117625\u4e2a\uff0c\u8fd9\u4e2a\u6570\u91cf\u7ea7\u5230\u73b0\u5728\u4e3a\u6b62\u4e5f\u662f\u4e00\u4e2a\u5f88\u6050\u6016\u7684\u6570\u91cf\u7ea7\uff0c\u4e00\u6b21\u53cd\u5411\u4f20\u64ad\u8ba1\u7b97\u91cf\u90fd\u662f\u5de8\u5927\u7684\uff0c\u8fd9\u8fd8\u5c55\u793a\u4e00\u4e2a\u5355\u8272\u768428\u50cf\u7d20\u5927\u5c0f\u7684\u56fe\u7247\uff0c\u5982\u679c\u6211\u4eec\u4f7f\u7528\u66f4\u5927\u7684\u50cf\u7d20\uff0c\u8ba1\u7b97\u91cf\u53ef\u60f3\u800c\u77e5\u3002 2.4.2\u7ed3\u6784\u7ec4\u6210 \u00b6 \u4e0a\u9762\u8bf4\u5230\u4f20\u7edf\u7684\u7f51\u7edc\u9700\u8981\u5927\u91cf\u7684\u53c2\u6570\uff0c\u4f46\u662f\u8fd9\u4e9b\u53c2\u6570\u662f\u5426\u91cd\u590d\u4e86\u5462\uff0c\u4f8b\u5982\uff0c\u6211\u4eec\u8bc6\u522b\u4e00\u4e2a\u4eba\uff0c\u53ea\u8981\u770b\u5230\u4ed6\u7684\u773c\u775b\uff0c\u9f3b\u5b50\uff0c\u5634\uff0c\u8fd8\u6709\u8138\u57fa\u672c\u4e0a\u5c31\u77e5\u9053\u8fd9\u4e2a\u4eba\u662f\u8c01\u4e86\uff0c\u53ea\u662f\u7528\u8fd9\u4e9b\u5c40\u90e8\u7684\u7279\u5f81\u5c31\u80fd\u505a\u505a\u5224\u65ad\u4e86\uff0c\u5e76\u4e0d\u9700\u8981\u6240\u6709\u7684\u7279\u5f81\u3002 \u53e6\u5916\u4e00\u70b9\u5c31\u662f\u6211\u4eec\u4e0a\u9762\u8bf4\u7684\u53ef\u4ee5\u6709\u6548\u63d0\u53d6\u4e86\u8f93\u5165\u56fe\u50cf\u7684\u5e73\u79fb\u4e0d\u53d8\u7279\u5f81\uff0c\u5c31\u597d\u50cf\u6211\u4eec\u770b\u5230\u4e86\u8fd9\u662f\u4e2a\u773c\u775b\uff0c\u8fd9\u4e2a\u773c\u955c\u5728\u5de6\u8fb9\u8fd8\u662f\u5728\u53f3\u8fb9\u4ed6\u90fd\u662f\u773c\u775b\uff0c\u8fd9\u5c31\u662f\u5e73\u79fb\u4e0d\u53d8\u6027\u3002 \u6211\u4eec\u901a\u8fc7\u5377\u79ef\u7684\u8ba1\u7b97\u64cd\u4f5c\u6765\u63d0\u53d6\u56fe\u50cf\u5c40\u90e8\u7684\u7279\u5f81\uff0c\u6bcf\u4e00\u5c42\u90fd\u4f1a\u8ba1\u7b97\u51fa\u4e00\u4e9b\u5c40\u90e8\u7279\u5f81\uff0c\u8fd9\u4e9b\u5c40\u90e8\u7279\u5f81\u518d\u6c47\u603b\u5230\u4e0b\u4e00\u5c42\uff0c\u8fd9\u6837\u4e00\u5c42\u4e00\u5c42\u7684\u4f20\u9012\u4e0b\u53bb\uff0c\u7279\u5f81\u7531\u5c0f\u53d8\u5927\uff0c\u6700\u540e\u5728\u901a\u8fc7\u8fd9\u4e9b\u5c40\u90e8\u7684\u7279\u5f81\u5bf9\u56fe\u7247\u8fdb\u884c\u5904\u7406\uff0c\u8fd9\u6837\u5927\u5927\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u4e5f\u63d0\u9ad8\u4e86\u51c6\u786e\u5ea6\u3002 \u5377\u79ef\u5c42 \u00b6 \u5377\u79ef\u8ba1\u7b97 \u00b6 \u5728\u4ecb\u7ecd\u5377\u79ef\u5c42\u4e4b\u524d\u8981\u5148\u4ecb\u7ecd\u4e00\u4e0b\u5377\u79ef\u7684\u8ba1\u7b97\uff0c\u8fd9\u91cc\u4f7f\u7528 \u77e5\u4e4e \u4e0a\u7684\u4e00\u5f20\u56fe\u7247: \u6211\u4eec\u4f1a\u5b9a\u4e49\u4e00\u4e2a\u6743\u91cd\u77e9\u9635\uff0c\u4e5f\u5c31\u662f\u6211\u4eec\u8bf4\u7684W\uff08\u4e00\u822c\u5bf9\u4e8e\u5377\u79ef\u6765\u8bf4\uff0c\u79f0\u4f5c\u5377\u79ef\u7684\u6838kernel\u4e5f\u6709\u6709\u4eba\u79f0\u505a\u8fc7\u6ee4\u5668filter\uff09\uff0c\u8fd9\u4e2a\u6743\u91cd\u77e9\u9635\u7684\u5927\u5c0f\u4e00\u822c\u4e3a 3 * 3 \u6216\u8005 5 * 5 \uff0c\u4f46\u662f\u5728LeNet\u91cc\u9762\u8fd8\u7528\u5230\u4e86\u6bd4\u8f83\u5927\u7684 7 * 7 \uff0c\u73b0\u5728\u5df2\u7ecf\u5f88\u5c11\u89c1\u4e86\uff0c\u56e0\u4e3a\u6839\u636e\u7ecf\u9a8c\u7684\u9a8c\u8bc1\uff0c3\u548c5\u662f\u6700\u4f73\u7684\u5927\u5c0f\u3002 \u6211\u4eec\u4ee5\u56fe\u4e0a\u6240\u793a\u7684\u65b9\u5f0f\uff0c\u6211\u4eec\u5728\u8f93\u5165\u77e9\u9635\u4e0a\u4f7f\u7528\u6211\u4eec\u7684\u6743\u91cd\u77e9\u9635\u8fdb\u884c\u6ed1\u52a8\uff0c\u6bcf\u6ed1\u52a8\u4e00\u6b65\uff0c\u5c06\u6240\u8986\u76d6\u7684\u503c\u4e0e\u77e9\u9635\u5bf9\u5e94\u7684\u503c\u76f8\u4e58\uff0c\u5e76\u5c06\u7ed3\u679c\u6c42\u548c\u5e76\u4f5c\u4e3a\u8f93\u51fa\u77e9\u9635\u7684\u4e00\u9879\uff0c\u4f9d\u6b21\u7c7b\u63a8\u76f4\u5230\u5168\u90e8\u8ba1\u7b97\u5b8c\u6210\u3002 \u4e0a\u56fe\u6240\u793a\uff0c\u6211\u4eec\u8f93\u5165\u662f\u4e00\u4e2a 5 * 5 \u7684\u77e9\u9635\uff0c\u901a\u8fc7\u4f7f\u7528\u4e00\u6b21 3 * 3 \u7684\u5377\u79ef\u6838\u8ba1\u7b97\u5f97\u5230\u7684\u8ba1\u7b97\u7ed3\u679c\u662f\u4e00\u4e2a 3 * 3 \u7684\u65b0\u77e9\u9635\u3002 \u90a3\u4e48\u65b0\u77e9\u9635\u7684\u5927\u5c0f\u662f\u5982\u4f55\u8ba1\u7b97\u7684\u5462\uff1f \u5377\u79ef\u6838\u5927\u5c0f f \u00b6 \u521a\u624d\u5df2\u7ecf\u8bf4\u5230\u4e86\u4e00\u4e2a\u91cd\u8981\u7684\u53c2\u6570\uff0c\u5c31\u662f\u6838\u7684\u5927\u5c0f\uff0c\u6211\u4eec\u8fd9\u91cc\u7528f\u6765\u8868\u793a \u8fb9\u754c\u586b\u5145 (p)adding \u00b6 \u6211\u4eec\u770b\u5230\u4e0a\u56fe\uff0c\u7ecf\u8fc7\u8ba1\u7b97\u540e\u77e9\u9635\u7684\u5927\u5c0f\u6539\u53d8\u4e86\uff0c\u5982\u679c\u8981\u4f7f\u77e9\u9635\u5927\u5c0f\u4e0d\u6539\u53d8\u5462\uff0c\u6211\u4eec\u53ef\u4ee5\u5148\u5bf9\u77e9\u9635\u505a\u4e00\u4e2a\u586b\u5145\uff0c\u5c06\u77e9\u9635\u7684\u5468\u56f4\u5168\u90e8\u518d\u5305\u56f4\u4e00\u5c42\uff0c\u8fd9\u4e2a\u77e9\u9635\u5c31\u53d8\u6210\u4e86 7*7 ,\u4e0a\u4e0b\u5de6\u53f3\u5404\u52a01\uff0c\u76f8\u5f53\u4e8e 5+1+1=7 \u8fd9\u65f6\uff0c\u8ba1\u7b97\u7684\u7ed3\u679c\u8fd8\u662f 5 * 5 \u7684\u77e9\u9635\uff0c\u4fdd\u8bc1\u4e86\u5927\u5c0f\u4e0d\u53d8\uff0c\u8fd9\u91cc\u7684p=1 \u6b65\u957f (s)tride \u00b6 \u4ece\u52a8\u56fe\u4e0a\u6211\u4eec\u80fd\u591f\u770b\u5230\uff0c\u6bcf\u6b21\u6ed1\u52a8\u53ea\u662f\u6ed1\u52a8\u4e86\u4e00\u4e2a\u8ddd\u79bb\uff0c\u5982\u679c\u6bcf\u6b21\u6ed1\u52a8\u4e24\u4e2a\u8ddd\u79bb\u5462\uff1f\u90a3\u5c31\u9700\u8981\u4f7f\u7528\u6b65\u957f\u8fd9\u4e2a\u53c2\u6570\u3002 \u8ba1\u7b97\u516c\u5f0f \u00b6 n\u4e3a\u6211\u4eec\u8f93\u5165\u7684\u77e9\u9635\u7684\u5927\u5c0f\uff0c$ \\frac{n-f+2p}{s} +1 $ \u5411\u4e0b\u53d6\u6574 \u8fd9\u4e2a\u516c\u5f0f\u975e\u5e38\u91cd\u8981\u4e00\u5b9a\u8981\u8bb0\u4f4f \u5377\u79ef\u5c42 \u00b6 \u5728\u6bcf\u4e00\u4e2a\u5377\u79ef\u5c42\u4e2d\u6211\u4eec\u90fd\u4f1a\u8bbe\u7f6e\u591a\u4e2a\u6838\uff0c\u6bcf\u4e2a\u6838\u4ee3\u8868\u7740\u4e0d\u540c\u7684\u7279\u5f81\uff0c\u8fd9\u4e9b\u7279\u5f81\u5c31\u662f\u6211\u4eec\u9700\u8981\u4f20\u9012\u5230\u4e0b\u4e00\u5c42\u7684\u8f93\u51fa\uff0c\u800c\u6211\u4eec\u8bad\u7ec3\u7684\u8fc7\u7a0b\u5c31\u662f\u8bad\u7ec3\u8fd9\u4e9b\u4e0d\u540c\u7684\u6838\u3002 \u6fc0\u6d3b\u51fd\u6570 \u00b6 \u7531\u4e8e\u5377\u79ef\u7684\u64cd\u4f5c\u4e5f\u662f\u7ebf\u6027\u7684\uff0c\u6240\u4ee5\u4e5f\u9700\u8981\u8fdb\u884c\u6fc0\u6d3b\uff0c\u4e00\u822c\u60c5\u51b5\u4e0b\uff0c\u90fd\u4f1a\u4f7f\u7528relu\u3002 \u6c60\u5316\u5c42\uff08pooling\uff09 \u00b6 \u6c60\u5316\u5c42\u662fCNN\u7684\u91cd\u8981\u7ec4\u6210\u90e8\u5206\uff0c\u901a\u8fc7\u51cf\u5c11\u5377\u79ef\u5c42\u4e4b\u95f4\u7684\u8fde\u63a5\uff0c\u964d\u4f4e\u8fd0\u7b97\u590d\u6742\u7a0b\u5ea6\uff0c\u6c60\u5316\u5c42\u7684\u64cd\u4f5c\u5f88\u7b80\u5355\uff0c\u5c31\u60f3\u76f8\u5f53\u4e8e\u662f\u5408\u5e76\uff0c\u6211\u4eec\u8f93\u5165\u4e00\u4e2a\u8fc7\u6ee4\u5668\u7684\u5927\u5c0f\uff0c\u4e0e\u5377\u79ef\u7684\u64cd\u4f5c\u4e00\u6837\uff0c\u4e5f\u662f\u4e00\u6b65\u4e00\u6b65\u6ed1\u52a8\uff0c\u4f46\u662f\u8fc7\u6ee4\u5668\u8986\u76d6\u7684\u533a\u57df\u8fdb\u884c\u5408\u5e76\uff0c\u53ea\u4fdd\u7559\u4e00\u4e2a\u503c\u3002 \u5408\u5e76\u7684\u65b9\u5f0f\u4e5f\u6709\u5f88\u591a\u79cd\uff0c\u4f8b\u5982\u6211\u4eec\u5e38\u7528\u7684\u4e24\u79cd\u53d6\u6700\u5927\u503cmaxpooling\uff0c\u53d6\u5e73\u5747\u503cavgpooling \u6c60\u5316\u5c42\u7684\u8f93\u51fa\u5927\u5c0f\u516c\u5f0f\u4e5f\u4e0e\u5377\u79ef\u5c42\u4e00\u6837\uff0c\u7531\u4e8e\u6ca1\u6709\u8fdb\u884c\u586b\u5145\uff0c\u6240\u4ee5p=0\uff0c\u53ef\u4ee5\u7b80\u5316\u4e3a $ \\frac{n-f}{s} +1 $ dropout\u5c42 \u00b6 dropout\u662f2014\u5e74 Hinton \u63d0\u51fa\u9632\u6b62\u8fc7\u62df\u5408\u800c\u91c7\u7528\u7684trick\uff0c\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b Dropout\uff08\u968f\u673a\u5931\u6d3b\uff09\u662f\u6307\u5728\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\u7684\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6309\u7167\u4e00\u5b9a\u7684\u6982\u7387\u5c06\u4e00\u90e8\u5206\u795e\u7ecf\u7f51\u7edc\u5355\u5143\u6682\u65f6\u4ece\u7f51\u7edc\u4e2d\u4e22\u5f03\uff0c\u76f8\u5f53\u4e8e\u4ece\u539f\u59cb\u7684\u7f51\u7edc\u4e2d\u627e\u5230\u4e00\u4e2a\u66f4\u7626\u7684\u7f51\u7edc\uff0c\u8bf4\u7684\u901a\u4fd7\u4e00\u70b9\uff0c\u5c31\u662f\u968f\u673a\u5c06\u4e00\u90e8\u5206\u7f51\u7edc\u7684\u4f20\u64ad\u6390\u65ad\uff0c\u542c\u8d77\u6765\u597d\u50cf\u4e0d\u9760\u8c31\uff0c\u4f46\u662f\u901a\u8fc7\u5b9e\u9645\u6d4b\u8bd5\u6548\u679c\u975e\u5e38\u597d\u3002 \u6709\u5174\u8da3\u7684\u53ef\u4ee5\u53bb\u770b\u4e00\u4e0b\u539f\u6587 Dropout: A Simple Way to Prevent Neural Networks from Overfitting \u8fd9\u91cc\u5c31\u4e0d\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u3002 \u5168\u8fde\u63a5\u5c42 \u00b6 \u5168\u94fe\u63a5\u5c42\u4e00\u822c\u662f\u4f5c\u4e3a\u6700\u540e\u7684\u8f93\u51fa\u5c42\u4f7f\u7528\uff0c\u5377\u79ef\u7684\u4f5c\u7528\u662f\u63d0\u53d6\u56fe\u50cf\u7684\u7279\u5f81\uff0c\u6700\u540e\u7684\u5168\u8fde\u63a5\u5c42\u5c31\u662f\u8981\u901a\u8fc7\u8fd9\u4e9b\u7279\u5f81\u6765\u8fdb\u884c\u8ba1\u7b97\uff0c\u8f93\u51fa\u6211\u4eec\u6240\u8981\u7684\u7ed3\u679c\u4e86\uff0c\u65e0\u8bba\u662f\u5206\u7c7b\uff0c\u8fd8\u662f\u56de\u5f52\u3002 \u6211\u4eec\u7684\u7279\u5f81\u90fd\u662f\u4f7f\u7528\u77e9\u9635\u8868\u793a\u7684\uff0c\u6240\u4ee5\u518d\u4f20\u5165\u5168\u8fde\u63a5\u5c42\u4e4b\u524d\u8fd8\u9700\u8981\u5bf9\u7279\u5f81\u8fdb\u884c\u538b\u6241\uff0c\u5c06\u4ed6\u8fd9\u4e9b\u7279\u5f81\u53d8\u6210\u4e00\u7ef4\u7684\u5411\u91cf\uff0c\u5982\u679c\u8981\u8fdb\u884c\u5206\u7c7b\u7684\u8bdd\uff0c\u5c31\u662f\u7528sofmax\u4f5c\u4e3a\u8f93\u51fa\uff0c\u5982\u679c\u8981\u662f\u56de\u5f52\u7684\u8bdd\u5c31\u76f4\u63a5\u4f7f\u7528linear\u5373\u53ef\u3002 \u4ee5\u4e0a\u5c31\u662f\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u51e0\u4e2a\u4e3b\u8981\u7684\u7ec4\u6210\u90e8\u5206\uff0c\u4e0b\u9762\u6211\u4eec\u4ecb\u7ecd\u4e00\u4e9b\u7ecf\u5178\u7684\u7f51\u7edc\u6a21\u578b 2.4.3 \u7ecf\u5178\u6a21\u578b \u00b6 LeNet-5 \u00b6 1998\uff0c Yann LeCun \u7684 LeNet5 \u5b98\u7f51 \u5377\u79ef\u795e\u7ecf\u7f51\u8def\u7684\u5f00\u5c71\u4e4b\u4f5c\uff0c\u9ebb\u96c0\u867d\u5c0f\uff0c\u4f46\u4e94\u810f\u4ff1\u5168\uff0c\u5377\u79ef\u5c42\u3001pooling\u5c42\u3001\u5168\u8fde\u63a5\u5c42\uff0c\u8fd9\u4e9b\u90fd\u662f\u73b0\u4ee3CNN\u7f51\u7edc\u7684\u57fa\u672c\u7ec4\u4ef6 - \u7528\u5377\u79ef\u63d0\u53d6\u7a7a\u95f4\u7279\u5f81\uff1b - \u7531\u7a7a\u95f4\u5e73\u5747\u5f97\u5230\u5b50\u6837\u672c\uff1b - \u7528 tanh \u6216 sigmoid \u5f97\u5230\u975e\u7ebf\u6027\uff1b - \u7528 multi-layer neural network\uff08MLP\uff09\u4f5c\u4e3a\u6700\u7ec8\u5206\u7c7b\u5668\uff1b - \u5c42\u5c42\u4e4b\u95f4\u7528\u7a00\u758f\u7684\u8fde\u63a5\u77e9\u9635\uff0c\u4ee5\u907f\u514d\u5927\u7684\u8ba1\u7b97\u6210\u672c\u3002 \u8f93\u5165\uff1a\u56fe\u50cfSize\u4e3a32*32\u3002\u8fd9\u8981\u6bd4mnist\u6570\u636e\u5e93\u4e2d\u6700\u5927\u7684\u5b57\u6bcd(28*28)\u8fd8\u5927\u3002\u8fd9\u6837\u505a\u7684\u76ee\u7684\u662f\u5e0c\u671b\u6f5c\u5728\u7684\u660e\u663e\u7279\u5f81\uff0c\u5982\u7b14\u753b\u65ad\u7eed\u3001\u89d2\u70b9\u80fd\u591f\u51fa\u73b0\u5728\u6700\u9ad8\u5c42\u7279\u5f81\u76d1\u6d4b\u5b50\u611f\u53d7\u91ce\u7684\u4e2d\u5fc3\u3002 \u8f93\u51fa\uff1a10\u4e2a\u7c7b\u522b\uff0c\u5206\u522b\u4e3a0-9\u6570\u5b57\u7684\u6982\u7387 C1\u5c42\u662f\u4e00\u4e2a\u5377\u79ef\u5c42\uff0c\u67096\u4e2a\u5377\u79ef\u6838\uff08\u63d0\u53d66\u79cd\u5c40\u90e8\u7279\u5f81\uff09\uff0c\u6838\u5927\u5c0f\u4e3a5 * 5 S2\u5c42\u662fpooling\u5c42\uff0c\u4e0b\u91c7\u6837\uff08\u533a\u57df:2 * 2 \uff09\u964d\u4f4e\u7f51\u7edc\u8bad\u7ec3\u53c2\u6570\u53ca\u6a21\u578b\u7684\u8fc7\u62df\u5408\u7a0b\u5ea6\u3002 C3\u5c42\u662f\u7b2c\u4e8c\u4e2a\u5377\u79ef\u5c42\uff0c\u4f7f\u752816\u4e2a\u5377\u79ef\u6838\uff0c\u6838\u5927\u5c0f:5 * 5 \u63d0\u53d6\u7279\u5f81 S4\u5c42\u4e5f\u662f\u4e00\u4e2apooling\u5c42\uff0c\u533a\u57df:2*2 C5\u5c42\u662f\u6700\u540e\u4e00\u4e2a\u5377\u79ef\u5c42\uff0c\u5377\u79ef\u6838\u5927\u5c0f:5 * 5 \u5377\u79ef\u6838\u79cd\u7c7b:120 \u6700\u540e\u4f7f\u7528\u5168\u8fde\u63a5\u5c42\uff0c\u5c06C5\u7684120\u4e2a\u7279\u5f81\u8fdb\u884c\u5206\u7c7b\uff0c\u6700\u540e\u8f93\u51fa0-9\u7684\u6982\u7387 \u4e00\u4e0b\u4ee3\u7801\u6765\u81ea \u5b98\u65b9\u6559\u7a0b import torch.nn as nn class LeNet5 ( nn . Module ): def __init__ ( self ): super ( LeNet5 , self ) . __init__ () # 1 input image channel, 6 output channels, 5x5 square convolution # kernel self . conv1 = nn . Conv2d ( 1 , 6 , 5 ) self . conv2 = nn . Conv2d ( 6 , 16 , 5 ) # an affine operation: y = Wx + b self . fc1 = nn . Linear ( 16 * 5 * 5 , 120 ) # \u8fd9\u91cc\u8bba\u6587\u4e0a\u5199\u7684\u662fconv,\u5b98\u65b9\u6559\u7a0b\u7528\u4e86\u7ebf\u6027\u5c42 self . fc2 = nn . Linear ( 120 , 84 ) self . fc3 = nn . Linear ( 84 , 10 ) def forward ( self , x ): # Max pooling over a (2, 2) window x = F . max_pool2d ( F . relu ( self . conv1 ( x )), ( 2 , 2 )) # If the size is a square you can only specify a single number x = F . max_pool2d ( F . relu ( self . conv2 ( x )), 2 ) x = x . view ( - 1 , self . num_flat_features ( x )) x = F . relu ( self . fc1 ( x )) x = F . relu ( self . fc2 ( x )) x = self . fc3 ( x ) return x def num_flat_features ( self , x ): size = x . size ()[ 1 :] # all dimensions except the batch dimension num_features = 1 for s in size : num_features *= s return num_features net = LeNet5 () print ( net ) LeNet5( (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1)) (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)) (fc1): Linear(in_features=400, out_features=120, bias=True) (fc2): Linear(in_features=120, out_features=84, bias=True) (fc3): Linear(in_features=84, out_features=10, bias=True) ) AlexNet \u00b6 2012\uff0cAlex Krizhevsky \u53ef\u4ee5\u7b97\u4f5cLeNet\u7684\u4e00\u4e2a\u66f4\u6df1\u548c\u66f4\u5e7f\u7684\u7248\u672c\uff0c\u53ef\u4ee5\u7528\u6765\u5b66\u4e60\u66f4\u590d\u6742\u7684\u5bf9\u8c61 \u8bba\u6587 - \u7528rectified linear units\uff08ReLU\uff09\u5f97\u5230\u975e\u7ebf\u6027\uff1b - \u4f7f\u7528 dropout \u6280\u5de7\u5728\u8bad\u7ec3\u671f\u95f4\u6709\u9009\u62e9\u6027\u5730\u5ffd\u7565\u5355\u4e2a\u795e\u7ecf\u5143\uff0c\u6765\u51cf\u7f13\u6a21\u578b\u7684\u8fc7\u62df\u5408\uff1b - \u91cd\u53e0\u6700\u5927\u6c60\uff0c\u907f\u514d\u5e73\u5747\u6c60\u7684\u5e73\u5747\u6548\u679c\uff1b - \u4f7f\u7528 GPU NVIDIA GTX 580 \u53ef\u4ee5\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f4\uff0c\u8fd9\u6bd4\u7528CPU\u5904\u7406\u5feb\u4e86 10 \u500d\uff0c\u6240\u4ee5\u53ef\u4ee5\u88ab\u7528\u4e8e\u66f4\u5927\u7684\u6570\u636e\u96c6\u548c\u56fe\u50cf\u4e0a\u3002 \u867d\u7136 AlexNet\u53ea\u67098\u5c42\uff0c\u4f46\u662f\u5b83\u670960M\u4ee5\u4e0a\u7684\u53c2\u6570\u603b\u91cf\uff0cAlexnet\u6709\u4e00\u4e2a\u7279\u6b8a\u7684\u8ba1\u7b97\u5c42\uff0cLRN\u5c42\uff0c\u505a\u7684\u4e8b\u662f\u5bf9\u5f53\u524d\u5c42\u7684\u8f93\u51fa\u7ed3\u679c\u505a\u5e73\u6ed1\u5904\u7406\uff0c\u8fd9\u91cc\u5c31\u4e0d\u505a\u8be6\u7ec6\u4ecb\u7ecd\u4e86\uff0c Alexnet\u7684\u6bcf\u4e00\u9636\u6bb5\uff08\u542b\u4e00\u6b21\u5377\u79ef\u4e3b\u8981\u8ba1\u7b97\u7684\u7b97\u4f5c\u4e00\u5c42\uff09\u53ef\u4ee5\u5206\u4e3a8\u5c42\uff1a 1. con - relu - pooling - LRN \uff1a \u8981\u6ce8\u610f\u7684\u662finput\u5c42\u662f227*227\uff0c\u800c\u4e0d\u662fpaper\u91cc\u9762\u7684224\uff0c\u8fd9\u91cc\u53ef\u4ee5\u7b97\u4e00\u4e0b\uff0c\u4e3b\u8981\u662f227\u53ef\u4ee5\u6574\u9664\u540e\u9762\u7684conv1\u8ba1\u7b97\uff0c224\u4e0d\u6574\u9664\u3002\u5982\u679c\u4e00\u5b9a\u8981\u7528224\u53ef\u4ee5\u901a\u8fc7\u81ea\u52a8\u8865\u8fb9\u5b9e\u73b0\uff0c\u4e0d\u8fc7\u5728input\u5c31\u8865\u8fb9\u611f\u89c9\u6ca1\u6709\u610f\u4e49\uff0c\u8865\u5f97\u4e5f\u662f0\uff0c\u8fd9\u5c31\u662f\u6211\u4eec\u4e0a\u9762\u8bf4\u7684\u516c\u5f0f\u7684\u91cd\u8981\u6027\u3002 conv - relu - pool - LRN \uff1a group=2\uff0c\u8fd9\u4e2a\u5c5e\u6027\u5f3a\u884c\u628a\u524d\u9762\u7ed3\u679c\u7684feature map\u5206\u5f00\uff0c\u5377\u79ef\u90e8\u5206\u5206\u6210\u4e24\u90e8\u5206\u505a conv - relu conv-relu conv - relu - pool fc - relu - dropout \uff1a dropout\u5c42\uff0c\u5728alexnet\u4e2d\u662f\u8bf4\u5728\u8bad\u7ec3\u7684\u4ee5\u00bd\u6982\u7387\u4f7f\u5f97\u9690\u85cf\u5c42\u7684\u67d0\u4e9bneuron\u7684\u8f93\u51fa\u4e3a0\uff0c\u8fd9\u6837\u5c31\u4e22\u5230\u4e86\u4e00\u534a\u8282\u70b9\u7684\u8f93\u51fa\uff0cBP\u7684\u65f6\u5019\u4e5f\u4e0d\u66f4\u65b0\u8fd9\u4e9b\u8282\u70b9\uff0c\u9632\u6b62\u8fc7\u62df\u5408\u3002 fc - relu - dropout fc - softmax \u5728Pytorch\u7684vision\u5305\u4e2d\u662f\u5305\u542bAlexnet\u7684\u5b98\u65b9\u5b9e\u73b0\u7684\uff0c\u6211\u4eec\u76f4\u63a5\u4f7f\u7528\u5b98\u65b9\u7248\u672c\u770b\u4e0b\u7f51\u7edc import torchvision model = torchvision . models . alexnet ( pretrained = False ) #\u6211\u4eec\u4e0d\u4e0b\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd print ( model ) AlexNet( (features): Sequential( (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2)) (1): ReLU(inplace) (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False) (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)) (4): ReLU(inplace) (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False) (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (7): ReLU(inplace) (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (9): ReLU(inplace) (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (11): ReLU(inplace) (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False) ) (classifier): Sequential( (0): Dropout(p=0.5) (1): Linear(in_features=9216, out_features=4096, bias=True) (2): ReLU(inplace) (3): Dropout(p=0.5) (4): Linear(in_features=4096, out_features=4096, bias=True) (5): ReLU(inplace) (6): Linear(in_features=4096, out_features=1000, bias=True) ) ) VGG \u00b6 2015\uff0c\u725b\u6d25\u7684 VGG\u3002 \u8bba\u6587 \u6bcf\u4e2a\u5377\u79ef\u5c42\u4e2d\u4f7f\u7528\u66f4\u5c0f\u7684 3\u00d73 filters\uff0c\u5e76\u5c06\u5b83\u4eec\u7ec4\u5408\u6210\u5377\u79ef\u5e8f\u5217 \u591a\u4e2a3\u00d73\u5377\u79ef\u5e8f\u5217\u53ef\u4ee5\u6a21\u62df\u66f4\u5927\u7684\u63a5\u6536\u573a\u7684\u6548\u679c \u6bcf\u6b21\u7684\u56fe\u50cf\u50cf\u7d20\u7f29\u5c0f\u4e00\u500d\uff0c\u5377\u79ef\u6838\u7684\u6570\u91cf\u589e\u52a0\u4e00\u500d VGG\u6709\u5f88\u591a\u4e2a\u7248\u672c\uff0c\u4e5f\u7b97\u662f\u6bd4\u8f83\u7a33\u5b9a\u548c\u7ecf\u5178\u7684model\u3002\u5b83\u7684\u7279\u70b9\u4e5f\u662f\u8fde\u7eedconv\u591a\u8ba1\u7b97\u91cf\u5de8\u5927\uff0c\u8fd9\u91cc\u6211\u4eec\u4ee5VGG16\u4e3a\u4f8b. \u56fe\u7247\u6765\u6e90 VGG\u6e05\u4e00\u8272\u7528\u5c0f\u5377\u79ef\u6838\uff0c\u7ed3\u5408\u4f5c\u8005\u548c\u81ea\u5df1\u7684\u89c2\u70b9\uff0c\u8fd9\u91cc\u6574\u7406\u51fa\u5c0f\u5377\u79ef\u6838\u6bd4\u7528\u5927\u5377\u79ef\u6838\u7684\u4f18\u52bf\uff1a \u6839\u636e\u4f5c\u8005\u7684\u89c2\u70b9\uff0cinput8 -> 3\u5c42conv3x3\u540e\uff0coutput=2\uff0c\u7b49\u540c\u4e8e1\u5c42conv7x7\u7684\u7ed3\u679c\uff1b input=8 -> 2\u5c42conv3x3\u540e\uff0coutput=2\uff0c\u7b49\u540c\u4e8e2\u5c42conv5x5\u7684\u7ed3\u679c \u5377\u79ef\u5c42\u7684\u53c2\u6570\u51cf\u5c11\u3002\u76f8\u6bd45x5\u30017x7\u548c11x11\u7684\u5927\u5377\u79ef\u6838\uff0c3x3\u660e\u663e\u5730\u51cf\u5c11\u4e86\u53c2\u6570\u91cf \u901a\u8fc7\u5377\u79ef\u548c\u6c60\u5316\u5c42\u540e\uff0c\u56fe\u50cf\u7684\u5206\u8fa8\u7387\u964d\u4f4e\u4e3a\u539f\u6765\u7684\u4e00\u534a\uff0c\u4f46\u662f\u56fe\u50cf\u7684\u7279\u5f81\u589e\u52a0\u4e00\u500d\uff0c\u8fd9\u662f\u4e00\u4e2a\u5341\u5206\u89c4\u6574\u7684\u64cd\u4f5c: \u5206\u8fa8\u7387\u7531\u8f93\u5165\u7684224->112->56->28->14->7, \u7279\u5f81\u4ece\u539f\u59cb\u7684RGB3\u4e2a\u901a\u9053-> 64 ->128 -> 256 -> 512 \u8fd9\u4e3a\u540e\u9762\u7684\u7f51\u7edc\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6807\u51c6,\u6211\u4eec\u4f9d\u65e7\u4f7f\u7528Pytorch\u5b98\u65b9\u5b9e\u73b0\u7248\u672c\u6765\u67e5\u770b import torchvision model = torchvision . models . vgg16 ( pretrained = False ) #\u6211\u4eec\u4e0d\u4e0b\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd print ( model ) VGG( (features): Sequential( (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): ReLU(inplace) (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (3): ReLU(inplace) (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (6): ReLU(inplace) (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (8): ReLU(inplace) (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (11): ReLU(inplace) (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (13): ReLU(inplace) (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (15): ReLU(inplace) (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (18): ReLU(inplace) (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (20): ReLU(inplace) (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (22): ReLU(inplace) (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (25): ReLU(inplace) (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (27): ReLU(inplace) (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (29): ReLU(inplace) (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) ) (classifier): Sequential( (0): Linear(in_features=25088, out_features=4096, bias=True) (1): ReLU(inplace) (2): Dropout(p=0.5) (3): Linear(in_features=4096, out_features=4096, bias=True) (4): ReLU(inplace) (5): Dropout(p=0.5) (6): Linear(in_features=4096, out_features=1000, bias=True) ) ) GoogLeNet (Inception) \u00b6 2014\uff0cGoogle Christian Szegedy \u8bba\u6587 - \u4f7f\u75281\u00d71\u5377\u79ef\u5757\uff08NiN\uff09\u6765\u51cf\u5c11\u7279\u5f81\u6570\u91cf\uff0c\u8fd9\u901a\u5e38\u88ab\u79f0\u4e3a\u201c\u74f6\u9888\u201d\uff0c\u53ef\u4ee5\u51cf\u5c11\u6df1\u5c42\u795e\u7ecf\u7f51\u7edc\u7684\u8ba1\u7b97\u8d1f\u62c5\u3002 - \u6bcf\u4e2a\u6c60\u5316\u5c42\u4e4b\u524d\uff0c\u589e\u52a0 feature maps\uff0c\u589e\u52a0\u6bcf\u4e00\u5c42\u7684\u5bbd\u5ea6\u6765\u589e\u591a\u7279\u5f81\u7684\u7ec4\u5408\u6027 googlenet\u6700\u5927\u7684\u7279\u70b9\u5c31\u662f\u5305\u542b\u82e5\u5e72\u4e2ainception\u6a21\u5757\uff0c\u6240\u4ee5\u6709\u65f6\u5019\u4e5f\u79f0\u4f5c inception net googlenet\u867d\u7136\u5c42\u6570\u8981\u6bd4VGG\u591a\u5f88\u591a\uff0c\u4f46\u662f\u7531\u4e8einception\u7684\u8bbe\u8ba1\uff0c\u8ba1\u7b97\u901f\u5ea6\u65b9\u9762\u8981\u5feb\u5f88\u591a\u3002 \u4e0d\u8981\u88ab\u8fd9\u4e2a\u56fe\u5413\u5230\uff0c\u5176\u5b9e\u539f\u7406\u5f88\u7b80\u5355\u3002 Inception\u67b6\u6784\u7684\u4e3b\u8981\u601d\u60f3\u662f\u627e\u51fa\u5982\u4f55\u8ba9\u5df2\u6709\u7684\u7a20\u5bc6\u7ec4\u4ef6\u63a5\u8fd1\u4e0e\u8986\u76d6\u5377\u79ef\u89c6\u89c9\u7f51\u7edc\u4e2d\u7684\u6700\u4f73\u5c40\u90e8\u7a00\u758f\u7ed3\u6784\u3002\u73b0\u5728\u9700\u8981\u627e\u51fa\u6700\u4f18\u7684\u5c40\u90e8\u6784\u9020\uff0c\u5e76\u4e14\u91cd\u590d \u51e0\u6b21\u3002\u4e4b\u524d\u7684\u4e00\u7bc7\u6587\u732e\u63d0\u51fa\u4e00\u4e2a\u5c42\u4e0e\u5c42\u7684\u7ed3\u6784\uff0c\u5728\u6700\u540e\u4e00\u5c42\u8fdb\u884c\u76f8\u5173\u6027\u7edf\u8ba1\uff0c\u5c06\u9ad8\u76f8\u5173\u6027\u7684\u805a\u96c6\u5230\u4e00\u8d77\u3002\u8fd9\u4e9b\u805a\u7c7b\u6784\u6210\u4e0b\u4e00\u5c42\u7684\u5355\u5143\uff0c\u4e14\u4e0e\u4e0a\u4e00\u5c42\u5355\u5143\u8fde\u63a5\u3002\u5047\u8bbe\u524d \u9762\u5c42\u7684\u6bcf\u4e2a\u5355\u5143\u5bf9\u5e94\u4e8e\u8f93\u5165\u56fe\u50cf\u7684\u67d0\u4e9b\u533a\u57df\uff0c\u8fd9\u4e9b\u5355\u5143\u88ab\u5206\u4e3a\u6ee4\u6ce2\u5668\u7ec4\u3002\u5728\u63a5\u8fd1\u8f93\u5165\u5c42\u7684\u4f4e\u5c42\u4e2d\uff0c\u76f8\u5173\u5355\u5143\u96c6\u4e2d\u5728\u67d0\u4e9b\u5c40\u90e8\u533a\u57df\uff0c\u6700\u7ec8\u5f97\u5230\u5728\u5355\u4e2a\u533a\u57df\u4e2d\u7684\u5927\u91cf\u805a\u7c7b\uff0c\u5728\u6700\u540e\u4e00\u5c42\u901a\u8fc71x1\u7684\u5377\u79ef\u8986\u76d6\u3002 \u4e0a\u9762\u7684\u8bdd\u542c\u8d77\u6765\u5f88\u751f\u786c\uff0c\u5176\u5b9e\u89e3\u91ca\u8d77\u6765\u5f88\u7b80\u5355\uff1a\u6bcf\u4e00\u6a21\u5757\u6211\u4eec\u90fd\u662f\u7528\u82e5\u5e72\u4e2a\u4e0d\u540c\u7684\u7279\u5f81\u63d0\u53d6\u65b9\u5f0f\uff0c\u4f8b\u5982 3x3\u5377\u79ef\uff0c5x5\u5377\u79ef\uff0c1x1\u7684\u5377\u79ef\uff0cpooling\u7b49\uff0c\u90fd\u8ba1\u7b97\u4e00\u4e0b\uff0c\u6700\u540e\u518d\u628a\u8fd9\u4e9b\u7ed3\u679c\u901a\u8fc7Filter Concat\u6765\u8fdb\u884c\u8fde\u63a5\uff0c\u627e\u5230\u8fd9\u91cc\u9762\u4f5c\u7528\u6700\u5927\u7684\u3002\u800c\u7f51\u7edc\u91cc\u9762\u5305\u542b\u4e86\u8bb8\u591a\u8fd9\u6837\u7684\u6a21\u5757\uff0c\u8fd9\u6837\u4e0d\u7528\u6211\u4eec\u4eba\u4e3a\u53bb\u5224\u65ad\u54ea\u4e2a\u7279\u5f81\u63d0\u53d6\u65b9\u5f0f\u597d\uff0c\u7f51\u7edc\u4f1a\u81ea\u5df1\u89e3\u51b3\uff08\u662f\u4e0d\u662f\u6709\u70b9\u50cfAUTO ML\uff09\uff0c\u5728Pytorch\u4e2d\u5b9e\u73b0\u4e86InceptionA-E\uff0c\u8fd8\u6709InceptionAUX \u6a21\u5757\u3002 # inception_v3\u9700\u8981scipy\uff0c\u6240\u4ee5\u6ca1\u6709\u5b89\u88c5\u7684\u8bddpip install scipy \u4e00\u4e0b import torchvision model = torchvision . models . inception_v3 ( pretrained = False ) #\u6211\u4eec\u4e0d\u4e0b\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd print ( model ) Inception3( (Conv2d_1a_3x3): BasicConv2d( (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False) (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (Conv2d_2a_3x3): BasicConv2d( (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False) (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (Conv2d_2b_3x3): BasicConv2d( (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (Conv2d_3b_1x1): BasicConv2d( (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (Conv2d_4a_3x3): BasicConv2d( (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (Mixed_5b): InceptionA( (branch1x1): BasicConv2d( (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch5x5_1): BasicConv2d( (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch5x5_2): BasicConv2d( (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False) (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_1): BasicConv2d( (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_2): BasicConv2d( (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_3): BasicConv2d( (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch_pool): BasicConv2d( (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) ) (Mixed_5c): InceptionA( (branch1x1): BasicConv2d( (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch5x5_1): BasicConv2d( (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch5x5_2): BasicConv2d( (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False) (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_1): BasicConv2d( (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_2): BasicConv2d( (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_3): BasicConv2d( (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch_pool): BasicConv2d( (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) ) (Mixed_5d): InceptionA( (branch1x1): BasicConv2d( (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch5x5_1): BasicConv2d( (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch5x5_2): BasicConv2d( (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False) (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_1): BasicConv2d( (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_2): BasicConv2d( (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_3): BasicConv2d( (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch_pool): BasicConv2d( (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) ) (Mixed_6a): InceptionB( (branch3x3): BasicConv2d( (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False) (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_1): BasicConv2d( (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_2): BasicConv2d( (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_3): BasicConv2d( (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False) (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) ) (Mixed_6b): InceptionC( (branch1x1): BasicConv2d( (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7_1): BasicConv2d( (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7_2): BasicConv2d( (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False) (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7_3): BasicConv2d( (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_1): BasicConv2d( (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_2): BasicConv2d( (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False) (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_3): BasicConv2d( (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False) (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_4): BasicConv2d( (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False) (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_5): BasicConv2d( (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch_pool): BasicConv2d( (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) ) (Mixed_6c): InceptionC( (branch1x1): BasicConv2d( (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7_1): BasicConv2d( (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7_2): BasicConv2d( (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False) (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7_3): BasicConv2d( (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_1): BasicConv2d( (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_2): BasicConv2d( (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False) (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_3): BasicConv2d( (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False) (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_4): BasicConv2d( (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False) (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_5): BasicConv2d( (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch_pool): BasicConv2d( (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) ) (Mixed_6d): InceptionC( (branch1x1): BasicConv2d( (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7_1): BasicConv2d( (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7_2): BasicConv2d( (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False) (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7_3): BasicConv2d( (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_1): BasicConv2d( (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_2): BasicConv2d( (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False) (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_3): BasicConv2d( (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False) (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_4): BasicConv2d( (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False) (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_5): BasicConv2d( (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch_pool): BasicConv2d( (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) ) (Mixed_6e): InceptionC( (branch1x1): BasicConv2d( (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7_1): BasicConv2d( (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7_2): BasicConv2d( (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7_3): BasicConv2d( (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_1): BasicConv2d( (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_2): BasicConv2d( (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_3): BasicConv2d( (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_4): BasicConv2d( (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_5): BasicConv2d( (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch_pool): BasicConv2d( (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) ) (AuxLogits): InceptionAux( (conv0): BasicConv2d( (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (conv1): BasicConv2d( (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False) (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (fc): Linear(in_features=768, out_features=1000, bias=True) ) (Mixed_7a): InceptionD( (branch3x3_1): BasicConv2d( (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3_2): BasicConv2d( (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False) (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7x3_1): BasicConv2d( (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7x3_2): BasicConv2d( (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7x3_3): BasicConv2d( (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7x3_4): BasicConv2d( (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) ) (Mixed_7b): InceptionE( (branch1x1): BasicConv2d( (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3_1): BasicConv2d( (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3_2a): BasicConv2d( (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False) (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3_2b): BasicConv2d( (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False) (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_1): BasicConv2d( (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_2): BasicConv2d( (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_3a): BasicConv2d( (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False) (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_3b): BasicConv2d( (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False) (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch_pool): BasicConv2d( (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) ) (Mixed_7c): InceptionE( (branch1x1): BasicConv2d( (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3_1): BasicConv2d( (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3_2a): BasicConv2d( (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False) (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3_2b): BasicConv2d( (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False) (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_1): BasicConv2d( (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_2): BasicConv2d( (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_3a): BasicConv2d( (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False) (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_3b): BasicConv2d( (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False) (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch_pool): BasicConv2d( (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) ) (fc): Linear(in_features=2048, out_features=1000, bias=True) ) ResNet \u00b6 2015\uff0cKaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun \u8bba\u6587 Kaiming He \u4f55\u51ef\u660e\uff08\u97f3\u8bd1\uff09\u8fd9\u4e2a\u5927\u795e\u5927\u5bb6\u4e00\u5b9a\u8981\u8bb0\u4f4f\uff0c\u73b0\u5728\u5f88\u591a\u8bba\u6587\u90fd\u6709\u4ed6\u53c2\u4e0e(mask rcnn, focal loss)\uff0cJian Sun\u5b59\u5251\u8001\u5e08\u5c31\u4e0d\u7528\u8bf4\u4e86\uff0c\u73b0\u5728\u65f7\u4e16\u79d1\u6280\u7684\u9996\u5e2d\u79d1\u5b66\u5bb6 \u521a\u624d\u7684googlenet\u5df2\u7ecf\u5f88\u6df1\u4e86\uff0cResNet\u53ef\u4ee5\u505a\u5230\u66f4\u6df1\uff0c\u901a\u8fc7\u6b8b\u5dee\u8ba1\u7b97\uff0c\u53ef\u4ee5\u8bad\u7ec3\u8d85\u8fc71000\u5c42\u7684\u7f51\u7edc\uff0c\u4fd7\u79f0\u8df3\u8fde\u63a5\u3002 \u9000\u5316\u95ee\u9898 \u00b6 \u7f51\u7edc\u5c42\u6570\u589e\u52a0\uff0c\u4f46\u662f\u5728\u8bad\u7ec3\u96c6\u4e0a\u7684\u51c6\u786e\u7387\u5374\u9971\u548c\u751a\u81f3\u4e0b\u964d\u4e86\u3002\u8fd9\u4e2a\u4e0d\u80fd\u89e3\u91ca\u4e3aoverfitting\uff0c\u56e0\u4e3aoverfit\u5e94\u8be5\u8868\u73b0\u4e3a\u5728\u8bad\u7ec3\u96c6\u4e0a\u8868\u73b0\u66f4\u597d\u624d\u5bf9\u3002\u8fd9\u4e2a\u5c31\u662f\u7f51\u7edc\u9000\u5316\u7684\u95ee\u9898\uff0c\u9000\u5316\u95ee\u9898\u8bf4\u660e\u4e86\u6df1\u5ea6\u7f51\u7edc\u4e0d\u80fd\u5f88\u7b80\u5355\u5730\u88ab\u5f88\u597d\u5730\u4f18\u5316\u3002 \u6b8b\u5dee\u7f51\u7edc\u7684\u89e3\u51b3\u529e\u6cd5 \u00b6 \u6df1\u5c42\u7f51\u7edc\u7684\u540e\u9762\u90a3\u4e9b\u5c42\u662f\u6052\u7b49\u6620\u5c04\uff0c\u90a3\u4e48\u6a21\u578b\u5c31\u9000\u5316\u4e3a\u4e00\u4e2a\u6d45\u5c42\u7f51\u7edc\u3002\u90a3\u73b0\u5728\u8981\u89e3\u51b3\u7684\u5c31\u662f\u5b66\u4e60\u6052\u7b49\u6620\u5c04\u51fd\u6570\u4e86\u3002\u8ba9\u4e00\u4e9b\u5c42\u53bb\u62df\u5408\u4e00\u4e2a\u6f5c\u5728\u7684\u6052\u7b49\u6620\u5c04\u51fd\u6570H(x) = x\uff0c\u6bd4\u8f83\u56f0\u96be\u3002\u5982\u679c\u628a\u7f51\u7edc\u8bbe\u8ba1\u4e3aH(x) = F(x) + x\u3002\u6211\u4eec\u53ef\u4ee5\u8f6c\u6362\u4e3a\u5b66\u4e60\u4e00\u4e2a\u6b8b\u5dee\u51fd\u6570F(x) = H(x) - x. \u53ea\u8981F(x)=0\uff0c\u5c31\u6784\u6210\u4e86\u4e00\u4e2a\u6052\u7b49\u6620\u5c04H(x) = x. \u800c\u4e14\uff0c\u62df\u5408\u6b8b\u5dee\u80af\u5b9a\u66f4\u52a0\u5bb9\u6613\u3002 \u4ee5\u4e0a\u53c8\u5f88\u4e0d\u597d\u7406\u89e3\uff0c\u7ee7\u7eed\u89e3\u91ca\u4e0b\uff0c\u5148\u770b\u56fe\uff1a \u6211\u4eec\u5728\u6fc0\u6d3b\u51fd\u6570\u524d\u5c06\u4e0a\u4e00\u5c42\uff08\u6216\u51e0\u5c42\uff09\u7684\u8f93\u51fa\u4e0e\u672c\u5c42\u8ba1\u7b97\u7684\u8f93\u51fa\u76f8\u52a0\uff0c\u5c06\u6c42\u548c\u7684\u7ed3\u679c\u8f93\u5165\u5230\u6fc0\u6d3b\u51fd\u6570\u4e2d\u505a\u4e3a\u672c\u5c42\u7684\u8f93\u51fa\uff0c\u5f15\u5165\u6b8b\u5dee\u540e\u7684\u6620\u5c04\u5bf9\u8f93\u51fa\u7684\u53d8\u5316\u66f4\u654f\u611f\uff0c\u5176\u5b9e\u5c31\u662f\u770b\u672c\u5c42\u76f8\u5bf9\u524d\u51e0\u5c42\u662f\u5426\u6709\u5927\u7684\u53d8\u5316\uff0c\u76f8\u5f53\u4e8e\u662f\u4e00\u4e2a\u5dee\u5206\u653e\u5927\u5668\u7684\u4f5c\u7528\u3002\u56fe\u4e2d\u7684\u66f2\u7ebf\u5c31\u662f\u6b8b\u5dee\u4e2d\u7684shoutcut\uff0c\u4ed6\u5c06\u524d\u4e00\u5c42\u7684\u7ed3\u679c\u76f4\u63a5\u8fde\u63a5\u5230\u4e86\u672c\u5c42\uff0c\u4e5f\u5c31\u662f\u4fd7\u79f0\u7684\u8df3\u8fde\u63a5\u3002 \u6211\u4eec\u4ee5\u7ecf\u5178\u7684resnet18\u6765\u770b\u4e00\u4e0b\u7f51\u7edc\u7ed3\u6784 \u56fe\u7247\u6765\u6e90 import torchvision model = torchvision . models . resnet18 ( pretrained = False ) #\u6211\u4eec\u4e0d\u4e0b\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd print ( model ) ResNet( (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False) (layer1): Sequential( (0): BasicBlock( (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (1): BasicBlock( (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (layer2): Sequential( (0): BasicBlock( (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (layer3): Sequential( (0): BasicBlock( (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (layer4): Sequential( (0): BasicBlock( (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0) (fc): Linear(in_features=512, out_features=1000, bias=True) ) \u90a3\u4e48\u6211\u4eec\u8be5\u5982\u4f55\u9009\u62e9\u7f51\u7edc\u5462\uff1f \u6765\u6e90 \u4ee5\u4e0a\u8868\u683c\u53ef\u4ee5\u6e05\u695a\u7684\u770b\u5230\u51c6\u786e\u7387\u548c\u8ba1\u7b97\u91cf\u4e4b\u95f4\u7684\u5bf9\u6bd4\u3002\u6211\u7684\u5efa\u8bae\u662f\uff0c\u5c0f\u578b\u56fe\u7247\u5206\u7c7b\u4efb\u52a1\uff0cresnet18\u57fa\u672c\u4e0a\u5df2\u7ecf\u53ef\u4ee5\u4e86\uff0c\u5982\u679c\u771f\u5bf9\u51c6\u786e\u5ea6\u8981\u6c42\u6bd4\u8f83\u9ad8\uff0c\u518d\u9009\u5176\u4ed6\u66f4\u597d\u7684\u7f51\u7edc\u67b6\u6784\u3002","title":"2.4 Convolutional Neural Network"},{"location":"tutorial/chapter02_basics/2_4_convolutional-neural-network/#24","text":"\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7531\u4e00\u4e2a\u6216\u591a\u4e2a\u5377\u79ef\u5c42\u548c\u9876\u7aef\u7684\u5168\u8fde\u901a\u5c42\uff08\u4e5f\u53ef\u4ee5\u4f7f\u75281x1\u7684\u5377\u79ef\u5c42\u4f5c\u4e3a\u6700\u7ec8\u7684\u8f93\u51fa\uff09\u7ec4\u6210\u4e00\u79cd\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u3002\u4e00\u822c\u7684\u8ba4\u4e3a\uff0c\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u662f\u7531Yann LeCun\u5927\u795e\u57281989\u5e74\u63d0\u51fa\u7684LeNet\u4e2d\u9996\u5148\u88ab\u4f7f\u7528\uff0c\u4f46\u662f\u7531\u4e8e\u5f53\u65f6\u7684\u8ba1\u7b97\u80fd\u529b\u4e0d\u591f\uff0c\u5e76\u6ca1\u6709\u5f97\u5230\u5e7f\u6cdb\u7684\u5e94\u7528\uff0c\u5230\u4e861998\u5e74Yann LeCun\u53ca\u5176\u5408\u4f5c\u8005\u6784\u5efa\u4e86\u66f4\u52a0\u5b8c\u5907\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edcLeNet-5\u5e76\u5728\u624b\u5199\u6570\u5b57\u7684\u8bc6\u522b\u95ee\u9898\u4e2d\u53d6\u5f97\u6210\u529f\uff0cLeNet-5\u7684\u6210\u529f\u4f7f\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u5e94\u7528\u5f97\u5230\u5173\u6ce8\u3002LeNet-5\u6cbf\u7528\u4e86LeCun (1989) \u7684\u5b66\u4e60\u7b56\u7565\u5e76\u5728\u539f\u6709\u8bbe\u8ba1\u4e2d\u52a0\u5165\u4e86\u6c60\u5316\u5c42\u5bf9\u8f93\u5165\u7279\u5f81\u8fdb\u884c\u7b5b\u9009 \u3002LeNet-5\u57fa\u672c\u4e0a\u5b9a\u4e49\u4e86\u73b0\u4ee3\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u57fa\u672c\u7ed3\u6784\uff0c\u5176\u6784\u7b51\u4e2d\u4ea4\u66ff\u51fa\u73b0\u7684\u5377\u79ef\u5c42-\u6c60\u5316\u5c42\u88ab\u8ba4\u4e3a\u6709\u6548\u63d0\u53d6\u4e86\u8f93\u5165\u56fe\u50cf\u7684\u5e73\u79fb\u4e0d\u53d8\u7279\u5f81\uff0c\u4f7f\u5f97\u5bf9\u4e8e\u7279\u5f81\u7684\u63d0\u53d6\u524d\u8fdb\u4e86\u4e00\u5927\u6b65\uff0c\u6240\u4ee5\u6211\u4eec\u4e00\u822c\u7684\u8ba4\u4e3a\uff0cYann LeCun\u662f\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u521b\u59cb\u4eba\u3002 2006\u5e74\u540e\uff0c\u968f\u7740\u6df1\u5ea6\u5b66\u4e60\u7406\u8bba\u7684\u5b8c\u5584\uff0c\u5c24\u5176\u662f\u8ba1\u7b97\u80fd\u529b\u7684\u63d0\u5347\u548c\u53c2\u6570\u5fae\u8c03\uff08fine-tuning\uff09\u7b49\u6280\u672f\u7684\u51fa\u73b0\uff0c\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5f00\u59cb\u5feb\u901f\u53d1\u5c55\uff0c\u5728\u7ed3\u6784\u4e0a\u4e0d\u65ad\u52a0\u6df1\uff0c\u5404\u7c7b\u5b66\u4e60\u548c\u4f18\u5316\u7406\u8bba\u5f97\u5230\u5f15\u5165\uff0c2012\u5e74\u7684AlexNet\u30012014\u5e74\u7684VGGNet\u3001GoogLeNet \u548c2015\u5e74\u7684ResNet,\u4f7f\u5f97\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u51e0\u4e4e\u6210\u4e3a\u4e86\u6df1\u5ea6\u5b66\u4e60\u4e2d\u56fe\u50cf\u5904\u7406\u65b9\u9762\u7684\u6807\u914d\u3002","title":"2.4 \u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7b80\u4ecb"},{"location":"tutorial/chapter02_basics/2_4_convolutional-neural-network/#241","text":"\u5bf9\u4e8e\u8ba1\u7b97\u673a\u89c6\u89c9\u6765\u8bf4\uff0c\u6bcf\u4e00\u4e2a\u56fe\u50cf\u662f\u7531\u4e00\u4e2a\u4e2a\u50cf\u7d20\u70b9\u6784\u6210\uff0c\u6bcf\u4e2a\u50cf\u7d20\u70b9\u6709\u4e09\u4e2a\u901a\u9053\uff0c\u5206\u522b\u4ee3\u8868RGB\u4e09\u79cd\u989c\u8272(\u4e0d\u8ba1\u7b97\u900f\u660e\u5ea6)\uff0c\u6211\u4eec\u4ee5\u624b\u5199\u8bc6\u522b\u7684\u6570\u636e\u4f60MNIST\u4e3e\u4f8b\uff0c\u6bcf\u4e2a\u56fe\u50cf\u7684\u662f\u4e00\u4e2a\u957f\u5bbd\u5747\u4e3a28\uff0cchannel\u4e3a1\u7684\u5355\u8272\u56fe\u50cf\uff0c\u5982\u679c\u4f7f\u7528\u5168\u8fde\u63a5\u7684\u7f51\u7edc\u7ed3\u6784\uff0c\u5373\uff0c\u7f51\u7edc\u4e2d\u7684\u795e\u7ecf\u4e0e\u76f8\u90bb\u5c42\u4e0a\u7684\u6bcf\u4e2a\u795e\u7ecf\u5143\u5747\u8fde\u63a5\uff0c\u90a3\u5c31\u610f\u5473\u7740\u6211\u4eec\u7684\u7f51\u7edc\u670928 * 28 =784\u4e2a\u795e\u7ecf\u5143\uff08RGB3\u8272\u7684\u8bdd\u8fd8\u8981*3\uff09\uff0chidden\u5c42\u5982\u679c\u4f7f\u7528\u4e8615\u4e2a\u795e\u7ecf\u5143\uff0c\u9700\u8981\u7684\u53c2\u6570\u4e2a\u6570(w\u548cb)\u5c31\u6709\uff1a28 * 28 * 15 * 10 + 15 + 10=117625\u4e2a\uff0c\u8fd9\u4e2a\u6570\u91cf\u7ea7\u5230\u73b0\u5728\u4e3a\u6b62\u4e5f\u662f\u4e00\u4e2a\u5f88\u6050\u6016\u7684\u6570\u91cf\u7ea7\uff0c\u4e00\u6b21\u53cd\u5411\u4f20\u64ad\u8ba1\u7b97\u91cf\u90fd\u662f\u5de8\u5927\u7684\uff0c\u8fd9\u8fd8\u5c55\u793a\u4e00\u4e2a\u5355\u8272\u768428\u50cf\u7d20\u5927\u5c0f\u7684\u56fe\u7247\uff0c\u5982\u679c\u6211\u4eec\u4f7f\u7528\u66f4\u5927\u7684\u50cf\u7d20\uff0c\u8ba1\u7b97\u91cf\u53ef\u60f3\u800c\u77e5\u3002","title":"2.4.1 \u4e3a\u4ec0\u4e48\u8981\u7528\u5377\u79ef\u795e\u7ecf\u7f51\u7edc"},{"location":"tutorial/chapter02_basics/2_4_convolutional-neural-network/#242","text":"\u4e0a\u9762\u8bf4\u5230\u4f20\u7edf\u7684\u7f51\u7edc\u9700\u8981\u5927\u91cf\u7684\u53c2\u6570\uff0c\u4f46\u662f\u8fd9\u4e9b\u53c2\u6570\u662f\u5426\u91cd\u590d\u4e86\u5462\uff0c\u4f8b\u5982\uff0c\u6211\u4eec\u8bc6\u522b\u4e00\u4e2a\u4eba\uff0c\u53ea\u8981\u770b\u5230\u4ed6\u7684\u773c\u775b\uff0c\u9f3b\u5b50\uff0c\u5634\uff0c\u8fd8\u6709\u8138\u57fa\u672c\u4e0a\u5c31\u77e5\u9053\u8fd9\u4e2a\u4eba\u662f\u8c01\u4e86\uff0c\u53ea\u662f\u7528\u8fd9\u4e9b\u5c40\u90e8\u7684\u7279\u5f81\u5c31\u80fd\u505a\u505a\u5224\u65ad\u4e86\uff0c\u5e76\u4e0d\u9700\u8981\u6240\u6709\u7684\u7279\u5f81\u3002 \u53e6\u5916\u4e00\u70b9\u5c31\u662f\u6211\u4eec\u4e0a\u9762\u8bf4\u7684\u53ef\u4ee5\u6709\u6548\u63d0\u53d6\u4e86\u8f93\u5165\u56fe\u50cf\u7684\u5e73\u79fb\u4e0d\u53d8\u7279\u5f81\uff0c\u5c31\u597d\u50cf\u6211\u4eec\u770b\u5230\u4e86\u8fd9\u662f\u4e2a\u773c\u775b\uff0c\u8fd9\u4e2a\u773c\u955c\u5728\u5de6\u8fb9\u8fd8\u662f\u5728\u53f3\u8fb9\u4ed6\u90fd\u662f\u773c\u775b\uff0c\u8fd9\u5c31\u662f\u5e73\u79fb\u4e0d\u53d8\u6027\u3002 \u6211\u4eec\u901a\u8fc7\u5377\u79ef\u7684\u8ba1\u7b97\u64cd\u4f5c\u6765\u63d0\u53d6\u56fe\u50cf\u5c40\u90e8\u7684\u7279\u5f81\uff0c\u6bcf\u4e00\u5c42\u90fd\u4f1a\u8ba1\u7b97\u51fa\u4e00\u4e9b\u5c40\u90e8\u7279\u5f81\uff0c\u8fd9\u4e9b\u5c40\u90e8\u7279\u5f81\u518d\u6c47\u603b\u5230\u4e0b\u4e00\u5c42\uff0c\u8fd9\u6837\u4e00\u5c42\u4e00\u5c42\u7684\u4f20\u9012\u4e0b\u53bb\uff0c\u7279\u5f81\u7531\u5c0f\u53d8\u5927\uff0c\u6700\u540e\u5728\u901a\u8fc7\u8fd9\u4e9b\u5c40\u90e8\u7684\u7279\u5f81\u5bf9\u56fe\u7247\u8fdb\u884c\u5904\u7406\uff0c\u8fd9\u6837\u5927\u5927\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u4e5f\u63d0\u9ad8\u4e86\u51c6\u786e\u5ea6\u3002","title":"2.4.2\u7ed3\u6784\u7ec4\u6210"},{"location":"tutorial/chapter02_basics/2_4_convolutional-neural-network/#_1","text":"","title":"\u5377\u79ef\u5c42"},{"location":"tutorial/chapter02_basics/2_4_convolutional-neural-network/#_2","text":"\u5728\u4ecb\u7ecd\u5377\u79ef\u5c42\u4e4b\u524d\u8981\u5148\u4ecb\u7ecd\u4e00\u4e0b\u5377\u79ef\u7684\u8ba1\u7b97\uff0c\u8fd9\u91cc\u4f7f\u7528 \u77e5\u4e4e \u4e0a\u7684\u4e00\u5f20\u56fe\u7247: \u6211\u4eec\u4f1a\u5b9a\u4e49\u4e00\u4e2a\u6743\u91cd\u77e9\u9635\uff0c\u4e5f\u5c31\u662f\u6211\u4eec\u8bf4\u7684W\uff08\u4e00\u822c\u5bf9\u4e8e\u5377\u79ef\u6765\u8bf4\uff0c\u79f0\u4f5c\u5377\u79ef\u7684\u6838kernel\u4e5f\u6709\u6709\u4eba\u79f0\u505a\u8fc7\u6ee4\u5668filter\uff09\uff0c\u8fd9\u4e2a\u6743\u91cd\u77e9\u9635\u7684\u5927\u5c0f\u4e00\u822c\u4e3a 3 * 3 \u6216\u8005 5 * 5 \uff0c\u4f46\u662f\u5728LeNet\u91cc\u9762\u8fd8\u7528\u5230\u4e86\u6bd4\u8f83\u5927\u7684 7 * 7 \uff0c\u73b0\u5728\u5df2\u7ecf\u5f88\u5c11\u89c1\u4e86\uff0c\u56e0\u4e3a\u6839\u636e\u7ecf\u9a8c\u7684\u9a8c\u8bc1\uff0c3\u548c5\u662f\u6700\u4f73\u7684\u5927\u5c0f\u3002 \u6211\u4eec\u4ee5\u56fe\u4e0a\u6240\u793a\u7684\u65b9\u5f0f\uff0c\u6211\u4eec\u5728\u8f93\u5165\u77e9\u9635\u4e0a\u4f7f\u7528\u6211\u4eec\u7684\u6743\u91cd\u77e9\u9635\u8fdb\u884c\u6ed1\u52a8\uff0c\u6bcf\u6ed1\u52a8\u4e00\u6b65\uff0c\u5c06\u6240\u8986\u76d6\u7684\u503c\u4e0e\u77e9\u9635\u5bf9\u5e94\u7684\u503c\u76f8\u4e58\uff0c\u5e76\u5c06\u7ed3\u679c\u6c42\u548c\u5e76\u4f5c\u4e3a\u8f93\u51fa\u77e9\u9635\u7684\u4e00\u9879\uff0c\u4f9d\u6b21\u7c7b\u63a8\u76f4\u5230\u5168\u90e8\u8ba1\u7b97\u5b8c\u6210\u3002 \u4e0a\u56fe\u6240\u793a\uff0c\u6211\u4eec\u8f93\u5165\u662f\u4e00\u4e2a 5 * 5 \u7684\u77e9\u9635\uff0c\u901a\u8fc7\u4f7f\u7528\u4e00\u6b21 3 * 3 \u7684\u5377\u79ef\u6838\u8ba1\u7b97\u5f97\u5230\u7684\u8ba1\u7b97\u7ed3\u679c\u662f\u4e00\u4e2a 3 * 3 \u7684\u65b0\u77e9\u9635\u3002 \u90a3\u4e48\u65b0\u77e9\u9635\u7684\u5927\u5c0f\u662f\u5982\u4f55\u8ba1\u7b97\u7684\u5462\uff1f","title":"\u5377\u79ef\u8ba1\u7b97"},{"location":"tutorial/chapter02_basics/2_4_convolutional-neural-network/#f","text":"\u521a\u624d\u5df2\u7ecf\u8bf4\u5230\u4e86\u4e00\u4e2a\u91cd\u8981\u7684\u53c2\u6570\uff0c\u5c31\u662f\u6838\u7684\u5927\u5c0f\uff0c\u6211\u4eec\u8fd9\u91cc\u7528f\u6765\u8868\u793a","title":"\u5377\u79ef\u6838\u5927\u5c0f f"},{"location":"tutorial/chapter02_basics/2_4_convolutional-neural-network/#padding","text":"\u6211\u4eec\u770b\u5230\u4e0a\u56fe\uff0c\u7ecf\u8fc7\u8ba1\u7b97\u540e\u77e9\u9635\u7684\u5927\u5c0f\u6539\u53d8\u4e86\uff0c\u5982\u679c\u8981\u4f7f\u77e9\u9635\u5927\u5c0f\u4e0d\u6539\u53d8\u5462\uff0c\u6211\u4eec\u53ef\u4ee5\u5148\u5bf9\u77e9\u9635\u505a\u4e00\u4e2a\u586b\u5145\uff0c\u5c06\u77e9\u9635\u7684\u5468\u56f4\u5168\u90e8\u518d\u5305\u56f4\u4e00\u5c42\uff0c\u8fd9\u4e2a\u77e9\u9635\u5c31\u53d8\u6210\u4e86 7*7 ,\u4e0a\u4e0b\u5de6\u53f3\u5404\u52a01\uff0c\u76f8\u5f53\u4e8e 5+1+1=7 \u8fd9\u65f6\uff0c\u8ba1\u7b97\u7684\u7ed3\u679c\u8fd8\u662f 5 * 5 \u7684\u77e9\u9635\uff0c\u4fdd\u8bc1\u4e86\u5927\u5c0f\u4e0d\u53d8\uff0c\u8fd9\u91cc\u7684p=1","title":"\u8fb9\u754c\u586b\u5145 (p)adding"},{"location":"tutorial/chapter02_basics/2_4_convolutional-neural-network/#stride","text":"\u4ece\u52a8\u56fe\u4e0a\u6211\u4eec\u80fd\u591f\u770b\u5230\uff0c\u6bcf\u6b21\u6ed1\u52a8\u53ea\u662f\u6ed1\u52a8\u4e86\u4e00\u4e2a\u8ddd\u79bb\uff0c\u5982\u679c\u6bcf\u6b21\u6ed1\u52a8\u4e24\u4e2a\u8ddd\u79bb\u5462\uff1f\u90a3\u5c31\u9700\u8981\u4f7f\u7528\u6b65\u957f\u8fd9\u4e2a\u53c2\u6570\u3002","title":"\u6b65\u957f (s)tride"},{"location":"tutorial/chapter02_basics/2_4_convolutional-neural-network/#_3","text":"n\u4e3a\u6211\u4eec\u8f93\u5165\u7684\u77e9\u9635\u7684\u5927\u5c0f\uff0c$ \\frac{n-f+2p}{s} +1 $ \u5411\u4e0b\u53d6\u6574 \u8fd9\u4e2a\u516c\u5f0f\u975e\u5e38\u91cd\u8981\u4e00\u5b9a\u8981\u8bb0\u4f4f","title":"\u8ba1\u7b97\u516c\u5f0f"},{"location":"tutorial/chapter02_basics/2_4_convolutional-neural-network/#_4","text":"\u5728\u6bcf\u4e00\u4e2a\u5377\u79ef\u5c42\u4e2d\u6211\u4eec\u90fd\u4f1a\u8bbe\u7f6e\u591a\u4e2a\u6838\uff0c\u6bcf\u4e2a\u6838\u4ee3\u8868\u7740\u4e0d\u540c\u7684\u7279\u5f81\uff0c\u8fd9\u4e9b\u7279\u5f81\u5c31\u662f\u6211\u4eec\u9700\u8981\u4f20\u9012\u5230\u4e0b\u4e00\u5c42\u7684\u8f93\u51fa\uff0c\u800c\u6211\u4eec\u8bad\u7ec3\u7684\u8fc7\u7a0b\u5c31\u662f\u8bad\u7ec3\u8fd9\u4e9b\u4e0d\u540c\u7684\u6838\u3002","title":"\u5377\u79ef\u5c42"},{"location":"tutorial/chapter02_basics/2_4_convolutional-neural-network/#_5","text":"\u7531\u4e8e\u5377\u79ef\u7684\u64cd\u4f5c\u4e5f\u662f\u7ebf\u6027\u7684\uff0c\u6240\u4ee5\u4e5f\u9700\u8981\u8fdb\u884c\u6fc0\u6d3b\uff0c\u4e00\u822c\u60c5\u51b5\u4e0b\uff0c\u90fd\u4f1a\u4f7f\u7528relu\u3002","title":"\u6fc0\u6d3b\u51fd\u6570"},{"location":"tutorial/chapter02_basics/2_4_convolutional-neural-network/#pooling","text":"\u6c60\u5316\u5c42\u662fCNN\u7684\u91cd\u8981\u7ec4\u6210\u90e8\u5206\uff0c\u901a\u8fc7\u51cf\u5c11\u5377\u79ef\u5c42\u4e4b\u95f4\u7684\u8fde\u63a5\uff0c\u964d\u4f4e\u8fd0\u7b97\u590d\u6742\u7a0b\u5ea6\uff0c\u6c60\u5316\u5c42\u7684\u64cd\u4f5c\u5f88\u7b80\u5355\uff0c\u5c31\u60f3\u76f8\u5f53\u4e8e\u662f\u5408\u5e76\uff0c\u6211\u4eec\u8f93\u5165\u4e00\u4e2a\u8fc7\u6ee4\u5668\u7684\u5927\u5c0f\uff0c\u4e0e\u5377\u79ef\u7684\u64cd\u4f5c\u4e00\u6837\uff0c\u4e5f\u662f\u4e00\u6b65\u4e00\u6b65\u6ed1\u52a8\uff0c\u4f46\u662f\u8fc7\u6ee4\u5668\u8986\u76d6\u7684\u533a\u57df\u8fdb\u884c\u5408\u5e76\uff0c\u53ea\u4fdd\u7559\u4e00\u4e2a\u503c\u3002 \u5408\u5e76\u7684\u65b9\u5f0f\u4e5f\u6709\u5f88\u591a\u79cd\uff0c\u4f8b\u5982\u6211\u4eec\u5e38\u7528\u7684\u4e24\u79cd\u53d6\u6700\u5927\u503cmaxpooling\uff0c\u53d6\u5e73\u5747\u503cavgpooling \u6c60\u5316\u5c42\u7684\u8f93\u51fa\u5927\u5c0f\u516c\u5f0f\u4e5f\u4e0e\u5377\u79ef\u5c42\u4e00\u6837\uff0c\u7531\u4e8e\u6ca1\u6709\u8fdb\u884c\u586b\u5145\uff0c\u6240\u4ee5p=0\uff0c\u53ef\u4ee5\u7b80\u5316\u4e3a $ \\frac{n-f}{s} +1 $","title":"\u6c60\u5316\u5c42\uff08pooling\uff09"},{"location":"tutorial/chapter02_basics/2_4_convolutional-neural-network/#dropout","text":"dropout\u662f2014\u5e74 Hinton \u63d0\u51fa\u9632\u6b62\u8fc7\u62df\u5408\u800c\u91c7\u7528\u7684trick\uff0c\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b Dropout\uff08\u968f\u673a\u5931\u6d3b\uff09\u662f\u6307\u5728\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\u7684\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6309\u7167\u4e00\u5b9a\u7684\u6982\u7387\u5c06\u4e00\u90e8\u5206\u795e\u7ecf\u7f51\u7edc\u5355\u5143\u6682\u65f6\u4ece\u7f51\u7edc\u4e2d\u4e22\u5f03\uff0c\u76f8\u5f53\u4e8e\u4ece\u539f\u59cb\u7684\u7f51\u7edc\u4e2d\u627e\u5230\u4e00\u4e2a\u66f4\u7626\u7684\u7f51\u7edc\uff0c\u8bf4\u7684\u901a\u4fd7\u4e00\u70b9\uff0c\u5c31\u662f\u968f\u673a\u5c06\u4e00\u90e8\u5206\u7f51\u7edc\u7684\u4f20\u64ad\u6390\u65ad\uff0c\u542c\u8d77\u6765\u597d\u50cf\u4e0d\u9760\u8c31\uff0c\u4f46\u662f\u901a\u8fc7\u5b9e\u9645\u6d4b\u8bd5\u6548\u679c\u975e\u5e38\u597d\u3002 \u6709\u5174\u8da3\u7684\u53ef\u4ee5\u53bb\u770b\u4e00\u4e0b\u539f\u6587 Dropout: A Simple Way to Prevent Neural Networks from Overfitting \u8fd9\u91cc\u5c31\u4e0d\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u3002","title":"dropout\u5c42"},{"location":"tutorial/chapter02_basics/2_4_convolutional-neural-network/#_6","text":"\u5168\u94fe\u63a5\u5c42\u4e00\u822c\u662f\u4f5c\u4e3a\u6700\u540e\u7684\u8f93\u51fa\u5c42\u4f7f\u7528\uff0c\u5377\u79ef\u7684\u4f5c\u7528\u662f\u63d0\u53d6\u56fe\u50cf\u7684\u7279\u5f81\uff0c\u6700\u540e\u7684\u5168\u8fde\u63a5\u5c42\u5c31\u662f\u8981\u901a\u8fc7\u8fd9\u4e9b\u7279\u5f81\u6765\u8fdb\u884c\u8ba1\u7b97\uff0c\u8f93\u51fa\u6211\u4eec\u6240\u8981\u7684\u7ed3\u679c\u4e86\uff0c\u65e0\u8bba\u662f\u5206\u7c7b\uff0c\u8fd8\u662f\u56de\u5f52\u3002 \u6211\u4eec\u7684\u7279\u5f81\u90fd\u662f\u4f7f\u7528\u77e9\u9635\u8868\u793a\u7684\uff0c\u6240\u4ee5\u518d\u4f20\u5165\u5168\u8fde\u63a5\u5c42\u4e4b\u524d\u8fd8\u9700\u8981\u5bf9\u7279\u5f81\u8fdb\u884c\u538b\u6241\uff0c\u5c06\u4ed6\u8fd9\u4e9b\u7279\u5f81\u53d8\u6210\u4e00\u7ef4\u7684\u5411\u91cf\uff0c\u5982\u679c\u8981\u8fdb\u884c\u5206\u7c7b\u7684\u8bdd\uff0c\u5c31\u662f\u7528sofmax\u4f5c\u4e3a\u8f93\u51fa\uff0c\u5982\u679c\u8981\u662f\u56de\u5f52\u7684\u8bdd\u5c31\u76f4\u63a5\u4f7f\u7528linear\u5373\u53ef\u3002 \u4ee5\u4e0a\u5c31\u662f\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u51e0\u4e2a\u4e3b\u8981\u7684\u7ec4\u6210\u90e8\u5206\uff0c\u4e0b\u9762\u6211\u4eec\u4ecb\u7ecd\u4e00\u4e9b\u7ecf\u5178\u7684\u7f51\u7edc\u6a21\u578b","title":"\u5168\u8fde\u63a5\u5c42"},{"location":"tutorial/chapter02_basics/2_4_convolutional-neural-network/#243","text":"","title":"2.4.3 \u7ecf\u5178\u6a21\u578b"},{"location":"tutorial/chapter02_basics/2_4_convolutional-neural-network/#lenet-5","text":"1998\uff0c Yann LeCun \u7684 LeNet5 \u5b98\u7f51 \u5377\u79ef\u795e\u7ecf\u7f51\u8def\u7684\u5f00\u5c71\u4e4b\u4f5c\uff0c\u9ebb\u96c0\u867d\u5c0f\uff0c\u4f46\u4e94\u810f\u4ff1\u5168\uff0c\u5377\u79ef\u5c42\u3001pooling\u5c42\u3001\u5168\u8fde\u63a5\u5c42\uff0c\u8fd9\u4e9b\u90fd\u662f\u73b0\u4ee3CNN\u7f51\u7edc\u7684\u57fa\u672c\u7ec4\u4ef6 - \u7528\u5377\u79ef\u63d0\u53d6\u7a7a\u95f4\u7279\u5f81\uff1b - \u7531\u7a7a\u95f4\u5e73\u5747\u5f97\u5230\u5b50\u6837\u672c\uff1b - \u7528 tanh \u6216 sigmoid \u5f97\u5230\u975e\u7ebf\u6027\uff1b - \u7528 multi-layer neural network\uff08MLP\uff09\u4f5c\u4e3a\u6700\u7ec8\u5206\u7c7b\u5668\uff1b - \u5c42\u5c42\u4e4b\u95f4\u7528\u7a00\u758f\u7684\u8fde\u63a5\u77e9\u9635\uff0c\u4ee5\u907f\u514d\u5927\u7684\u8ba1\u7b97\u6210\u672c\u3002 \u8f93\u5165\uff1a\u56fe\u50cfSize\u4e3a32*32\u3002\u8fd9\u8981\u6bd4mnist\u6570\u636e\u5e93\u4e2d\u6700\u5927\u7684\u5b57\u6bcd(28*28)\u8fd8\u5927\u3002\u8fd9\u6837\u505a\u7684\u76ee\u7684\u662f\u5e0c\u671b\u6f5c\u5728\u7684\u660e\u663e\u7279\u5f81\uff0c\u5982\u7b14\u753b\u65ad\u7eed\u3001\u89d2\u70b9\u80fd\u591f\u51fa\u73b0\u5728\u6700\u9ad8\u5c42\u7279\u5f81\u76d1\u6d4b\u5b50\u611f\u53d7\u91ce\u7684\u4e2d\u5fc3\u3002 \u8f93\u51fa\uff1a10\u4e2a\u7c7b\u522b\uff0c\u5206\u522b\u4e3a0-9\u6570\u5b57\u7684\u6982\u7387 C1\u5c42\u662f\u4e00\u4e2a\u5377\u79ef\u5c42\uff0c\u67096\u4e2a\u5377\u79ef\u6838\uff08\u63d0\u53d66\u79cd\u5c40\u90e8\u7279\u5f81\uff09\uff0c\u6838\u5927\u5c0f\u4e3a5 * 5 S2\u5c42\u662fpooling\u5c42\uff0c\u4e0b\u91c7\u6837\uff08\u533a\u57df:2 * 2 \uff09\u964d\u4f4e\u7f51\u7edc\u8bad\u7ec3\u53c2\u6570\u53ca\u6a21\u578b\u7684\u8fc7\u62df\u5408\u7a0b\u5ea6\u3002 C3\u5c42\u662f\u7b2c\u4e8c\u4e2a\u5377\u79ef\u5c42\uff0c\u4f7f\u752816\u4e2a\u5377\u79ef\u6838\uff0c\u6838\u5927\u5c0f:5 * 5 \u63d0\u53d6\u7279\u5f81 S4\u5c42\u4e5f\u662f\u4e00\u4e2apooling\u5c42\uff0c\u533a\u57df:2*2 C5\u5c42\u662f\u6700\u540e\u4e00\u4e2a\u5377\u79ef\u5c42\uff0c\u5377\u79ef\u6838\u5927\u5c0f:5 * 5 \u5377\u79ef\u6838\u79cd\u7c7b:120 \u6700\u540e\u4f7f\u7528\u5168\u8fde\u63a5\u5c42\uff0c\u5c06C5\u7684120\u4e2a\u7279\u5f81\u8fdb\u884c\u5206\u7c7b\uff0c\u6700\u540e\u8f93\u51fa0-9\u7684\u6982\u7387 \u4e00\u4e0b\u4ee3\u7801\u6765\u81ea \u5b98\u65b9\u6559\u7a0b import torch.nn as nn class LeNet5 ( nn . Module ): def __init__ ( self ): super ( LeNet5 , self ) . __init__ () # 1 input image channel, 6 output channels, 5x5 square convolution # kernel self . conv1 = nn . Conv2d ( 1 , 6 , 5 ) self . conv2 = nn . Conv2d ( 6 , 16 , 5 ) # an affine operation: y = Wx + b self . fc1 = nn . Linear ( 16 * 5 * 5 , 120 ) # \u8fd9\u91cc\u8bba\u6587\u4e0a\u5199\u7684\u662fconv,\u5b98\u65b9\u6559\u7a0b\u7528\u4e86\u7ebf\u6027\u5c42 self . fc2 = nn . Linear ( 120 , 84 ) self . fc3 = nn . Linear ( 84 , 10 ) def forward ( self , x ): # Max pooling over a (2, 2) window x = F . max_pool2d ( F . relu ( self . conv1 ( x )), ( 2 , 2 )) # If the size is a square you can only specify a single number x = F . max_pool2d ( F . relu ( self . conv2 ( x )), 2 ) x = x . view ( - 1 , self . num_flat_features ( x )) x = F . relu ( self . fc1 ( x )) x = F . relu ( self . fc2 ( x )) x = self . fc3 ( x ) return x def num_flat_features ( self , x ): size = x . size ()[ 1 :] # all dimensions except the batch dimension num_features = 1 for s in size : num_features *= s return num_features net = LeNet5 () print ( net ) LeNet5( (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1)) (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)) (fc1): Linear(in_features=400, out_features=120, bias=True) (fc2): Linear(in_features=120, out_features=84, bias=True) (fc3): Linear(in_features=84, out_features=10, bias=True) )","title":"LeNet-5"},{"location":"tutorial/chapter02_basics/2_4_convolutional-neural-network/#alexnet","text":"2012\uff0cAlex Krizhevsky \u53ef\u4ee5\u7b97\u4f5cLeNet\u7684\u4e00\u4e2a\u66f4\u6df1\u548c\u66f4\u5e7f\u7684\u7248\u672c\uff0c\u53ef\u4ee5\u7528\u6765\u5b66\u4e60\u66f4\u590d\u6742\u7684\u5bf9\u8c61 \u8bba\u6587 - \u7528rectified linear units\uff08ReLU\uff09\u5f97\u5230\u975e\u7ebf\u6027\uff1b - \u4f7f\u7528 dropout \u6280\u5de7\u5728\u8bad\u7ec3\u671f\u95f4\u6709\u9009\u62e9\u6027\u5730\u5ffd\u7565\u5355\u4e2a\u795e\u7ecf\u5143\uff0c\u6765\u51cf\u7f13\u6a21\u578b\u7684\u8fc7\u62df\u5408\uff1b - \u91cd\u53e0\u6700\u5927\u6c60\uff0c\u907f\u514d\u5e73\u5747\u6c60\u7684\u5e73\u5747\u6548\u679c\uff1b - \u4f7f\u7528 GPU NVIDIA GTX 580 \u53ef\u4ee5\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f4\uff0c\u8fd9\u6bd4\u7528CPU\u5904\u7406\u5feb\u4e86 10 \u500d\uff0c\u6240\u4ee5\u53ef\u4ee5\u88ab\u7528\u4e8e\u66f4\u5927\u7684\u6570\u636e\u96c6\u548c\u56fe\u50cf\u4e0a\u3002 \u867d\u7136 AlexNet\u53ea\u67098\u5c42\uff0c\u4f46\u662f\u5b83\u670960M\u4ee5\u4e0a\u7684\u53c2\u6570\u603b\u91cf\uff0cAlexnet\u6709\u4e00\u4e2a\u7279\u6b8a\u7684\u8ba1\u7b97\u5c42\uff0cLRN\u5c42\uff0c\u505a\u7684\u4e8b\u662f\u5bf9\u5f53\u524d\u5c42\u7684\u8f93\u51fa\u7ed3\u679c\u505a\u5e73\u6ed1\u5904\u7406\uff0c\u8fd9\u91cc\u5c31\u4e0d\u505a\u8be6\u7ec6\u4ecb\u7ecd\u4e86\uff0c Alexnet\u7684\u6bcf\u4e00\u9636\u6bb5\uff08\u542b\u4e00\u6b21\u5377\u79ef\u4e3b\u8981\u8ba1\u7b97\u7684\u7b97\u4f5c\u4e00\u5c42\uff09\u53ef\u4ee5\u5206\u4e3a8\u5c42\uff1a 1. con - relu - pooling - LRN \uff1a \u8981\u6ce8\u610f\u7684\u662finput\u5c42\u662f227*227\uff0c\u800c\u4e0d\u662fpaper\u91cc\u9762\u7684224\uff0c\u8fd9\u91cc\u53ef\u4ee5\u7b97\u4e00\u4e0b\uff0c\u4e3b\u8981\u662f227\u53ef\u4ee5\u6574\u9664\u540e\u9762\u7684conv1\u8ba1\u7b97\uff0c224\u4e0d\u6574\u9664\u3002\u5982\u679c\u4e00\u5b9a\u8981\u7528224\u53ef\u4ee5\u901a\u8fc7\u81ea\u52a8\u8865\u8fb9\u5b9e\u73b0\uff0c\u4e0d\u8fc7\u5728input\u5c31\u8865\u8fb9\u611f\u89c9\u6ca1\u6709\u610f\u4e49\uff0c\u8865\u5f97\u4e5f\u662f0\uff0c\u8fd9\u5c31\u662f\u6211\u4eec\u4e0a\u9762\u8bf4\u7684\u516c\u5f0f\u7684\u91cd\u8981\u6027\u3002 conv - relu - pool - LRN \uff1a group=2\uff0c\u8fd9\u4e2a\u5c5e\u6027\u5f3a\u884c\u628a\u524d\u9762\u7ed3\u679c\u7684feature map\u5206\u5f00\uff0c\u5377\u79ef\u90e8\u5206\u5206\u6210\u4e24\u90e8\u5206\u505a conv - relu conv-relu conv - relu - pool fc - relu - dropout \uff1a dropout\u5c42\uff0c\u5728alexnet\u4e2d\u662f\u8bf4\u5728\u8bad\u7ec3\u7684\u4ee5\u00bd\u6982\u7387\u4f7f\u5f97\u9690\u85cf\u5c42\u7684\u67d0\u4e9bneuron\u7684\u8f93\u51fa\u4e3a0\uff0c\u8fd9\u6837\u5c31\u4e22\u5230\u4e86\u4e00\u534a\u8282\u70b9\u7684\u8f93\u51fa\uff0cBP\u7684\u65f6\u5019\u4e5f\u4e0d\u66f4\u65b0\u8fd9\u4e9b\u8282\u70b9\uff0c\u9632\u6b62\u8fc7\u62df\u5408\u3002 fc - relu - dropout fc - softmax \u5728Pytorch\u7684vision\u5305\u4e2d\u662f\u5305\u542bAlexnet\u7684\u5b98\u65b9\u5b9e\u73b0\u7684\uff0c\u6211\u4eec\u76f4\u63a5\u4f7f\u7528\u5b98\u65b9\u7248\u672c\u770b\u4e0b\u7f51\u7edc import torchvision model = torchvision . models . alexnet ( pretrained = False ) #\u6211\u4eec\u4e0d\u4e0b\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd print ( model ) AlexNet( (features): Sequential( (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2)) (1): ReLU(inplace) (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False) (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)) (4): ReLU(inplace) (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False) (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (7): ReLU(inplace) (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (9): ReLU(inplace) (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (11): ReLU(inplace) (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False) ) (classifier): Sequential( (0): Dropout(p=0.5) (1): Linear(in_features=9216, out_features=4096, bias=True) (2): ReLU(inplace) (3): Dropout(p=0.5) (4): Linear(in_features=4096, out_features=4096, bias=True) (5): ReLU(inplace) (6): Linear(in_features=4096, out_features=1000, bias=True) ) )","title":"AlexNet"},{"location":"tutorial/chapter02_basics/2_4_convolutional-neural-network/#vgg","text":"2015\uff0c\u725b\u6d25\u7684 VGG\u3002 \u8bba\u6587 \u6bcf\u4e2a\u5377\u79ef\u5c42\u4e2d\u4f7f\u7528\u66f4\u5c0f\u7684 3\u00d73 filters\uff0c\u5e76\u5c06\u5b83\u4eec\u7ec4\u5408\u6210\u5377\u79ef\u5e8f\u5217 \u591a\u4e2a3\u00d73\u5377\u79ef\u5e8f\u5217\u53ef\u4ee5\u6a21\u62df\u66f4\u5927\u7684\u63a5\u6536\u573a\u7684\u6548\u679c \u6bcf\u6b21\u7684\u56fe\u50cf\u50cf\u7d20\u7f29\u5c0f\u4e00\u500d\uff0c\u5377\u79ef\u6838\u7684\u6570\u91cf\u589e\u52a0\u4e00\u500d VGG\u6709\u5f88\u591a\u4e2a\u7248\u672c\uff0c\u4e5f\u7b97\u662f\u6bd4\u8f83\u7a33\u5b9a\u548c\u7ecf\u5178\u7684model\u3002\u5b83\u7684\u7279\u70b9\u4e5f\u662f\u8fde\u7eedconv\u591a\u8ba1\u7b97\u91cf\u5de8\u5927\uff0c\u8fd9\u91cc\u6211\u4eec\u4ee5VGG16\u4e3a\u4f8b. \u56fe\u7247\u6765\u6e90 VGG\u6e05\u4e00\u8272\u7528\u5c0f\u5377\u79ef\u6838\uff0c\u7ed3\u5408\u4f5c\u8005\u548c\u81ea\u5df1\u7684\u89c2\u70b9\uff0c\u8fd9\u91cc\u6574\u7406\u51fa\u5c0f\u5377\u79ef\u6838\u6bd4\u7528\u5927\u5377\u79ef\u6838\u7684\u4f18\u52bf\uff1a \u6839\u636e\u4f5c\u8005\u7684\u89c2\u70b9\uff0cinput8 -> 3\u5c42conv3x3\u540e\uff0coutput=2\uff0c\u7b49\u540c\u4e8e1\u5c42conv7x7\u7684\u7ed3\u679c\uff1b input=8 -> 2\u5c42conv3x3\u540e\uff0coutput=2\uff0c\u7b49\u540c\u4e8e2\u5c42conv5x5\u7684\u7ed3\u679c \u5377\u79ef\u5c42\u7684\u53c2\u6570\u51cf\u5c11\u3002\u76f8\u6bd45x5\u30017x7\u548c11x11\u7684\u5927\u5377\u79ef\u6838\uff0c3x3\u660e\u663e\u5730\u51cf\u5c11\u4e86\u53c2\u6570\u91cf \u901a\u8fc7\u5377\u79ef\u548c\u6c60\u5316\u5c42\u540e\uff0c\u56fe\u50cf\u7684\u5206\u8fa8\u7387\u964d\u4f4e\u4e3a\u539f\u6765\u7684\u4e00\u534a\uff0c\u4f46\u662f\u56fe\u50cf\u7684\u7279\u5f81\u589e\u52a0\u4e00\u500d\uff0c\u8fd9\u662f\u4e00\u4e2a\u5341\u5206\u89c4\u6574\u7684\u64cd\u4f5c: \u5206\u8fa8\u7387\u7531\u8f93\u5165\u7684224->112->56->28->14->7, \u7279\u5f81\u4ece\u539f\u59cb\u7684RGB3\u4e2a\u901a\u9053-> 64 ->128 -> 256 -> 512 \u8fd9\u4e3a\u540e\u9762\u7684\u7f51\u7edc\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6807\u51c6,\u6211\u4eec\u4f9d\u65e7\u4f7f\u7528Pytorch\u5b98\u65b9\u5b9e\u73b0\u7248\u672c\u6765\u67e5\u770b import torchvision model = torchvision . models . vgg16 ( pretrained = False ) #\u6211\u4eec\u4e0d\u4e0b\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd print ( model ) VGG( (features): Sequential( (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): ReLU(inplace) (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (3): ReLU(inplace) (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (6): ReLU(inplace) (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (8): ReLU(inplace) (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (11): ReLU(inplace) (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (13): ReLU(inplace) (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (15): ReLU(inplace) (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (18): ReLU(inplace) (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (20): ReLU(inplace) (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (22): ReLU(inplace) (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (25): ReLU(inplace) (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (27): ReLU(inplace) (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (29): ReLU(inplace) (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) ) (classifier): Sequential( (0): Linear(in_features=25088, out_features=4096, bias=True) (1): ReLU(inplace) (2): Dropout(p=0.5) (3): Linear(in_features=4096, out_features=4096, bias=True) (4): ReLU(inplace) (5): Dropout(p=0.5) (6): Linear(in_features=4096, out_features=1000, bias=True) ) )","title":"VGG"},{"location":"tutorial/chapter02_basics/2_4_convolutional-neural-network/#googlenet-inception","text":"2014\uff0cGoogle Christian Szegedy \u8bba\u6587 - \u4f7f\u75281\u00d71\u5377\u79ef\u5757\uff08NiN\uff09\u6765\u51cf\u5c11\u7279\u5f81\u6570\u91cf\uff0c\u8fd9\u901a\u5e38\u88ab\u79f0\u4e3a\u201c\u74f6\u9888\u201d\uff0c\u53ef\u4ee5\u51cf\u5c11\u6df1\u5c42\u795e\u7ecf\u7f51\u7edc\u7684\u8ba1\u7b97\u8d1f\u62c5\u3002 - \u6bcf\u4e2a\u6c60\u5316\u5c42\u4e4b\u524d\uff0c\u589e\u52a0 feature maps\uff0c\u589e\u52a0\u6bcf\u4e00\u5c42\u7684\u5bbd\u5ea6\u6765\u589e\u591a\u7279\u5f81\u7684\u7ec4\u5408\u6027 googlenet\u6700\u5927\u7684\u7279\u70b9\u5c31\u662f\u5305\u542b\u82e5\u5e72\u4e2ainception\u6a21\u5757\uff0c\u6240\u4ee5\u6709\u65f6\u5019\u4e5f\u79f0\u4f5c inception net googlenet\u867d\u7136\u5c42\u6570\u8981\u6bd4VGG\u591a\u5f88\u591a\uff0c\u4f46\u662f\u7531\u4e8einception\u7684\u8bbe\u8ba1\uff0c\u8ba1\u7b97\u901f\u5ea6\u65b9\u9762\u8981\u5feb\u5f88\u591a\u3002 \u4e0d\u8981\u88ab\u8fd9\u4e2a\u56fe\u5413\u5230\uff0c\u5176\u5b9e\u539f\u7406\u5f88\u7b80\u5355\u3002 Inception\u67b6\u6784\u7684\u4e3b\u8981\u601d\u60f3\u662f\u627e\u51fa\u5982\u4f55\u8ba9\u5df2\u6709\u7684\u7a20\u5bc6\u7ec4\u4ef6\u63a5\u8fd1\u4e0e\u8986\u76d6\u5377\u79ef\u89c6\u89c9\u7f51\u7edc\u4e2d\u7684\u6700\u4f73\u5c40\u90e8\u7a00\u758f\u7ed3\u6784\u3002\u73b0\u5728\u9700\u8981\u627e\u51fa\u6700\u4f18\u7684\u5c40\u90e8\u6784\u9020\uff0c\u5e76\u4e14\u91cd\u590d \u51e0\u6b21\u3002\u4e4b\u524d\u7684\u4e00\u7bc7\u6587\u732e\u63d0\u51fa\u4e00\u4e2a\u5c42\u4e0e\u5c42\u7684\u7ed3\u6784\uff0c\u5728\u6700\u540e\u4e00\u5c42\u8fdb\u884c\u76f8\u5173\u6027\u7edf\u8ba1\uff0c\u5c06\u9ad8\u76f8\u5173\u6027\u7684\u805a\u96c6\u5230\u4e00\u8d77\u3002\u8fd9\u4e9b\u805a\u7c7b\u6784\u6210\u4e0b\u4e00\u5c42\u7684\u5355\u5143\uff0c\u4e14\u4e0e\u4e0a\u4e00\u5c42\u5355\u5143\u8fde\u63a5\u3002\u5047\u8bbe\u524d \u9762\u5c42\u7684\u6bcf\u4e2a\u5355\u5143\u5bf9\u5e94\u4e8e\u8f93\u5165\u56fe\u50cf\u7684\u67d0\u4e9b\u533a\u57df\uff0c\u8fd9\u4e9b\u5355\u5143\u88ab\u5206\u4e3a\u6ee4\u6ce2\u5668\u7ec4\u3002\u5728\u63a5\u8fd1\u8f93\u5165\u5c42\u7684\u4f4e\u5c42\u4e2d\uff0c\u76f8\u5173\u5355\u5143\u96c6\u4e2d\u5728\u67d0\u4e9b\u5c40\u90e8\u533a\u57df\uff0c\u6700\u7ec8\u5f97\u5230\u5728\u5355\u4e2a\u533a\u57df\u4e2d\u7684\u5927\u91cf\u805a\u7c7b\uff0c\u5728\u6700\u540e\u4e00\u5c42\u901a\u8fc71x1\u7684\u5377\u79ef\u8986\u76d6\u3002 \u4e0a\u9762\u7684\u8bdd\u542c\u8d77\u6765\u5f88\u751f\u786c\uff0c\u5176\u5b9e\u89e3\u91ca\u8d77\u6765\u5f88\u7b80\u5355\uff1a\u6bcf\u4e00\u6a21\u5757\u6211\u4eec\u90fd\u662f\u7528\u82e5\u5e72\u4e2a\u4e0d\u540c\u7684\u7279\u5f81\u63d0\u53d6\u65b9\u5f0f\uff0c\u4f8b\u5982 3x3\u5377\u79ef\uff0c5x5\u5377\u79ef\uff0c1x1\u7684\u5377\u79ef\uff0cpooling\u7b49\uff0c\u90fd\u8ba1\u7b97\u4e00\u4e0b\uff0c\u6700\u540e\u518d\u628a\u8fd9\u4e9b\u7ed3\u679c\u901a\u8fc7Filter Concat\u6765\u8fdb\u884c\u8fde\u63a5\uff0c\u627e\u5230\u8fd9\u91cc\u9762\u4f5c\u7528\u6700\u5927\u7684\u3002\u800c\u7f51\u7edc\u91cc\u9762\u5305\u542b\u4e86\u8bb8\u591a\u8fd9\u6837\u7684\u6a21\u5757\uff0c\u8fd9\u6837\u4e0d\u7528\u6211\u4eec\u4eba\u4e3a\u53bb\u5224\u65ad\u54ea\u4e2a\u7279\u5f81\u63d0\u53d6\u65b9\u5f0f\u597d\uff0c\u7f51\u7edc\u4f1a\u81ea\u5df1\u89e3\u51b3\uff08\u662f\u4e0d\u662f\u6709\u70b9\u50cfAUTO ML\uff09\uff0c\u5728Pytorch\u4e2d\u5b9e\u73b0\u4e86InceptionA-E\uff0c\u8fd8\u6709InceptionAUX \u6a21\u5757\u3002 # inception_v3\u9700\u8981scipy\uff0c\u6240\u4ee5\u6ca1\u6709\u5b89\u88c5\u7684\u8bddpip install scipy \u4e00\u4e0b import torchvision model = torchvision . models . inception_v3 ( pretrained = False ) #\u6211\u4eec\u4e0d\u4e0b\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd print ( model ) Inception3( (Conv2d_1a_3x3): BasicConv2d( (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False) (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (Conv2d_2a_3x3): BasicConv2d( (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False) (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (Conv2d_2b_3x3): BasicConv2d( (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (Conv2d_3b_1x1): BasicConv2d( (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (Conv2d_4a_3x3): BasicConv2d( (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (Mixed_5b): InceptionA( (branch1x1): BasicConv2d( (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch5x5_1): BasicConv2d( (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch5x5_2): BasicConv2d( (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False) (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_1): BasicConv2d( (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_2): BasicConv2d( (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_3): BasicConv2d( (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch_pool): BasicConv2d( (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) ) (Mixed_5c): InceptionA( (branch1x1): BasicConv2d( (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch5x5_1): BasicConv2d( (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch5x5_2): BasicConv2d( (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False) (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_1): BasicConv2d( (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_2): BasicConv2d( (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_3): BasicConv2d( (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch_pool): BasicConv2d( (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) ) (Mixed_5d): InceptionA( (branch1x1): BasicConv2d( (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch5x5_1): BasicConv2d( (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch5x5_2): BasicConv2d( (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False) (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_1): BasicConv2d( (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_2): BasicConv2d( (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_3): BasicConv2d( (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch_pool): BasicConv2d( (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) ) (Mixed_6a): InceptionB( (branch3x3): BasicConv2d( (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False) (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_1): BasicConv2d( (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_2): BasicConv2d( (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_3): BasicConv2d( (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False) (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) ) (Mixed_6b): InceptionC( (branch1x1): BasicConv2d( (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7_1): BasicConv2d( (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7_2): BasicConv2d( (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False) (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7_3): BasicConv2d( (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_1): BasicConv2d( (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_2): BasicConv2d( (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False) (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_3): BasicConv2d( (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False) (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_4): BasicConv2d( (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False) (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_5): BasicConv2d( (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch_pool): BasicConv2d( (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) ) (Mixed_6c): InceptionC( (branch1x1): BasicConv2d( (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7_1): BasicConv2d( (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7_2): BasicConv2d( (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False) (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7_3): BasicConv2d( (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_1): BasicConv2d( (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_2): BasicConv2d( (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False) (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_3): BasicConv2d( (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False) (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_4): BasicConv2d( (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False) (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_5): BasicConv2d( (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch_pool): BasicConv2d( (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) ) (Mixed_6d): InceptionC( (branch1x1): BasicConv2d( (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7_1): BasicConv2d( (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7_2): BasicConv2d( (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False) (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7_3): BasicConv2d( (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_1): BasicConv2d( (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_2): BasicConv2d( (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False) (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_3): BasicConv2d( (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False) (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_4): BasicConv2d( (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False) (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_5): BasicConv2d( (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch_pool): BasicConv2d( (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) ) (Mixed_6e): InceptionC( (branch1x1): BasicConv2d( (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7_1): BasicConv2d( (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7_2): BasicConv2d( (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7_3): BasicConv2d( (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_1): BasicConv2d( (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_2): BasicConv2d( (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_3): BasicConv2d( (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_4): BasicConv2d( (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7dbl_5): BasicConv2d( (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch_pool): BasicConv2d( (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) ) (AuxLogits): InceptionAux( (conv0): BasicConv2d( (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (conv1): BasicConv2d( (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False) (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (fc): Linear(in_features=768, out_features=1000, bias=True) ) (Mixed_7a): InceptionD( (branch3x3_1): BasicConv2d( (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3_2): BasicConv2d( (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False) (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7x3_1): BasicConv2d( (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7x3_2): BasicConv2d( (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7x3_3): BasicConv2d( (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch7x7x3_4): BasicConv2d( (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) ) (Mixed_7b): InceptionE( (branch1x1): BasicConv2d( (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3_1): BasicConv2d( (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3_2a): BasicConv2d( (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False) (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3_2b): BasicConv2d( (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False) (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_1): BasicConv2d( (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_2): BasicConv2d( (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_3a): BasicConv2d( (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False) (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_3b): BasicConv2d( (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False) (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch_pool): BasicConv2d( (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) ) (Mixed_7c): InceptionE( (branch1x1): BasicConv2d( (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3_1): BasicConv2d( (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3_2a): BasicConv2d( (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False) (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3_2b): BasicConv2d( (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False) (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_1): BasicConv2d( (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_2): BasicConv2d( (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_3a): BasicConv2d( (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False) (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch3x3dbl_3b): BasicConv2d( (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False) (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) (branch_pool): BasicConv2d( (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True) ) ) (fc): Linear(in_features=2048, out_features=1000, bias=True) )","title":"GoogLeNet (Inception)"},{"location":"tutorial/chapter02_basics/2_4_convolutional-neural-network/#resnet","text":"2015\uff0cKaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun \u8bba\u6587 Kaiming He \u4f55\u51ef\u660e\uff08\u97f3\u8bd1\uff09\u8fd9\u4e2a\u5927\u795e\u5927\u5bb6\u4e00\u5b9a\u8981\u8bb0\u4f4f\uff0c\u73b0\u5728\u5f88\u591a\u8bba\u6587\u90fd\u6709\u4ed6\u53c2\u4e0e(mask rcnn, focal loss)\uff0cJian Sun\u5b59\u5251\u8001\u5e08\u5c31\u4e0d\u7528\u8bf4\u4e86\uff0c\u73b0\u5728\u65f7\u4e16\u79d1\u6280\u7684\u9996\u5e2d\u79d1\u5b66\u5bb6 \u521a\u624d\u7684googlenet\u5df2\u7ecf\u5f88\u6df1\u4e86\uff0cResNet\u53ef\u4ee5\u505a\u5230\u66f4\u6df1\uff0c\u901a\u8fc7\u6b8b\u5dee\u8ba1\u7b97\uff0c\u53ef\u4ee5\u8bad\u7ec3\u8d85\u8fc71000\u5c42\u7684\u7f51\u7edc\uff0c\u4fd7\u79f0\u8df3\u8fde\u63a5\u3002","title":"ResNet"},{"location":"tutorial/chapter02_basics/2_4_convolutional-neural-network/#_7","text":"\u7f51\u7edc\u5c42\u6570\u589e\u52a0\uff0c\u4f46\u662f\u5728\u8bad\u7ec3\u96c6\u4e0a\u7684\u51c6\u786e\u7387\u5374\u9971\u548c\u751a\u81f3\u4e0b\u964d\u4e86\u3002\u8fd9\u4e2a\u4e0d\u80fd\u89e3\u91ca\u4e3aoverfitting\uff0c\u56e0\u4e3aoverfit\u5e94\u8be5\u8868\u73b0\u4e3a\u5728\u8bad\u7ec3\u96c6\u4e0a\u8868\u73b0\u66f4\u597d\u624d\u5bf9\u3002\u8fd9\u4e2a\u5c31\u662f\u7f51\u7edc\u9000\u5316\u7684\u95ee\u9898\uff0c\u9000\u5316\u95ee\u9898\u8bf4\u660e\u4e86\u6df1\u5ea6\u7f51\u7edc\u4e0d\u80fd\u5f88\u7b80\u5355\u5730\u88ab\u5f88\u597d\u5730\u4f18\u5316\u3002","title":"\u9000\u5316\u95ee\u9898"},{"location":"tutorial/chapter02_basics/2_4_convolutional-neural-network/#_8","text":"\u6df1\u5c42\u7f51\u7edc\u7684\u540e\u9762\u90a3\u4e9b\u5c42\u662f\u6052\u7b49\u6620\u5c04\uff0c\u90a3\u4e48\u6a21\u578b\u5c31\u9000\u5316\u4e3a\u4e00\u4e2a\u6d45\u5c42\u7f51\u7edc\u3002\u90a3\u73b0\u5728\u8981\u89e3\u51b3\u7684\u5c31\u662f\u5b66\u4e60\u6052\u7b49\u6620\u5c04\u51fd\u6570\u4e86\u3002\u8ba9\u4e00\u4e9b\u5c42\u53bb\u62df\u5408\u4e00\u4e2a\u6f5c\u5728\u7684\u6052\u7b49\u6620\u5c04\u51fd\u6570H(x) = x\uff0c\u6bd4\u8f83\u56f0\u96be\u3002\u5982\u679c\u628a\u7f51\u7edc\u8bbe\u8ba1\u4e3aH(x) = F(x) + x\u3002\u6211\u4eec\u53ef\u4ee5\u8f6c\u6362\u4e3a\u5b66\u4e60\u4e00\u4e2a\u6b8b\u5dee\u51fd\u6570F(x) = H(x) - x. \u53ea\u8981F(x)=0\uff0c\u5c31\u6784\u6210\u4e86\u4e00\u4e2a\u6052\u7b49\u6620\u5c04H(x) = x. \u800c\u4e14\uff0c\u62df\u5408\u6b8b\u5dee\u80af\u5b9a\u66f4\u52a0\u5bb9\u6613\u3002 \u4ee5\u4e0a\u53c8\u5f88\u4e0d\u597d\u7406\u89e3\uff0c\u7ee7\u7eed\u89e3\u91ca\u4e0b\uff0c\u5148\u770b\u56fe\uff1a \u6211\u4eec\u5728\u6fc0\u6d3b\u51fd\u6570\u524d\u5c06\u4e0a\u4e00\u5c42\uff08\u6216\u51e0\u5c42\uff09\u7684\u8f93\u51fa\u4e0e\u672c\u5c42\u8ba1\u7b97\u7684\u8f93\u51fa\u76f8\u52a0\uff0c\u5c06\u6c42\u548c\u7684\u7ed3\u679c\u8f93\u5165\u5230\u6fc0\u6d3b\u51fd\u6570\u4e2d\u505a\u4e3a\u672c\u5c42\u7684\u8f93\u51fa\uff0c\u5f15\u5165\u6b8b\u5dee\u540e\u7684\u6620\u5c04\u5bf9\u8f93\u51fa\u7684\u53d8\u5316\u66f4\u654f\u611f\uff0c\u5176\u5b9e\u5c31\u662f\u770b\u672c\u5c42\u76f8\u5bf9\u524d\u51e0\u5c42\u662f\u5426\u6709\u5927\u7684\u53d8\u5316\uff0c\u76f8\u5f53\u4e8e\u662f\u4e00\u4e2a\u5dee\u5206\u653e\u5927\u5668\u7684\u4f5c\u7528\u3002\u56fe\u4e2d\u7684\u66f2\u7ebf\u5c31\u662f\u6b8b\u5dee\u4e2d\u7684shoutcut\uff0c\u4ed6\u5c06\u524d\u4e00\u5c42\u7684\u7ed3\u679c\u76f4\u63a5\u8fde\u63a5\u5230\u4e86\u672c\u5c42\uff0c\u4e5f\u5c31\u662f\u4fd7\u79f0\u7684\u8df3\u8fde\u63a5\u3002 \u6211\u4eec\u4ee5\u7ecf\u5178\u7684resnet18\u6765\u770b\u4e00\u4e0b\u7f51\u7edc\u7ed3\u6784 \u56fe\u7247\u6765\u6e90 import torchvision model = torchvision . models . resnet18 ( pretrained = False ) #\u6211\u4eec\u4e0d\u4e0b\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd print ( model ) ResNet( (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False) (layer1): Sequential( (0): BasicBlock( (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (1): BasicBlock( (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (layer2): Sequential( (0): BasicBlock( (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (layer3): Sequential( (0): BasicBlock( (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (layer4): Sequential( (0): BasicBlock( (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0) (fc): Linear(in_features=512, out_features=1000, bias=True) ) \u90a3\u4e48\u6211\u4eec\u8be5\u5982\u4f55\u9009\u62e9\u7f51\u7edc\u5462\uff1f \u6765\u6e90 \u4ee5\u4e0a\u8868\u683c\u53ef\u4ee5\u6e05\u695a\u7684\u770b\u5230\u51c6\u786e\u7387\u548c\u8ba1\u7b97\u91cf\u4e4b\u95f4\u7684\u5bf9\u6bd4\u3002\u6211\u7684\u5efa\u8bae\u662f\uff0c\u5c0f\u578b\u56fe\u7247\u5206\u7c7b\u4efb\u52a1\uff0cresnet18\u57fa\u672c\u4e0a\u5df2\u7ecf\u53ef\u4ee5\u4e86\uff0c\u5982\u679c\u771f\u5bf9\u51c6\u786e\u5ea6\u8981\u6c42\u6bd4\u8f83\u9ad8\uff0c\u518d\u9009\u5176\u4ed6\u66f4\u597d\u7684\u7f51\u7edc\u67b6\u6784\u3002","title":"\u6b8b\u5dee\u7f51\u7edc\u7684\u89e3\u51b3\u529e\u6cd5"},{"location":"tutorial/chapter02_basics/2_5_recurrent-neural-network/","text":"import torch torch . __version__ '1.0.0' 2.5 \u5faa\u73af\u795e\u7ecf\u7f51\u7edc \u00b6 2.5.1 RNN\u7b80\u4ecb \u00b6 \u6211\u4eec\u7684\u5927\u8111\u533a\u522b\u4e8e\u673a\u5668\u7684\u4e00\u4e2a\u6700\u5927\u7684\u7279\u5f81\u5c31\u662f\u6211\u4eec\u6709\u8bb0\u5fc6\uff0c\u5e76\u4e14\u80fd\u591f\u6839\u636e\u81ea\u5df1\u7684\u8bb0\u5fc6\u5bf9\u672a\u77e5\u7684\u4e8b\u52a1\u8fdb\u884c\u63a8\u5bfc\uff0c\u6211\u4eec\u7684\u601d\u60f3\u62e5\u6709\u6301\u4e45\u6027\u7684\u3002\u4f46\u662f\u672c\u6559\u7a0b\u76ee\u524d\u6240\u4ecb\u7ecd\u7684\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u5404\u4e2a\u5143\u7d20\u4e4b\u95f4\u662f\u76f8\u4e92\u72ec\u7acb\u7684\uff0c\u8f93\u5165\u4e0e\u8f93\u51fa\u662f\u72ec\u7acb\u7684\u3002 RNN\u7684\u8d77\u56e0 \u00b6 \u73b0\u5b9e\u4e16\u754c\u4e2d\uff0c\u5f88\u591a\u5143\u7d20\u90fd\u662f\u76f8\u4e92\u8fde\u63a5\u7684\uff0c\u6bd4\u5982\u5ba4\u5916\u7684\u6e29\u5ea6\u662f\u968f\u7740\u6c14\u5019\u7684\u53d8\u5316\u800c\u5468\u671f\u6027\u7684\u53d8\u5316\u7684\u3001\u6211\u4eec\u7684\u8bed\u8a00\u4e5f\u9700\u8981\u901a\u8fc7\u4e0a\u4e0b\u6587\u7684\u5173\u7cfb\u6765\u786e\u8ba4\u6240\u8868\u8fbe\u7684\u542b\u4e49\u3002\u4f46\u662f\u673a\u5668\u8981\u505a\u5230\u8fd9\u4e00\u6b65\u5c31\u76f8\u5f53\u5f97\u96be\u4e86\u3002\u56e0\u6b64\uff0c\u5c31\u6709\u4e86\u73b0\u5728\u7684\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff0c\u4ed6\u7684\u672c\u8d28\u662f\uff1a\u62e5\u6709\u8bb0\u5fc6\u7684\u80fd\u529b\uff0c\u5e76\u4e14\u4f1a\u6839\u636e\u8fd9\u4e9b\u8bb0\u5fc6\u7684\u5185\u5bb9\u6765\u8fdb\u884c\u63a8\u65ad\u3002\u56e0\u6b64\uff0c\u4ed6\u7684\u8f93\u51fa\u5c31\u4f9d\u8d56\u4e8e\u5f53\u524d\u7684\u8f93\u5165\u548c\u8bb0\u5fc6\u3002 \u4e3a\u4ec0\u4e48\u9700\u8981RNN \u00b6 RNN\u80cc\u540e\u7684\u60f3\u6cd5\u662f\u5229\u7528\u987a\u5e8f\u7684\u4fe1\u606f\u3002 \u5728\u4f20\u7edf\u7684\u795e\u7ecf\u7f51\u7edc\u4e2d\uff0c\u6211\u4eec\u5047\u8bbe\u6240\u6709\u8f93\u5165\uff08\u548c\u8f93\u51fa\uff09\u5f7c\u6b64\u72ec\u7acb\u3002 \u5982\u679c\u4f60\u60f3\u9884\u6d4b\u53e5\u5b50\u4e2d\u7684\u4e0b\u4e00\u4e2a\u5355\u8bcd\uff0c\u4f60\u5c31\u8981\u77e5\u9053\u5b83\u524d\u9762\u6709\u54ea\u4e9b\u5355\u8bcd\uff0c\u751a\u81f3\u8981\u770b\u5230\u540e\u9762\u7684\u5355\u8bcd\u624d\u80fd\u591f\u7ed9\u51fa\u6b63\u786e\u7684\u7b54\u6848\u3002 RNN\u4e4b\u6240\u4ee5\u79f0\u4e3a\u5faa\u73af\uff0c\u5c31\u662f\u56e0\u4e3a\u5b83\u4eec\u5bf9\u5e8f\u5217\u7684\u6bcf\u4e2a\u5143\u7d20\u90fd\u4f1a\u6267\u884c\u76f8\u540c\u7684\u4efb\u52a1\uff0c\u6240\u6709\u7684\u8f93\u51fa\u90fd\u53d6\u51b3\u4e8e\u5148\u524d\u7684\u8ba1\u7b97\u3002 \u4ece\u53e6\u4e00\u4e2a\u89d2\u5ea6\u8bb2RNN\u7684\u5b83\u662f\u6709\u201c\u8bb0\u5fc6\u201d\u7684\uff0c\u53ef\u4ee5\u6355\u83b7\u5230\u76ee\u524d\u4e3a\u6b62\u8ba1\u7b97\u7684\u4fe1\u606f\u3002 \u7406\u8bba\u4e0a\uff0cRNN\u53ef\u4ee5\u5728\u4efb\u610f\u957f\u7684\u5e8f\u5217\u4e2d\u4f7f\u7528\u4fe1\u606f\uff0c\u4f46\u5b9e\u9645\u4e0a\u5b83\u4eec\u4ec5\u9650\u4e8e\u56de\u987e\u51e0\u4e2a\u6b65\u9aa4\u3002 \u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u7684\u63d0\u51fa\u4fbf\u662f\u57fa\u4e8e\u8bb0\u5fc6\u6a21\u578b\u7684\u60f3\u6cd5\uff0c\u671f\u671b\u7f51\u7edc\u80fd\u591f\u8bb0\u4f4f\u524d\u9762\u51fa\u73b0\u7684\u7279\u5f81.\u5e76\u4f9d\u636e\u7279\u5f81\u63a8\u65ad\u540e\u9762\u7684\u7ed3\u679c\uff0c\u800c\u4e14\u6574\u4f53\u7684\u7f51\u7edc\u7ed3\u6784\u4e0d\u65ad\u5faa\u73af\uff0c\u56e0\u4e3a\u5f97\u540d\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u3002 RNN\u90fd\u80fd\u505a\u4ec0\u4e48 \u00b6 RNN\u5728\u8bb8\u591aNLP\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u5de8\u5927\u6210\u529f\u3002 \u5728\u8fd9\u4e00\u70b9\u4e0a\uff0c\u6211\u5e94\u8be5\u63d0\u5230\u6700\u5e38\u7528\u7684RNN\u7c7b\u578b\u662fLSTM\uff0c\u5b83\u5728\u6355\u83b7\u957f\u671f\u4f9d\u8d56\u6027\u65b9\u9762\u8981\u6bd4RNN\u597d\u5f97\u591a\u3002 \u4f46\u4e0d\u8981\u62c5\u5fc3\uff0cLSTM\u4e0e\u6211\u4eec\u5c06\u5728\u672c\u6559\u7a0b\u4e2d\u5f00\u53d1\u7684RNN\u57fa\u672c\u76f8\u540c\uff0c\u5b83\u4eec\u53ea\u662f\u91c7\u7528\u4e0d\u540c\u7684\u65b9\u5f0f\u6765\u8ba1\u7b97\u9690\u85cf\u72b6\u6001\u3002 \u6211\u4eec\u5c06\u5728\u540e\u9762\u66f4\u8be6\u7ec6\u5730\u4ecb\u7ecdLSTM\u3002 \u4ee5\u4e0b\u662fRNN\u5728NLP\u4e2d\u7684\u4e00\u4e9b\u793a\u4f8b\uff1a \u8bed\u8a00\u5efa\u6a21\u4e0e\u751f\u6210\u6587\u672c \u6211\u4eec\u901a\u8fc7\u8bed\u8a00\u7684\u5efa\u6a21\uff0c\u53ef\u4ee5\u901a\u8fc7\u7ed9\u5b9a\u7684\u5355\u8bcd\u751f\u6210\u4eba\u7c7b\u53ef\u4ee5\u7406\u89e3\u7684\u4ee5\u5047\u4e71\u771f\u7684\u6587\u672c \u673a\u5668\u7ffb\u8bd1 \u673a\u5668\u7ffb\u8bd1\u7c7b\u4f3c\u4e8e\u8bed\u8a00\u5efa\u6a21\uff0c\u6211\u4eec\u7684\u8f93\u5165\u6e90\u8bed\u8a00\u4e2d\u7684\u4e00\u7cfb\u5217\u5355\u8bcd\uff0c\u901a\u8fc7\u6a21\u578b\u7684\u8ba1\u7b97\u53ef\u4ee5\u8f93\u51fa\u76ee\u6807\u8bed\u8a00\u4e0e\u4e4b\u5bf9\u5e94\u7684\u5185\u5bb9\u3002 \u8bed\u97f3\u8bc6\u522b \u7ed9\u5b9a\u6765\u81ea\u58f0\u6ce2\u7684\u58f0\u5b66\u4fe1\u53f7\u7684\u8f93\u5165\u5e8f\u5217\uff0c\u6211\u4eec\u53ef\u4ee5\u9884\u6d4b\u4e00\u7cfb\u5217\u8bed\u97f3\u7247\u6bb5\u53ca\u5176\u6982\u7387\uff0c\u5e76\u628a\u8bed\u97f3\u8f6c\u5316\u6210\u6587\u5b57 \u751f\u6210\u56fe\u50cf\u63cf\u8ff0 \u4e0e\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u4e00\u8d77\uff0cRNN\u53ef\u4ee5\u751f\u6210\u672a\u6807\u8bb0\u56fe\u50cf\u7684\u63cf\u8ff0\u3002 2.5.2 RNN\u7684\u7f51\u7edc\u7ed3\u6784\u53ca\u539f\u7406 \u00b6 RNN \u00b6 \u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u7684\u57fa\u672c\u7ed3\u6784\u7279\u522b\u7b80\u5355\uff0c\u5c31\u662f\u5c06\u7f51\u7edc\u7684\u8f93\u51fa\u4fdd\u5b58\u5728\u4e00\u4e2a\u8bb0\u5fc6\u5355\u5143\u4e2d\uff0c\u8fd9\u4e2a\u8bb0\u5fc6\u5355\u5143\u548c\u4e0b\u4e00\u6b21\u7684\u8f93\u5165\u4e00\u8d77\u8fdb\u5165\u795e\u7ecf\u7f51\u7edc\u4e2d\u3002\u6211\u4eec\u53ef\u4ee5\u770b\u5230\u7f51\u7edc\u5728\u8f93\u5165\u7684\u65f6\u5019\u4f1a\u8054\u5408\u8bb0\u5fc6\u5355\u5143\u4e00\u8d77\u4f5c\u4e3a\u8f93\u5165\uff0c\u7f51\u7edc\u4e0d\u4ec5\u8f93\u51fa\u7ed3\u679c\uff0c\u8fd8\u4f1a\u5c06\u7ed3\u679c\u4fdd\u5b58\u5230\u8bb0\u5fc6\u5355\u5143\u4e2d\uff0c\u4e0b\u56fe\u5c31\u662f\u4e00\u4e2a\u6700\u7b80\u5355\u7684\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u5728\u8f93\u5165\u65f6\u7684\u7ed3\u6784\u793a\u610f\u56fe. \u56fe\u7247\u6765\u6e90 RNN \u53ef\u4ee5\u88ab\u770b\u505a\u662f\u540c\u4e00\u795e\u7ecf\u7f51\u7edc\u7684\u591a\u6b21\u8d4b\u503c\uff0c\u6bcf\u4e2a\u795e\u7ecf\u7f51\u7edc\u6a21\u5757\u4f1a\u628a\u6d88\u606f\u4f20\u9012\u7ed9\u4e0b\u4e00\u4e2a,\u6211\u4eec\u5c06\u8fd9\u4e2a\u56fe\u7684\u7ed3\u6784\u5c55\u5f00\uff1a \u7f51\u7edc\u4e2d\u5177\u6709\u5faa\u73af\u7ed3\u6784\uff0c\u8fd9\u4e5f\u662f\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u540d\u5b57\u7684\u7531\u6765\uff0c\u540c\u65f6\u6839\u636e\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u7684\u7ed3\u6784\u4e5f\u53ef\u4ee5\u770b\u51fa\u5b83\u5728\u5904\u7406\u5e8f\u5217\u7c7b\u578b\u7684\u6570\u636e\u4e0a\u5177\u6709\u5929\u7136\u7684\u4f18\u52bf.\u56e0\u4e3a\u7f51\u7edc\u672c\u8eab\u5c31\u662f \u4e00\u4e2a\u5e8f\u5217\u7ed3\u6784\uff0c\u8fd9\u4e5f\u662f\u6240\u6709\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u6700\u672c\u8d28\u7684\u7ed3\u6784\u3002 \u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u5177\u6709\u7279\u522b\u597d\u7684\u8bb0\u5fc6\u7279\u6027\uff0c\u80fd\u591f\u5c06\u8bb0\u5fc6\u5185\u5bb9\u5e94\u7528\u5230\u5f53\u524d\u60c5\u666f\u4e0b\uff0c\u4f46\u662f\u7f51\u7edc\u7684\u8bb0\u5fc6\u80fd\u529b\u5e76\u6ca1\u6709\u60f3\u8c61\u7684\u90a3\u4e48\u6709\u6548\u3002\u8bb0\u5fc6\u6700\u5927\u7684\u95ee\u9898\u5728\u4e8e\u5b83\u6709\u9057\u5fd8\u6027\uff0c\u6211\u4eec\u603b\u662f\u66f4\u52a0\u6e05\u695a\u5730\u8bb0\u5f97\u6700\u8fd1\u53d1\u751f\u7684\u4e8b\u60c5\u800c\u9057\u5fd8\u5f88\u4e45\u4e4b\u524d\u53d1\u751f\u7684\u4e8b\u60c5\uff0c\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u540c\u6837\u6709\u8fd9\u6837\u7684\u95ee\u9898\u3002 pytorch \u4e2d\u4f7f\u7528 nn.RNN \u7c7b\u6765\u642d\u5efa\u57fa\u4e8e\u5e8f\u5217\u7684\u5faa\u73af\u795e\u7ecf\u7f51\u7edc,\u5b83\u7684\u6784\u9020\u51fd\u6570\u6709\u4ee5\u4e0b\u51e0\u4e2a\u53c2\u6570\uff1a - nput_size\uff1a\u8f93\u5165\u6570\u636eX\u7684\u7279\u5f81\u503c\u7684\u6570\u76ee\u3002 - hidden_size\uff1a\u9690\u85cf\u5c42\u7684\u795e\u7ecf\u5143\u6570\u91cf\uff0c\u4e5f\u5c31\u662f\u9690\u85cf\u5c42\u7684\u7279\u5f81\u6570\u91cf\u3002 - num_layers\uff1a\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u7684\u5c42\u6570\uff0c\u9ed8\u8ba4\u503c\u662f 1\u3002 - bias\uff1a\u9ed8\u8ba4\u4e3a True\uff0c\u5982\u679c\u4e3a false \u5219\u8868\u793a\u795e\u7ecf\u5143\u4e0d\u4f7f\u7528 bias \u504f\u79fb\u53c2\u6570\u3002 - batch_first\uff1a\u5982\u679c\u8bbe\u7f6e\u4e3a True\uff0c\u5219\u8f93\u5165\u6570\u636e\u7684\u7ef4\u5ea6\u4e2d\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u5c31 \u662f batch \u503c\uff0c\u9ed8\u8ba4\u4e3a False\u3002\u9ed8\u8ba4\u60c5\u51b5\u4e0b\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u662f\u5e8f\u5217\u7684\u957f\u5ea6\uff0c \u7b2c\u4e8c\u4e2a\u7ef4\u5ea6\u624d\u662f - - batch\uff0c\u7b2c\u4e09\u4e2a\u7ef4\u5ea6\u662f\u7279\u5f81\u6570\u76ee\u3002 - dropout\uff1a\u5982\u679c\u4e0d\u4e3a\u7a7a\uff0c\u5219\u8868\u793a\u6700\u540e\u8ddf\u4e00\u4e2a dropout \u5c42\u629b\u5f03\u90e8\u5206\u6570\u636e\uff0c\u629b\u5f03\u6570\u636e\u7684\u6bd4\u4f8b\u7531\u8be5\u53c2\u6570\u6307\u5b9a\u3002 RNN \u4e2d\u6700\u4e3b\u8981\u7684\u53c2\u6570\u662f input_size \u548c hidden_size\uff0c\u8fd9\u4e24\u4e2a\u53c2\u6570\u52a1\u5fc5\u8981\u641e\u6e05\u695a\u3002\u5176\u4f59\u7684\u53c2\u6570\u901a\u5e38\u4e0d\u7528\u8bbe\u7f6e\uff0c\u91c7\u7528\u9ed8\u8ba4\u503c\u5c31\u53ef\u4ee5\u4e86\u3002 rnn = torch . nn . RNN ( 20 , 50 , 2 ) input = torch . randn ( 100 , 32 , 20 ) h_0 = torch . randn ( 2 , 32 , 50 ) output , hn = rnn ( input , h_0 ) print ( output . size (), hn . size ()) torch.Size([100, 32, 50]) torch.Size([2, 32, 50]) LSTM \u00b6 LSTM \u662f Long Short Term Memory Networks \u7684\u7f29\u5199\uff0c\u6309\u5b57\u9762\u7ffb\u8bd1\u5c31\u662f\u957f\u7684\u77ed\u65f6\u8bb0\u5fc6\u7f51\u7edc\u3002LSTM \u7684\u7f51\u7edc\u7ed3\u6784\u662f 1997 \u5e74\u7531 Hochreiter \u548c Schmidhuber \u63d0\u51fa\u7684\uff0c\u968f\u540e\u8fd9\u79cd\u7f51\u7edc\u7ed3\u6784\u53d8\u5f97\u975e\u5e38\u6d41\u884c\uff0c\u3002 LSTM\u867d\u7136\u53ea\u89e3\u51b3\u4e86\u77ed\u671f\u4f9d\u8d56\u7684\u95ee\u9898\uff0c\u5e76\u4e14\u5b83\u901a\u8fc7\u523b\u610f\u7684\u8bbe\u8ba1\u6765\u907f\u514d\u957f\u671f\u4f9d\u8d56\u95ee\u9898\uff0c\u8fd9\u6837\u7684\u505a\u6cd5\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u88ab\u8bc1\u660e\u8fd8\u662f\u5341\u5206\u6709\u6548\u7684\uff0c\u6709\u5f88\u591a\u4eba\u8ddf\u8fdb\u76f8\u5173\u7684\u5de5\u4f5c\u89e3\u51b3\u4e86\u5f88\u591a\u5b9e\u9645\u7684\u95ee\u9898\uff0c\u6240\u4ee5\u73b0\u5728LSTM \u4ecd\u7136\u88ab\u5e7f\u6cdb\u5730\u4f7f\u7528\u3002 \u56fe\u7247\u6765\u6e90 \u6807\u51c6\u7684\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u5185\u90e8\u53ea\u6709\u4e00\u4e2a\u7b80\u5355\u7684\u5c42\u7ed3\u6784\uff0c\u800c LSTM \u5185\u90e8\u6709 4 \u4e2a\u5c42\u7ed3\u6784\uff1a \u7b2c\u4e00\u5c42\u662f\u4e2a\u5fd8\u8bb0\u5c42\uff1a\u51b3\u5b9a\u72b6\u6001\u4e2d\u4e22\u5f03\u4ec0\u4e48\u4fe1\u606f \u7b2c\u4e8c\u5c42tanh\u5c42\u7528\u6765\u4ea7\u751f\u66f4\u65b0\u503c\u7684\u5019\u9009\u9879\uff0c\u8bf4\u660e\u72b6\u6001\u5728\u67d0\u4e9b\u7ef4\u5ea6\u4e0a\u9700\u8981\u52a0\u5f3a\uff0c\u5728\u67d0\u4e9b\u7ef4\u5ea6\u4e0a\u9700\u8981\u51cf\u5f31 \u7b2c\u4e09\u5c42sigmoid\u5c42\uff08\u8f93\u5165\u95e8\u5c42\uff09\uff0c\u5b83\u7684\u8f93\u51fa\u503c\u8981\u4e58\u5230tanh\u5c42\u7684\u8f93\u51fa\u4e0a\uff0c\u8d77\u5230\u4e00\u4e2a\u7f29\u653e\u7684\u4f5c\u7528\uff0c\u6781\u7aef\u60c5\u51b5\u4e0bsigmoid\u8f93\u51fa0\u8bf4\u660e\u76f8\u5e94\u7ef4\u5ea6\u4e0a\u7684\u72b6\u6001\u4e0d\u9700\u8981\u66f4\u65b0 \u6700\u540e\u4e00\u5c42 \u51b3\u5b9a\u8f93\u51fa\u4ec0\u4e48,\u8f93\u51fa\u503c\u8ddf\u72b6\u6001\u6709\u5173\u3002\u5019\u9009\u9879\u4e2d\u7684\u54ea\u4e9b\u90e8\u5206\u6700\u7ec8\u4f1a\u88ab\u8f93\u51fa\u7531\u4e00\u4e2asigmoid\u5c42\u6765\u51b3\u5b9a\u3002 pytorch \u4e2d\u4f7f\u7528 nn.LSTM \u7c7b\u6765\u642d\u5efa\u57fa\u4e8e\u5e8f\u5217\u7684\u5faa\u73af\u795e\u7ecf\u7f51\u7edc,\u4ed6\u7684\u53c2\u6570\u57fa\u672c\u4e0eRNN\u7c7b\u4f3c\uff0c\u8fd9\u91cc\u5c31\u4e0d\u5217\u51fa\u4e86\u3002 lstm = torch . nn . LSTM ( 10 , 20 , 2 ) input = torch . randn ( 5 , 3 , 10 ) h0 = torch . randn ( 2 , 3 , 20 ) c0 = torch . randn ( 2 , 3 , 20 ) output , hn = lstm ( input , ( h0 , c0 )) print ( output . size (), hn [ 0 ] . size (), hn [ 1 ] . size ()) torch.Size([5, 3, 20]) torch.Size([2, 3, 20]) torch.Size([2, 3, 20]) GRU \u00b6 GRU \u662f gated recurrent units \u7684\u7f29\u5199\uff0c\u7531 Cho\u5728 2014 \u5e74\u63d0\u51faGRU \u548c LSTM \u6700 \u7684\u4e0d\u540c\u5728\u4e8e GRU \u5c06\u9057\u5fd8\u95e8\u548c\u8f93\u5165\u95e8\u5408\u6210\u4e86\u4e00\u4e2a\"\u66f4\u65b0\u95e8\"\uff0c\u540c\u65f6\u7f51\u7edc\u4e0d\u518d\u989d\u5916\u7ed9\u51fa\u8bb0\u5fc6\u72b6\u6001\uff0c\u800c\u662f\u5c06\u8f93\u51fa\u7ed3\u679c\u4f5c\u4e3a\u8bb0\u5fc6\u72b6\u6001\u4e0d\u65ad\u5411\u540e\u5faa\u73af\u4f20\u9012\uff0c\u7f51\u7edc\u7684\u8f93\u4eba\u548c\u8f93\u51fa\u90fd\u53d8\u5f97\u7279\u522b\u7b80\u5355\u3002 rnn = torch . nn . GRU ( 10 , 20 , 2 ) input = torch . randn ( 5 , 3 , 10 ) h_0 = torch . randn ( 2 , 3 , 20 ) output , hn = rnn ( input , h0 ) print ( output . size (), h0 . size ()) torch.Size([5, 3, 20]) torch.Size([2, 3, 20]) 2.5.3 \u5faa\u73af\u7f51\u7edc\u7684\u5411\u540e\u4f20\u64ad\uff08BPTT\uff09 \u00b6 \u5728\u5411\u524d\u4f20\u64ad\u7684\u60c5\u51b5\u4e0b\uff0cRNN\u7684\u8f93\u5165\u968f\u7740\u6bcf\u4e00\u4e2a\u65f6\u95f4\u6b65\u524d\u8fdb\u3002\u5728\u53cd\u5411\u4f20\u64ad\u7684\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u201c\u56de\u5230\u8fc7\u53bb\u201d\u6539\u53d8\u6743\u91cd\uff0c\u56e0\u6b64\u6211\u4eec\u53eb\u5b83\u901a\u8fc7\u65f6\u95f4\u7684\u53cd\u5411\u4f20\u64ad\uff08BPTT\uff09\u3002 \u6211\u4eec\u901a\u5e38\u628a\u6574\u4e2a\u5e8f\u5217\uff08\u5355\u8bcd\uff09\u770b\u4f5c\u4e00\u4e2a\u8bad\u7ec3\u6837\u672c\uff0c\u6240\u4ee5\u603b\u7684\u8bef\u5dee\u662f\u6bcf\u4e2a\u65f6\u95f4\u6b65\uff08\u5b57\u7b26\uff09\u4e2d\u8bef\u5dee\u7684\u548c\u3002\u6743\u91cd\u5728\u6bcf\u4e00\u4e2a\u65f6\u95f4\u6b65\u957f\u662f\u76f8\u540c\u7684\uff08\u6240\u4ee5\u53ef\u4ee5\u8ba1\u7b97\u603b\u8bef\u5dee\u540e\u4e00\u8d77\u66f4\u65b0\uff09\u3002 1. \u4f7f\u7528\u9884\u6d4b\u8f93\u51fa\u548c\u5b9e\u9645\u8f93\u51fa\u8ba1\u7b97\u4ea4\u53c9\u71b5\u8bef\u5dee 2. \u7f51\u7edc\u6309\u7167\u65f6\u95f4\u6b65\u5b8c\u5168\u5c55\u5f00 3. \u5bf9\u4e8e\u5c55\u5f00\u7684\u7f51\u7edc\uff0c\u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u5b9e\u8df5\u6b65\u8ba1\u7b97\u6743\u91cd\u7684\u68af\u5ea6 4. \u56e0\u4e3a\u5bf9\u4e8e\u6240\u6709\u65f6\u95f4\u6b65\u6765\u8bf4\uff0c\u6743\u91cd\u90fd\u4e00\u6837\uff0c\u6240\u4ee5\u5bf9\u4e8e\u6240\u6709\u7684\u65f6\u95f4\u6b65\uff0c\u53ef\u4ee5\u4e00\u8d77\u5f97\u5230\u68af\u5ea6\uff08\u800c\u4e0d\u662f\u50cf\u795e\u7ecf\u7f51\u7edc\u4e00\u6837\u5bf9\u4e0d\u540c\u7684\u9690\u85cf\u5c42\u5f97\u5230\u4e0d\u540c\u7684\u68af\u5ea6\uff09 5. \u968f\u540e\u5bf9\u5faa\u73af\u795e\u7ecf\u5143\u7684\u6743\u91cd\u8fdb\u884c\u5347\u7ea7 RNN\u5c55\u5f00\u7684\u7f51\u7edc\u770b\u8d77\u6765\u50cf\u4e00\u4e2a\u666e\u901a\u7684\u795e\u7ecf\u7f51\u7edc\u3002\u53cd\u5411\u4f20\u64ad\u4e5f\u7c7b\u4f3c\u4e8e\u666e\u901a\u7684\u795e\u7ecf\u7f51\u7edc\uff0c\u53ea\u4e0d\u8fc7\u6211\u4eec\u4e00\u6b21\u5f97\u5230\u6240\u6709\u65f6\u95f4\u6b65\u7684\u68af\u5ea6\u3002\u5982\u679c\u6709100\u4e2a\u65f6\u95f4\u6b65\uff0c\u90a3\u4e48\u7f51\u7edc\u5c55\u5f00\u540e\u5c06\u53d8\u5f97\u975e\u5e38\u5de8\u5927\uff0c\u6240\u4ee5\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u624d\u4f1a\u51fa\u73b0LSTM\u548cGRU\u8fd9\u6837\u7684\u7ed3\u6784\u3002 \u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u76ee\u524d\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u5e94\u7528\u6700\u4e3a\u706b\u70ed\uff0c\u6240\u4ee5\u540e\u9762\u7684\u5185\u5bb9\u5c06\u4ecb\u7ecd\u4e00\u4e0b\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u5728\u5904\u7406NLP\u7684\u65f6\u5019\u9700\u8981\u7528\u5230\u7684\u4e00\u4e9b\u5176\u4ed6\u7684\u77e5\u8bc6 2.5.4 \u8bcd\u5d4c\u5165\uff08word embedding\uff09 \u00b6 \u5728\u6211\u4eec\u4eba\u7c7b\u4ea4\u6d41\u8fc7\u7a0b\u4e2d\u8868\u5f81\u8bcd\u6c47\u662f\u76f4\u63a5\u4f7f\u7528\u82f1\u6587\u5355\u8bcd\u6765\u8fdb\u884c\u8868\u5f81\u7684\uff0c\u4f46\u662f\u5bf9\u4e8e\u8ba1\u7b97\u673a\u6765\u8bf4\uff0c\u662f\u65e0\u6cd5\u76f4\u63a5\u8ba4\u8bc6\u5355\u8bcd\u7684\u3002\u4e3a\u4e86\u8ba9\u8ba1\u7b97\u673a\u80fd\u591f\u80fd\u66f4\u597d\u5730\u7406\u89e3\u6211\u4eec\u7684\u8bed\u8a00\uff0c\u5efa\u7acb\u66f4\u597d\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u6211\u4eec\u9700\u8981\u5c06\u8bcd\u6c47\u8fdb\u884c\u8868\u5f81\u3002 \u5728\u56fe\u50cf\u5206\u7c7b\u95ee\u9898\u4f1a\u4f7f\u7528 one-hot \u7f16\u7801.\u6bd4\u5982LeNet\u4e2d\u4e00\u5171\u670910\u4e2a\u6570\u5b570-9\uff0c\u5982\u679c\u8fd9\u4e2a\u6570\u5b57\u662f2\u7684\u8bdd\u7c7b\uff0c\u5b83\u7684 \u7f16\u7801\u5c31\u662f (0\uff0c0\uff0c1\uff0c0\uff0c 0\uff0c0 \uff0c0\uff0c0\uff0c0\uff0c0)\uff0c\u5bf9\u4e8e\u5206\u7c7b\u95ee\u9898\u8fd9\u6837\u8868\u793a\u5341\u5206\u7684\u6e05\u695a\uff0c\u4f46\u662f\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\uff0c\u56e0\u4e3a\u5355\u8bcd\u7684\u6570\u76ee\u8fc7\u591a\u6bd4\u5982\u6709 10000 \u4e2a\u4e0d\u540c\u7684\u8bcd\uff0c\u90a3\u4e48\u4f7f\u7528 one-hot \u8fd9\u6837\u7684\u65b9\u5f0f\u6765\u5b9a\u4e49\uff0c\u6548\u7387\u5c31\u7279\u522b\u4f4e\uff0c\u6bcf\u4e2a\u5355\u8bcd\u90fd\u662f 10000 \u7ef4\u7684\u5411\u91cf.\u5176\u4e2d\u53ea\u6709\u4e00\u4f4d\u662f 1 , \u5176\u4f59\u90fd\u662f 0\uff0c\u7279\u522b\u5360\u7528\u5185\u5b58,\u800c\u4e14\u4e5f\u4e0d\u80fd\u4f53\u73b0\u5355\u8bcd\u7684\u8bcd\u6027\uff0c\u56e0\u4e3a\u6bcf\u4e00\u4e2a\u5355\u8bcd\u90fd\u662f one-hot\uff0c\u867d\u7136\u6709\u4e9b\u5355\u8bcd\u5728\u8bed\u4e49\u4e0a\u4f1a\u66f4\u52a0\u63a5\u8fd1.\u4f46\u662f one-hot \u6ca1\u529e\u6cd5\u4f53\u73b0\u8fd9\u4e2a\u7279\u70b9\uff0c\u6240\u4ee5 \u5fc5\u987b\u4f7f\u7528\u53e6\u5916\u4e00\u79cd\u65b9\u5f0f\u5b9a\u4e49\u6bcf\u4e00\u4e2a\u5355\u8bcd\u3002 \u7528\u4e0d\u540c\u7684\u7279\u5f81\u6765\u5bf9\u5404\u4e2a\u8bcd\u6c47\u8fdb\u884c\u8868\u5f81\uff0c\u76f8\u5bf9\u4e0e\u4e0d\u540c\u7684\u7279\u5f81\uff0c\u4e0d\u540c\u7684\u5355\u8bcd\u5747\u6709\u4e0d\u540c\u7684\u503c\u8fd9\u5c31\u662f\u8bcd\u5d4c\u5165\u3002\u4e0b\u56fe\u8fd8\u662f\u6765\u81ea\u5434\u6069\u8fbe\u8001\u5e08\u7684\u8bfe\u7a0b\u622a\u56fe\uff1a \u8bcd\u5d4c\u5165\u4e0d\u4ec5\u5bf9\u4e0d\u540c\u5355\u8bcd\u5b9e\u73b0\u4e86\u7279\u5f81\u5316\u7684\u8868\u793a\uff0c\u8fd8\u80fd\u901a\u8fc7\u8ba1\u7b97\u8bcd\u4e0e\u8bcd\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6\uff0c\u5b9e\u9645\u4e0a\u662f\u5728\u591a\u7ef4\u7a7a\u95f4\u4e2d\uff0c\u5bfb\u627e\u8bcd\u5411\u91cf\u4e4b\u95f4\u5404\u4e2a\u7ef4\u5ea6\u7684\u8ddd\u79bb\u76f8\u4f3c\u5ea6\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u5b9e\u73b0\u7c7b\u6bd4\u63a8\u7406\uff0c\u6bd4\u5982\u8bf4\u590f\u5929\u548c\u70ed\uff0c\u51ac\u5929\u548c\u51b7\uff0c\u90fd\u662f\u6709\u5173\u8054\u5173\u7cfb\u7684\u3002 \u5728 PyTorch \u4e2d\u6211\u4eec\u7528 nn.Embedding \u5c42\u6765\u505a\u5d4c\u5165\u8bcd\u888b\u6a21\u578b\uff0cEmbedding\u5c42\u7b2c\u4e00\u4e2a\u8f93\u5165\u8868\u793a\u6211\u4eec\u6709\u591a\u5c11\u4e2a\u8bcd\uff0c\u7b2c\u4e8c\u4e2a\u8f93\u5165\u8868\u793a\u6bcf\u4e00\u4e2a\u8bcd\u4f7f\u7528\u591a\u5c11\u4e2a\u5411\u91cf\u8868\u793a\u3002 # an Embedding module containing 10 tensors of size 3 embedding = torch . nn . Embedding ( 10 , 3 ) # a batch of 2 samples of 4 indices each input = torch . LongTensor ([[ 1 , 2 , 4 , 5 ],[ 4 , 3 , 2 , 9 ]]) output = embedding ( input ) print ( output . size ()) torch.Size([2, 4, 3]) 2.5.5 \u5176\u4ed6\u91cd\u8981\u6982\u5ff5 \u00b6 Beam search \u00b6 \u5728\u751f\u6210\u7b2c\u4e00\u4e2a\u8bcd\u7684\u5206\u5e03\u540e\uff0c\u53ef\u4ee5\u4f7f\u7528\u8d2a\u5fc3\u641c\u7d22\u4f1a\u6839\u636e\u6211\u4eec\u7684\u6761\u4ef6\u8bed\u8a00\u6a21\u578b\u6311\u9009\u51fa\u6700\u6709\u53ef\u80fd\u8f93\u51fa\u7684\u7b2c\u4e00\u4e2a\u8bcd\u8bed\uff0c\u4f46\u662f\u5bf9\u4e8e\u8d2a\u5fc3\u641c\u7d22\u7b97\u6cd5\u6765\u8bf4\uff0c\u6211\u4eec\u7684\u5355\u8bcd\u5e93\u4e2d\u6709\u6210\u767e\u5230\u5343\u4e07\u7684\u8bcd\u6c47\uff0c\u53bb\u8ba1\u7b97\u6bcf\u4e00\u79cd\u5355\u8bcd\u7684\u7ec4\u5408\u7684\u53ef\u80fd\u6027\u662f\u4e0d\u53ef\u884c\u7684\u3002\u6240\u4ee5\u6211\u4eec\u4f7f\u7528\u8fd1\u4f3c\u7684\u641c\u7d22\u529e\u6cd5\uff0c\u4f7f\u5f97\u6761\u4ef6\u6982\u7387\u6700\u5927\u5316\u6216\u8005\u8fd1\u4f3c\u6700\u5927\u5316\u7684\u53e5\u5b50\uff0c\u800c\u4e0d\u662f\u901a\u8fc7\u5355\u8bcd\u53bb\u5b9e\u73b0\u3002 Beam Search\uff08\u96c6\u675f\u641c\u7d22\uff09\u662f\u4e00\u79cd\u542f\u53d1\u5f0f\u56fe\u641c\u7d22\u7b97\u6cd5\uff0c\u901a\u5e38\u7528\u5728\u56fe\u7684\u89e3\u7a7a\u95f4\u6bd4\u8f83\u5927\u7684\u60c5\u51b5\u4e0b\uff0c\u4e3a\u4e86\u51cf\u5c11\u641c\u7d22\u6240\u5360\u7528\u7684\u7a7a\u95f4\u548c\u65f6\u95f4\uff0c\u5728\u6bcf\u4e00\u6b65\u6df1\u5ea6\u6269\u5c55\u7684\u65f6\u5019\uff0c\u526a\u6389\u4e00\u4e9b\u8d28\u91cf\u6bd4\u8f83\u5dee\u7684\u7ed3\u70b9\uff0c\u4fdd\u7559\u4e0b\u4e00\u4e9b\u8d28\u91cf\u8f83\u9ad8\u7684\u7ed3\u70b9\u3002\u867d\u7136Beam Search\u7b97\u6cd5\u662f\u4e0d\u5b8c\u5168\u7684\uff0c\u4f46\u662f\u7528\u4e8e\u4e86\u89e3\u7a7a\u95f4\u8f83\u5927\u7684\u7cfb\u7edf\u4e2d\uff0c\u53ef\u4ee5\u51cf\u5c11\u7a7a\u95f4\u5360\u7528\u548c\u65f6\u95f4\u3002 beam search\u53ef\u4ee5\u770b\u505a\u662f\u505a\u4e86\u7ea6\u675f\u4f18\u5316\u7684\u5e7f\u5ea6\u4f18\u5148\u641c\u7d22\uff0c\u9996\u5148\u4f7f\u7528\u5e7f\u5ea6\u4f18\u5148\u7b56\u7565\u5efa\u7acb\u641c\u7d22\u6811\uff0c\u6811\u7684\u6bcf\u5c42\uff0c\u6309\u7167\u542f\u53d1\u4ee3\u4ef7\u5bf9\u8282\u70b9\u8fdb\u884c\u6392\u5e8f\uff0c\u7136\u540e\u4ec5\u7559\u4e0b\u9884\u5148\u786e\u5b9a\u7684\u4e2a\u6570\uff08Beam width-\u96c6\u675f\u5bbd\u5ea6\uff09\u7684\u8282\u70b9\uff0c\u4ec5\u8fd9\u4e9b\u8282\u70b9\u5728\u4e0b\u4e00\u5c42\u6b21\u7ee7\u7eed\u6269\u5c55\uff0c\u5176\u4ed6\u8282\u70b9\u88ab\u526a\u5207\u6389\u3002 1. \u5c06\u521d\u59cb\u8282\u70b9\u63d2\u5165\u5230list\u4e2d 2. \u5c06\u7ed9\u8282\u70b9\u51fa\u5806\uff0c\u5982\u679c\u8be5\u8282\u70b9\u662f\u76ee\u6807\u8282\u70b9\uff0c\u5219\u7b97\u6cd5\u7ed3\u675f\uff1b 3. \u5426\u5219\u6269\u5c55\u8be5\u8282\u70b9\uff0c\u53d6\u96c6\u675f\u5bbd\u5ea6\u7684\u8282\u70b9\u5165\u5806\u3002\u7136\u540e\u5230\u7b2c\u4e8c\u6b65\u7ee7\u7eed\u5faa\u73af\u3002 4. \u7b97\u6cd5\u7ed3\u675f\u7684\u6761\u4ef6\u662f\u627e\u5230\u6700\u4f18\u89e3\u6216\u8005\u5806\u4e3a\u7a7a\u3002 \u5728\u4f7f\u7528\u4e0a\uff0c\u96c6\u675f\u5bbd\u5ea6\u53ef\u4ee5\u662f\u9884\u5148\u7ea6\u5b9a\u7684\uff0c\u4e5f\u53ef\u4ee5\u662f\u53d8\u5316\u7684\uff0c\u5177\u4f53\u53ef\u4ee5\u6839\u636e\u5b9e\u9645\u573a\u666f\u8c03\u6574\u8bbe\u5b9a\u3002 \u6ce8\u610f\u529b\u6a21\u578b \u00b6 \u5bf9\u4e8e\u4f7f\u7528\u7f16\u7801\u548c\u89e3\u7801\u7684RNN\u6a21\u578b\uff0c\u6211\u4eec\u80fd\u591f\u5b9e\u73b0\u8f83\u4e3a\u51c6\u786e\u5ea6\u673a\u5668\u7ffb\u8bd1\u7ed3\u679c\u3002\u5bf9\u4e8e\u77ed\u53e5\u5b50\u6765\u8bf4\uff0c\u5176\u6027\u80fd\u662f\u5341\u5206\u826f\u597d\u7684\uff0c\u4f46\u662f\u5982\u679c\u662f\u5f88\u957f\u7684\u53e5\u5b50\uff0c\u7ffb\u8bd1\u7684\u7ed3\u679c\u5c31\u4f1a\u53d8\u5dee\u3002 \u6211\u4eec\u4eba\u7c7b\u8fdb\u884c\u4eba\u5de5\u7ffb\u8bd1\u7684\u65f6\u5019\uff0c\u90fd\u662f\u4e00\u90e8\u5206\u4e00\u90e8\u5206\u5730\u8fdb\u884c\u7ffb\u8bd1\uff0c\u5f15\u5165\u7684\u6ce8\u610f\u529b\u673a\u5236\uff0c\u548c\u4eba\u7c7b\u7684\u7ffb\u8bd1\u8fc7\u7a0b\u975e\u5e38\u76f8\u4f3c\uff0c\u5176\u4e5f\u662f\u4e00\u90e8\u5206\u4e00\u90e8\u5206\u5730\u8fdb\u884c\u957f\u53e5\u5b50\u7684\u7ffb\u8bd1\u3002 \u5177\u4f53\u7684\u5185\u5bb9\u5728\u8fd9\u91cc\u5c31\u4e0d\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u3002","title":"2.5 Recurrent Neural Network"},{"location":"tutorial/chapter02_basics/2_5_recurrent-neural-network/#25","text":"","title":"2.5 \u5faa\u73af\u795e\u7ecf\u7f51\u7edc"},{"location":"tutorial/chapter02_basics/2_5_recurrent-neural-network/#251-rnn","text":"\u6211\u4eec\u7684\u5927\u8111\u533a\u522b\u4e8e\u673a\u5668\u7684\u4e00\u4e2a\u6700\u5927\u7684\u7279\u5f81\u5c31\u662f\u6211\u4eec\u6709\u8bb0\u5fc6\uff0c\u5e76\u4e14\u80fd\u591f\u6839\u636e\u81ea\u5df1\u7684\u8bb0\u5fc6\u5bf9\u672a\u77e5\u7684\u4e8b\u52a1\u8fdb\u884c\u63a8\u5bfc\uff0c\u6211\u4eec\u7684\u601d\u60f3\u62e5\u6709\u6301\u4e45\u6027\u7684\u3002\u4f46\u662f\u672c\u6559\u7a0b\u76ee\u524d\u6240\u4ecb\u7ecd\u7684\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u5404\u4e2a\u5143\u7d20\u4e4b\u95f4\u662f\u76f8\u4e92\u72ec\u7acb\u7684\uff0c\u8f93\u5165\u4e0e\u8f93\u51fa\u662f\u72ec\u7acb\u7684\u3002","title":"2.5.1 RNN\u7b80\u4ecb"},{"location":"tutorial/chapter02_basics/2_5_recurrent-neural-network/#rnn","text":"\u73b0\u5b9e\u4e16\u754c\u4e2d\uff0c\u5f88\u591a\u5143\u7d20\u90fd\u662f\u76f8\u4e92\u8fde\u63a5\u7684\uff0c\u6bd4\u5982\u5ba4\u5916\u7684\u6e29\u5ea6\u662f\u968f\u7740\u6c14\u5019\u7684\u53d8\u5316\u800c\u5468\u671f\u6027\u7684\u53d8\u5316\u7684\u3001\u6211\u4eec\u7684\u8bed\u8a00\u4e5f\u9700\u8981\u901a\u8fc7\u4e0a\u4e0b\u6587\u7684\u5173\u7cfb\u6765\u786e\u8ba4\u6240\u8868\u8fbe\u7684\u542b\u4e49\u3002\u4f46\u662f\u673a\u5668\u8981\u505a\u5230\u8fd9\u4e00\u6b65\u5c31\u76f8\u5f53\u5f97\u96be\u4e86\u3002\u56e0\u6b64\uff0c\u5c31\u6709\u4e86\u73b0\u5728\u7684\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff0c\u4ed6\u7684\u672c\u8d28\u662f\uff1a\u62e5\u6709\u8bb0\u5fc6\u7684\u80fd\u529b\uff0c\u5e76\u4e14\u4f1a\u6839\u636e\u8fd9\u4e9b\u8bb0\u5fc6\u7684\u5185\u5bb9\u6765\u8fdb\u884c\u63a8\u65ad\u3002\u56e0\u6b64\uff0c\u4ed6\u7684\u8f93\u51fa\u5c31\u4f9d\u8d56\u4e8e\u5f53\u524d\u7684\u8f93\u5165\u548c\u8bb0\u5fc6\u3002","title":"RNN\u7684\u8d77\u56e0"},{"location":"tutorial/chapter02_basics/2_5_recurrent-neural-network/#rnn_1","text":"RNN\u80cc\u540e\u7684\u60f3\u6cd5\u662f\u5229\u7528\u987a\u5e8f\u7684\u4fe1\u606f\u3002 \u5728\u4f20\u7edf\u7684\u795e\u7ecf\u7f51\u7edc\u4e2d\uff0c\u6211\u4eec\u5047\u8bbe\u6240\u6709\u8f93\u5165\uff08\u548c\u8f93\u51fa\uff09\u5f7c\u6b64\u72ec\u7acb\u3002 \u5982\u679c\u4f60\u60f3\u9884\u6d4b\u53e5\u5b50\u4e2d\u7684\u4e0b\u4e00\u4e2a\u5355\u8bcd\uff0c\u4f60\u5c31\u8981\u77e5\u9053\u5b83\u524d\u9762\u6709\u54ea\u4e9b\u5355\u8bcd\uff0c\u751a\u81f3\u8981\u770b\u5230\u540e\u9762\u7684\u5355\u8bcd\u624d\u80fd\u591f\u7ed9\u51fa\u6b63\u786e\u7684\u7b54\u6848\u3002 RNN\u4e4b\u6240\u4ee5\u79f0\u4e3a\u5faa\u73af\uff0c\u5c31\u662f\u56e0\u4e3a\u5b83\u4eec\u5bf9\u5e8f\u5217\u7684\u6bcf\u4e2a\u5143\u7d20\u90fd\u4f1a\u6267\u884c\u76f8\u540c\u7684\u4efb\u52a1\uff0c\u6240\u6709\u7684\u8f93\u51fa\u90fd\u53d6\u51b3\u4e8e\u5148\u524d\u7684\u8ba1\u7b97\u3002 \u4ece\u53e6\u4e00\u4e2a\u89d2\u5ea6\u8bb2RNN\u7684\u5b83\u662f\u6709\u201c\u8bb0\u5fc6\u201d\u7684\uff0c\u53ef\u4ee5\u6355\u83b7\u5230\u76ee\u524d\u4e3a\u6b62\u8ba1\u7b97\u7684\u4fe1\u606f\u3002 \u7406\u8bba\u4e0a\uff0cRNN\u53ef\u4ee5\u5728\u4efb\u610f\u957f\u7684\u5e8f\u5217\u4e2d\u4f7f\u7528\u4fe1\u606f\uff0c\u4f46\u5b9e\u9645\u4e0a\u5b83\u4eec\u4ec5\u9650\u4e8e\u56de\u987e\u51e0\u4e2a\u6b65\u9aa4\u3002 \u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u7684\u63d0\u51fa\u4fbf\u662f\u57fa\u4e8e\u8bb0\u5fc6\u6a21\u578b\u7684\u60f3\u6cd5\uff0c\u671f\u671b\u7f51\u7edc\u80fd\u591f\u8bb0\u4f4f\u524d\u9762\u51fa\u73b0\u7684\u7279\u5f81.\u5e76\u4f9d\u636e\u7279\u5f81\u63a8\u65ad\u540e\u9762\u7684\u7ed3\u679c\uff0c\u800c\u4e14\u6574\u4f53\u7684\u7f51\u7edc\u7ed3\u6784\u4e0d\u65ad\u5faa\u73af\uff0c\u56e0\u4e3a\u5f97\u540d\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u3002","title":"\u4e3a\u4ec0\u4e48\u9700\u8981RNN"},{"location":"tutorial/chapter02_basics/2_5_recurrent-neural-network/#rnn_2","text":"RNN\u5728\u8bb8\u591aNLP\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u5de8\u5927\u6210\u529f\u3002 \u5728\u8fd9\u4e00\u70b9\u4e0a\uff0c\u6211\u5e94\u8be5\u63d0\u5230\u6700\u5e38\u7528\u7684RNN\u7c7b\u578b\u662fLSTM\uff0c\u5b83\u5728\u6355\u83b7\u957f\u671f\u4f9d\u8d56\u6027\u65b9\u9762\u8981\u6bd4RNN\u597d\u5f97\u591a\u3002 \u4f46\u4e0d\u8981\u62c5\u5fc3\uff0cLSTM\u4e0e\u6211\u4eec\u5c06\u5728\u672c\u6559\u7a0b\u4e2d\u5f00\u53d1\u7684RNN\u57fa\u672c\u76f8\u540c\uff0c\u5b83\u4eec\u53ea\u662f\u91c7\u7528\u4e0d\u540c\u7684\u65b9\u5f0f\u6765\u8ba1\u7b97\u9690\u85cf\u72b6\u6001\u3002 \u6211\u4eec\u5c06\u5728\u540e\u9762\u66f4\u8be6\u7ec6\u5730\u4ecb\u7ecdLSTM\u3002 \u4ee5\u4e0b\u662fRNN\u5728NLP\u4e2d\u7684\u4e00\u4e9b\u793a\u4f8b\uff1a \u8bed\u8a00\u5efa\u6a21\u4e0e\u751f\u6210\u6587\u672c \u6211\u4eec\u901a\u8fc7\u8bed\u8a00\u7684\u5efa\u6a21\uff0c\u53ef\u4ee5\u901a\u8fc7\u7ed9\u5b9a\u7684\u5355\u8bcd\u751f\u6210\u4eba\u7c7b\u53ef\u4ee5\u7406\u89e3\u7684\u4ee5\u5047\u4e71\u771f\u7684\u6587\u672c \u673a\u5668\u7ffb\u8bd1 \u673a\u5668\u7ffb\u8bd1\u7c7b\u4f3c\u4e8e\u8bed\u8a00\u5efa\u6a21\uff0c\u6211\u4eec\u7684\u8f93\u5165\u6e90\u8bed\u8a00\u4e2d\u7684\u4e00\u7cfb\u5217\u5355\u8bcd\uff0c\u901a\u8fc7\u6a21\u578b\u7684\u8ba1\u7b97\u53ef\u4ee5\u8f93\u51fa\u76ee\u6807\u8bed\u8a00\u4e0e\u4e4b\u5bf9\u5e94\u7684\u5185\u5bb9\u3002 \u8bed\u97f3\u8bc6\u522b \u7ed9\u5b9a\u6765\u81ea\u58f0\u6ce2\u7684\u58f0\u5b66\u4fe1\u53f7\u7684\u8f93\u5165\u5e8f\u5217\uff0c\u6211\u4eec\u53ef\u4ee5\u9884\u6d4b\u4e00\u7cfb\u5217\u8bed\u97f3\u7247\u6bb5\u53ca\u5176\u6982\u7387\uff0c\u5e76\u628a\u8bed\u97f3\u8f6c\u5316\u6210\u6587\u5b57 \u751f\u6210\u56fe\u50cf\u63cf\u8ff0 \u4e0e\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u4e00\u8d77\uff0cRNN\u53ef\u4ee5\u751f\u6210\u672a\u6807\u8bb0\u56fe\u50cf\u7684\u63cf\u8ff0\u3002","title":"RNN\u90fd\u80fd\u505a\u4ec0\u4e48"},{"location":"tutorial/chapter02_basics/2_5_recurrent-neural-network/#252-rnn","text":"","title":"2.5.2 RNN\u7684\u7f51\u7edc\u7ed3\u6784\u53ca\u539f\u7406"},{"location":"tutorial/chapter02_basics/2_5_recurrent-neural-network/#rnn_3","text":"\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u7684\u57fa\u672c\u7ed3\u6784\u7279\u522b\u7b80\u5355\uff0c\u5c31\u662f\u5c06\u7f51\u7edc\u7684\u8f93\u51fa\u4fdd\u5b58\u5728\u4e00\u4e2a\u8bb0\u5fc6\u5355\u5143\u4e2d\uff0c\u8fd9\u4e2a\u8bb0\u5fc6\u5355\u5143\u548c\u4e0b\u4e00\u6b21\u7684\u8f93\u5165\u4e00\u8d77\u8fdb\u5165\u795e\u7ecf\u7f51\u7edc\u4e2d\u3002\u6211\u4eec\u53ef\u4ee5\u770b\u5230\u7f51\u7edc\u5728\u8f93\u5165\u7684\u65f6\u5019\u4f1a\u8054\u5408\u8bb0\u5fc6\u5355\u5143\u4e00\u8d77\u4f5c\u4e3a\u8f93\u5165\uff0c\u7f51\u7edc\u4e0d\u4ec5\u8f93\u51fa\u7ed3\u679c\uff0c\u8fd8\u4f1a\u5c06\u7ed3\u679c\u4fdd\u5b58\u5230\u8bb0\u5fc6\u5355\u5143\u4e2d\uff0c\u4e0b\u56fe\u5c31\u662f\u4e00\u4e2a\u6700\u7b80\u5355\u7684\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u5728\u8f93\u5165\u65f6\u7684\u7ed3\u6784\u793a\u610f\u56fe. \u56fe\u7247\u6765\u6e90 RNN \u53ef\u4ee5\u88ab\u770b\u505a\u662f\u540c\u4e00\u795e\u7ecf\u7f51\u7edc\u7684\u591a\u6b21\u8d4b\u503c\uff0c\u6bcf\u4e2a\u795e\u7ecf\u7f51\u7edc\u6a21\u5757\u4f1a\u628a\u6d88\u606f\u4f20\u9012\u7ed9\u4e0b\u4e00\u4e2a,\u6211\u4eec\u5c06\u8fd9\u4e2a\u56fe\u7684\u7ed3\u6784\u5c55\u5f00\uff1a \u7f51\u7edc\u4e2d\u5177\u6709\u5faa\u73af\u7ed3\u6784\uff0c\u8fd9\u4e5f\u662f\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u540d\u5b57\u7684\u7531\u6765\uff0c\u540c\u65f6\u6839\u636e\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u7684\u7ed3\u6784\u4e5f\u53ef\u4ee5\u770b\u51fa\u5b83\u5728\u5904\u7406\u5e8f\u5217\u7c7b\u578b\u7684\u6570\u636e\u4e0a\u5177\u6709\u5929\u7136\u7684\u4f18\u52bf.\u56e0\u4e3a\u7f51\u7edc\u672c\u8eab\u5c31\u662f \u4e00\u4e2a\u5e8f\u5217\u7ed3\u6784\uff0c\u8fd9\u4e5f\u662f\u6240\u6709\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u6700\u672c\u8d28\u7684\u7ed3\u6784\u3002 \u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u5177\u6709\u7279\u522b\u597d\u7684\u8bb0\u5fc6\u7279\u6027\uff0c\u80fd\u591f\u5c06\u8bb0\u5fc6\u5185\u5bb9\u5e94\u7528\u5230\u5f53\u524d\u60c5\u666f\u4e0b\uff0c\u4f46\u662f\u7f51\u7edc\u7684\u8bb0\u5fc6\u80fd\u529b\u5e76\u6ca1\u6709\u60f3\u8c61\u7684\u90a3\u4e48\u6709\u6548\u3002\u8bb0\u5fc6\u6700\u5927\u7684\u95ee\u9898\u5728\u4e8e\u5b83\u6709\u9057\u5fd8\u6027\uff0c\u6211\u4eec\u603b\u662f\u66f4\u52a0\u6e05\u695a\u5730\u8bb0\u5f97\u6700\u8fd1\u53d1\u751f\u7684\u4e8b\u60c5\u800c\u9057\u5fd8\u5f88\u4e45\u4e4b\u524d\u53d1\u751f\u7684\u4e8b\u60c5\uff0c\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u540c\u6837\u6709\u8fd9\u6837\u7684\u95ee\u9898\u3002 pytorch \u4e2d\u4f7f\u7528 nn.RNN \u7c7b\u6765\u642d\u5efa\u57fa\u4e8e\u5e8f\u5217\u7684\u5faa\u73af\u795e\u7ecf\u7f51\u7edc,\u5b83\u7684\u6784\u9020\u51fd\u6570\u6709\u4ee5\u4e0b\u51e0\u4e2a\u53c2\u6570\uff1a - nput_size\uff1a\u8f93\u5165\u6570\u636eX\u7684\u7279\u5f81\u503c\u7684\u6570\u76ee\u3002 - hidden_size\uff1a\u9690\u85cf\u5c42\u7684\u795e\u7ecf\u5143\u6570\u91cf\uff0c\u4e5f\u5c31\u662f\u9690\u85cf\u5c42\u7684\u7279\u5f81\u6570\u91cf\u3002 - num_layers\uff1a\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u7684\u5c42\u6570\uff0c\u9ed8\u8ba4\u503c\u662f 1\u3002 - bias\uff1a\u9ed8\u8ba4\u4e3a True\uff0c\u5982\u679c\u4e3a false \u5219\u8868\u793a\u795e\u7ecf\u5143\u4e0d\u4f7f\u7528 bias \u504f\u79fb\u53c2\u6570\u3002 - batch_first\uff1a\u5982\u679c\u8bbe\u7f6e\u4e3a True\uff0c\u5219\u8f93\u5165\u6570\u636e\u7684\u7ef4\u5ea6\u4e2d\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u5c31 \u662f batch \u503c\uff0c\u9ed8\u8ba4\u4e3a False\u3002\u9ed8\u8ba4\u60c5\u51b5\u4e0b\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u662f\u5e8f\u5217\u7684\u957f\u5ea6\uff0c \u7b2c\u4e8c\u4e2a\u7ef4\u5ea6\u624d\u662f - - batch\uff0c\u7b2c\u4e09\u4e2a\u7ef4\u5ea6\u662f\u7279\u5f81\u6570\u76ee\u3002 - dropout\uff1a\u5982\u679c\u4e0d\u4e3a\u7a7a\uff0c\u5219\u8868\u793a\u6700\u540e\u8ddf\u4e00\u4e2a dropout \u5c42\u629b\u5f03\u90e8\u5206\u6570\u636e\uff0c\u629b\u5f03\u6570\u636e\u7684\u6bd4\u4f8b\u7531\u8be5\u53c2\u6570\u6307\u5b9a\u3002 RNN \u4e2d\u6700\u4e3b\u8981\u7684\u53c2\u6570\u662f input_size \u548c hidden_size\uff0c\u8fd9\u4e24\u4e2a\u53c2\u6570\u52a1\u5fc5\u8981\u641e\u6e05\u695a\u3002\u5176\u4f59\u7684\u53c2\u6570\u901a\u5e38\u4e0d\u7528\u8bbe\u7f6e\uff0c\u91c7\u7528\u9ed8\u8ba4\u503c\u5c31\u53ef\u4ee5\u4e86\u3002 rnn = torch . nn . RNN ( 20 , 50 , 2 ) input = torch . randn ( 100 , 32 , 20 ) h_0 = torch . randn ( 2 , 32 , 50 ) output , hn = rnn ( input , h_0 ) print ( output . size (), hn . size ()) torch.Size([100, 32, 50]) torch.Size([2, 32, 50])","title":"RNN"},{"location":"tutorial/chapter02_basics/2_5_recurrent-neural-network/#lstm","text":"LSTM \u662f Long Short Term Memory Networks \u7684\u7f29\u5199\uff0c\u6309\u5b57\u9762\u7ffb\u8bd1\u5c31\u662f\u957f\u7684\u77ed\u65f6\u8bb0\u5fc6\u7f51\u7edc\u3002LSTM \u7684\u7f51\u7edc\u7ed3\u6784\u662f 1997 \u5e74\u7531 Hochreiter \u548c Schmidhuber \u63d0\u51fa\u7684\uff0c\u968f\u540e\u8fd9\u79cd\u7f51\u7edc\u7ed3\u6784\u53d8\u5f97\u975e\u5e38\u6d41\u884c\uff0c\u3002 LSTM\u867d\u7136\u53ea\u89e3\u51b3\u4e86\u77ed\u671f\u4f9d\u8d56\u7684\u95ee\u9898\uff0c\u5e76\u4e14\u5b83\u901a\u8fc7\u523b\u610f\u7684\u8bbe\u8ba1\u6765\u907f\u514d\u957f\u671f\u4f9d\u8d56\u95ee\u9898\uff0c\u8fd9\u6837\u7684\u505a\u6cd5\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u88ab\u8bc1\u660e\u8fd8\u662f\u5341\u5206\u6709\u6548\u7684\uff0c\u6709\u5f88\u591a\u4eba\u8ddf\u8fdb\u76f8\u5173\u7684\u5de5\u4f5c\u89e3\u51b3\u4e86\u5f88\u591a\u5b9e\u9645\u7684\u95ee\u9898\uff0c\u6240\u4ee5\u73b0\u5728LSTM \u4ecd\u7136\u88ab\u5e7f\u6cdb\u5730\u4f7f\u7528\u3002 \u56fe\u7247\u6765\u6e90 \u6807\u51c6\u7684\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u5185\u90e8\u53ea\u6709\u4e00\u4e2a\u7b80\u5355\u7684\u5c42\u7ed3\u6784\uff0c\u800c LSTM \u5185\u90e8\u6709 4 \u4e2a\u5c42\u7ed3\u6784\uff1a \u7b2c\u4e00\u5c42\u662f\u4e2a\u5fd8\u8bb0\u5c42\uff1a\u51b3\u5b9a\u72b6\u6001\u4e2d\u4e22\u5f03\u4ec0\u4e48\u4fe1\u606f \u7b2c\u4e8c\u5c42tanh\u5c42\u7528\u6765\u4ea7\u751f\u66f4\u65b0\u503c\u7684\u5019\u9009\u9879\uff0c\u8bf4\u660e\u72b6\u6001\u5728\u67d0\u4e9b\u7ef4\u5ea6\u4e0a\u9700\u8981\u52a0\u5f3a\uff0c\u5728\u67d0\u4e9b\u7ef4\u5ea6\u4e0a\u9700\u8981\u51cf\u5f31 \u7b2c\u4e09\u5c42sigmoid\u5c42\uff08\u8f93\u5165\u95e8\u5c42\uff09\uff0c\u5b83\u7684\u8f93\u51fa\u503c\u8981\u4e58\u5230tanh\u5c42\u7684\u8f93\u51fa\u4e0a\uff0c\u8d77\u5230\u4e00\u4e2a\u7f29\u653e\u7684\u4f5c\u7528\uff0c\u6781\u7aef\u60c5\u51b5\u4e0bsigmoid\u8f93\u51fa0\u8bf4\u660e\u76f8\u5e94\u7ef4\u5ea6\u4e0a\u7684\u72b6\u6001\u4e0d\u9700\u8981\u66f4\u65b0 \u6700\u540e\u4e00\u5c42 \u51b3\u5b9a\u8f93\u51fa\u4ec0\u4e48,\u8f93\u51fa\u503c\u8ddf\u72b6\u6001\u6709\u5173\u3002\u5019\u9009\u9879\u4e2d\u7684\u54ea\u4e9b\u90e8\u5206\u6700\u7ec8\u4f1a\u88ab\u8f93\u51fa\u7531\u4e00\u4e2asigmoid\u5c42\u6765\u51b3\u5b9a\u3002 pytorch \u4e2d\u4f7f\u7528 nn.LSTM \u7c7b\u6765\u642d\u5efa\u57fa\u4e8e\u5e8f\u5217\u7684\u5faa\u73af\u795e\u7ecf\u7f51\u7edc,\u4ed6\u7684\u53c2\u6570\u57fa\u672c\u4e0eRNN\u7c7b\u4f3c\uff0c\u8fd9\u91cc\u5c31\u4e0d\u5217\u51fa\u4e86\u3002 lstm = torch . nn . LSTM ( 10 , 20 , 2 ) input = torch . randn ( 5 , 3 , 10 ) h0 = torch . randn ( 2 , 3 , 20 ) c0 = torch . randn ( 2 , 3 , 20 ) output , hn = lstm ( input , ( h0 , c0 )) print ( output . size (), hn [ 0 ] . size (), hn [ 1 ] . size ()) torch.Size([5, 3, 20]) torch.Size([2, 3, 20]) torch.Size([2, 3, 20])","title":"LSTM"},{"location":"tutorial/chapter02_basics/2_5_recurrent-neural-network/#gru","text":"GRU \u662f gated recurrent units \u7684\u7f29\u5199\uff0c\u7531 Cho\u5728 2014 \u5e74\u63d0\u51faGRU \u548c LSTM \u6700 \u7684\u4e0d\u540c\u5728\u4e8e GRU \u5c06\u9057\u5fd8\u95e8\u548c\u8f93\u5165\u95e8\u5408\u6210\u4e86\u4e00\u4e2a\"\u66f4\u65b0\u95e8\"\uff0c\u540c\u65f6\u7f51\u7edc\u4e0d\u518d\u989d\u5916\u7ed9\u51fa\u8bb0\u5fc6\u72b6\u6001\uff0c\u800c\u662f\u5c06\u8f93\u51fa\u7ed3\u679c\u4f5c\u4e3a\u8bb0\u5fc6\u72b6\u6001\u4e0d\u65ad\u5411\u540e\u5faa\u73af\u4f20\u9012\uff0c\u7f51\u7edc\u7684\u8f93\u4eba\u548c\u8f93\u51fa\u90fd\u53d8\u5f97\u7279\u522b\u7b80\u5355\u3002 rnn = torch . nn . GRU ( 10 , 20 , 2 ) input = torch . randn ( 5 , 3 , 10 ) h_0 = torch . randn ( 2 , 3 , 20 ) output , hn = rnn ( input , h0 ) print ( output . size (), h0 . size ()) torch.Size([5, 3, 20]) torch.Size([2, 3, 20])","title":"GRU"},{"location":"tutorial/chapter02_basics/2_5_recurrent-neural-network/#253-bptt","text":"\u5728\u5411\u524d\u4f20\u64ad\u7684\u60c5\u51b5\u4e0b\uff0cRNN\u7684\u8f93\u5165\u968f\u7740\u6bcf\u4e00\u4e2a\u65f6\u95f4\u6b65\u524d\u8fdb\u3002\u5728\u53cd\u5411\u4f20\u64ad\u7684\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u201c\u56de\u5230\u8fc7\u53bb\u201d\u6539\u53d8\u6743\u91cd\uff0c\u56e0\u6b64\u6211\u4eec\u53eb\u5b83\u901a\u8fc7\u65f6\u95f4\u7684\u53cd\u5411\u4f20\u64ad\uff08BPTT\uff09\u3002 \u6211\u4eec\u901a\u5e38\u628a\u6574\u4e2a\u5e8f\u5217\uff08\u5355\u8bcd\uff09\u770b\u4f5c\u4e00\u4e2a\u8bad\u7ec3\u6837\u672c\uff0c\u6240\u4ee5\u603b\u7684\u8bef\u5dee\u662f\u6bcf\u4e2a\u65f6\u95f4\u6b65\uff08\u5b57\u7b26\uff09\u4e2d\u8bef\u5dee\u7684\u548c\u3002\u6743\u91cd\u5728\u6bcf\u4e00\u4e2a\u65f6\u95f4\u6b65\u957f\u662f\u76f8\u540c\u7684\uff08\u6240\u4ee5\u53ef\u4ee5\u8ba1\u7b97\u603b\u8bef\u5dee\u540e\u4e00\u8d77\u66f4\u65b0\uff09\u3002 1. \u4f7f\u7528\u9884\u6d4b\u8f93\u51fa\u548c\u5b9e\u9645\u8f93\u51fa\u8ba1\u7b97\u4ea4\u53c9\u71b5\u8bef\u5dee 2. \u7f51\u7edc\u6309\u7167\u65f6\u95f4\u6b65\u5b8c\u5168\u5c55\u5f00 3. \u5bf9\u4e8e\u5c55\u5f00\u7684\u7f51\u7edc\uff0c\u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u5b9e\u8df5\u6b65\u8ba1\u7b97\u6743\u91cd\u7684\u68af\u5ea6 4. \u56e0\u4e3a\u5bf9\u4e8e\u6240\u6709\u65f6\u95f4\u6b65\u6765\u8bf4\uff0c\u6743\u91cd\u90fd\u4e00\u6837\uff0c\u6240\u4ee5\u5bf9\u4e8e\u6240\u6709\u7684\u65f6\u95f4\u6b65\uff0c\u53ef\u4ee5\u4e00\u8d77\u5f97\u5230\u68af\u5ea6\uff08\u800c\u4e0d\u662f\u50cf\u795e\u7ecf\u7f51\u7edc\u4e00\u6837\u5bf9\u4e0d\u540c\u7684\u9690\u85cf\u5c42\u5f97\u5230\u4e0d\u540c\u7684\u68af\u5ea6\uff09 5. \u968f\u540e\u5bf9\u5faa\u73af\u795e\u7ecf\u5143\u7684\u6743\u91cd\u8fdb\u884c\u5347\u7ea7 RNN\u5c55\u5f00\u7684\u7f51\u7edc\u770b\u8d77\u6765\u50cf\u4e00\u4e2a\u666e\u901a\u7684\u795e\u7ecf\u7f51\u7edc\u3002\u53cd\u5411\u4f20\u64ad\u4e5f\u7c7b\u4f3c\u4e8e\u666e\u901a\u7684\u795e\u7ecf\u7f51\u7edc\uff0c\u53ea\u4e0d\u8fc7\u6211\u4eec\u4e00\u6b21\u5f97\u5230\u6240\u6709\u65f6\u95f4\u6b65\u7684\u68af\u5ea6\u3002\u5982\u679c\u6709100\u4e2a\u65f6\u95f4\u6b65\uff0c\u90a3\u4e48\u7f51\u7edc\u5c55\u5f00\u540e\u5c06\u53d8\u5f97\u975e\u5e38\u5de8\u5927\uff0c\u6240\u4ee5\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u624d\u4f1a\u51fa\u73b0LSTM\u548cGRU\u8fd9\u6837\u7684\u7ed3\u6784\u3002 \u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u76ee\u524d\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u5e94\u7528\u6700\u4e3a\u706b\u70ed\uff0c\u6240\u4ee5\u540e\u9762\u7684\u5185\u5bb9\u5c06\u4ecb\u7ecd\u4e00\u4e0b\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u5728\u5904\u7406NLP\u7684\u65f6\u5019\u9700\u8981\u7528\u5230\u7684\u4e00\u4e9b\u5176\u4ed6\u7684\u77e5\u8bc6","title":"2.5.3 \u5faa\u73af\u7f51\u7edc\u7684\u5411\u540e\u4f20\u64ad\uff08BPTT\uff09"},{"location":"tutorial/chapter02_basics/2_5_recurrent-neural-network/#254-word-embedding","text":"\u5728\u6211\u4eec\u4eba\u7c7b\u4ea4\u6d41\u8fc7\u7a0b\u4e2d\u8868\u5f81\u8bcd\u6c47\u662f\u76f4\u63a5\u4f7f\u7528\u82f1\u6587\u5355\u8bcd\u6765\u8fdb\u884c\u8868\u5f81\u7684\uff0c\u4f46\u662f\u5bf9\u4e8e\u8ba1\u7b97\u673a\u6765\u8bf4\uff0c\u662f\u65e0\u6cd5\u76f4\u63a5\u8ba4\u8bc6\u5355\u8bcd\u7684\u3002\u4e3a\u4e86\u8ba9\u8ba1\u7b97\u673a\u80fd\u591f\u80fd\u66f4\u597d\u5730\u7406\u89e3\u6211\u4eec\u7684\u8bed\u8a00\uff0c\u5efa\u7acb\u66f4\u597d\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u6211\u4eec\u9700\u8981\u5c06\u8bcd\u6c47\u8fdb\u884c\u8868\u5f81\u3002 \u5728\u56fe\u50cf\u5206\u7c7b\u95ee\u9898\u4f1a\u4f7f\u7528 one-hot \u7f16\u7801.\u6bd4\u5982LeNet\u4e2d\u4e00\u5171\u670910\u4e2a\u6570\u5b570-9\uff0c\u5982\u679c\u8fd9\u4e2a\u6570\u5b57\u662f2\u7684\u8bdd\u7c7b\uff0c\u5b83\u7684 \u7f16\u7801\u5c31\u662f (0\uff0c0\uff0c1\uff0c0\uff0c 0\uff0c0 \uff0c0\uff0c0\uff0c0\uff0c0)\uff0c\u5bf9\u4e8e\u5206\u7c7b\u95ee\u9898\u8fd9\u6837\u8868\u793a\u5341\u5206\u7684\u6e05\u695a\uff0c\u4f46\u662f\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\uff0c\u56e0\u4e3a\u5355\u8bcd\u7684\u6570\u76ee\u8fc7\u591a\u6bd4\u5982\u6709 10000 \u4e2a\u4e0d\u540c\u7684\u8bcd\uff0c\u90a3\u4e48\u4f7f\u7528 one-hot \u8fd9\u6837\u7684\u65b9\u5f0f\u6765\u5b9a\u4e49\uff0c\u6548\u7387\u5c31\u7279\u522b\u4f4e\uff0c\u6bcf\u4e2a\u5355\u8bcd\u90fd\u662f 10000 \u7ef4\u7684\u5411\u91cf.\u5176\u4e2d\u53ea\u6709\u4e00\u4f4d\u662f 1 , \u5176\u4f59\u90fd\u662f 0\uff0c\u7279\u522b\u5360\u7528\u5185\u5b58,\u800c\u4e14\u4e5f\u4e0d\u80fd\u4f53\u73b0\u5355\u8bcd\u7684\u8bcd\u6027\uff0c\u56e0\u4e3a\u6bcf\u4e00\u4e2a\u5355\u8bcd\u90fd\u662f one-hot\uff0c\u867d\u7136\u6709\u4e9b\u5355\u8bcd\u5728\u8bed\u4e49\u4e0a\u4f1a\u66f4\u52a0\u63a5\u8fd1.\u4f46\u662f one-hot \u6ca1\u529e\u6cd5\u4f53\u73b0\u8fd9\u4e2a\u7279\u70b9\uff0c\u6240\u4ee5 \u5fc5\u987b\u4f7f\u7528\u53e6\u5916\u4e00\u79cd\u65b9\u5f0f\u5b9a\u4e49\u6bcf\u4e00\u4e2a\u5355\u8bcd\u3002 \u7528\u4e0d\u540c\u7684\u7279\u5f81\u6765\u5bf9\u5404\u4e2a\u8bcd\u6c47\u8fdb\u884c\u8868\u5f81\uff0c\u76f8\u5bf9\u4e0e\u4e0d\u540c\u7684\u7279\u5f81\uff0c\u4e0d\u540c\u7684\u5355\u8bcd\u5747\u6709\u4e0d\u540c\u7684\u503c\u8fd9\u5c31\u662f\u8bcd\u5d4c\u5165\u3002\u4e0b\u56fe\u8fd8\u662f\u6765\u81ea\u5434\u6069\u8fbe\u8001\u5e08\u7684\u8bfe\u7a0b\u622a\u56fe\uff1a \u8bcd\u5d4c\u5165\u4e0d\u4ec5\u5bf9\u4e0d\u540c\u5355\u8bcd\u5b9e\u73b0\u4e86\u7279\u5f81\u5316\u7684\u8868\u793a\uff0c\u8fd8\u80fd\u901a\u8fc7\u8ba1\u7b97\u8bcd\u4e0e\u8bcd\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6\uff0c\u5b9e\u9645\u4e0a\u662f\u5728\u591a\u7ef4\u7a7a\u95f4\u4e2d\uff0c\u5bfb\u627e\u8bcd\u5411\u91cf\u4e4b\u95f4\u5404\u4e2a\u7ef4\u5ea6\u7684\u8ddd\u79bb\u76f8\u4f3c\u5ea6\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u5b9e\u73b0\u7c7b\u6bd4\u63a8\u7406\uff0c\u6bd4\u5982\u8bf4\u590f\u5929\u548c\u70ed\uff0c\u51ac\u5929\u548c\u51b7\uff0c\u90fd\u662f\u6709\u5173\u8054\u5173\u7cfb\u7684\u3002 \u5728 PyTorch \u4e2d\u6211\u4eec\u7528 nn.Embedding \u5c42\u6765\u505a\u5d4c\u5165\u8bcd\u888b\u6a21\u578b\uff0cEmbedding\u5c42\u7b2c\u4e00\u4e2a\u8f93\u5165\u8868\u793a\u6211\u4eec\u6709\u591a\u5c11\u4e2a\u8bcd\uff0c\u7b2c\u4e8c\u4e2a\u8f93\u5165\u8868\u793a\u6bcf\u4e00\u4e2a\u8bcd\u4f7f\u7528\u591a\u5c11\u4e2a\u5411\u91cf\u8868\u793a\u3002 # an Embedding module containing 10 tensors of size 3 embedding = torch . nn . Embedding ( 10 , 3 ) # a batch of 2 samples of 4 indices each input = torch . LongTensor ([[ 1 , 2 , 4 , 5 ],[ 4 , 3 , 2 , 9 ]]) output = embedding ( input ) print ( output . size ()) torch.Size([2, 4, 3])","title":"2.5.4 \u8bcd\u5d4c\u5165\uff08word embedding\uff09"},{"location":"tutorial/chapter02_basics/2_5_recurrent-neural-network/#255","text":"","title":"2.5.5  \u5176\u4ed6\u91cd\u8981\u6982\u5ff5"},{"location":"tutorial/chapter02_basics/2_5_recurrent-neural-network/#beam-search","text":"\u5728\u751f\u6210\u7b2c\u4e00\u4e2a\u8bcd\u7684\u5206\u5e03\u540e\uff0c\u53ef\u4ee5\u4f7f\u7528\u8d2a\u5fc3\u641c\u7d22\u4f1a\u6839\u636e\u6211\u4eec\u7684\u6761\u4ef6\u8bed\u8a00\u6a21\u578b\u6311\u9009\u51fa\u6700\u6709\u53ef\u80fd\u8f93\u51fa\u7684\u7b2c\u4e00\u4e2a\u8bcd\u8bed\uff0c\u4f46\u662f\u5bf9\u4e8e\u8d2a\u5fc3\u641c\u7d22\u7b97\u6cd5\u6765\u8bf4\uff0c\u6211\u4eec\u7684\u5355\u8bcd\u5e93\u4e2d\u6709\u6210\u767e\u5230\u5343\u4e07\u7684\u8bcd\u6c47\uff0c\u53bb\u8ba1\u7b97\u6bcf\u4e00\u79cd\u5355\u8bcd\u7684\u7ec4\u5408\u7684\u53ef\u80fd\u6027\u662f\u4e0d\u53ef\u884c\u7684\u3002\u6240\u4ee5\u6211\u4eec\u4f7f\u7528\u8fd1\u4f3c\u7684\u641c\u7d22\u529e\u6cd5\uff0c\u4f7f\u5f97\u6761\u4ef6\u6982\u7387\u6700\u5927\u5316\u6216\u8005\u8fd1\u4f3c\u6700\u5927\u5316\u7684\u53e5\u5b50\uff0c\u800c\u4e0d\u662f\u901a\u8fc7\u5355\u8bcd\u53bb\u5b9e\u73b0\u3002 Beam Search\uff08\u96c6\u675f\u641c\u7d22\uff09\u662f\u4e00\u79cd\u542f\u53d1\u5f0f\u56fe\u641c\u7d22\u7b97\u6cd5\uff0c\u901a\u5e38\u7528\u5728\u56fe\u7684\u89e3\u7a7a\u95f4\u6bd4\u8f83\u5927\u7684\u60c5\u51b5\u4e0b\uff0c\u4e3a\u4e86\u51cf\u5c11\u641c\u7d22\u6240\u5360\u7528\u7684\u7a7a\u95f4\u548c\u65f6\u95f4\uff0c\u5728\u6bcf\u4e00\u6b65\u6df1\u5ea6\u6269\u5c55\u7684\u65f6\u5019\uff0c\u526a\u6389\u4e00\u4e9b\u8d28\u91cf\u6bd4\u8f83\u5dee\u7684\u7ed3\u70b9\uff0c\u4fdd\u7559\u4e0b\u4e00\u4e9b\u8d28\u91cf\u8f83\u9ad8\u7684\u7ed3\u70b9\u3002\u867d\u7136Beam Search\u7b97\u6cd5\u662f\u4e0d\u5b8c\u5168\u7684\uff0c\u4f46\u662f\u7528\u4e8e\u4e86\u89e3\u7a7a\u95f4\u8f83\u5927\u7684\u7cfb\u7edf\u4e2d\uff0c\u53ef\u4ee5\u51cf\u5c11\u7a7a\u95f4\u5360\u7528\u548c\u65f6\u95f4\u3002 beam search\u53ef\u4ee5\u770b\u505a\u662f\u505a\u4e86\u7ea6\u675f\u4f18\u5316\u7684\u5e7f\u5ea6\u4f18\u5148\u641c\u7d22\uff0c\u9996\u5148\u4f7f\u7528\u5e7f\u5ea6\u4f18\u5148\u7b56\u7565\u5efa\u7acb\u641c\u7d22\u6811\uff0c\u6811\u7684\u6bcf\u5c42\uff0c\u6309\u7167\u542f\u53d1\u4ee3\u4ef7\u5bf9\u8282\u70b9\u8fdb\u884c\u6392\u5e8f\uff0c\u7136\u540e\u4ec5\u7559\u4e0b\u9884\u5148\u786e\u5b9a\u7684\u4e2a\u6570\uff08Beam width-\u96c6\u675f\u5bbd\u5ea6\uff09\u7684\u8282\u70b9\uff0c\u4ec5\u8fd9\u4e9b\u8282\u70b9\u5728\u4e0b\u4e00\u5c42\u6b21\u7ee7\u7eed\u6269\u5c55\uff0c\u5176\u4ed6\u8282\u70b9\u88ab\u526a\u5207\u6389\u3002 1. \u5c06\u521d\u59cb\u8282\u70b9\u63d2\u5165\u5230list\u4e2d 2. \u5c06\u7ed9\u8282\u70b9\u51fa\u5806\uff0c\u5982\u679c\u8be5\u8282\u70b9\u662f\u76ee\u6807\u8282\u70b9\uff0c\u5219\u7b97\u6cd5\u7ed3\u675f\uff1b 3. \u5426\u5219\u6269\u5c55\u8be5\u8282\u70b9\uff0c\u53d6\u96c6\u675f\u5bbd\u5ea6\u7684\u8282\u70b9\u5165\u5806\u3002\u7136\u540e\u5230\u7b2c\u4e8c\u6b65\u7ee7\u7eed\u5faa\u73af\u3002 4. \u7b97\u6cd5\u7ed3\u675f\u7684\u6761\u4ef6\u662f\u627e\u5230\u6700\u4f18\u89e3\u6216\u8005\u5806\u4e3a\u7a7a\u3002 \u5728\u4f7f\u7528\u4e0a\uff0c\u96c6\u675f\u5bbd\u5ea6\u53ef\u4ee5\u662f\u9884\u5148\u7ea6\u5b9a\u7684\uff0c\u4e5f\u53ef\u4ee5\u662f\u53d8\u5316\u7684\uff0c\u5177\u4f53\u53ef\u4ee5\u6839\u636e\u5b9e\u9645\u573a\u666f\u8c03\u6574\u8bbe\u5b9a\u3002","title":"Beam search"},{"location":"tutorial/chapter02_basics/2_5_recurrent-neural-network/#_1","text":"\u5bf9\u4e8e\u4f7f\u7528\u7f16\u7801\u548c\u89e3\u7801\u7684RNN\u6a21\u578b\uff0c\u6211\u4eec\u80fd\u591f\u5b9e\u73b0\u8f83\u4e3a\u51c6\u786e\u5ea6\u673a\u5668\u7ffb\u8bd1\u7ed3\u679c\u3002\u5bf9\u4e8e\u77ed\u53e5\u5b50\u6765\u8bf4\uff0c\u5176\u6027\u80fd\u662f\u5341\u5206\u826f\u597d\u7684\uff0c\u4f46\u662f\u5982\u679c\u662f\u5f88\u957f\u7684\u53e5\u5b50\uff0c\u7ffb\u8bd1\u7684\u7ed3\u679c\u5c31\u4f1a\u53d8\u5dee\u3002 \u6211\u4eec\u4eba\u7c7b\u8fdb\u884c\u4eba\u5de5\u7ffb\u8bd1\u7684\u65f6\u5019\uff0c\u90fd\u662f\u4e00\u90e8\u5206\u4e00\u90e8\u5206\u5730\u8fdb\u884c\u7ffb\u8bd1\uff0c\u5f15\u5165\u7684\u6ce8\u610f\u529b\u673a\u5236\uff0c\u548c\u4eba\u7c7b\u7684\u7ffb\u8bd1\u8fc7\u7a0b\u975e\u5e38\u76f8\u4f3c\uff0c\u5176\u4e5f\u662f\u4e00\u90e8\u5206\u4e00\u90e8\u5206\u5730\u8fdb\u884c\u957f\u53e5\u5b50\u7684\u7ffb\u8bd1\u3002 \u5177\u4f53\u7684\u5185\u5bb9\u5728\u8fd9\u91cc\u5c31\u4e0d\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u3002","title":"\u6ce8\u610f\u529b\u6a21\u578b"},{"location":"tutorial/chapter03_intermediate/3_1_logistic-regression/","text":"import torch import torch.nn as nn import numpy as np torch . __version__ '1.0.0' 3.1 logistic\u56de\u5f52\u5b9e\u6218 \u00b6 \u5728\u8fd9\u4e00\u7ae0\u91cc\u9762\uff0c\u6211\u4eec\u5c06\u5904\u7406\u4e00\u4e0b\u7ed3\u6784\u5316\u6570\u636e\uff0c\u5e76\u4f7f\u7528logistic\u56de\u5f52\u5bf9\u7ed3\u6784\u5316\u6570\u636e\u8fdb\u884c\u7b80\u5355\u7684\u5206\u7c7b\u3002 3.1.1 logistic\u56de\u5f52\u4ecb\u7ecd \u00b6 logistic\u56de\u5f52\u662f\u4e00\u79cd\u5e7f\u4e49\u7ebf\u6027\u56de\u5f52\uff08generalized linear model\uff09\uff0c\u4e0e\u591a\u91cd\u7ebf\u6027\u56de\u5f52\u5206\u6790\u6709\u5f88\u591a\u76f8\u540c\u4e4b\u5904\u3002\u5b83\u4eec\u7684\u6a21\u578b\u5f62\u5f0f\u57fa\u672c\u4e0a\u76f8\u540c\uff0c\u90fd\u5177\u6709 wx + b\uff0c\u5176\u4e2dw\u548cb\u662f\u5f85\u6c42\u53c2\u6570\uff0c\u5176\u533a\u522b\u5728\u4e8e\u4ed6\u4eec\u7684\u56e0\u53d8\u91cf\u4e0d\u540c\uff0c\u591a\u91cd\u7ebf\u6027\u56de\u5f52\u76f4\u63a5\u5c06wx+b\u4f5c\u4e3a\u56e0\u53d8\u91cf\uff0c\u5373y =wx+b,\u800clogistic\u56de\u5f52\u5219\u901a\u8fc7\u51fd\u6570L\u5c06wx+b\u5bf9\u5e94\u4e00\u4e2a\u9690\u72b6\u6001p\uff0cp =L(wx+b),\u7136\u540e\u6839\u636ep \u4e0e1-p\u7684\u5927\u5c0f\u51b3\u5b9a\u56e0\u53d8\u91cf\u7684\u503c\u3002\u5982\u679cL\u662flogistic\u51fd\u6570\uff0c\u5c31\u662flogistic\u56de\u5f52\uff0c\u5982\u679cL\u662f\u591a\u9879\u5f0f\u51fd\u6570\u5c31\u662f\u591a\u9879\u5f0f\u56de\u5f52\u3002 \u8bf4\u7684\u66f4\u901a\u4fd7\u4e00\u70b9\uff0c\u5c31\u662flogistic\u56de\u5f52\u4f1a\u5728\u7ebf\u6027\u56de\u5f52\u540e\u518d\u52a0\u4e00\u5c42logistic\u51fd\u6570\u7684\u8c03\u7528\u3002 logistic\u56de\u5f52\u4e3b\u8981\u662f\u8fdb\u884c\u4e8c\u5206\u7c7b\u9884\u6d4b\uff0c\u6211\u4eec\u5728\u6fc0\u6d3b\u51fd\u6570\u65f6\u5019\u8bb2\u5230\u8fc7 Sigmod\u51fd\u6570\uff0cSigmod\u51fd\u6570\u662f\u6700\u5e38\u89c1\u7684logistic\u51fd\u6570\uff0c\u56e0\u4e3aSigmod\u51fd\u6570\u7684\u8f93\u51fa\u7684\u662f\u662f\u5bf9\u4e8e0~1\u4e4b\u95f4\u7684\u6982\u7387\u503c\uff0c\u5f53\u6982\u7387\u5927\u4e8e0.5\u9884\u6d4b\u4e3a1\uff0c\u5c0f\u4e8e0.5\u9884\u6d4b\u4e3a0\u3002 \u4e0b\u9762\u6211\u4eec\u5c31\u6765\u4f7f\u7528\u516c\u5f00\u7684\u6570\u636e\u6765\u8fdb\u884c\u4ecb\u7ecd 3.1.2 UCI German Credit \u6570\u636e\u96c6 \u00b6 UCI German Credit\u662fUCI\u7684\u5fb7\u56fd\u4fe1\u7528\u6570\u636e\u96c6\uff0c\u91cc\u9762\u6709\u539f\u6570\u636e\u548c\u6570\u503c\u5316\u540e\u7684\u6570\u636e\u3002 German Credit\u6570\u636e\u662f\u6839\u636e\u4e2a\u4eba\u7684\u94f6\u884c\u8d37\u6b3e\u4fe1\u606f\u548c\u7533\u8bf7\u5ba2\u6237\u8d37\u6b3e\u903e\u671f\u53d1\u751f\u60c5\u51b5\u6765\u9884\u6d4b\u8d37\u6b3e\u8fdd\u7ea6\u503e\u5411\u7684\u6570\u636e\u96c6\uff0c\u6570\u636e\u96c6\u5305\u542b24\u4e2a\u7ef4\u5ea6\u7684\uff0c1000\u6761\u6570\u636e\uff0c \u5728\u8fd9\u91cc\u6211\u4eec\u76f4\u63a5\u4f7f\u7528\u5904\u7406\u597d\u7684\u6570\u503c\u5316\u7684\u6570\u636e\uff0c\u4f5c\u4e3a\u5c55\u793a\u3002 \u5730\u5740 3.2 \u4ee3\u7801\u5b9e\u6218 \u00b6 \u6211\u4eec\u8fd9\u91cc\u4f7f\u7528\u7684 german.data-numeric\u662fnumpy\u5904\u7406\u597d\u6570\u503c\u5316\u6570\u636e\uff0c\u6211\u4eec\u76f4\u63a5\u4f7f\u7528numpy\u7684load\u65b9\u6cd5\u8bfb\u53d6\u5373\u53ef data = np . loadtxt ( \"german.data-numeric\" ) \u6570\u636e\u8bfb\u53d6\u5b8c\u6210\u540e\u6211\u4eec\u8981\u5bf9\u6570\u636e\u505a\u4e00\u4e0b\u5f52\u4e00\u5316\u7684\u5904\u7406 n , l = data . shape for j in range ( l - 1 ): meanVal = np . mean ( data [:, j ]) stdVal = np . std ( data [:, j ]) data [:, j ] = ( data [:, j ] - meanVal ) / stdVal \u6253\u4e71\u6570\u636e np . random . shuffle ( data ) \u533a\u5206\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\uff0c\u7531\u4e8e\u8fd9\u91cc\u6ca1\u6709\u9a8c\u8bc1\u96c6\uff0c\u6240\u4ee5\u6211\u4eec\u76f4\u63a5\u4f7f\u7528\u6d4b\u8bd5\u96c6\u7684\u51c6\u786e\u5ea6\u4f5c\u4e3a\u8bc4\u5224\u597d\u574f\u7684\u6807\u51c6 \u533a\u5206\u89c4\u5219\uff1a900\u6761\u7528\u4e8e\u8bad\u7ec3\uff0c100\u6761\u4f5c\u4e3a\u6d4b\u8bd5 german.data-numeric\u7684\u683c\u5f0f\u4e3a\uff0c\u524d24\u5217\u4e3a24\u4e2a\u7ef4\u5ea6\uff0c\u6700\u540e\u4e00\u4e2a\u4e3a\u8981\u6253\u7684\u6807\u7b7e\uff080\uff0c1\uff09\uff0c\u6240\u4ee5\u6211\u4eec\u5c06\u6570\u636e\u548c\u6807\u7b7e\u4e00\u8d77\u533a\u5206\u51fa\u6765 train_data = data [: 900 ,: l - 1 ] train_lab = data [: 900 , l - 1 ] - 1 test_data = data [ 900 :,: l - 1 ] test_lab = data [ 900 :, l - 1 ] - 1 \u4e0b\u9762\u6211\u4eec\u5b9a\u4e49\u6a21\u578b\uff0c\u6a21\u578b\u5f88\u7b80\u5355 class LR ( nn . Module ): def __init__ ( self ): super ( LR , self ) . __init__ () self . fc = nn . Linear ( 24 , 2 ) # \u7531\u4e8e24\u4e2a\u7ef4\u5ea6\u5df2\u7ecf\u56fa\u5b9a\u4e86\uff0c\u6240\u4ee5\u8fd9\u91cc\u519924 def forward ( self , x ): out = self . fc ( x ) out = torch . sigmoid ( out ) return out \u6d4b\u8bd5\u96c6\u4e0a\u7684\u51c6\u786e\u7387 def test ( pred , lab ): t = pred . max ( - 1 )[ 1 ] == lab return torch . mean ( t . float ()) \u4e0b\u9762\u5c31\u662f\u5bf9\u4e00\u4e9b\u8bbe\u7f6e net = LR () criterion = nn . CrossEntropyLoss () # \u4f7f\u7528CrossEntropyLoss\u635f\u5931 optm = torch . optim . Adam ( net . parameters ()) # Adam\u4f18\u5316 epochs = 1000 # \u8bad\u7ec31000\u6b21 \u4e0b\u9762\u5f00\u59cb\u8bad\u7ec3\u4e86 for i in range ( epochs ): # \u6307\u5b9a\u6a21\u578b\u4e3a\u8bad\u7ec3\u6a21\u5f0f\uff0c\u8ba1\u7b97\u68af\u5ea6 net . train () # \u8f93\u5165\u503c\u90fd\u9700\u8981\u8f6c\u5316\u6210torch\u7684Tensor x = torch . from_numpy ( train_data ) . float () y = torch . from_numpy ( train_lab ) . long () y_hat = net ( x ) loss = criterion ( y_hat , y ) # \u8ba1\u7b97\u635f\u5931 optm . zero_grad () # \u524d\u4e00\u6b65\u7684\u635f\u5931\u6e05\u96f6 loss . backward () # \u53cd\u5411\u4f20\u64ad optm . step () # \u4f18\u5316 if ( i + 1 ) % 100 == 0 : # \u8fd9\u91cc\u6211\u4eec\u6bcf100\u6b21\u8f93\u51fa\u76f8\u5173\u7684\u4fe1\u606f # \u6307\u5b9a\u6a21\u578b\u4e3a\u8ba1\u7b97\u6a21\u5f0f net . eval () test_in = torch . from_numpy ( test_data ) . float () test_l = torch . from_numpy ( test_lab ) . long () test_out = net ( test_in ) # \u4f7f\u7528\u6211\u4eec\u7684\u6d4b\u8bd5\u51fd\u6570\u8ba1\u7b97\u51c6\u786e\u7387 accu = test ( test_out , test_l ) print ( \"Epoch:{},Loss:{:.4f},Accuracy\uff1a{:.2f}\" . format ( i + 1 , loss . item (), accu )) Epoch:100,Loss:0.6313,Accuracy\uff1a0.76 Epoch:200,Loss:0.6065,Accuracy\uff1a0.79 Epoch:300,Loss:0.5909,Accuracy\uff1a0.80 Epoch:400,Loss:0.5801,Accuracy\uff1a0.81 Epoch:500,Loss:0.5720,Accuracy\uff1a0.82 Epoch:600,Loss:0.5657,Accuracy\uff1a0.81 Epoch:700,Loss:0.5606,Accuracy\uff1a0.81 Epoch:800,Loss:0.5563,Accuracy\uff1a0.81 Epoch:900,Loss:0.5527,Accuracy\uff1a0.81 Epoch:1000,Loss:0.5496,Accuracy\uff1a0.80 \u8bad\u7ec3\u5b8c\u6210\u4e86\uff0c\u6211\u4eec\u7684\u51c6\u786e\u5ea6\u8fbe\u5230\u4e8680%","title":"3.1 Logistic Regression"},{"location":"tutorial/chapter03_intermediate/3_1_logistic-regression/#31-logistic","text":"\u5728\u8fd9\u4e00\u7ae0\u91cc\u9762\uff0c\u6211\u4eec\u5c06\u5904\u7406\u4e00\u4e0b\u7ed3\u6784\u5316\u6570\u636e\uff0c\u5e76\u4f7f\u7528logistic\u56de\u5f52\u5bf9\u7ed3\u6784\u5316\u6570\u636e\u8fdb\u884c\u7b80\u5355\u7684\u5206\u7c7b\u3002","title":"3.1 logistic\u56de\u5f52\u5b9e\u6218"},{"location":"tutorial/chapter03_intermediate/3_1_logistic-regression/#311-logistic","text":"logistic\u56de\u5f52\u662f\u4e00\u79cd\u5e7f\u4e49\u7ebf\u6027\u56de\u5f52\uff08generalized linear model\uff09\uff0c\u4e0e\u591a\u91cd\u7ebf\u6027\u56de\u5f52\u5206\u6790\u6709\u5f88\u591a\u76f8\u540c\u4e4b\u5904\u3002\u5b83\u4eec\u7684\u6a21\u578b\u5f62\u5f0f\u57fa\u672c\u4e0a\u76f8\u540c\uff0c\u90fd\u5177\u6709 wx + b\uff0c\u5176\u4e2dw\u548cb\u662f\u5f85\u6c42\u53c2\u6570\uff0c\u5176\u533a\u522b\u5728\u4e8e\u4ed6\u4eec\u7684\u56e0\u53d8\u91cf\u4e0d\u540c\uff0c\u591a\u91cd\u7ebf\u6027\u56de\u5f52\u76f4\u63a5\u5c06wx+b\u4f5c\u4e3a\u56e0\u53d8\u91cf\uff0c\u5373y =wx+b,\u800clogistic\u56de\u5f52\u5219\u901a\u8fc7\u51fd\u6570L\u5c06wx+b\u5bf9\u5e94\u4e00\u4e2a\u9690\u72b6\u6001p\uff0cp =L(wx+b),\u7136\u540e\u6839\u636ep \u4e0e1-p\u7684\u5927\u5c0f\u51b3\u5b9a\u56e0\u53d8\u91cf\u7684\u503c\u3002\u5982\u679cL\u662flogistic\u51fd\u6570\uff0c\u5c31\u662flogistic\u56de\u5f52\uff0c\u5982\u679cL\u662f\u591a\u9879\u5f0f\u51fd\u6570\u5c31\u662f\u591a\u9879\u5f0f\u56de\u5f52\u3002 \u8bf4\u7684\u66f4\u901a\u4fd7\u4e00\u70b9\uff0c\u5c31\u662flogistic\u56de\u5f52\u4f1a\u5728\u7ebf\u6027\u56de\u5f52\u540e\u518d\u52a0\u4e00\u5c42logistic\u51fd\u6570\u7684\u8c03\u7528\u3002 logistic\u56de\u5f52\u4e3b\u8981\u662f\u8fdb\u884c\u4e8c\u5206\u7c7b\u9884\u6d4b\uff0c\u6211\u4eec\u5728\u6fc0\u6d3b\u51fd\u6570\u65f6\u5019\u8bb2\u5230\u8fc7 Sigmod\u51fd\u6570\uff0cSigmod\u51fd\u6570\u662f\u6700\u5e38\u89c1\u7684logistic\u51fd\u6570\uff0c\u56e0\u4e3aSigmod\u51fd\u6570\u7684\u8f93\u51fa\u7684\u662f\u662f\u5bf9\u4e8e0~1\u4e4b\u95f4\u7684\u6982\u7387\u503c\uff0c\u5f53\u6982\u7387\u5927\u4e8e0.5\u9884\u6d4b\u4e3a1\uff0c\u5c0f\u4e8e0.5\u9884\u6d4b\u4e3a0\u3002 \u4e0b\u9762\u6211\u4eec\u5c31\u6765\u4f7f\u7528\u516c\u5f00\u7684\u6570\u636e\u6765\u8fdb\u884c\u4ecb\u7ecd","title":"3.1.1 logistic\u56de\u5f52\u4ecb\u7ecd"},{"location":"tutorial/chapter03_intermediate/3_1_logistic-regression/#312-uci-german-credit","text":"UCI German Credit\u662fUCI\u7684\u5fb7\u56fd\u4fe1\u7528\u6570\u636e\u96c6\uff0c\u91cc\u9762\u6709\u539f\u6570\u636e\u548c\u6570\u503c\u5316\u540e\u7684\u6570\u636e\u3002 German Credit\u6570\u636e\u662f\u6839\u636e\u4e2a\u4eba\u7684\u94f6\u884c\u8d37\u6b3e\u4fe1\u606f\u548c\u7533\u8bf7\u5ba2\u6237\u8d37\u6b3e\u903e\u671f\u53d1\u751f\u60c5\u51b5\u6765\u9884\u6d4b\u8d37\u6b3e\u8fdd\u7ea6\u503e\u5411\u7684\u6570\u636e\u96c6\uff0c\u6570\u636e\u96c6\u5305\u542b24\u4e2a\u7ef4\u5ea6\u7684\uff0c1000\u6761\u6570\u636e\uff0c \u5728\u8fd9\u91cc\u6211\u4eec\u76f4\u63a5\u4f7f\u7528\u5904\u7406\u597d\u7684\u6570\u503c\u5316\u7684\u6570\u636e\uff0c\u4f5c\u4e3a\u5c55\u793a\u3002 \u5730\u5740","title":"3.1.2 UCI German Credit  \u6570\u636e\u96c6"},{"location":"tutorial/chapter03_intermediate/3_1_logistic-regression/#32","text":"\u6211\u4eec\u8fd9\u91cc\u4f7f\u7528\u7684 german.data-numeric\u662fnumpy\u5904\u7406\u597d\u6570\u503c\u5316\u6570\u636e\uff0c\u6211\u4eec\u76f4\u63a5\u4f7f\u7528numpy\u7684load\u65b9\u6cd5\u8bfb\u53d6\u5373\u53ef data = np . loadtxt ( \"german.data-numeric\" ) \u6570\u636e\u8bfb\u53d6\u5b8c\u6210\u540e\u6211\u4eec\u8981\u5bf9\u6570\u636e\u505a\u4e00\u4e0b\u5f52\u4e00\u5316\u7684\u5904\u7406 n , l = data . shape for j in range ( l - 1 ): meanVal = np . mean ( data [:, j ]) stdVal = np . std ( data [:, j ]) data [:, j ] = ( data [:, j ] - meanVal ) / stdVal \u6253\u4e71\u6570\u636e np . random . shuffle ( data ) \u533a\u5206\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\uff0c\u7531\u4e8e\u8fd9\u91cc\u6ca1\u6709\u9a8c\u8bc1\u96c6\uff0c\u6240\u4ee5\u6211\u4eec\u76f4\u63a5\u4f7f\u7528\u6d4b\u8bd5\u96c6\u7684\u51c6\u786e\u5ea6\u4f5c\u4e3a\u8bc4\u5224\u597d\u574f\u7684\u6807\u51c6 \u533a\u5206\u89c4\u5219\uff1a900\u6761\u7528\u4e8e\u8bad\u7ec3\uff0c100\u6761\u4f5c\u4e3a\u6d4b\u8bd5 german.data-numeric\u7684\u683c\u5f0f\u4e3a\uff0c\u524d24\u5217\u4e3a24\u4e2a\u7ef4\u5ea6\uff0c\u6700\u540e\u4e00\u4e2a\u4e3a\u8981\u6253\u7684\u6807\u7b7e\uff080\uff0c1\uff09\uff0c\u6240\u4ee5\u6211\u4eec\u5c06\u6570\u636e\u548c\u6807\u7b7e\u4e00\u8d77\u533a\u5206\u51fa\u6765 train_data = data [: 900 ,: l - 1 ] train_lab = data [: 900 , l - 1 ] - 1 test_data = data [ 900 :,: l - 1 ] test_lab = data [ 900 :, l - 1 ] - 1 \u4e0b\u9762\u6211\u4eec\u5b9a\u4e49\u6a21\u578b\uff0c\u6a21\u578b\u5f88\u7b80\u5355 class LR ( nn . Module ): def __init__ ( self ): super ( LR , self ) . __init__ () self . fc = nn . Linear ( 24 , 2 ) # \u7531\u4e8e24\u4e2a\u7ef4\u5ea6\u5df2\u7ecf\u56fa\u5b9a\u4e86\uff0c\u6240\u4ee5\u8fd9\u91cc\u519924 def forward ( self , x ): out = self . fc ( x ) out = torch . sigmoid ( out ) return out \u6d4b\u8bd5\u96c6\u4e0a\u7684\u51c6\u786e\u7387 def test ( pred , lab ): t = pred . max ( - 1 )[ 1 ] == lab return torch . mean ( t . float ()) \u4e0b\u9762\u5c31\u662f\u5bf9\u4e00\u4e9b\u8bbe\u7f6e net = LR () criterion = nn . CrossEntropyLoss () # \u4f7f\u7528CrossEntropyLoss\u635f\u5931 optm = torch . optim . Adam ( net . parameters ()) # Adam\u4f18\u5316 epochs = 1000 # \u8bad\u7ec31000\u6b21 \u4e0b\u9762\u5f00\u59cb\u8bad\u7ec3\u4e86 for i in range ( epochs ): # \u6307\u5b9a\u6a21\u578b\u4e3a\u8bad\u7ec3\u6a21\u5f0f\uff0c\u8ba1\u7b97\u68af\u5ea6 net . train () # \u8f93\u5165\u503c\u90fd\u9700\u8981\u8f6c\u5316\u6210torch\u7684Tensor x = torch . from_numpy ( train_data ) . float () y = torch . from_numpy ( train_lab ) . long () y_hat = net ( x ) loss = criterion ( y_hat , y ) # \u8ba1\u7b97\u635f\u5931 optm . zero_grad () # \u524d\u4e00\u6b65\u7684\u635f\u5931\u6e05\u96f6 loss . backward () # \u53cd\u5411\u4f20\u64ad optm . step () # \u4f18\u5316 if ( i + 1 ) % 100 == 0 : # \u8fd9\u91cc\u6211\u4eec\u6bcf100\u6b21\u8f93\u51fa\u76f8\u5173\u7684\u4fe1\u606f # \u6307\u5b9a\u6a21\u578b\u4e3a\u8ba1\u7b97\u6a21\u5f0f net . eval () test_in = torch . from_numpy ( test_data ) . float () test_l = torch . from_numpy ( test_lab ) . long () test_out = net ( test_in ) # \u4f7f\u7528\u6211\u4eec\u7684\u6d4b\u8bd5\u51fd\u6570\u8ba1\u7b97\u51c6\u786e\u7387 accu = test ( test_out , test_l ) print ( \"Epoch:{},Loss:{:.4f},Accuracy\uff1a{:.2f}\" . format ( i + 1 , loss . item (), accu )) Epoch:100,Loss:0.6313,Accuracy\uff1a0.76 Epoch:200,Loss:0.6065,Accuracy\uff1a0.79 Epoch:300,Loss:0.5909,Accuracy\uff1a0.80 Epoch:400,Loss:0.5801,Accuracy\uff1a0.81 Epoch:500,Loss:0.5720,Accuracy\uff1a0.82 Epoch:600,Loss:0.5657,Accuracy\uff1a0.81 Epoch:700,Loss:0.5606,Accuracy\uff1a0.81 Epoch:800,Loss:0.5563,Accuracy\uff1a0.81 Epoch:900,Loss:0.5527,Accuracy\uff1a0.81 Epoch:1000,Loss:0.5496,Accuracy\uff1a0.80 \u8bad\u7ec3\u5b8c\u6210\u4e86\uff0c\u6211\u4eec\u7684\u51c6\u786e\u5ea6\u8fbe\u5230\u4e8680%","title":"3.2 \u4ee3\u7801\u5b9e\u6218"},{"location":"tutorial/chapter03_intermediate/3_2_1_cnn_convnet_mnist/","text":"import torch import torch.nn as nn import torch.nn.functional as F import torch.optim as optim from torchvision import datasets , transforms torch . __version__ '1.0.0' 3.2 MNIST\u6570\u636e\u96c6\u624b\u5199\u6570\u5b57\u8bc6\u522b \u00b6 3.2.1 \u6570\u636e\u96c6\u4ecb\u7ecd \u00b6 MNIST \u5305\u62ec6\u4e07\u5f2028x28\u7684\u8bad\u7ec3\u6837\u672c\uff0c1\u4e07\u5f20\u6d4b\u8bd5\u6837\u672c\uff0c\u5f88\u591a\u6559\u7a0b\u90fd\u4f1a\u5bf9\u5b83\u201d\u4e0b\u624b\u201d\u51e0\u4e4e\u6210\u4e3a\u4e00\u4e2a \u201c\u5178\u8303\u201d\uff0c\u53ef\u4ee5\u8bf4\u5b83\u5c31\u662f\u8ba1\u7b97\u673a\u89c6\u89c9\u91cc\u9762\u7684Hello World\u3002\u6240\u4ee5\u6211\u4eec\u8fd9\u91cc\u4e5f\u4f1a\u4f7f\u7528MNIST\u6765\u8fdb\u884c\u5b9e\u6218\u3002 \u524d\u9762\u5728\u4ecb\u7ecd\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u65f6\u5019\u8bf4\u5230\u8fc7LeNet-5\uff0cLeNet-5\u4e4b\u6240\u4ee5\u5f3a\u5927\u5c31\u662f\u56e0\u4e3a\u5728\u5f53\u65f6\u7684\u73af\u5883\u4e0b\u5c06MNIST\u6570\u636e\u7684\u8bc6\u522b\u7387\u63d0\u9ad8\u5230\u4e8699%\uff0c\u8fd9\u91cc\u6211\u4eec\u4e5f\u81ea\u5df1\u4ece\u5934\u642d\u5efa\u4e00\u4e2a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u4e5f\u8fbe\u523099%\u7684\u51c6\u786e\u7387 3.2.2 \u624b\u5199\u6570\u5b57\u8bc6\u522b \u00b6 \u9996\u5148\uff0c\u6211\u4eec\u5b9a\u4e49\u4e00\u4e9b\u8d85\u53c2\u6570\uff1a BATCH_SIZE = 512 #\u5927\u6982\u9700\u89812G\u7684\u663e\u5b58 EPOCHS = 20 # \u603b\u5171\u8bad\u7ec3\u6279\u6b21 DEVICE = torch . device ( \"cuda\" if torch . cuda . is_available () else \"cpu\" ) # \u8ba9torch\u5224\u65ad\u662f\u5426\u4f7f\u7528GPU\uff0c\u5efa\u8bae\u4f7f\u7528GPU\u73af\u5883\uff0c\u56e0\u4e3a\u4f1a\u5feb\u5f88\u591a \u56e0\u4e3aPytorch\u91cc\u9762\u5305\u542b\u4e86MNIST\u7684\u6570\u636e\u96c6\uff0c\u6240\u4ee5\u6211\u4eec\u8fd9\u91cc\u76f4\u63a5\u4f7f\u7528\u5373\u53ef\u3002 \u5982\u679c\u7b2c\u4e00\u6b21\u6267\u884c\u4f1a\u751f\u6210data\u6587\u4ef6\u5939\uff0c\u5e76\u4e14\u9700\u8981\u4e00\u4e9b\u65f6\u95f4\u4e0b\u8f7d\uff0c\u5982\u679c\u4ee5\u524d\u4e0b\u8f7d\u8fc7\u5c31\u4e0d\u4f1a\u518d\u6b21\u4e0b\u8f7d\u4e86\u3002 \u7531\u4e8e\u5b98\u65b9\u5df2\u7ecf\u5b9e\u73b0\u4e86dataset\uff0c\u6240\u4ee5\u8fd9\u91cc\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528DataLoader\u6765\u5bf9\u6570\u636e\u8fdb\u884c\u8bfb\u53d6\uff1a train_loader = torch . utils . data . DataLoader ( datasets . MNIST ( 'data' , train = True , download = True , transform = transforms . Compose ([ transforms . ToTensor (), transforms . Normalize (( 0.1307 ,), ( 0.3081 ,)) ])), batch_size = BATCH_SIZE , shuffle = True ) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz Processing... Done! \u6d4b\u8bd5\u96c6\uff1a test_loader = torch . utils . data . DataLoader ( datasets . MNIST ( 'data' , train = False , transform = transforms . Compose ([ transforms . ToTensor (), transforms . Normalize (( 0.1307 ,), ( 0.3081 ,)) ])), batch_size = BATCH_SIZE , shuffle = True ) \u4e0b\u9762\u6211\u4eec\u5b9a\u4e49\u4e00\u4e2a\u7f51\u7edc\uff0c\u7f51\u7edc\u5305\u542b\u4e24\u4e2a\u5377\u79ef\u5c42\uff0cconv1\u548cconv2\uff0c\u7136\u540e\u7d27\u63a5\u7740\u4e24\u4e2a\u7ebf\u6027\u5c42\u4f5c\u4e3a\u8f93\u51fa\uff0c\u6700\u540e\u8f93\u51fa10\u4e2a\u7ef4\u5ea6\uff0c\u8fd910\u4e2a\u7ef4\u5ea6\u6211\u4eec\u4f5c\u4e3a0-9\u7684\u6807\u8bc6\u6765\u786e\u5b9a\u8bc6\u522b\u51fa\u7684\u662f\u90a3\u4e2a\u6570\u5b57\u3002 \u5728\u8fd9\u91cc\u5efa\u8bae\u5927\u5bb6\u5c06\u6bcf\u4e00\u5c42\u7684\u8f93\u5165\u548c\u8f93\u51fa\u7ef4\u5ea6\u90fd\u4f5c\u4e3a\u6ce8\u91ca\u6807\u6ce8\u51fa\u6765\uff0c\u8fd9\u6837\u540e\u9762\u9605\u8bfb\u4ee3\u7801\u7684\u4f1a\u65b9\u4fbf\u5f88\u591a\u3002 class ConvNet ( nn . Module ): def __init__ ( self ): super () . __init__ () # 1,28x28 self . conv1 = nn . Conv2d ( 1 , 10 , 5 ) # 10, 24x24 self . conv2 = nn . Conv2d ( 10 , 20 , 3 ) # 128, 10x10 self . fc1 = nn . Linear ( 20 * 10 * 10 , 500 ) self . fc2 = nn . Linear ( 500 , 10 ) def forward ( self , x ): in_size = x . size ( 0 ) out = self . conv1 ( x ) #24 out = F . relu ( out ) out = F . max_pool2d ( out , 2 , 2 ) #12 out = self . conv2 ( out ) #10 out = F . relu ( out ) out = out . view ( in_size , - 1 ) out = self . fc1 ( out ) out = F . relu ( out ) out = self . fc2 ( out ) out = F . log_softmax ( out , dim = 1 ) return out \u6211\u4eec\u5b9e\u4f8b\u5316\u4e00\u4e2a\u7f51\u7edc\uff0c\u5b9e\u4f8b\u5316\u540e\u4f7f\u7528.to\u65b9\u6cd5\u5c06\u7f51\u7edc\u79fb\u52a8\u5230GPU \u4f18\u5316\u5668\u6211\u4eec\u4e5f\u76f4\u63a5\u9009\u62e9\u7b80\u5355\u66b4\u529b\u7684Adam model = ConvNet () . to ( DEVICE ) optimizer = optim . Adam ( model . parameters ()) \u4e0b\u9762\u5b9a\u4e49\u4e00\u4e0b\u8bad\u7ec3\u7684\u51fd\u6570\uff0c\u6211\u4eec\u5c06\u8bad\u7ec3\u7684\u6240\u6709\u64cd\u4f5c\u90fd\u5c01\u88c5\u5230\u8fd9\u4e2a\u51fd\u6570\u4e2d def train ( model , device , train_loader , optimizer , epoch ): model . train () for batch_idx , ( data , target ) in enumerate ( train_loader ): data , target = data . to ( device ), target . to ( device ) optimizer . zero_grad () output = model ( data ) loss = F . nll_loss ( output , target ) loss . backward () optimizer . step () if ( batch_idx + 1 ) % 30 == 0 : print ( 'Train Epoch: {} [{}/{} ({:.0f}%)] \\t Loss: {:.6f}' . format ( epoch , batch_idx * len ( data ), len ( train_loader . dataset ), 100. * batch_idx / len ( train_loader ), loss . item ())) \u6d4b\u8bd5\u7684\u64cd\u4f5c\u4e5f\u4e00\u6837\u5c01\u88c5\u6210\u4e00\u4e2a\u51fd\u6570\uff1a def test ( model , device , test_loader ): model . eval () test_loss = 0 correct = 0 with torch . no_grad (): for data , target in test_loader : data , target = data . to ( device ), target . to ( device ) output = model ( data ) test_loss += F . nll_loss ( output , target , reduction = 'sum' ) . item () # \u5c06\u4e00\u6279\u7684\u635f\u5931\u76f8\u52a0 pred = output . max ( 1 , keepdim = True )[ 1 ] # \u627e\u5230\u6982\u7387\u6700\u5927\u7684\u4e0b\u6807 correct += pred . eq ( target . view_as ( pred )) . sum () . item () test_loss /= len ( test_loader . dataset ) print ( ' \\n Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%) \\n ' . format ( test_loss , correct , len ( test_loader . dataset ), 100. * correct / len ( test_loader . dataset ))) \u4e0b\u9762\u5f00\u59cb\u8bad\u7ec3\uff0c\u8fd9\u91cc\u5c31\u4f53\u73b0\u51fa\u5c01\u88c5\u8d77\u6765\u7684\u597d\u5904\u4e86\uff0c\u53ea\u8981\u5199\u4e24\u884c\u5c31\u53ef\u4ee5\u4e86\uff1a for epoch in range ( 1 , EPOCHS + 1 ): train ( model , DEVICE , train_loader , optimizer , epoch ) test ( model , DEVICE , test_loader ) Train Epoch: 1 [14848/60000 (25%)] Loss: 0.272529 Train Epoch: 1 [30208/60000 (50%)] Loss: 0.235455 Train Epoch: 1 [45568/60000 (75%)] Loss: 0.101858 Test set: Average loss: 0.1018, Accuracy: 9695/10000 (97%) Train Epoch: 2 [14848/60000 (25%)] Loss: 0.057989 Train Epoch: 2 [30208/60000 (50%)] Loss: 0.083935 Train Epoch: 2 [45568/60000 (75%)] Loss: 0.051921 Test set: Average loss: 0.0523, Accuracy: 9825/10000 (98%) Train Epoch: 3 [14848/60000 (25%)] Loss: 0.045383 Train Epoch: 3 [30208/60000 (50%)] Loss: 0.049402 Train Epoch: 3 [45568/60000 (75%)] Loss: 0.061366 Test set: Average loss: 0.0408, Accuracy: 9866/10000 (99%) Train Epoch: 4 [14848/60000 (25%)] Loss: 0.035253 Train Epoch: 4 [30208/60000 (50%)] Loss: 0.038444 Train Epoch: 4 [45568/60000 (75%)] Loss: 0.036877 Test set: Average loss: 0.0433, Accuracy: 9859/10000 (99%) Train Epoch: 5 [14848/60000 (25%)] Loss: 0.038996 Train Epoch: 5 [30208/60000 (50%)] Loss: 0.020670 Train Epoch: 5 [45568/60000 (75%)] Loss: 0.034658 Test set: Average loss: 0.0339, Accuracy: 9885/10000 (99%) Train Epoch: 6 [14848/60000 (25%)] Loss: 0.067320 Train Epoch: 6 [30208/60000 (50%)] Loss: 0.016328 Train Epoch: 6 [45568/60000 (75%)] Loss: 0.017037 Test set: Average loss: 0.0348, Accuracy: 9881/10000 (99%) Train Epoch: 7 [14848/60000 (25%)] Loss: 0.022150 Train Epoch: 7 [30208/60000 (50%)] Loss: 0.009608 Train Epoch: 7 [45568/60000 (75%)] Loss: 0.012742 Test set: Average loss: 0.0346, Accuracy: 9895/10000 (99%) Train Epoch: 8 [14848/60000 (25%)] Loss: 0.010173 Train Epoch: 8 [30208/60000 (50%)] Loss: 0.019482 Train Epoch: 8 [45568/60000 (75%)] Loss: 0.012159 Test set: Average loss: 0.0323, Accuracy: 9886/10000 (99%) Train Epoch: 9 [14848/60000 (25%)] Loss: 0.007792 Train Epoch: 9 [30208/60000 (50%)] Loss: 0.006970 Train Epoch: 9 [45568/60000 (75%)] Loss: 0.004989 Test set: Average loss: 0.0294, Accuracy: 9909/10000 (99%) Train Epoch: 10 [14848/60000 (25%)] Loss: 0.003764 Train Epoch: 10 [30208/60000 (50%)] Loss: 0.005944 Train Epoch: 10 [45568/60000 (75%)] Loss: 0.001866 Test set: Average loss: 0.0361, Accuracy: 9902/10000 (99%) Train Epoch: 11 [14848/60000 (25%)] Loss: 0.002737 Train Epoch: 11 [30208/60000 (50%)] Loss: 0.014134 Train Epoch: 11 [45568/60000 (75%)] Loss: 0.001365 Test set: Average loss: 0.0309, Accuracy: 9905/10000 (99%) Train Epoch: 12 [14848/60000 (25%)] Loss: 0.003344 Train Epoch: 12 [30208/60000 (50%)] Loss: 0.003090 Train Epoch: 12 [45568/60000 (75%)] Loss: 0.004847 Test set: Average loss: 0.0318, Accuracy: 9902/10000 (99%) Train Epoch: 13 [14848/60000 (25%)] Loss: 0.001278 Train Epoch: 13 [30208/60000 (50%)] Loss: 0.003016 Train Epoch: 13 [45568/60000 (75%)] Loss: 0.001328 Test set: Average loss: 0.0358, Accuracy: 9906/10000 (99%) Train Epoch: 14 [14848/60000 (25%)] Loss: 0.002219 Train Epoch: 14 [30208/60000 (50%)] Loss: 0.003487 Train Epoch: 14 [45568/60000 (75%)] Loss: 0.014429 Test set: Average loss: 0.0376, Accuracy: 9896/10000 (99%) Train Epoch: 15 [14848/60000 (25%)] Loss: 0.003042 Train Epoch: 15 [30208/60000 (50%)] Loss: 0.002974 Train Epoch: 15 [45568/60000 (75%)] Loss: 0.000871 Test set: Average loss: 0.0346, Accuracy: 9909/10000 (99%) Train Epoch: 16 [14848/60000 (25%)] Loss: 0.000618 Train Epoch: 16 [30208/60000 (50%)] Loss: 0.003164 Train Epoch: 16 [45568/60000 (75%)] Loss: 0.007245 Test set: Average loss: 0.0357, Accuracy: 9905/10000 (99%) Train Epoch: 17 [14848/60000 (25%)] Loss: 0.001874 Train Epoch: 17 [30208/60000 (50%)] Loss: 0.013951 Train Epoch: 17 [45568/60000 (75%)] Loss: 0.000729 Test set: Average loss: 0.0322, Accuracy: 9922/10000 (99%) Train Epoch: 18 [14848/60000 (25%)] Loss: 0.002581 Train Epoch: 18 [30208/60000 (50%)] Loss: 0.001396 Train Epoch: 18 [45568/60000 (75%)] Loss: 0.015521 Test set: Average loss: 0.0389, Accuracy: 9914/10000 (99%) Train Epoch: 19 [14848/60000 (25%)] Loss: 0.000283 Train Epoch: 19 [30208/60000 (50%)] Loss: 0.001385 Train Epoch: 19 [45568/60000 (75%)] Loss: 0.011184 Test set: Average loss: 0.0383, Accuracy: 9901/10000 (99%) Train Epoch: 20 [14848/60000 (25%)] Loss: 0.000472 Train Epoch: 20 [30208/60000 (50%)] Loss: 0.003306 Train Epoch: 20 [45568/60000 (75%)] Loss: 0.018017 Test set: Average loss: 0.0393, Accuracy: 9899/10000 (99%) \u6211\u4eec\u770b\u4e00\u4e0b\u7ed3\u679c\uff0c\u51c6\u786e\u738799%\uff0c\u6ca1\u95ee\u9898\u3002 \u5982\u679c\u4f60\u7684\u6a21\u578b\u8fdeMNIST\u90fd\u641e\u4e0d\u5b9a\uff0c\u90a3\u4e48\u4f60\u7684\u6a21\u578b\u6ca1\u6709\u4efb\u4f55\u7684\u4ef7\u503c\u3002 \u5373\u4f7f\u4f60\u7684\u6a21\u578b\u641e\u5b9a\u4e86MNIST\uff0c\u4f60\u7684\u6a21\u578b\u4e5f\u53ef\u80fd\u6ca1\u6709\u4efb\u4f55\u7684\u4ef7\u503c\u3002 MNIST\u662f\u4e00\u4e2a\u5f88\u7b80\u5355\u7684\u6570\u636e\u96c6\uff0c\u7531\u4e8e\u5b83\u7684\u5c40\u9650\u6027\u53ea\u80fd\u4f5c\u4e3a\u7814\u7a76\u7528\u9014\uff0c\u5bf9\u5b9e\u9645\u5e94\u7528\u5e26\u6765\u7684\u4ef7\u503c\u975e\u5e38\u6709\u9650\u3002\u4f46\u662f\u901a\u8fc7\u8fd9\u4e2a\u4f8b\u5b50\uff0c\u6211\u4eec\u53ef\u4ee5\u5b8c\u5168\u4e86\u89e3\u4e00\u4e2a\u5b9e\u9645\u9879\u76ee\u7684\u5de5\u4f5c\u6d41\u7a0b\u3002 \u6211\u4eec\u627e\u5230\u6570\u636e\u96c6\uff0c\u5bf9\u6570\u636e\u505a\u9884\u5904\u7406\uff0c\u5b9a\u4e49\u6211\u4eec\u7684\u6a21\u578b\uff0c\u8c03\u6574\u8d85\u53c2\u6570\uff0c\u6d4b\u8bd5\u8bad\u7ec3\uff0c\u518d\u901a\u8fc7\u8bad\u7ec3\u7ed3\u679c\u5bf9\u8d85\u53c2\u6570\u8fdb\u884c\u8c03\u6574\u6216\u8005\u5bf9\u6a21\u578b\u8fdb\u884c\u8c03\u6574\u3002 \u5e76\u4e14\u901a\u8fc7\u8fd9\u4e2a\u5b9e\u6218\u6211\u4eec\u5df2\u7ecf\u6709\u4e86\u4e00\u4e2a\u5f88\u597d\u7684\u6a21\u677f\uff0c\u4ee5\u540e\u7684\u9879\u76ee\u90fd\u53ef\u4ee5\u4ee5\u8fd9\u4e2a\u6a21\u677f\u4e3a\u6837\u4f8b\u3002","title":"3.2.1 ConvNet Mnist"},{"location":"tutorial/chapter03_intermediate/3_2_1_cnn_convnet_mnist/#32-mnist","text":"","title":"3.2  MNIST\u6570\u636e\u96c6\u624b\u5199\u6570\u5b57\u8bc6\u522b"},{"location":"tutorial/chapter03_intermediate/3_2_1_cnn_convnet_mnist/#321","text":"MNIST \u5305\u62ec6\u4e07\u5f2028x28\u7684\u8bad\u7ec3\u6837\u672c\uff0c1\u4e07\u5f20\u6d4b\u8bd5\u6837\u672c\uff0c\u5f88\u591a\u6559\u7a0b\u90fd\u4f1a\u5bf9\u5b83\u201d\u4e0b\u624b\u201d\u51e0\u4e4e\u6210\u4e3a\u4e00\u4e2a \u201c\u5178\u8303\u201d\uff0c\u53ef\u4ee5\u8bf4\u5b83\u5c31\u662f\u8ba1\u7b97\u673a\u89c6\u89c9\u91cc\u9762\u7684Hello World\u3002\u6240\u4ee5\u6211\u4eec\u8fd9\u91cc\u4e5f\u4f1a\u4f7f\u7528MNIST\u6765\u8fdb\u884c\u5b9e\u6218\u3002 \u524d\u9762\u5728\u4ecb\u7ecd\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u65f6\u5019\u8bf4\u5230\u8fc7LeNet-5\uff0cLeNet-5\u4e4b\u6240\u4ee5\u5f3a\u5927\u5c31\u662f\u56e0\u4e3a\u5728\u5f53\u65f6\u7684\u73af\u5883\u4e0b\u5c06MNIST\u6570\u636e\u7684\u8bc6\u522b\u7387\u63d0\u9ad8\u5230\u4e8699%\uff0c\u8fd9\u91cc\u6211\u4eec\u4e5f\u81ea\u5df1\u4ece\u5934\u642d\u5efa\u4e00\u4e2a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u4e5f\u8fbe\u523099%\u7684\u51c6\u786e\u7387","title":"3.2.1  \u6570\u636e\u96c6\u4ecb\u7ecd"},{"location":"tutorial/chapter03_intermediate/3_2_1_cnn_convnet_mnist/#322","text":"\u9996\u5148\uff0c\u6211\u4eec\u5b9a\u4e49\u4e00\u4e9b\u8d85\u53c2\u6570\uff1a BATCH_SIZE = 512 #\u5927\u6982\u9700\u89812G\u7684\u663e\u5b58 EPOCHS = 20 # \u603b\u5171\u8bad\u7ec3\u6279\u6b21 DEVICE = torch . device ( \"cuda\" if torch . cuda . is_available () else \"cpu\" ) # \u8ba9torch\u5224\u65ad\u662f\u5426\u4f7f\u7528GPU\uff0c\u5efa\u8bae\u4f7f\u7528GPU\u73af\u5883\uff0c\u56e0\u4e3a\u4f1a\u5feb\u5f88\u591a \u56e0\u4e3aPytorch\u91cc\u9762\u5305\u542b\u4e86MNIST\u7684\u6570\u636e\u96c6\uff0c\u6240\u4ee5\u6211\u4eec\u8fd9\u91cc\u76f4\u63a5\u4f7f\u7528\u5373\u53ef\u3002 \u5982\u679c\u7b2c\u4e00\u6b21\u6267\u884c\u4f1a\u751f\u6210data\u6587\u4ef6\u5939\uff0c\u5e76\u4e14\u9700\u8981\u4e00\u4e9b\u65f6\u95f4\u4e0b\u8f7d\uff0c\u5982\u679c\u4ee5\u524d\u4e0b\u8f7d\u8fc7\u5c31\u4e0d\u4f1a\u518d\u6b21\u4e0b\u8f7d\u4e86\u3002 \u7531\u4e8e\u5b98\u65b9\u5df2\u7ecf\u5b9e\u73b0\u4e86dataset\uff0c\u6240\u4ee5\u8fd9\u91cc\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528DataLoader\u6765\u5bf9\u6570\u636e\u8fdb\u884c\u8bfb\u53d6\uff1a train_loader = torch . utils . data . DataLoader ( datasets . MNIST ( 'data' , train = True , download = True , transform = transforms . Compose ([ transforms . ToTensor (), transforms . Normalize (( 0.1307 ,), ( 0.3081 ,)) ])), batch_size = BATCH_SIZE , shuffle = True ) Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz Processing... Done! \u6d4b\u8bd5\u96c6\uff1a test_loader = torch . utils . data . DataLoader ( datasets . MNIST ( 'data' , train = False , transform = transforms . Compose ([ transforms . ToTensor (), transforms . Normalize (( 0.1307 ,), ( 0.3081 ,)) ])), batch_size = BATCH_SIZE , shuffle = True ) \u4e0b\u9762\u6211\u4eec\u5b9a\u4e49\u4e00\u4e2a\u7f51\u7edc\uff0c\u7f51\u7edc\u5305\u542b\u4e24\u4e2a\u5377\u79ef\u5c42\uff0cconv1\u548cconv2\uff0c\u7136\u540e\u7d27\u63a5\u7740\u4e24\u4e2a\u7ebf\u6027\u5c42\u4f5c\u4e3a\u8f93\u51fa\uff0c\u6700\u540e\u8f93\u51fa10\u4e2a\u7ef4\u5ea6\uff0c\u8fd910\u4e2a\u7ef4\u5ea6\u6211\u4eec\u4f5c\u4e3a0-9\u7684\u6807\u8bc6\u6765\u786e\u5b9a\u8bc6\u522b\u51fa\u7684\u662f\u90a3\u4e2a\u6570\u5b57\u3002 \u5728\u8fd9\u91cc\u5efa\u8bae\u5927\u5bb6\u5c06\u6bcf\u4e00\u5c42\u7684\u8f93\u5165\u548c\u8f93\u51fa\u7ef4\u5ea6\u90fd\u4f5c\u4e3a\u6ce8\u91ca\u6807\u6ce8\u51fa\u6765\uff0c\u8fd9\u6837\u540e\u9762\u9605\u8bfb\u4ee3\u7801\u7684\u4f1a\u65b9\u4fbf\u5f88\u591a\u3002 class ConvNet ( nn . Module ): def __init__ ( self ): super () . __init__ () # 1,28x28 self . conv1 = nn . Conv2d ( 1 , 10 , 5 ) # 10, 24x24 self . conv2 = nn . Conv2d ( 10 , 20 , 3 ) # 128, 10x10 self . fc1 = nn . Linear ( 20 * 10 * 10 , 500 ) self . fc2 = nn . Linear ( 500 , 10 ) def forward ( self , x ): in_size = x . size ( 0 ) out = self . conv1 ( x ) #24 out = F . relu ( out ) out = F . max_pool2d ( out , 2 , 2 ) #12 out = self . conv2 ( out ) #10 out = F . relu ( out ) out = out . view ( in_size , - 1 ) out = self . fc1 ( out ) out = F . relu ( out ) out = self . fc2 ( out ) out = F . log_softmax ( out , dim = 1 ) return out \u6211\u4eec\u5b9e\u4f8b\u5316\u4e00\u4e2a\u7f51\u7edc\uff0c\u5b9e\u4f8b\u5316\u540e\u4f7f\u7528.to\u65b9\u6cd5\u5c06\u7f51\u7edc\u79fb\u52a8\u5230GPU \u4f18\u5316\u5668\u6211\u4eec\u4e5f\u76f4\u63a5\u9009\u62e9\u7b80\u5355\u66b4\u529b\u7684Adam model = ConvNet () . to ( DEVICE ) optimizer = optim . Adam ( model . parameters ()) \u4e0b\u9762\u5b9a\u4e49\u4e00\u4e0b\u8bad\u7ec3\u7684\u51fd\u6570\uff0c\u6211\u4eec\u5c06\u8bad\u7ec3\u7684\u6240\u6709\u64cd\u4f5c\u90fd\u5c01\u88c5\u5230\u8fd9\u4e2a\u51fd\u6570\u4e2d def train ( model , device , train_loader , optimizer , epoch ): model . train () for batch_idx , ( data , target ) in enumerate ( train_loader ): data , target = data . to ( device ), target . to ( device ) optimizer . zero_grad () output = model ( data ) loss = F . nll_loss ( output , target ) loss . backward () optimizer . step () if ( batch_idx + 1 ) % 30 == 0 : print ( 'Train Epoch: {} [{}/{} ({:.0f}%)] \\t Loss: {:.6f}' . format ( epoch , batch_idx * len ( data ), len ( train_loader . dataset ), 100. * batch_idx / len ( train_loader ), loss . item ())) \u6d4b\u8bd5\u7684\u64cd\u4f5c\u4e5f\u4e00\u6837\u5c01\u88c5\u6210\u4e00\u4e2a\u51fd\u6570\uff1a def test ( model , device , test_loader ): model . eval () test_loss = 0 correct = 0 with torch . no_grad (): for data , target in test_loader : data , target = data . to ( device ), target . to ( device ) output = model ( data ) test_loss += F . nll_loss ( output , target , reduction = 'sum' ) . item () # \u5c06\u4e00\u6279\u7684\u635f\u5931\u76f8\u52a0 pred = output . max ( 1 , keepdim = True )[ 1 ] # \u627e\u5230\u6982\u7387\u6700\u5927\u7684\u4e0b\u6807 correct += pred . eq ( target . view_as ( pred )) . sum () . item () test_loss /= len ( test_loader . dataset ) print ( ' \\n Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%) \\n ' . format ( test_loss , correct , len ( test_loader . dataset ), 100. * correct / len ( test_loader . dataset ))) \u4e0b\u9762\u5f00\u59cb\u8bad\u7ec3\uff0c\u8fd9\u91cc\u5c31\u4f53\u73b0\u51fa\u5c01\u88c5\u8d77\u6765\u7684\u597d\u5904\u4e86\uff0c\u53ea\u8981\u5199\u4e24\u884c\u5c31\u53ef\u4ee5\u4e86\uff1a for epoch in range ( 1 , EPOCHS + 1 ): train ( model , DEVICE , train_loader , optimizer , epoch ) test ( model , DEVICE , test_loader ) Train Epoch: 1 [14848/60000 (25%)] Loss: 0.272529 Train Epoch: 1 [30208/60000 (50%)] Loss: 0.235455 Train Epoch: 1 [45568/60000 (75%)] Loss: 0.101858 Test set: Average loss: 0.1018, Accuracy: 9695/10000 (97%) Train Epoch: 2 [14848/60000 (25%)] Loss: 0.057989 Train Epoch: 2 [30208/60000 (50%)] Loss: 0.083935 Train Epoch: 2 [45568/60000 (75%)] Loss: 0.051921 Test set: Average loss: 0.0523, Accuracy: 9825/10000 (98%) Train Epoch: 3 [14848/60000 (25%)] Loss: 0.045383 Train Epoch: 3 [30208/60000 (50%)] Loss: 0.049402 Train Epoch: 3 [45568/60000 (75%)] Loss: 0.061366 Test set: Average loss: 0.0408, Accuracy: 9866/10000 (99%) Train Epoch: 4 [14848/60000 (25%)] Loss: 0.035253 Train Epoch: 4 [30208/60000 (50%)] Loss: 0.038444 Train Epoch: 4 [45568/60000 (75%)] Loss: 0.036877 Test set: Average loss: 0.0433, Accuracy: 9859/10000 (99%) Train Epoch: 5 [14848/60000 (25%)] Loss: 0.038996 Train Epoch: 5 [30208/60000 (50%)] Loss: 0.020670 Train Epoch: 5 [45568/60000 (75%)] Loss: 0.034658 Test set: Average loss: 0.0339, Accuracy: 9885/10000 (99%) Train Epoch: 6 [14848/60000 (25%)] Loss: 0.067320 Train Epoch: 6 [30208/60000 (50%)] Loss: 0.016328 Train Epoch: 6 [45568/60000 (75%)] Loss: 0.017037 Test set: Average loss: 0.0348, Accuracy: 9881/10000 (99%) Train Epoch: 7 [14848/60000 (25%)] Loss: 0.022150 Train Epoch: 7 [30208/60000 (50%)] Loss: 0.009608 Train Epoch: 7 [45568/60000 (75%)] Loss: 0.012742 Test set: Average loss: 0.0346, Accuracy: 9895/10000 (99%) Train Epoch: 8 [14848/60000 (25%)] Loss: 0.010173 Train Epoch: 8 [30208/60000 (50%)] Loss: 0.019482 Train Epoch: 8 [45568/60000 (75%)] Loss: 0.012159 Test set: Average loss: 0.0323, Accuracy: 9886/10000 (99%) Train Epoch: 9 [14848/60000 (25%)] Loss: 0.007792 Train Epoch: 9 [30208/60000 (50%)] Loss: 0.006970 Train Epoch: 9 [45568/60000 (75%)] Loss: 0.004989 Test set: Average loss: 0.0294, Accuracy: 9909/10000 (99%) Train Epoch: 10 [14848/60000 (25%)] Loss: 0.003764 Train Epoch: 10 [30208/60000 (50%)] Loss: 0.005944 Train Epoch: 10 [45568/60000 (75%)] Loss: 0.001866 Test set: Average loss: 0.0361, Accuracy: 9902/10000 (99%) Train Epoch: 11 [14848/60000 (25%)] Loss: 0.002737 Train Epoch: 11 [30208/60000 (50%)] Loss: 0.014134 Train Epoch: 11 [45568/60000 (75%)] Loss: 0.001365 Test set: Average loss: 0.0309, Accuracy: 9905/10000 (99%) Train Epoch: 12 [14848/60000 (25%)] Loss: 0.003344 Train Epoch: 12 [30208/60000 (50%)] Loss: 0.003090 Train Epoch: 12 [45568/60000 (75%)] Loss: 0.004847 Test set: Average loss: 0.0318, Accuracy: 9902/10000 (99%) Train Epoch: 13 [14848/60000 (25%)] Loss: 0.001278 Train Epoch: 13 [30208/60000 (50%)] Loss: 0.003016 Train Epoch: 13 [45568/60000 (75%)] Loss: 0.001328 Test set: Average loss: 0.0358, Accuracy: 9906/10000 (99%) Train Epoch: 14 [14848/60000 (25%)] Loss: 0.002219 Train Epoch: 14 [30208/60000 (50%)] Loss: 0.003487 Train Epoch: 14 [45568/60000 (75%)] Loss: 0.014429 Test set: Average loss: 0.0376, Accuracy: 9896/10000 (99%) Train Epoch: 15 [14848/60000 (25%)] Loss: 0.003042 Train Epoch: 15 [30208/60000 (50%)] Loss: 0.002974 Train Epoch: 15 [45568/60000 (75%)] Loss: 0.000871 Test set: Average loss: 0.0346, Accuracy: 9909/10000 (99%) Train Epoch: 16 [14848/60000 (25%)] Loss: 0.000618 Train Epoch: 16 [30208/60000 (50%)] Loss: 0.003164 Train Epoch: 16 [45568/60000 (75%)] Loss: 0.007245 Test set: Average loss: 0.0357, Accuracy: 9905/10000 (99%) Train Epoch: 17 [14848/60000 (25%)] Loss: 0.001874 Train Epoch: 17 [30208/60000 (50%)] Loss: 0.013951 Train Epoch: 17 [45568/60000 (75%)] Loss: 0.000729 Test set: Average loss: 0.0322, Accuracy: 9922/10000 (99%) Train Epoch: 18 [14848/60000 (25%)] Loss: 0.002581 Train Epoch: 18 [30208/60000 (50%)] Loss: 0.001396 Train Epoch: 18 [45568/60000 (75%)] Loss: 0.015521 Test set: Average loss: 0.0389, Accuracy: 9914/10000 (99%) Train Epoch: 19 [14848/60000 (25%)] Loss: 0.000283 Train Epoch: 19 [30208/60000 (50%)] Loss: 0.001385 Train Epoch: 19 [45568/60000 (75%)] Loss: 0.011184 Test set: Average loss: 0.0383, Accuracy: 9901/10000 (99%) Train Epoch: 20 [14848/60000 (25%)] Loss: 0.000472 Train Epoch: 20 [30208/60000 (50%)] Loss: 0.003306 Train Epoch: 20 [45568/60000 (75%)] Loss: 0.018017 Test set: Average loss: 0.0393, Accuracy: 9899/10000 (99%) \u6211\u4eec\u770b\u4e00\u4e0b\u7ed3\u679c\uff0c\u51c6\u786e\u738799%\uff0c\u6ca1\u95ee\u9898\u3002 \u5982\u679c\u4f60\u7684\u6a21\u578b\u8fdeMNIST\u90fd\u641e\u4e0d\u5b9a\uff0c\u90a3\u4e48\u4f60\u7684\u6a21\u578b\u6ca1\u6709\u4efb\u4f55\u7684\u4ef7\u503c\u3002 \u5373\u4f7f\u4f60\u7684\u6a21\u578b\u641e\u5b9a\u4e86MNIST\uff0c\u4f60\u7684\u6a21\u578b\u4e5f\u53ef\u80fd\u6ca1\u6709\u4efb\u4f55\u7684\u4ef7\u503c\u3002 MNIST\u662f\u4e00\u4e2a\u5f88\u7b80\u5355\u7684\u6570\u636e\u96c6\uff0c\u7531\u4e8e\u5b83\u7684\u5c40\u9650\u6027\u53ea\u80fd\u4f5c\u4e3a\u7814\u7a76\u7528\u9014\uff0c\u5bf9\u5b9e\u9645\u5e94\u7528\u5e26\u6765\u7684\u4ef7\u503c\u975e\u5e38\u6709\u9650\u3002\u4f46\u662f\u901a\u8fc7\u8fd9\u4e2a\u4f8b\u5b50\uff0c\u6211\u4eec\u53ef\u4ee5\u5b8c\u5168\u4e86\u89e3\u4e00\u4e2a\u5b9e\u9645\u9879\u76ee\u7684\u5de5\u4f5c\u6d41\u7a0b\u3002 \u6211\u4eec\u627e\u5230\u6570\u636e\u96c6\uff0c\u5bf9\u6570\u636e\u505a\u9884\u5904\u7406\uff0c\u5b9a\u4e49\u6211\u4eec\u7684\u6a21\u578b\uff0c\u8c03\u6574\u8d85\u53c2\u6570\uff0c\u6d4b\u8bd5\u8bad\u7ec3\uff0c\u518d\u901a\u8fc7\u8bad\u7ec3\u7ed3\u679c\u5bf9\u8d85\u53c2\u6570\u8fdb\u884c\u8c03\u6574\u6216\u8005\u5bf9\u6a21\u578b\u8fdb\u884c\u8c03\u6574\u3002 \u5e76\u4e14\u901a\u8fc7\u8fd9\u4e2a\u5b9e\u6218\u6211\u4eec\u5df2\u7ecf\u6709\u4e86\u4e00\u4e2a\u5f88\u597d\u7684\u6a21\u677f\uff0c\u4ee5\u540e\u7684\u9879\u76ee\u90fd\u53ef\u4ee5\u4ee5\u8fd9\u4e2a\u6a21\u677f\u4e3a\u6837\u4f8b\u3002","title":"3.2.2 \u624b\u5199\u6570\u5b57\u8bc6\u522b"},{"location":"tutorial/chapter03_intermediate/3_2_2_cnn_resnet_cifar10/","text":"# ---------------------------------------------------------------------------- # # An implementation of https://arxiv.org/pdf/1512.03385.pdf # # See section 4.2 for the model architecture on CIFAR-10 # # Some part of the code was referenced from below # # https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py # # ---------------------------------------------------------------------------- # import torch import torch.nn as nn import torchvision import torchvision.transforms as transforms # Device configuration device = torch . device ( 'cuda' if torch . cuda . is_available () else 'cpu' ) # Hyper-parameters num_epochs = 80 learning_rate = 0.001 # Image preprocessing modules transform = transforms . Compose ([ transforms . Pad ( 4 ), transforms . RandomHorizontalFlip (), transforms . RandomCrop ( 32 ), transforms . ToTensor ()]) # CIFAR-10 dataset train_dataset = torchvision . datasets . CIFAR10 ( root = '../../data/' , train = True , transform = transform , download = True ) test_dataset = torchvision . datasets . CIFAR10 ( root = '../../data/' , train = False , transform = transforms . ToTensor ()) # Data loader train_loader = torch . utils . data . DataLoader ( dataset = train_dataset , batch_size = 100 , shuffle = True ) test_loader = torch . utils . data . DataLoader ( dataset = test_dataset , batch_size = 100 , shuffle = False ) # 3x3 convolution def conv3x3 ( in_channels , out_channels , stride = 1 ): return nn . Conv2d ( in_channels , out_channels , kernel_size = 3 , stride = stride , padding = 1 , bias = False ) # Residual block class ResidualBlock ( nn . Module ): def __init__ ( self , in_channels , out_channels , stride = 1 , downsample = None ): super ( ResidualBlock , self ) . __init__ () self . conv1 = conv3x3 ( in_channels , out_channels , stride ) self . bn1 = nn . BatchNorm2d ( out_channels ) self . relu = nn . ReLU ( inplace = True ) self . conv2 = conv3x3 ( out_channels , out_channels ) self . bn2 = nn . BatchNorm2d ( out_channels ) self . downsample = downsample def forward ( self , x ): residual = x out = self . conv1 ( x ) out = self . bn1 ( out ) out = self . relu ( out ) out = self . conv2 ( out ) out = self . bn2 ( out ) if self . downsample : residual = self . downsample ( x ) out += residual out = self . relu ( out ) return out # ResNet class ResNet ( nn . Module ): def __init__ ( self , block , layers , num_classes = 10 ): super ( ResNet , self ) . __init__ () self . in_channels = 16 self . conv = conv3x3 ( 3 , 16 ) self . bn = nn . BatchNorm2d ( 16 ) self . relu = nn . ReLU ( inplace = True ) self . layer1 = self . make_layer ( block , 16 , layers [ 0 ]) self . layer2 = self . make_layer ( block , 32 , layers [ 1 ], 2 ) self . layer3 = self . make_layer ( block , 64 , layers [ 2 ], 2 ) self . avg_pool = nn . AvgPool2d ( 8 ) self . fc = nn . Linear ( 64 , num_classes ) def make_layer ( self , block , out_channels , blocks , stride = 1 ): downsample = None if ( stride != 1 ) or ( self . in_channels != out_channels ): downsample = nn . Sequential ( conv3x3 ( self . in_channels , out_channels , stride = stride ), nn . BatchNorm2d ( out_channels )) layers = [] layers . append ( block ( self . in_channels , out_channels , stride , downsample )) self . in_channels = out_channels for i in range ( 1 , blocks ): layers . append ( block ( out_channels , out_channels )) return nn . Sequential ( * layers ) def forward ( self , x ): out = self . conv ( x ) out = self . bn ( out ) out = self . relu ( out ) out = self . layer1 ( out ) out = self . layer2 ( out ) out = self . layer3 ( out ) out = self . avg_pool ( out ) out = out . view ( out . size ( 0 ), - 1 ) out = self . fc ( out ) return out model = ResNet ( ResidualBlock , [ 2 , 2 , 2 ]) . to ( device ) # Loss and optimizer criterion = nn . CrossEntropyLoss () optimizer = torch . optim . Adam ( model . parameters (), lr = learning_rate ) # For updating learning rate def update_lr ( optimizer , lr ): for param_group in optimizer . param_groups : param_group [ 'lr' ] = lr # Train the model total_step = len ( train_loader ) curr_lr = learning_rate for epoch in range ( num_epochs ): for i , ( images , labels ) in enumerate ( train_loader ): images = images . to ( device ) labels = labels . to ( device ) # Forward pass outputs = model ( images ) loss = criterion ( outputs , labels ) # Backward and optimize optimizer . zero_grad () loss . backward () optimizer . step () if ( i + 1 ) % 100 == 0 : print ( \"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f}\" . format ( epoch + 1 , num_epochs , i + 1 , total_step , loss . item ())) # Decay learning rate if ( epoch + 1 ) % 20 == 0 : curr_lr /= 3 update_lr ( optimizer , curr_lr ) # Test the model model . eval () with torch . no_grad (): correct = 0 total = 0 for images , labels in test_loader : images = images . to ( device ) labels = labels . to ( device ) outputs = model ( images ) _ , predicted = torch . max ( outputs . data , 1 ) total += labels . size ( 0 ) correct += ( predicted == labels ) . sum () . item () print ( 'Accuracy of the model on the test images: {} %' . format ( 100 * correct / total )) # Save the model checkpoint torch . save ( model . state_dict (), 'resnet.ckpt' )","title":"3.2.2 ResNet_Cifar10"},{"location":"tutorial/chapter03_intermediate/3_3_rnn/","text":"% matplotlib inline import torch import torch.nn as nn from torch.nn import functional as F from torch import optim import numpy as np from matplotlib import pyplot as plt import matplotlib.animation import math , random torch . __version__ '1.0.0' 3.3 \u901a\u8fc7Sin\u9884\u6d4bCos \u00b6 \u5728\u4ecb\u7ecd\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u65f6\u5019\u6211\u4eec\u8bf4\u8fc7\uff0c\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u7531\u4e8e\u5176\u7684\u7279\u6b8a\u7ed3\u6784\uff0c\u5341\u5206\u5341\u5206\u64c5\u957f\u5904\u7406\u65f6\u95f4\u76f8\u5173\u7684\u6570\u636e\uff0c\u4e0b\u9762\u6211\u4eec\u5c31\u6765\u901a\u8fc7\u8f93\u5165sin\u51fd\u6570\uff0c\u8f93\u51facos\u51fd\u6570\u6765\u5b9e\u9645\u4f7f\u7528\u3002 \u9996\u5148\uff0c\u6211\u4eec\u8fd8\u662f\u5b9a\u4e49\u4e00\u4e9b\u8d85\u53c2\u6570: TIME_STEP = 10 # rnn \u65f6\u5e8f\u6b65\u957f\u6570 INPUT_SIZE = 1 # rnn \u7684\u8f93\u5165\u7ef4\u5ea6 DEVICE = torch . device ( \"cuda\" if torch . cuda . is_available () else \"cpu\" ) H_SIZE = 64 # of rnn \u9690\u85cf\u5355\u5143\u4e2a\u6570 EPOCHS = 300 # \u603b\u5171\u8bad\u7ec3\u6b21\u6570 h_state = None # \u9690\u85cf\u5c42\u72b6\u6001 \u7531\u4e8e\u662f\u4f7f\u7528sin\u548ccos\u51fd\u6570\uff0c\u6240\u4ee5\u8fd9\u91cc\u4e0d\u9700\u8981dataloader\uff0c\u6211\u4eec\u76f4\u63a5\u4f7f\u7528Numpy\u751f\u6210\u6570\u636e\uff0cPytorch\u6ca1\u6709\u03c0\u8fd9\u4e2a\u5e38\u91cf\uff0c\u6240\u4ee5\u6240\u6709\u64cd\u4f5c\u90fd\u662f\u7528Numpy\u5b8c\u6210: steps = np . linspace ( 0 , np . pi * 2 , 256 , dtype = np . float32 ) x_np = np . sin ( steps ) y_np = np . cos ( steps ) \u751f\u6210\u5b8c\u540e\uff0c\u6211\u4eec\u53ef\u89c6\u5316\u4e00\u4e0b\u6570\u636e: plt . figure ( 1 ) plt . suptitle ( 'Sin and Cos' , fontsize = '18' ) plt . plot ( steps , y_np , 'r-' , label = 'target (cos)' ) plt . plot ( steps , x_np , 'b-' , label = 'input (sin)' ) plt . legend ( loc = 'best' ) plt . show () \u4e0b\u9762\u5b9a\u4e49\u4e00\u4e0b\u6211\u4eec\u7684\u7f51\u7edc\u7ed3\u6784\uff1a class RNN ( nn . Module ): def __init__ ( self ): super ( RNN , self ) . __init__ () self . rnn = nn . RNN ( input_size = INPUT_SIZE , hidden_size = H_SIZE , num_layers = 1 , batch_first = True , ) self . out = nn . Linear ( H_SIZE , 1 ) def forward ( self , x , h_state ): # x (batch, time_step, input_size) # h_state (n_layers, batch, hidden_size) # r_out (batch, time_step, hidden_size) r_out , h_state = self . rnn ( x , h_state ) outs = [] # \u4fdd\u5b58\u6240\u6709\u7684\u9884\u6d4b\u503c for time_step in range ( r_out . size ( 1 )): # \u8ba1\u7b97\u6bcf\u4e00\u6b65\u957f\u7684\u9884\u6d4b\u503c outs . append ( self . out ( r_out [:, time_step , :])) return torch . stack ( outs , dim = 1 ), h_state # \u4e5f\u53ef\u4f7f\u7528\u4ee5\u4e0b\u8fd9\u6837\u7684\u8fd4\u56de\u503c # r_out = r_out.view(-1, 32) # outs = self.out(r_out) # return outs, h_state \u4e0b\u9762\u6211\u4eec\u5b9a\u4e49\u6211\u4eec\u7684\u7f51\u7edc\uff1a rnn = RNN () . to ( DEVICE ) optimizer = torch . optim . Adam ( rnn . parameters ()) # Adam\u4f18\u5316\uff0c\u51e0\u4e4e\u4e0d\u7528\u8c03\u53c2 criterion = nn . MSELoss () # \u56e0\u4e3a\u6700\u7ec8\u7684\u7ed3\u679c\u662f\u4e00\u4e2a\u6570\u503c\uff0c\u6240\u4ee5\u635f\u5931\u51fd\u6570\u7528\u5747\u65b9\u8bef\u5dee \u7531\u4e8e\u6ca1\u6709\u6d4b\u8bd5\u96c6\uff0c\u6240\u4ee5\u6211\u4eec\u8bad\u7ec3\u548c\u6d4b\u8bd5\u5199\u5728\u4e00\u8d77\u4e86\uff1a rnn . train () plt . figure ( 2 ) for step in range ( EPOCHS ): start , end = step * np . pi , ( step + 1 ) * np . pi # \u4e00\u4e2a\u65f6\u95f4\u5468\u671f steps = np . linspace ( start , end , TIME_STEP , dtype = np . float32 ) x_np = np . sin ( steps ) y_np = np . cos ( steps ) x = torch . from_numpy ( x_np [ np . newaxis , :, np . newaxis ]) # shape (batch, time_step, input_size) y = torch . from_numpy ( y_np [ np . newaxis , :, np . newaxis ]) prediction , h_state = rnn ( x , h_state ) # rnn output # \u8fd9\u4e00\u6b65\u975e\u5e38\u91cd\u8981 h_state = h_state . data # \u91cd\u7f6e\u9690\u85cf\u5c42\u7684\u72b6\u6001, \u5207\u65ad\u548c\u524d\u4e00\u6b21\u8fed\u4ee3\u7684\u94fe\u63a5 loss = criterion ( prediction , y ) # \u8fd9\u4e09\u884c\u5199\u5728\u4e00\u8d77\u5c31\u53ef\u4ee5 optimizer . zero_grad () loss . backward () optimizer . step () if ( step + 1 ) % 20 == 0 : #\u6bcf\u8bad\u7ec320\u4e2a\u6279\u6b21\u53ef\u89c6\u5316\u4e00\u4e0b\u6548\u679c\uff0c\u5e76\u6253\u5370\u4e00\u4e0bloss print ( \"EPOCHS: {},Loss:{:4f}\" . format ( step , loss )) plt . plot ( steps , y_np . flatten (), 'r-' ) plt . plot ( steps , prediction . data . numpy () . flatten (), 'b-' ) plt . draw () plt . pause ( 0.01 ) EPOCHS: 19,Loss:0.030555 EPOCHS: 39,Loss:0.012050 EPOCHS: 59,Loss:0.002512 EPOCHS: 79,Loss:0.000799 EPOCHS: 99,Loss:0.010520 EPOCHS: 119,Loss:0.043775 EPOCHS: 139,Loss:0.008239 EPOCHS: 159,Loss:0.001041 EPOCHS: 179,Loss:0.002480 EPOCHS: 199,Loss:0.000720 EPOCHS: 219,Loss:0.002120 EPOCHS: 239,Loss:0.004574 EPOCHS: 259,Loss:0.001296 EPOCHS: 279,Loss:0.018041 EPOCHS: 299,Loss:0.001029 \u84dd\u8272\u662f\u6a21\u578b\u9884\u6d4b\u7684\u7ed3\u679c\uff0c\u7ea2\u8272\u662f\u51fd\u6570\u7684\u7ed3\u679c\uff0c\u901a\u8fc7300\u6b21\u7684\u8bad\u7ec3\uff0c\u5df2\u7ecf\u57fa\u672c\u62df\u5408\u4e86\u3002","title":"3.3 RNN"},{"location":"tutorial/chapter03_intermediate/3_3_rnn/#33-sincos","text":"\u5728\u4ecb\u7ecd\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u65f6\u5019\u6211\u4eec\u8bf4\u8fc7\uff0c\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u7531\u4e8e\u5176\u7684\u7279\u6b8a\u7ed3\u6784\uff0c\u5341\u5206\u5341\u5206\u64c5\u957f\u5904\u7406\u65f6\u95f4\u76f8\u5173\u7684\u6570\u636e\uff0c\u4e0b\u9762\u6211\u4eec\u5c31\u6765\u901a\u8fc7\u8f93\u5165sin\u51fd\u6570\uff0c\u8f93\u51facos\u51fd\u6570\u6765\u5b9e\u9645\u4f7f\u7528\u3002 \u9996\u5148\uff0c\u6211\u4eec\u8fd8\u662f\u5b9a\u4e49\u4e00\u4e9b\u8d85\u53c2\u6570: TIME_STEP = 10 # rnn \u65f6\u5e8f\u6b65\u957f\u6570 INPUT_SIZE = 1 # rnn \u7684\u8f93\u5165\u7ef4\u5ea6 DEVICE = torch . device ( \"cuda\" if torch . cuda . is_available () else \"cpu\" ) H_SIZE = 64 # of rnn \u9690\u85cf\u5355\u5143\u4e2a\u6570 EPOCHS = 300 # \u603b\u5171\u8bad\u7ec3\u6b21\u6570 h_state = None # \u9690\u85cf\u5c42\u72b6\u6001 \u7531\u4e8e\u662f\u4f7f\u7528sin\u548ccos\u51fd\u6570\uff0c\u6240\u4ee5\u8fd9\u91cc\u4e0d\u9700\u8981dataloader\uff0c\u6211\u4eec\u76f4\u63a5\u4f7f\u7528Numpy\u751f\u6210\u6570\u636e\uff0cPytorch\u6ca1\u6709\u03c0\u8fd9\u4e2a\u5e38\u91cf\uff0c\u6240\u4ee5\u6240\u6709\u64cd\u4f5c\u90fd\u662f\u7528Numpy\u5b8c\u6210: steps = np . linspace ( 0 , np . pi * 2 , 256 , dtype = np . float32 ) x_np = np . sin ( steps ) y_np = np . cos ( steps ) \u751f\u6210\u5b8c\u540e\uff0c\u6211\u4eec\u53ef\u89c6\u5316\u4e00\u4e0b\u6570\u636e: plt . figure ( 1 ) plt . suptitle ( 'Sin and Cos' , fontsize = '18' ) plt . plot ( steps , y_np , 'r-' , label = 'target (cos)' ) plt . plot ( steps , x_np , 'b-' , label = 'input (sin)' ) plt . legend ( loc = 'best' ) plt . show () \u4e0b\u9762\u5b9a\u4e49\u4e00\u4e0b\u6211\u4eec\u7684\u7f51\u7edc\u7ed3\u6784\uff1a class RNN ( nn . Module ): def __init__ ( self ): super ( RNN , self ) . __init__ () self . rnn = nn . RNN ( input_size = INPUT_SIZE , hidden_size = H_SIZE , num_layers = 1 , batch_first = True , ) self . out = nn . Linear ( H_SIZE , 1 ) def forward ( self , x , h_state ): # x (batch, time_step, input_size) # h_state (n_layers, batch, hidden_size) # r_out (batch, time_step, hidden_size) r_out , h_state = self . rnn ( x , h_state ) outs = [] # \u4fdd\u5b58\u6240\u6709\u7684\u9884\u6d4b\u503c for time_step in range ( r_out . size ( 1 )): # \u8ba1\u7b97\u6bcf\u4e00\u6b65\u957f\u7684\u9884\u6d4b\u503c outs . append ( self . out ( r_out [:, time_step , :])) return torch . stack ( outs , dim = 1 ), h_state # \u4e5f\u53ef\u4f7f\u7528\u4ee5\u4e0b\u8fd9\u6837\u7684\u8fd4\u56de\u503c # r_out = r_out.view(-1, 32) # outs = self.out(r_out) # return outs, h_state \u4e0b\u9762\u6211\u4eec\u5b9a\u4e49\u6211\u4eec\u7684\u7f51\u7edc\uff1a rnn = RNN () . to ( DEVICE ) optimizer = torch . optim . Adam ( rnn . parameters ()) # Adam\u4f18\u5316\uff0c\u51e0\u4e4e\u4e0d\u7528\u8c03\u53c2 criterion = nn . MSELoss () # \u56e0\u4e3a\u6700\u7ec8\u7684\u7ed3\u679c\u662f\u4e00\u4e2a\u6570\u503c\uff0c\u6240\u4ee5\u635f\u5931\u51fd\u6570\u7528\u5747\u65b9\u8bef\u5dee \u7531\u4e8e\u6ca1\u6709\u6d4b\u8bd5\u96c6\uff0c\u6240\u4ee5\u6211\u4eec\u8bad\u7ec3\u548c\u6d4b\u8bd5\u5199\u5728\u4e00\u8d77\u4e86\uff1a rnn . train () plt . figure ( 2 ) for step in range ( EPOCHS ): start , end = step * np . pi , ( step + 1 ) * np . pi # \u4e00\u4e2a\u65f6\u95f4\u5468\u671f steps = np . linspace ( start , end , TIME_STEP , dtype = np . float32 ) x_np = np . sin ( steps ) y_np = np . cos ( steps ) x = torch . from_numpy ( x_np [ np . newaxis , :, np . newaxis ]) # shape (batch, time_step, input_size) y = torch . from_numpy ( y_np [ np . newaxis , :, np . newaxis ]) prediction , h_state = rnn ( x , h_state ) # rnn output # \u8fd9\u4e00\u6b65\u975e\u5e38\u91cd\u8981 h_state = h_state . data # \u91cd\u7f6e\u9690\u85cf\u5c42\u7684\u72b6\u6001, \u5207\u65ad\u548c\u524d\u4e00\u6b21\u8fed\u4ee3\u7684\u94fe\u63a5 loss = criterion ( prediction , y ) # \u8fd9\u4e09\u884c\u5199\u5728\u4e00\u8d77\u5c31\u53ef\u4ee5 optimizer . zero_grad () loss . backward () optimizer . step () if ( step + 1 ) % 20 == 0 : #\u6bcf\u8bad\u7ec320\u4e2a\u6279\u6b21\u53ef\u89c6\u5316\u4e00\u4e0b\u6548\u679c\uff0c\u5e76\u6253\u5370\u4e00\u4e0bloss print ( \"EPOCHS: {},Loss:{:4f}\" . format ( step , loss )) plt . plot ( steps , y_np . flatten (), 'r-' ) plt . plot ( steps , prediction . data . numpy () . flatten (), 'b-' ) plt . draw () plt . pause ( 0.01 ) EPOCHS: 19,Loss:0.030555 EPOCHS: 39,Loss:0.012050 EPOCHS: 59,Loss:0.002512 EPOCHS: 79,Loss:0.000799 EPOCHS: 99,Loss:0.010520 EPOCHS: 119,Loss:0.043775 EPOCHS: 139,Loss:0.008239 EPOCHS: 159,Loss:0.001041 EPOCHS: 179,Loss:0.002480 EPOCHS: 199,Loss:0.000720 EPOCHS: 219,Loss:0.002120 EPOCHS: 239,Loss:0.004574 EPOCHS: 259,Loss:0.001296 EPOCHS: 279,Loss:0.018041 EPOCHS: 299,Loss:0.001029 \u84dd\u8272\u662f\u6a21\u578b\u9884\u6d4b\u7684\u7ed3\u679c\uff0c\u7ea2\u8272\u662f\u51fd\u6570\u7684\u7ed3\u679c\uff0c\u901a\u8fc7300\u6b21\u7684\u8bad\u7ec3\uff0c\u5df2\u7ecf\u57fa\u672c\u62df\u5408\u4e86\u3002","title":"3.3 \u901a\u8fc7Sin\u9884\u6d4bCos"},{"location":"tutorial/chapter04_advanced/4_1_fine-tuning/","text":"% matplotlib inline import torch , os , torchvision import torch.nn as nn import torch.nn.functional as F import pandas as pd import numpy as np import matplotlib.pyplot as plt from torch.utils.data import DataLoader , Dataset from torchvision import datasets , models , transforms from PIL import Image from sklearn.model_selection import StratifiedShuffleSplit torch . __version__ '1.0.0' 4.1 Fine tuning \u6a21\u578b\u5fae\u8c03 \u00b6 \u5728\u524d\u9762\u7684\u4ecb\u7ecd\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u65f6\u5019\uff0c\u8bf4\u5230\u8fc7PyTorch\u5df2\u7ecf\u4e3a\u6211\u4eec\u8bad\u7ec3\u597d\u4e86\u4e00\u4e9b\u7ecf\u5178\u7684\u7f51\u7edc\u6a21\u578b\uff0c\u90a3\u4e48\u8fd9\u4e9b\u9884\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u662f\u7528\u6765\u505a\u4ec0\u4e48\u7684\u5462\uff1f\u5176\u5b9e\u5c31\u662f\u4e3a\u4e86\u6211\u4eec\u8fdb\u884c\u5fae\u8c03\u4f7f\u7528\u7684\u3002 4.1.1 \u4ec0\u4e48\u662f\u5fae\u8c03 \u00b6 \u9488\u5bf9\u4e8e\u67d0\u4e2a\u4efb\u52a1\uff0c\u81ea\u5df1\u7684\u8bad\u7ec3\u6570\u636e\u4e0d\u591a\uff0c\u90a3\u600e\u4e48\u529e\uff1f \u6ca1\u5173\u7cfb\uff0c\u6211\u4eec\u5148\u627e\u5230\u4e00\u4e2a\u540c\u7c7b\u7684\u522b\u4eba\u8bad\u7ec3\u597d\u7684\u6a21\u578b\uff0c\u628a\u522b\u4eba\u73b0\u6210\u7684\u8bad\u7ec3\u597d\u4e86\u7684\u6a21\u578b\u62ff\u8fc7\u6765\uff0c\u6362\u6210\u81ea\u5df1\u7684\u6570\u636e\uff0c\u8c03\u6574\u4e00\u4e0b\u53c2\u6570\uff0c\u518d\u8bad\u7ec3\u4e00\u904d\uff0c\u8fd9\u5c31\u662f\u5fae\u8c03\uff08fine-tune\uff09\u3002 PyTorch\u91cc\u9762\u63d0\u4f9b\u7684\u7ecf\u5178\u7684\u7f51\u7edc\u6a21\u578b\u90fd\u662f\u5b98\u65b9\u901a\u8fc7Imagenet\u7684\u6570\u636e\u96c6\u4e0e\u8bad\u7ec3\u597d\u7684\u6570\u636e\uff0c\u5982\u679c\u6211\u4eec\u7684\u6570\u636e\u8bad\u7ec3\u6570\u636e\u4e0d\u591f\uff0c\u8fd9\u4e9b\u6570\u636e\u662f\u53ef\u4ee5\u4f5c\u4e3a\u57fa\u7840\u6a21\u578b\u6765\u4f7f\u7528\u7684\u3002 \u4e3a\u4ec0\u4e48\u8981\u5fae\u8c03 \u00b6 \u5bf9\u4e8e\u6570\u636e\u96c6\u672c\u8eab\u5f88\u5c0f\uff08\u51e0\u5343\u5f20\u56fe\u7247\uff09\u7684\u60c5\u51b5\uff0c\u4ece\u5934\u5f00\u59cb\u8bad\u7ec3\u5177\u6709\u51e0\u5343\u4e07\u53c2\u6570\u7684\u5927\u578b\u795e\u7ecf\u7f51\u7edc\u662f\u4e0d\u73b0\u5b9e\u7684\uff0c\u56e0\u4e3a\u8d8a\u5927\u7684\u6a21\u578b\u5bf9\u6570\u636e\u91cf\u7684\u8981\u6c42\u8d8a\u5927\uff0c\u8fc7\u62df\u5408\u65e0\u6cd5\u907f\u514d\u3002\u8fd9\u65f6\u5019\u5982\u679c\u8fd8\u60f3\u7528\u4e0a\u5927\u578b\u795e\u7ecf\u7f51\u7edc\u7684\u8d85\u5f3a\u7279\u5f81\u63d0\u53d6\u80fd\u529b\uff0c\u53ea\u80fd\u9760\u5fae\u8c03\u5df2\u7ecf\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u3002 \u53ef\u4ee5\u964d\u4f4e\u8bad\u7ec3\u6210\u672c\uff1a\u5982\u679c\u4f7f\u7528\u5bfc\u51fa\u7279\u5f81\u5411\u91cf\u7684\u65b9\u6cd5\u8fdb\u884c\u8fc1\u79fb\u5b66\u4e60\uff0c\u540e\u671f\u7684\u8bad\u7ec3\u6210\u672c\u975e\u5e38\u4f4e\uff0c\u7528 CPU \u90fd\u5b8c\u5168\u65e0\u538b\u529b\uff0c\u6ca1\u6709\u6df1\u5ea6\u5b66\u4e60\u673a\u5668\u4e5f\u53ef\u4ee5\u505a\u3002 \u524d\u4eba\u82b1\u5f88\u5927\u7cbe\u529b\u8bad\u7ec3\u51fa\u6765\u7684\u6a21\u578b\u5728\u5927\u6982\u7387\u4e0a\u4f1a\u6bd4\u4f60\u81ea\u5df1\u4ece\u96f6\u5f00\u59cb\u642d\u7684\u6a21\u578b\u8981\u5f3a\u608d\uff0c\u6ca1\u6709\u5fc5\u8981\u91cd\u590d\u9020\u8f6e\u5b50\u3002 \u8fc1\u79fb\u5b66\u4e60 Transfer Learning \u00b6 \u603b\u662f\u6709\u4eba\u628a \u8fc1\u79fb\u5b66\u4e60\u548c\u795e\u7ecf\u7f51\u7edc\u7684\u8bad\u7ec3\u8054\u7cfb\u8d77\u6765\uff0c\u8fd9\u4e24\u4e2a\u6982\u5ff5\u521a\u5f00\u59cb\u662f\u65e0\u5173\u7684\u3002 \u8fc1\u79fb\u5b66\u4e60\u662f\u673a\u5668\u5b66\u4e60\u7684\u5206\u652f\uff0c\u73b0\u5728\u4e4b\u6240\u4ee5 \u8fc1\u79fb\u5b66\u4e60\u548c\u795e\u7ecf\u7f51\u7edc\u8054\u7cfb\u5982\u6b64\u7d27\u5bc6\uff0c\u73b0\u5728\u56fe\u50cf\u8bc6\u522b\u8fd9\u5757\u53d1\u5c55\u7684\u592a\u5feb\u6548\u679c\u4e5f\u592a\u597d\u4e86\uff0c\u6240\u4ee5\u51e0\u4e4e\u6240\u6709\u7684\u8fc1\u79fb\u5b66\u4e60\u90fd\u662f\u56fe\u50cf\u8bc6\u522b\u65b9\u5411\u7684\uff0c\u6240\u4ee5\u5927\u5bb6\u770b\u5230\u7684\u8fc1\u79fb\u5b66\u4e60\u57fa\u672c\u4e0a\u90fd\u662f\u4ee5\u795e\u7ecf\u7f51\u7edc\u76f8\u5173\u7684\u8ba1\u7b97\u673a\u89c6\u89c9\u4e3a\u4e3b\uff0c\u672c\u6587\u4e2d\u4e5f\u4f1a\u4ee5\u8fd9\u65b9\u9762\u6765\u4e3e\u4f8b\u5b50 \u8fc1\u79fb\u5b66\u4e60\u521d\u8877\u662f\u8282\u7701\u4eba\u5de5\u6807\u6ce8\u6837\u672c\u7684\u65f6\u95f4\uff0c\u8ba9\u6a21\u578b\u53ef\u4ee5\u901a\u8fc7\u4e00\u4e2a\u5df2\u6709\u7684\u6807\u8bb0\u6570\u636e\u7684\u9886\u57df\u5411\u672a\u6807\u8bb0\u6570\u636e\u9886\u57df\u8fdb\u884c\u8fc1\u79fb\u4ece\u800c\u8bad\u7ec3\u51fa\u9002\u7528\u4e8e\u8be5\u9886\u57df\u7684\u6a21\u578b\uff0c\u76f4\u63a5\u5bf9\u76ee\u6807\u57df\u4ece\u5934\u5f00\u59cb\u5b66\u4e60\u6210\u672c\u592a\u9ad8\uff0c\u6211\u4eec\u6545\u800c\u8f6c\u5411\u8fd0\u7528\u5df2\u6709\u7684\u76f8\u5173\u77e5\u8bc6\u6765\u8f85\u52a9\u5c3d\u5feb\u5730\u5b66\u4e60\u65b0\u77e5\u8bc6 \u4e3e\u4e00\u4e2a\u7b80\u5355\u7684\u4f8b\u5b50\u5c31\u80fd\u5f88\u597d\u7684\u8bf4\u660e\u95ee\u9898\uff0c\u6211\u4eec\u5b66\u4e60\u7f16\u7a0b\u7684\u65f6\u5019\u4f1a\u5b66\u4e60\u4ec0\u4e48\uff1f \u8bed\u6cd5\u3001\u7279\u5b9a\u8bed\u8a00\u7684API\u3001\u6d41\u7a0b\u5904\u7406\u3001\u9762\u5411\u5bf9\u8c61\uff0c\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u7b49\u7b49 \u8fd9\u91cc\u9762\u8bed\u6cd5\u548cAPI\u662f\u6bcf\u4e00\u4e2a\u8bed\u8a00\u7279\u6709\u7684\uff0c\u4f46\u662f\u9762\u5411\u5bf9\u8c61\u548c\u8bbe\u8ba1\u6a21\u5f0f\u53ef\u662f\u901a\u7528\u7684\uff0c\u6211\u4eec\u5b66\u4e86JAVA\uff0c\u518d\u53bb\u5b66C#\uff0c\u6216\u8005Python\uff0c\u9762\u5411\u5bf9\u8c61\u548c\u8bbe\u8ba1\u6a21\u5f0f\u662f\u4e0d\u7528\u53bb\u5b66\u7684\uff0c\u56e0\u4e3a\u539f\u7406\u90fd\u662f\u4e00\u6837\u7684\uff0c\u751a\u81f3\u5728\u5b66\u4e60C#\u7684\u65f6\u5019\u8bed\u6cd5\u90fd\u53ef\u4ee5\u5c11\u5b66\u5f88\u591a\uff0c\u8fd9\u5c31\u662f\u8fc1\u79fb\u5b66\u4e60\u7684\u6982\u5ff5\uff0c\u628a\u7edf\u4e00\u7684\u6982\u5ff5\u62bd\u8c61\u51fa\u6765\uff0c\u53ea\u5b66\u4e60\u4e0d\u540c\u7684\u5185\u5bb9\u3002 \u8fc1\u79fb\u5b66\u4e60\u6309\u7167\u5b66\u4e60\u65b9\u5f0f\u53ef\u4ee5\u5206\u4e3a\u57fa\u4e8e\u6837\u672c\u7684\u8fc1\u79fb\uff0c\u57fa\u4e8e\u7279\u5f81\u7684\u8fc1\u79fb\uff0c\u57fa\u4e8e\u6a21\u578b\u7684\u8fc1\u79fb\uff0c\u4ee5\u53ca\u57fa\u4e8e\u5173\u7cfb\u7684\u8fc1\u79fb\uff0c\u8fd9\u91cc\u5c31\u4e0d\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u3002 \u4e8c\u8005\u5173\u7cfb \u00b6 \u5176\u5b9e \"Transfer Learning\" \u548c \"Fine-tune\" \u5e76\u6ca1\u6709\u4e25\u683c\u7684\u533a\u5206\uff0c\u542b\u4e49\u53ef\u4ee5\u76f8\u4e92\u4ea4\u6362\uff0c\u53ea\u4e0d\u8fc7\u540e\u8005\u4f3c\u4e4e\u66f4\u5e38\u7528\u4e8e\u5f62\u5bb9\u8fc1\u79fb\u5b66\u4e60\u7684\u540e\u671f\u5fae\u8c03\u4e2d\u3002 \u6211\u4e2a\u4eba\u7684\u7406\u89e3\uff0c\u5fae\u8c03\u5e94\u8be5\u662f\u8fc1\u79fb\u5b66\u4e60\u4e2d\u7684\u4e00\u90e8\u5206\u3002\u5fae\u8c03\u53ea\u80fd\u8bf4\u662f\u4e00\u4e2atrick\u3002 4.1.2 \u5982\u4f55\u5fae\u8c03 \u00b6 \u5bf9\u4e8e\u4e0d\u540c\u7684\u9886\u57df\u5fae\u8c03\u7684\u65b9\u6cd5\u4e5f\u4e0d\u4e00\u6837\uff0c\u6bd4\u5982\u8bed\u97f3\u8bc6\u522b\u9886\u57df\u4e00\u822c\u5fae\u8c03\u524d\u51e0\u5c42\uff0c\u56fe\u7247\u8bc6\u522b\u95ee\u9898\u5fae\u8c03\u540e\u9762\u51e0\u5c42\uff0c\u8fd9\u4e2a\u539f\u56e0\u6211\u8fd9\u91cc\u4e5f\u53ea\u80fd\u8bb2\u4e2a\u5927\u6982\uff0c\u5177\u4f53\u8fd8\u8981\u5927\u795e\u6765\u89e3\u91ca\uff1a \u5bf9\u4e8e\u56fe\u7247\u6765\u8bf4\uff0c\u6211\u4eecCNN\u7684\u524d\u51e0\u5c42\u5b66\u4e60\u5230\u7684\u90fd\u662f\u4f4e\u7ea7\u7684\u7279\u5f81\uff0c\u6bd4\u5982\uff0c\u70b9\u3001\u7ebf\u3001\u9762\uff0c\u8fd9\u4e9b\u4f4e\u7ea7\u7684\u7279\u5f81\u5bf9\u4e8e\u4efb\u4f55\u56fe\u7247\u6765\u8bf4\u90fd\u662f\u53ef\u4ee5\u62bd\u8c61\u51fa\u6765\u7684\uff0c\u6240\u4ee5\u6211\u4eec\u5c06\u4ed6\u4f5c\u4e3a\u901a\u7528\u6570\u636e\uff0c\u53ea\u5fae\u8c03\u8fd9\u4e9b\u4f4e\u7ea7\u7279\u5f81\u7ec4\u5408\u8d77\u6765\u7684\u9ad8\u7ea7\u7279\u5f81\u5373\u53ef\uff0c\u4f8b\u5982\uff0c\u8fd9\u4e9b\u70b9\u3001\u7ebf\u3001\u9762\uff0c\u7ec4\u6210\u7684\u662f\u56ed\u8fd8\u662f\u692d\u5706\uff0c\u8fd8\u662f\u6b63\u65b9\u5f62\uff0c\u8fd9\u4e9b\u4ee3\u8868\u7684\u542b\u4e49\u662f\u6211\u4eec\u9700\u8981\u540e\u9762\u8bad\u7ec3\u51fa\u6765\u7684\u3002 \u5bf9\u4e8e\u8bed\u97f3\u6765\u8bf4\uff0c\u6bcf\u4e2a\u5355\u8bcd\u8868\u8fbe\u7684\u610f\u601d\u90fd\u662f\u4e00\u6837\u7684\uff0c\u53ea\u4e0d\u8fc7\u53d1\u97f3\u6216\u8005\u662f\u5355\u8bcd\u7684\u62fc\u5199\u4e0d\u4e00\u6837\uff0c\u6bd4\u5982 \u82f9\u679c\uff0capple\uff0capfel\uff08\u5fb7\u8bed\uff09\uff0c\u90fd\u8868\u793a\u7684\u662f\u540c\u4e00\u4e2a\u4e1c\u897f\uff0c\u53ea\u4e0d\u8fc7\u53d1\u97f3\u548c\u5355\u8bcd\u4e0d\u4e00\u6837\uff0c\u4f46\u662f\u4ed6\u5177\u4f53\u4ee3\u8868\u7684\u542b\u4e49\u662f\u4e00\u6837\u7684\uff0c\u5c31\u662f\u9ad8\u7ea7\u7279\u5f81\u662f\u76f8\u540c\u7684\uff0c\u6240\u4ee5\u6211\u4eec\u53ea\u8981\u5fae\u8c03\u4f4e\u7ea7\u7684\u7279\u5f81\u5c31\u53ef\u4ee5\u4e86\u3002 \u4e0b\u9762\u53ea\u4ecb\u7ecd\u4e0b\u8ba1\u7b97\u673a\u89c6\u89c9\u65b9\u5411\u7684\u5fae\u8c03\uff0c\u6458\u81ea cs231 ConvNet as fixed feature extractor.\uff1a \u5176\u5b9e\u8fd9\u91cc\u6709\u4e24\u79cd\u505a\u6cd5\uff1a \u4f7f\u7528\u6700\u540e\u4e00\u4e2afc layer\u4e4b\u524d\u7684fc layer\u83b7\u5f97\u7684\u7279\u5f81\uff0c\u5b66\u4e60\u4e2a\u7ebf\u6027\u5206\u7c7b\u5668(\u6bd4\u5982SVM) \u91cd\u65b0\u8bad\u7ec3\u6700\u540e\u4e00\u4e2afc layer Fine-tuning the ConvNet \u56fa\u5b9a\u524d\u51e0\u5c42\u7684\u53c2\u6570\uff0c\u53ea\u5bf9\u6700\u540e\u51e0\u5c42\u8fdb\u884cfine-tuning, \u5bf9\u4e8e\u4e0a\u9762\u4e24\u79cd\u65b9\u6848\u6709\u4e00\u4e9b\u5fae\u8c03\u7684\u5c0f\u6280\u5de7\uff0c\u6bd4\u5982\u5148\u8ba1\u7b97\u51fa\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u5377\u79ef\u5c42\u5bf9\u6240\u6709\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\u7684\u7279\u5f81\u5411\u91cf\uff0c\u7136\u540e\u629b\u5f00\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u53ea\u8bad\u7ec3\u81ea\u5df1\u5b9a\u5236\u7684\u7b80\u914d\u7248\u5168\u8fde\u63a5\u7f51\u7edc\u3002 \u8fd9\u4e2a\u65b9\u5f0f\u7684\u4e00\u4e2a\u597d\u5904\u5c31\u662f\u8282\u7701\u8ba1\u7b97\u8d44\u6e90\uff0c\u6bcf\u6b21\u8fed\u4ee3\u90fd\u4e0d\u4f1a\u518d\u53bb\u8dd1\u5168\u90e8\u7684\u6570\u636e\uff0c\u800c\u53ea\u662f\u8dd1\u4e00\u4e0b\u7b80\u914d\u7684\u5168\u8fde\u63a5 Pretrained models \u8fd9\u4e2a\u5176\u5b9e\u548c\u7b2c\u4e8c\u79cd\u662f\u4e00\u4e2a\u610f\u601d\uff0c\u4e0d\u8fc7\u6bd4\u8f83\u6781\u7aef\uff0c\u4f7f\u7528\u6574\u4e2apre-trained\u7684model\u4f5c\u4e3a\u521d\u59cb\u5316\uff0c\u7136\u540efine-tuning\u6574\u4e2a\u7f51\u7edc\u800c\u4e0d\u662f\u67d0\u4e9b\u5c42\uff0c\u4f46\u662f\u8fd9\u4e2a\u7684\u8ba1\u7b97\u91cf\u662f\u975e\u5e38\u5927\u7684,\u5c31\u53ea\u76f8\u5f53\u4e8e\u505a\u4e86\u4e00\u4e2a\u521d\u59cb\u5316\u3002 4.1.3 \u6ce8\u610f\u4e8b\u9879 \u00b6 \u65b0\u6570\u636e\u96c6\u548c\u539f\u59cb\u6570\u636e\u96c6\u5408\u7c7b\u4f3c\uff0c\u90a3\u4e48\u76f4\u63a5\u53ef\u4ee5\u5fae\u8c03\u4e00\u4e2a\u6700\u540e\u7684FC\u5c42\u6216\u8005\u91cd\u65b0\u6307\u5b9a\u4e00\u4e2a\u65b0\u7684\u5206\u7c7b\u5668 \u65b0\u6570\u636e\u96c6\u6bd4\u8f83\u5c0f\u548c\u539f\u59cb\u6570\u636e\u96c6\u5408\u5dee\u5f02\u6027\u6bd4\u8f83\u5927\uff0c\u90a3\u4e48\u53ef\u4ee5\u4f7f\u7528\u4ece\u6a21\u578b\u7684\u4e2d\u90e8\u5f00\u59cb\u8bad\u7ec3\uff0c\u53ea\u5bf9\u6700\u540e\u51e0\u5c42\u8fdb\u884cfine-tuning \u65b0\u6570\u636e\u96c6\u6bd4\u8f83\u5c0f\u548c\u539f\u59cb\u6570\u636e\u96c6\u5408\u5dee\u5f02\u6027\u6bd4\u8f83\u5927\uff0c\u5982\u679c\u4e0a\u9762\u65b9\u6cd5\u8fd8\u662f\u4e0d\u884c\u7684\u5316\u90a3\u4e48\u6700\u597d\u662f\u91cd\u65b0\u8bad\u7ec3\uff0c\u53ea\u5c06\u9884\u8bad\u7ec3\u7684\u6a21\u578b\u4f5c\u4e3a\u4e00\u4e2a\u65b0\u6a21\u578b\u521d\u59cb\u5316\u7684\u6570\u636e \u65b0\u6570\u636e\u96c6\u7684\u5927\u5c0f\u4e00\u5b9a\u8981\u4e0e\u539f\u59cb\u6570\u636e\u96c6\u76f8\u540c\uff0c\u6bd4\u5982CNN\u4e2d\u8f93\u5165\u7684\u56fe\u7247\u5927\u5c0f\u4e00\u5b9a\u8981\u76f8\u540c\uff0c\u624d\u4e0d\u4f1a\u62a5\u9519 \u5982\u679c\u6570\u636e\u96c6\u5927\u5c0f\u4e0d\u540c\u7684\u8bdd\uff0c\u53ef\u4ee5\u5728\u6700\u540e\u7684fc\u5c42\u4e4b\u524d\u6dfb\u52a0\u5377\u79ef\u6216\u8005pool\u5c42\uff0c\u4f7f\u5f97\u6700\u540e\u7684\u8f93\u51fa\u4e0efc\u5c42\u4e00\u81f4\uff0c\u4f46\u8fd9\u6837\u4f1a\u5bfc\u81f4\u51c6\u786e\u5ea6\u5927\u5e45\u4e0b\u964d\uff0c\u6240\u4ee5\u4e0d\u5efa\u8bae\u8fd9\u6837\u505a \u5bf9\u4e8e\u4e0d\u540c\u7684\u5c42\u53ef\u4ee5\u8bbe\u7f6e\u4e0d\u540c\u7684\u5b66\u4e60\u7387\uff0c\u4e00\u822c\u60c5\u51b5\u4e0b\u5efa\u8bae\uff0c\u5bf9\u4e8e\u4f7f\u7528\u7684\u539f\u59cb\u6570\u636e\u505a\u521d\u59cb\u5316\u7684\u5c42\u8bbe\u7f6e\u7684\u5b66\u4e60\u7387\u8981\u5c0f\u4e8e\uff08\u4e00\u822c\u53ef\u8bbe\u7f6e\u5c0f\u4e8e10\u500d\uff09\u521d\u59cb\u5316\u7684\u5b66\u4e60\u7387\uff0c\u8fd9\u6837\u4fdd\u8bc1\u5bf9\u4e8e\u5df2\u7ecf\u521d\u59cb\u5316\u7684\u6570\u636e\u4e0d\u4f1a\u626d\u66f2\u7684\u8fc7\u5feb\uff0c\u800c\u4f7f\u7528\u521d\u59cb\u5316\u5b66\u4e60\u7387\u7684\u65b0\u5c42\u53ef\u4ee5\u5feb\u901f\u7684\u6536\u655b\u3002 4.1.3 \u5fae\u8c03\u5b9e\u4f8b \u00b6 \u8fd9\u91cc\u9762\u6211\u4eec\u4f7f\u7528\u5b98\u65b9\u8bad\u7ec3\u597d\u7684resnet50\u6765\u53c2\u52a0kaggle\u4e0a\u9762\u7684 dog breed \u72d7\u7684\u79cd\u7c7b\u8bc6\u522b\u6765\u505a\u4e00\u4e2a\u7b80\u5355\u5fae\u8c03\u5b9e\u4f8b\u3002 \u9996\u5148\u6211\u4eec\u9700\u8981\u4e0b\u8f7d\u5b98\u65b9\u7684\u6570\u636e\u89e3\u538b\uff0c\u53ea\u8981\u4fdd\u6301\u6570\u636e\u7684\u76ee\u5f55\u7ed3\u6784\u5373\u53ef\uff0c\u8fd9\u91cc\u6307\u5b9a\u4e00\u4e0b\u76ee\u5f55\u7684\u4f4d\u7f6e\uff0c\u5e76\u4e14\u770b\u4e0b\u5185\u5bb9 DATA_ROOT = 'data' all_labels_df = pd . read_csv ( os . path . join ( DATA_ROOT , 'labels.csv' )) all_labels_df . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id breed 0 000bec180eb18c7604dcecc8fe0dba07 boston_bull 1 001513dfcb2ffafc82cccf4d8bbaba97 dingo 2 001cdf01b096e06d78e9e5112d419397 pekinese 3 00214f311d5d2247d5dfe4fe24b2303d bluetick 4 0021f9ceb3235effd7fcde7f7538ed62 golden_retriever \u83b7\u53d6\u72d7\u7684\u5206\u7c7b\uff0c\u6839\u636e\u5206\u7c7b\u8fdb\u884c\u7f16\u53f7\u3002\u8fd9\u91cc\u5b9a\u4e49\u4e86\u4e24\u4e2a\u5b57\u5178\uff0c\u5206\u522b\u4ee5\u540d\u5b57\u548cid\u4f5c\u4e3a\u5bf9\u5e94\uff0c\u65b9\u4fbf\u540e\u9762\u5904\u7406\uff1a breeds = all_labels_df . breed . unique () breed2idx = dict (( breed , idx ) for idx , breed in enumerate ( breeds )) idx2breed = dict (( idx , breed ) for idx , breed in enumerate ( breeds )) len ( breeds ) 120 \u6dfb\u52a0\u5230\u5217\u8868\u4e2d: all_labels_df [ 'label_idx' ] = [ breed2idx [ b ] for b in all_labels_df . breed ] all_labels_df . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id breed label_idx 0 000bec180eb18c7604dcecc8fe0dba07 boston_bull 0 1 001513dfcb2ffafc82cccf4d8bbaba97 dingo 1 2 001cdf01b096e06d78e9e5112d419397 pekinese 2 3 00214f311d5d2247d5dfe4fe24b2303d bluetick 3 4 0021f9ceb3235effd7fcde7f7538ed62 golden_retriever 4 \u7531\u4e8e\u6211\u4eec\u7684\u6570\u636e\u96c6\u4e0d\u662f\u5b98\u65b9\u6307\u5b9a\u7684\u683c\u5f0f\uff0c\u6211\u4eec\u81ea\u5df1\u5b9a\u4e49\u4e00\u4e2a\u6570\u636e\u96c6: class DogDataset ( Dataset ): def __init__ ( self , labels_df , img_path , transform = None ): self . labels_df = labels_df self . img_path = img_path self . transform = transform def __len__ ( self ): return self . labels_df . shape [ 0 ] def __getitem__ ( self , idx ): image_name = os . path . join ( self . img_path , self . labels_df . id [ idx ]) + '.jpg' img = Image . open ( image_name ) label = self . labels_df . label_idx [ idx ] if self . transform : img = self . transform ( img ) return img , label \u5b9a\u4e49\u4e00\u4e9b\u8d85\u53c2\u6570\uff1a IMG_SIZE = 224 # resnet50\u7684\u8f93\u5165\u662f224\u7684\u6240\u4ee5\u9700\u8981\u5c06\u56fe\u7247\u7edf\u4e00\u5927\u5c0f BATCH_SIZE = 256 #\u8fd9\u4e2a\u6279\u6b21\u5927\u5c0f\u9700\u8981\u5360\u75284.6-5g\u7684\u663e\u5b58\uff0c\u5982\u679c\u4e0d\u591f\u7684\u5316\u53ef\u4ee5\u6539\u4e0b\u6279\u6b21\uff0c\u5982\u679c\u5185\u5b58\u8d85\u8fc710G\u53ef\u4ee5\u6539\u4e3a512 IMG_MEAN = [ 0.485 , 0.456 , 0.406 ] IMG_STD = [ 0.229 , 0.224 , 0.225 ] CUDA = torch . cuda . is_available () DEVICE = torch . device ( \"cuda\" if CUDA else \"cpu\" ) \u5b9a\u4e49\u8bad\u7ec3\u548c\u9a8c\u8bc1\u6570\u636e\u7684\u56fe\u7247\u53d8\u6362\u89c4\u5219\uff1a train_transforms = transforms . Compose ([ transforms . Resize ( IMG_SIZE ), transforms . RandomResizedCrop ( IMG_SIZE ), transforms . RandomHorizontalFlip (), transforms . RandomRotation ( 30 ), transforms . ToTensor (), transforms . Normalize ( IMG_MEAN , IMG_STD ) ]) val_transforms = transforms . Compose ([ transforms . Resize ( IMG_SIZE ), transforms . CenterCrop ( IMG_SIZE ), transforms . ToTensor (), transforms . Normalize ( IMG_MEAN , IMG_STD ) ]) \u6211\u4eec\u8fd9\u91cc\u53ea\u5206\u527210%\u7684\u6570\u636e\u4f5c\u4e3a\u8bad\u7ec3\u65f6\u7684\u9a8c\u8bc1\u6570\u636e\uff1a dataset_names = [ 'train' , 'valid' ] stratified_split = StratifiedShuffleSplit ( n_splits = 1 , test_size = 0.1 , random_state = 0 ) train_split_idx , val_split_idx = next ( iter ( stratified_split . split ( all_labels_df . id , all_labels_df . breed ))) train_df = all_labels_df . iloc [ train_split_idx ] . reset_index () val_df = all_labels_df . iloc [ val_split_idx ] . reset_index () print ( len ( train_df )) print ( len ( val_df )) 9199 1023 \u4f7f\u7528\u5b98\u65b9\u7684dataloader\u8f7d\u5165\u6570\u636e\uff1a image_transforms = { 'train' : train_transforms , 'valid' : val_transforms } train_dataset = DogDataset ( train_df , os . path . join ( DATA_ROOT , 'train' ), transform = image_transforms [ 'train' ]) val_dataset = DogDataset ( val_df , os . path . join ( DATA_ROOT , 'train' ), transform = image_transforms [ 'valid' ]) image_dataset = { 'train' : train_dataset , 'valid' : val_dataset } image_dataloader = { x : DataLoader ( image_dataset [ x ], batch_size = BATCH_SIZE , shuffle = True , num_workers = 0 ) for x in dataset_names } dataset_sizes = { x : len ( image_dataset [ x ]) for x in dataset_names } \u5f00\u59cb\u914d\u7f6e\u7f51\u7edc\uff0c\u7531\u4e8eImageNet\u662f\u8bc6\u522b1000\u4e2a\u7269\u4f53\uff0c\u6211\u4eec\u7684\u72d7\u7684\u5206\u7c7b\u4e00\u5171\u53ea\u6709120\uff0c\u6240\u4ee5\u9700\u8981\u5bf9\u6a21\u578b\u7684\u6700\u540e\u4e00\u5c42\u5168\u8fde\u63a5\u5c42\u8fdb\u884c\u5fae\u8c03\uff0c\u5c06\u8f93\u51fa\u4ece1000\u6539\u4e3a120\uff1a model_ft = models . resnet50 ( pretrained = True ) # \u8fd9\u91cc\u81ea\u52a8\u4e0b\u8f7d\u5b98\u65b9\u7684\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u5e76\u4e14 # \u5c06\u6240\u6709\u7684\u53c2\u6570\u5c42\u8fdb\u884c\u51bb\u7ed3 for param in model_ft . parameters (): param . requires_grad = False # \u8fd9\u91cc\u6253\u5370\u4e0b\u5168\u8fde\u63a5\u5c42\u7684\u4fe1\u606f print ( model_ft . fc ) num_fc_ftr = model_ft . fc . in_features #\u83b7\u53d6\u5230fc\u5c42\u7684\u8f93\u5165 model_ft . fc = nn . Linear ( num_fc_ftr , len ( breeds )) # \u5b9a\u4e49\u4e00\u4e2a\u65b0\u7684FC\u5c42 model_ft = model_ft . to ( DEVICE ) # \u653e\u5230\u8bbe\u5907\u4e2d print ( model_ft ) # \u6700\u540e\u518d\u6253\u5370\u4e00\u4e0b\u65b0\u7684\u6a21\u578b Linear(in_features=2048, out_features=1000, bias=True) ResNet( (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False) (layer1): Sequential( (0): Bottleneck( (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (downsample): Sequential( (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): Bottleneck( (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (2): Bottleneck( (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) ) (layer2): Sequential( (0): Bottleneck( (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (downsample): Sequential( (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): Bottleneck( (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (2): Bottleneck( (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (3): Bottleneck( (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) ) (layer3): Sequential( (0): Bottleneck( (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (downsample): Sequential( (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (2): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (3): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (4): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (5): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) ) (layer4): Sequential( (0): Bottleneck( (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (downsample): Sequential( (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): Bottleneck( (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (2): Bottleneck( (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) ) (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0) (fc): Linear(in_features=2048, out_features=120, bias=True) ) \u8bbe\u7f6e\u8bad\u7ec3\u53c2\u6570\uff1a criterion = nn . CrossEntropyLoss () optimizer = torch . optim . Adam ([ { 'params' : model_ft . fc . parameters ()} ], lr = 0.001 ) #\u6307\u5b9a \u65b0\u52a0\u7684fc\u5c42\u7684\u5b66\u4e60\u7387 \u5b9a\u4e49\u8bad\u7ec3\u51fd\u6570\uff1a def train ( model , device , train_loader , epoch ): model . train () for batch_idx , data in enumerate ( train_loader ): x , y = data x = x . to ( device ) y = y . to ( device ) optimizer . zero_grad () y_hat = model ( x ) loss = criterion ( y_hat , y ) loss . backward () optimizer . step () print ( 'Train Epoch: {} \\t Loss: {:.6f}' . format ( epoch , loss . item ())) \u5b9a\u4e49\u6d4b\u8bd5\u51fd\u6570\uff1a def test ( model , device , test_loader ): model . eval () test_loss = 0 correct = 0 with torch . no_grad (): for i , data in enumerate ( test_loader ): x , y = data x = x . to ( device ) y = y . to ( device ) optimizer . zero_grad () y_hat = model ( x ) test_loss += criterion ( y_hat , y ) . item () # sum up batch loss pred = y_hat . max ( 1 , keepdim = True )[ 1 ] # get the index of the max log-probability correct += pred . eq ( y . view_as ( pred )) . sum () . item () test_loss /= len ( test_loader . dataset ) print ( ' \\n Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%) \\n ' . format ( test_loss , correct , len ( val_dataset ), 100. * correct / len ( val_dataset ))) \u8bad\u7ec39\u6b21\uff0c\u770b\u770b\u6548\u679c\uff1a for epoch in range ( 1 , 10 ): % time train ( model = model_ft , device = DEVICE , train_loader = image_dataloader [ \"train\" ], epoch = epoch ) test ( model = model_ft , device = DEVICE , test_loader = image_dataloader [ \"valid\" ]) Train Epoch: 1 Loss: 2.775527 Wall time: 1min 13s Test set: Average loss: 0.0079, Accuracy: 700/1023 (68%) Train Epoch: 2 Loss: 1.965775 Wall time: 56.5 s Test set: Average loss: 0.0047, Accuracy: 779/1023 (76%) Train Epoch: 3 Loss: 1.798122 Wall time: 56.4 s Test set: Average loss: 0.0037, Accuracy: 790/1023 (77%) Train Epoch: 4 Loss: 1.596331 Wall time: 57.1 s Test set: Average loss: 0.0031, Accuracy: 814/1023 (80%) Train Epoch: 5 Loss: 1.502677 Wall time: 56.3 s Test set: Average loss: 0.0029, Accuracy: 822/1023 (80%) Train Epoch: 6 Loss: 1.430908 Wall time: 56.4 s Test set: Average loss: 0.0028, Accuracy: 815/1023 (80%) Train Epoch: 7 Loss: 1.466642 Wall time: 56.4 s Test set: Average loss: 0.0028, Accuracy: 824/1023 (81%) Train Epoch: 8 Loss: 1.368286 Wall time: 56.9 s Test set: Average loss: 0.0025, Accuracy: 840/1023 (82%) Train Epoch: 9 Loss: 1.348546 Wall time: 56.9 s Test set: Average loss: 0.0027, Accuracy: 814/1023 (80%) \u6211\u4eec\u770b\u5230\u53ea\u8bad\u7ec3\u4e869\u6b21\u5c31\u8fbe\u5230\u4e8680%\u7684\u51c6\u786e\u7387\uff0c\u6548\u679c\u8fd8\u662f\u53ef\u4ee5\u7684\u3002 \u4f46\u662f\u6bcf\u6b21\u8bad\u7ec3\u90fd\u9700\u8981\u5c06\u4e00\u5f20\u56fe\u7247\u5728\u5168\u90e8\u7f51\u7edc\u4e2d\u8fdb\u884c\u8ba1\u7b97\uff0c\u800c\u4e14\u8ba1\u7b97\u7684\u7ed3\u679c\u6bcf\u6b21\u90fd\u662f\u4e00\u6837\u7684\uff0c\u8fd9\u6837\u6d6a\u8d39\u4e86\u5f88\u591a\u8ba1\u7b97\u7684\u8d44\u6e90\u3002 \u4e0b\u9762\u6211\u4eec\u5c31\u5c06\u8fd9\u4e9b\u4e0d\u8fdb\u884c\u53cd\u5411\u4f20\u64ad\u6216\u8005\u8bf4\u4e0d\u66f4\u65b0\u7f51\u7edc\u6743\u91cd\u53c2\u6570\u5c42\u7684\u8ba1\u7b97\u7ed3\u679c\u4fdd\u5b58\u4e0b\u6765\uff0c\u8fd9\u6837\u6211\u4eec\u4ee5\u540e\u4f7f\u7528\u7684\u65f6\u5019\u5c31\u53ef\u4ee5\u76f4\u63a5\u5c06\u8fd9\u4e9b\u7ed3\u679c\u8f93\u5165\u5230FC\u5c42\u6216\u8005\u4ee5\u8fd9\u4e9b\u7ed3\u679c\u6784\u5efa\u65b0\u7684\u7f51\u7edc\u5c42\uff0c\u7701\u53bb\u4e86\u8ba1\u7b97\u7684\u65f6\u95f4\uff0c\u5e76\u4e14\u8fd9\u6837\u5982\u679c\u53ea\u8bad\u7ec3\u5168\u8fde\u63a5\u5c42\uff0cCPU\u5c31\u53ef\u4ee5\u5b8c\u6210\u4e86\u3002 4.1.4 \u56fa\u5b9a\u5c42\u7684\u5411\u91cf\u5bfc\u51fa \u00b6 PyTorch\u8bba\u575b \u4e2d\u8bf4\u5230\u53ef\u4ee5\u4f7f\u7528\u81ea\u5df1\u624b\u52a8\u5b9e\u73b0\u6a21\u578b\u4e2d\u7684forward\u53c2\u6570\uff0c\u8fd9\u6837\u770b\u8d77\u6765\u662f\u5f88\u7b80\u4fbf\u7684\uff0c\u4f46\u662f\u8fd9\u6837\u5904\u7406\u8d77\u6765\u5f88\u9ebb\u70e6\uff0c\u4e0d\u5efa\u8bae\u8fd9\u6837\u4f7f\u7528\u3002 \u8fd9\u91cc\u6211\u4eec\u5c31\u8981\u91c7\u7528PyTorch\u6bd4\u8f83\u9ad8\u7ea7\u7684API\uff0chook\u6765\u5904\u7406\u4e86\uff0c\u6211\u4eec\u8981\u5148\u5b9a\u4e49\u4e00\u4e2ahook\u51fd\u6570 in_list = [] # \u8fd9\u91cc\u5b58\u653e\u6240\u6709\u7684\u8f93\u51fa def hook ( module , input , output ): #input\u662f\u4e00\u4e2atuple\u4ee3\u8868\u987a\u5e8f\u4ee3\u8868\u6bcf\u4e00\u4e2a\u8f93\u5165\u9879\uff0c\u6211\u4eec\u8fd9\u91cc\u53ea\u6709\u4e00\u9879\uff0c\u6240\u4ee5\u76f4\u63a5\u83b7\u53d6 #\u9700\u8981\u5168\u90e8\u7684\u53c2\u6570\u4fe1\u606f\u53ef\u4ee5\u4f7f\u7528\u8fd9\u4e2a\u6253\u5370 #for val in input: # print(\"input val:\",val) for i in range ( input [ 0 ] . size ( 0 )): in_list . append ( input [ 0 ][ i ] . cpu () . numpy ()) \u5728\u76f8\u5e94\u7684\u5c42\u6ce8\u518chook\u51fd\u6570\uff0c\u4fdd\u8bc1\u51fd\u6570\u80fd\u591f\u6b63\u5e38\u5de5\u4f5c\uff0c\u6211\u4eec\u8fd9\u91cc\u76f4\u63a5hook \u5168\u8fde\u63a5\u5c42\u524d\u9762\u7684pool\u5c42\uff0c\u83b7\u53d6pool\u5c42\u7684\u8f93\u5165\u6570\u636e\uff0c\u8fd9\u6837\u4f1a\u83b7\u5f97\u66f4\u591a\u7684\u7279\u5f81\uff1a model_ft . avgpool . register_forward_hook ( hook ) <torch.utils.hooks.RemovableHandle at 0x24812a5e978> \u5f00\u59cb\u83b7\u53d6\u8f93\u51fa\uff0c\u8fd9\u91cc\u6211\u4eec\u56e0\u4e3a\u4e0d\u9700\u8981\u53cd\u5411\u4f20\u64ad\uff0c\u6240\u4ee5\u76f4\u63a5\u53ef\u4ee5\u4f7f\u7528no_grad\u5d4c\u5957\uff1a %% time with torch . no_grad (): for batch_idx , data in enumerate ( image_dataloader [ \"train\" ]): x , y = data x = x . to ( DEVICE ) y = y . to ( DEVICE ) y_hat = model_ft ( x ) Wall time: 1min 23s features = np . array ( in_list ) np . save ( \"features\" , features ) \u8fd9\u6837\u518d\u8bad\u7ec3\u65f6\u6211\u4eec\u53ea\u9700\u5c06\u8fd9\u4e2a\u6570\u7ec4\u8bfb\u51fa\u6765\uff0c\u7136\u540e\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528\u8fd9\u4e2a\u6570\u7ec4\u518d\u8f93\u5165\u5230linear\u6216\u8005\u6211\u4eec\u524d\u9762\u8bb2\u5230\u7684sigmod\u5c42\u5c31\u53ef\u4ee5\u4e86\u3002 \u6211\u4eec\u5728\u8fd9\u91cc\u5728pool\u5c42\u524d\u83b7\u53d6\u4e86\u66f4\u591a\u7684\u7279\u5f81\uff0c\u53ef\u4ee5\u5c06\u8fd9\u4e9b\u7279\u5f81\u4f7f\u7528\u66f4\u9ad8\u7ea7\u7684\u5206\u7c7b\u5668\uff0c\u4f8b\u5982SVM\uff0c\u6811\u578b\u7684\u5206\u7c7b\u5668\u8fdb\u884c\u5206\u7c7b\u3002 \u4ee5\u4e0a\u5c31\u662f\u9488\u5bf9\u4e8e\u8ba1\u7b97\u673a\u89c6\u89c9\u65b9\u5411\u7684\u5fae\u8c03\u4ecb\u7ecd\uff0c\u5bf9\u4e8eNLP\u65b9\u5411\u6765\u8bb2fastai\u7684\u521b\u59cb\u4ebaJeremy \u5728\u4eca\u5e74\u51fa\u53d1\u5e03\u4e86ULMFiT\u53ef\u4ee5\u4f5c\u4e3a\u5f88\u597d\u7684\u53c2\u8003\u3002 \u5177\u4f53\u8bf7\u770b\u8fd9\u4e2a\u94fe\u63a5\uff1a Universal Language Model Fine-tuning for Text Classification","title":"Fine Tuning"},{"location":"tutorial/chapter04_advanced/4_1_fine-tuning/#41-fine-tuning","text":"\u5728\u524d\u9762\u7684\u4ecb\u7ecd\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u65f6\u5019\uff0c\u8bf4\u5230\u8fc7PyTorch\u5df2\u7ecf\u4e3a\u6211\u4eec\u8bad\u7ec3\u597d\u4e86\u4e00\u4e9b\u7ecf\u5178\u7684\u7f51\u7edc\u6a21\u578b\uff0c\u90a3\u4e48\u8fd9\u4e9b\u9884\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u662f\u7528\u6765\u505a\u4ec0\u4e48\u7684\u5462\uff1f\u5176\u5b9e\u5c31\u662f\u4e3a\u4e86\u6211\u4eec\u8fdb\u884c\u5fae\u8c03\u4f7f\u7528\u7684\u3002","title":"4.1 Fine tuning \u6a21\u578b\u5fae\u8c03"},{"location":"tutorial/chapter04_advanced/4_1_fine-tuning/#411","text":"\u9488\u5bf9\u4e8e\u67d0\u4e2a\u4efb\u52a1\uff0c\u81ea\u5df1\u7684\u8bad\u7ec3\u6570\u636e\u4e0d\u591a\uff0c\u90a3\u600e\u4e48\u529e\uff1f \u6ca1\u5173\u7cfb\uff0c\u6211\u4eec\u5148\u627e\u5230\u4e00\u4e2a\u540c\u7c7b\u7684\u522b\u4eba\u8bad\u7ec3\u597d\u7684\u6a21\u578b\uff0c\u628a\u522b\u4eba\u73b0\u6210\u7684\u8bad\u7ec3\u597d\u4e86\u7684\u6a21\u578b\u62ff\u8fc7\u6765\uff0c\u6362\u6210\u81ea\u5df1\u7684\u6570\u636e\uff0c\u8c03\u6574\u4e00\u4e0b\u53c2\u6570\uff0c\u518d\u8bad\u7ec3\u4e00\u904d\uff0c\u8fd9\u5c31\u662f\u5fae\u8c03\uff08fine-tune\uff09\u3002 PyTorch\u91cc\u9762\u63d0\u4f9b\u7684\u7ecf\u5178\u7684\u7f51\u7edc\u6a21\u578b\u90fd\u662f\u5b98\u65b9\u901a\u8fc7Imagenet\u7684\u6570\u636e\u96c6\u4e0e\u8bad\u7ec3\u597d\u7684\u6570\u636e\uff0c\u5982\u679c\u6211\u4eec\u7684\u6570\u636e\u8bad\u7ec3\u6570\u636e\u4e0d\u591f\uff0c\u8fd9\u4e9b\u6570\u636e\u662f\u53ef\u4ee5\u4f5c\u4e3a\u57fa\u7840\u6a21\u578b\u6765\u4f7f\u7528\u7684\u3002","title":"4.1.1 \u4ec0\u4e48\u662f\u5fae\u8c03"},{"location":"tutorial/chapter04_advanced/4_1_fine-tuning/#_1","text":"\u5bf9\u4e8e\u6570\u636e\u96c6\u672c\u8eab\u5f88\u5c0f\uff08\u51e0\u5343\u5f20\u56fe\u7247\uff09\u7684\u60c5\u51b5\uff0c\u4ece\u5934\u5f00\u59cb\u8bad\u7ec3\u5177\u6709\u51e0\u5343\u4e07\u53c2\u6570\u7684\u5927\u578b\u795e\u7ecf\u7f51\u7edc\u662f\u4e0d\u73b0\u5b9e\u7684\uff0c\u56e0\u4e3a\u8d8a\u5927\u7684\u6a21\u578b\u5bf9\u6570\u636e\u91cf\u7684\u8981\u6c42\u8d8a\u5927\uff0c\u8fc7\u62df\u5408\u65e0\u6cd5\u907f\u514d\u3002\u8fd9\u65f6\u5019\u5982\u679c\u8fd8\u60f3\u7528\u4e0a\u5927\u578b\u795e\u7ecf\u7f51\u7edc\u7684\u8d85\u5f3a\u7279\u5f81\u63d0\u53d6\u80fd\u529b\uff0c\u53ea\u80fd\u9760\u5fae\u8c03\u5df2\u7ecf\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u3002 \u53ef\u4ee5\u964d\u4f4e\u8bad\u7ec3\u6210\u672c\uff1a\u5982\u679c\u4f7f\u7528\u5bfc\u51fa\u7279\u5f81\u5411\u91cf\u7684\u65b9\u6cd5\u8fdb\u884c\u8fc1\u79fb\u5b66\u4e60\uff0c\u540e\u671f\u7684\u8bad\u7ec3\u6210\u672c\u975e\u5e38\u4f4e\uff0c\u7528 CPU \u90fd\u5b8c\u5168\u65e0\u538b\u529b\uff0c\u6ca1\u6709\u6df1\u5ea6\u5b66\u4e60\u673a\u5668\u4e5f\u53ef\u4ee5\u505a\u3002 \u524d\u4eba\u82b1\u5f88\u5927\u7cbe\u529b\u8bad\u7ec3\u51fa\u6765\u7684\u6a21\u578b\u5728\u5927\u6982\u7387\u4e0a\u4f1a\u6bd4\u4f60\u81ea\u5df1\u4ece\u96f6\u5f00\u59cb\u642d\u7684\u6a21\u578b\u8981\u5f3a\u608d\uff0c\u6ca1\u6709\u5fc5\u8981\u91cd\u590d\u9020\u8f6e\u5b50\u3002","title":"\u4e3a\u4ec0\u4e48\u8981\u5fae\u8c03"},{"location":"tutorial/chapter04_advanced/4_1_fine-tuning/#transfer-learning","text":"\u603b\u662f\u6709\u4eba\u628a \u8fc1\u79fb\u5b66\u4e60\u548c\u795e\u7ecf\u7f51\u7edc\u7684\u8bad\u7ec3\u8054\u7cfb\u8d77\u6765\uff0c\u8fd9\u4e24\u4e2a\u6982\u5ff5\u521a\u5f00\u59cb\u662f\u65e0\u5173\u7684\u3002 \u8fc1\u79fb\u5b66\u4e60\u662f\u673a\u5668\u5b66\u4e60\u7684\u5206\u652f\uff0c\u73b0\u5728\u4e4b\u6240\u4ee5 \u8fc1\u79fb\u5b66\u4e60\u548c\u795e\u7ecf\u7f51\u7edc\u8054\u7cfb\u5982\u6b64\u7d27\u5bc6\uff0c\u73b0\u5728\u56fe\u50cf\u8bc6\u522b\u8fd9\u5757\u53d1\u5c55\u7684\u592a\u5feb\u6548\u679c\u4e5f\u592a\u597d\u4e86\uff0c\u6240\u4ee5\u51e0\u4e4e\u6240\u6709\u7684\u8fc1\u79fb\u5b66\u4e60\u90fd\u662f\u56fe\u50cf\u8bc6\u522b\u65b9\u5411\u7684\uff0c\u6240\u4ee5\u5927\u5bb6\u770b\u5230\u7684\u8fc1\u79fb\u5b66\u4e60\u57fa\u672c\u4e0a\u90fd\u662f\u4ee5\u795e\u7ecf\u7f51\u7edc\u76f8\u5173\u7684\u8ba1\u7b97\u673a\u89c6\u89c9\u4e3a\u4e3b\uff0c\u672c\u6587\u4e2d\u4e5f\u4f1a\u4ee5\u8fd9\u65b9\u9762\u6765\u4e3e\u4f8b\u5b50 \u8fc1\u79fb\u5b66\u4e60\u521d\u8877\u662f\u8282\u7701\u4eba\u5de5\u6807\u6ce8\u6837\u672c\u7684\u65f6\u95f4\uff0c\u8ba9\u6a21\u578b\u53ef\u4ee5\u901a\u8fc7\u4e00\u4e2a\u5df2\u6709\u7684\u6807\u8bb0\u6570\u636e\u7684\u9886\u57df\u5411\u672a\u6807\u8bb0\u6570\u636e\u9886\u57df\u8fdb\u884c\u8fc1\u79fb\u4ece\u800c\u8bad\u7ec3\u51fa\u9002\u7528\u4e8e\u8be5\u9886\u57df\u7684\u6a21\u578b\uff0c\u76f4\u63a5\u5bf9\u76ee\u6807\u57df\u4ece\u5934\u5f00\u59cb\u5b66\u4e60\u6210\u672c\u592a\u9ad8\uff0c\u6211\u4eec\u6545\u800c\u8f6c\u5411\u8fd0\u7528\u5df2\u6709\u7684\u76f8\u5173\u77e5\u8bc6\u6765\u8f85\u52a9\u5c3d\u5feb\u5730\u5b66\u4e60\u65b0\u77e5\u8bc6 \u4e3e\u4e00\u4e2a\u7b80\u5355\u7684\u4f8b\u5b50\u5c31\u80fd\u5f88\u597d\u7684\u8bf4\u660e\u95ee\u9898\uff0c\u6211\u4eec\u5b66\u4e60\u7f16\u7a0b\u7684\u65f6\u5019\u4f1a\u5b66\u4e60\u4ec0\u4e48\uff1f \u8bed\u6cd5\u3001\u7279\u5b9a\u8bed\u8a00\u7684API\u3001\u6d41\u7a0b\u5904\u7406\u3001\u9762\u5411\u5bf9\u8c61\uff0c\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u7b49\u7b49 \u8fd9\u91cc\u9762\u8bed\u6cd5\u548cAPI\u662f\u6bcf\u4e00\u4e2a\u8bed\u8a00\u7279\u6709\u7684\uff0c\u4f46\u662f\u9762\u5411\u5bf9\u8c61\u548c\u8bbe\u8ba1\u6a21\u5f0f\u53ef\u662f\u901a\u7528\u7684\uff0c\u6211\u4eec\u5b66\u4e86JAVA\uff0c\u518d\u53bb\u5b66C#\uff0c\u6216\u8005Python\uff0c\u9762\u5411\u5bf9\u8c61\u548c\u8bbe\u8ba1\u6a21\u5f0f\u662f\u4e0d\u7528\u53bb\u5b66\u7684\uff0c\u56e0\u4e3a\u539f\u7406\u90fd\u662f\u4e00\u6837\u7684\uff0c\u751a\u81f3\u5728\u5b66\u4e60C#\u7684\u65f6\u5019\u8bed\u6cd5\u90fd\u53ef\u4ee5\u5c11\u5b66\u5f88\u591a\uff0c\u8fd9\u5c31\u662f\u8fc1\u79fb\u5b66\u4e60\u7684\u6982\u5ff5\uff0c\u628a\u7edf\u4e00\u7684\u6982\u5ff5\u62bd\u8c61\u51fa\u6765\uff0c\u53ea\u5b66\u4e60\u4e0d\u540c\u7684\u5185\u5bb9\u3002 \u8fc1\u79fb\u5b66\u4e60\u6309\u7167\u5b66\u4e60\u65b9\u5f0f\u53ef\u4ee5\u5206\u4e3a\u57fa\u4e8e\u6837\u672c\u7684\u8fc1\u79fb\uff0c\u57fa\u4e8e\u7279\u5f81\u7684\u8fc1\u79fb\uff0c\u57fa\u4e8e\u6a21\u578b\u7684\u8fc1\u79fb\uff0c\u4ee5\u53ca\u57fa\u4e8e\u5173\u7cfb\u7684\u8fc1\u79fb\uff0c\u8fd9\u91cc\u5c31\u4e0d\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u3002","title":"\u8fc1\u79fb\u5b66\u4e60 Transfer Learning"},{"location":"tutorial/chapter04_advanced/4_1_fine-tuning/#_2","text":"\u5176\u5b9e \"Transfer Learning\" \u548c \"Fine-tune\" \u5e76\u6ca1\u6709\u4e25\u683c\u7684\u533a\u5206\uff0c\u542b\u4e49\u53ef\u4ee5\u76f8\u4e92\u4ea4\u6362\uff0c\u53ea\u4e0d\u8fc7\u540e\u8005\u4f3c\u4e4e\u66f4\u5e38\u7528\u4e8e\u5f62\u5bb9\u8fc1\u79fb\u5b66\u4e60\u7684\u540e\u671f\u5fae\u8c03\u4e2d\u3002 \u6211\u4e2a\u4eba\u7684\u7406\u89e3\uff0c\u5fae\u8c03\u5e94\u8be5\u662f\u8fc1\u79fb\u5b66\u4e60\u4e2d\u7684\u4e00\u90e8\u5206\u3002\u5fae\u8c03\u53ea\u80fd\u8bf4\u662f\u4e00\u4e2atrick\u3002","title":"\u4e8c\u8005\u5173\u7cfb"},{"location":"tutorial/chapter04_advanced/4_1_fine-tuning/#412","text":"\u5bf9\u4e8e\u4e0d\u540c\u7684\u9886\u57df\u5fae\u8c03\u7684\u65b9\u6cd5\u4e5f\u4e0d\u4e00\u6837\uff0c\u6bd4\u5982\u8bed\u97f3\u8bc6\u522b\u9886\u57df\u4e00\u822c\u5fae\u8c03\u524d\u51e0\u5c42\uff0c\u56fe\u7247\u8bc6\u522b\u95ee\u9898\u5fae\u8c03\u540e\u9762\u51e0\u5c42\uff0c\u8fd9\u4e2a\u539f\u56e0\u6211\u8fd9\u91cc\u4e5f\u53ea\u80fd\u8bb2\u4e2a\u5927\u6982\uff0c\u5177\u4f53\u8fd8\u8981\u5927\u795e\u6765\u89e3\u91ca\uff1a \u5bf9\u4e8e\u56fe\u7247\u6765\u8bf4\uff0c\u6211\u4eecCNN\u7684\u524d\u51e0\u5c42\u5b66\u4e60\u5230\u7684\u90fd\u662f\u4f4e\u7ea7\u7684\u7279\u5f81\uff0c\u6bd4\u5982\uff0c\u70b9\u3001\u7ebf\u3001\u9762\uff0c\u8fd9\u4e9b\u4f4e\u7ea7\u7684\u7279\u5f81\u5bf9\u4e8e\u4efb\u4f55\u56fe\u7247\u6765\u8bf4\u90fd\u662f\u53ef\u4ee5\u62bd\u8c61\u51fa\u6765\u7684\uff0c\u6240\u4ee5\u6211\u4eec\u5c06\u4ed6\u4f5c\u4e3a\u901a\u7528\u6570\u636e\uff0c\u53ea\u5fae\u8c03\u8fd9\u4e9b\u4f4e\u7ea7\u7279\u5f81\u7ec4\u5408\u8d77\u6765\u7684\u9ad8\u7ea7\u7279\u5f81\u5373\u53ef\uff0c\u4f8b\u5982\uff0c\u8fd9\u4e9b\u70b9\u3001\u7ebf\u3001\u9762\uff0c\u7ec4\u6210\u7684\u662f\u56ed\u8fd8\u662f\u692d\u5706\uff0c\u8fd8\u662f\u6b63\u65b9\u5f62\uff0c\u8fd9\u4e9b\u4ee3\u8868\u7684\u542b\u4e49\u662f\u6211\u4eec\u9700\u8981\u540e\u9762\u8bad\u7ec3\u51fa\u6765\u7684\u3002 \u5bf9\u4e8e\u8bed\u97f3\u6765\u8bf4\uff0c\u6bcf\u4e2a\u5355\u8bcd\u8868\u8fbe\u7684\u610f\u601d\u90fd\u662f\u4e00\u6837\u7684\uff0c\u53ea\u4e0d\u8fc7\u53d1\u97f3\u6216\u8005\u662f\u5355\u8bcd\u7684\u62fc\u5199\u4e0d\u4e00\u6837\uff0c\u6bd4\u5982 \u82f9\u679c\uff0capple\uff0capfel\uff08\u5fb7\u8bed\uff09\uff0c\u90fd\u8868\u793a\u7684\u662f\u540c\u4e00\u4e2a\u4e1c\u897f\uff0c\u53ea\u4e0d\u8fc7\u53d1\u97f3\u548c\u5355\u8bcd\u4e0d\u4e00\u6837\uff0c\u4f46\u662f\u4ed6\u5177\u4f53\u4ee3\u8868\u7684\u542b\u4e49\u662f\u4e00\u6837\u7684\uff0c\u5c31\u662f\u9ad8\u7ea7\u7279\u5f81\u662f\u76f8\u540c\u7684\uff0c\u6240\u4ee5\u6211\u4eec\u53ea\u8981\u5fae\u8c03\u4f4e\u7ea7\u7684\u7279\u5f81\u5c31\u53ef\u4ee5\u4e86\u3002 \u4e0b\u9762\u53ea\u4ecb\u7ecd\u4e0b\u8ba1\u7b97\u673a\u89c6\u89c9\u65b9\u5411\u7684\u5fae\u8c03\uff0c\u6458\u81ea cs231 ConvNet as fixed feature extractor.\uff1a \u5176\u5b9e\u8fd9\u91cc\u6709\u4e24\u79cd\u505a\u6cd5\uff1a \u4f7f\u7528\u6700\u540e\u4e00\u4e2afc layer\u4e4b\u524d\u7684fc layer\u83b7\u5f97\u7684\u7279\u5f81\uff0c\u5b66\u4e60\u4e2a\u7ebf\u6027\u5206\u7c7b\u5668(\u6bd4\u5982SVM) \u91cd\u65b0\u8bad\u7ec3\u6700\u540e\u4e00\u4e2afc layer Fine-tuning the ConvNet \u56fa\u5b9a\u524d\u51e0\u5c42\u7684\u53c2\u6570\uff0c\u53ea\u5bf9\u6700\u540e\u51e0\u5c42\u8fdb\u884cfine-tuning, \u5bf9\u4e8e\u4e0a\u9762\u4e24\u79cd\u65b9\u6848\u6709\u4e00\u4e9b\u5fae\u8c03\u7684\u5c0f\u6280\u5de7\uff0c\u6bd4\u5982\u5148\u8ba1\u7b97\u51fa\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u5377\u79ef\u5c42\u5bf9\u6240\u6709\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\u7684\u7279\u5f81\u5411\u91cf\uff0c\u7136\u540e\u629b\u5f00\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u53ea\u8bad\u7ec3\u81ea\u5df1\u5b9a\u5236\u7684\u7b80\u914d\u7248\u5168\u8fde\u63a5\u7f51\u7edc\u3002 \u8fd9\u4e2a\u65b9\u5f0f\u7684\u4e00\u4e2a\u597d\u5904\u5c31\u662f\u8282\u7701\u8ba1\u7b97\u8d44\u6e90\uff0c\u6bcf\u6b21\u8fed\u4ee3\u90fd\u4e0d\u4f1a\u518d\u53bb\u8dd1\u5168\u90e8\u7684\u6570\u636e\uff0c\u800c\u53ea\u662f\u8dd1\u4e00\u4e0b\u7b80\u914d\u7684\u5168\u8fde\u63a5 Pretrained models \u8fd9\u4e2a\u5176\u5b9e\u548c\u7b2c\u4e8c\u79cd\u662f\u4e00\u4e2a\u610f\u601d\uff0c\u4e0d\u8fc7\u6bd4\u8f83\u6781\u7aef\uff0c\u4f7f\u7528\u6574\u4e2apre-trained\u7684model\u4f5c\u4e3a\u521d\u59cb\u5316\uff0c\u7136\u540efine-tuning\u6574\u4e2a\u7f51\u7edc\u800c\u4e0d\u662f\u67d0\u4e9b\u5c42\uff0c\u4f46\u662f\u8fd9\u4e2a\u7684\u8ba1\u7b97\u91cf\u662f\u975e\u5e38\u5927\u7684,\u5c31\u53ea\u76f8\u5f53\u4e8e\u505a\u4e86\u4e00\u4e2a\u521d\u59cb\u5316\u3002","title":"4.1.2 \u5982\u4f55\u5fae\u8c03"},{"location":"tutorial/chapter04_advanced/4_1_fine-tuning/#413","text":"\u65b0\u6570\u636e\u96c6\u548c\u539f\u59cb\u6570\u636e\u96c6\u5408\u7c7b\u4f3c\uff0c\u90a3\u4e48\u76f4\u63a5\u53ef\u4ee5\u5fae\u8c03\u4e00\u4e2a\u6700\u540e\u7684FC\u5c42\u6216\u8005\u91cd\u65b0\u6307\u5b9a\u4e00\u4e2a\u65b0\u7684\u5206\u7c7b\u5668 \u65b0\u6570\u636e\u96c6\u6bd4\u8f83\u5c0f\u548c\u539f\u59cb\u6570\u636e\u96c6\u5408\u5dee\u5f02\u6027\u6bd4\u8f83\u5927\uff0c\u90a3\u4e48\u53ef\u4ee5\u4f7f\u7528\u4ece\u6a21\u578b\u7684\u4e2d\u90e8\u5f00\u59cb\u8bad\u7ec3\uff0c\u53ea\u5bf9\u6700\u540e\u51e0\u5c42\u8fdb\u884cfine-tuning \u65b0\u6570\u636e\u96c6\u6bd4\u8f83\u5c0f\u548c\u539f\u59cb\u6570\u636e\u96c6\u5408\u5dee\u5f02\u6027\u6bd4\u8f83\u5927\uff0c\u5982\u679c\u4e0a\u9762\u65b9\u6cd5\u8fd8\u662f\u4e0d\u884c\u7684\u5316\u90a3\u4e48\u6700\u597d\u662f\u91cd\u65b0\u8bad\u7ec3\uff0c\u53ea\u5c06\u9884\u8bad\u7ec3\u7684\u6a21\u578b\u4f5c\u4e3a\u4e00\u4e2a\u65b0\u6a21\u578b\u521d\u59cb\u5316\u7684\u6570\u636e \u65b0\u6570\u636e\u96c6\u7684\u5927\u5c0f\u4e00\u5b9a\u8981\u4e0e\u539f\u59cb\u6570\u636e\u96c6\u76f8\u540c\uff0c\u6bd4\u5982CNN\u4e2d\u8f93\u5165\u7684\u56fe\u7247\u5927\u5c0f\u4e00\u5b9a\u8981\u76f8\u540c\uff0c\u624d\u4e0d\u4f1a\u62a5\u9519 \u5982\u679c\u6570\u636e\u96c6\u5927\u5c0f\u4e0d\u540c\u7684\u8bdd\uff0c\u53ef\u4ee5\u5728\u6700\u540e\u7684fc\u5c42\u4e4b\u524d\u6dfb\u52a0\u5377\u79ef\u6216\u8005pool\u5c42\uff0c\u4f7f\u5f97\u6700\u540e\u7684\u8f93\u51fa\u4e0efc\u5c42\u4e00\u81f4\uff0c\u4f46\u8fd9\u6837\u4f1a\u5bfc\u81f4\u51c6\u786e\u5ea6\u5927\u5e45\u4e0b\u964d\uff0c\u6240\u4ee5\u4e0d\u5efa\u8bae\u8fd9\u6837\u505a \u5bf9\u4e8e\u4e0d\u540c\u7684\u5c42\u53ef\u4ee5\u8bbe\u7f6e\u4e0d\u540c\u7684\u5b66\u4e60\u7387\uff0c\u4e00\u822c\u60c5\u51b5\u4e0b\u5efa\u8bae\uff0c\u5bf9\u4e8e\u4f7f\u7528\u7684\u539f\u59cb\u6570\u636e\u505a\u521d\u59cb\u5316\u7684\u5c42\u8bbe\u7f6e\u7684\u5b66\u4e60\u7387\u8981\u5c0f\u4e8e\uff08\u4e00\u822c\u53ef\u8bbe\u7f6e\u5c0f\u4e8e10\u500d\uff09\u521d\u59cb\u5316\u7684\u5b66\u4e60\u7387\uff0c\u8fd9\u6837\u4fdd\u8bc1\u5bf9\u4e8e\u5df2\u7ecf\u521d\u59cb\u5316\u7684\u6570\u636e\u4e0d\u4f1a\u626d\u66f2\u7684\u8fc7\u5feb\uff0c\u800c\u4f7f\u7528\u521d\u59cb\u5316\u5b66\u4e60\u7387\u7684\u65b0\u5c42\u53ef\u4ee5\u5feb\u901f\u7684\u6536\u655b\u3002","title":"4.1.3 \u6ce8\u610f\u4e8b\u9879"},{"location":"tutorial/chapter04_advanced/4_1_fine-tuning/#413_1","text":"\u8fd9\u91cc\u9762\u6211\u4eec\u4f7f\u7528\u5b98\u65b9\u8bad\u7ec3\u597d\u7684resnet50\u6765\u53c2\u52a0kaggle\u4e0a\u9762\u7684 dog breed \u72d7\u7684\u79cd\u7c7b\u8bc6\u522b\u6765\u505a\u4e00\u4e2a\u7b80\u5355\u5fae\u8c03\u5b9e\u4f8b\u3002 \u9996\u5148\u6211\u4eec\u9700\u8981\u4e0b\u8f7d\u5b98\u65b9\u7684\u6570\u636e\u89e3\u538b\uff0c\u53ea\u8981\u4fdd\u6301\u6570\u636e\u7684\u76ee\u5f55\u7ed3\u6784\u5373\u53ef\uff0c\u8fd9\u91cc\u6307\u5b9a\u4e00\u4e0b\u76ee\u5f55\u7684\u4f4d\u7f6e\uff0c\u5e76\u4e14\u770b\u4e0b\u5185\u5bb9 DATA_ROOT = 'data' all_labels_df = pd . read_csv ( os . path . join ( DATA_ROOT , 'labels.csv' )) all_labels_df . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id breed 0 000bec180eb18c7604dcecc8fe0dba07 boston_bull 1 001513dfcb2ffafc82cccf4d8bbaba97 dingo 2 001cdf01b096e06d78e9e5112d419397 pekinese 3 00214f311d5d2247d5dfe4fe24b2303d bluetick 4 0021f9ceb3235effd7fcde7f7538ed62 golden_retriever \u83b7\u53d6\u72d7\u7684\u5206\u7c7b\uff0c\u6839\u636e\u5206\u7c7b\u8fdb\u884c\u7f16\u53f7\u3002\u8fd9\u91cc\u5b9a\u4e49\u4e86\u4e24\u4e2a\u5b57\u5178\uff0c\u5206\u522b\u4ee5\u540d\u5b57\u548cid\u4f5c\u4e3a\u5bf9\u5e94\uff0c\u65b9\u4fbf\u540e\u9762\u5904\u7406\uff1a breeds = all_labels_df . breed . unique () breed2idx = dict (( breed , idx ) for idx , breed in enumerate ( breeds )) idx2breed = dict (( idx , breed ) for idx , breed in enumerate ( breeds )) len ( breeds ) 120 \u6dfb\u52a0\u5230\u5217\u8868\u4e2d: all_labels_df [ 'label_idx' ] = [ breed2idx [ b ] for b in all_labels_df . breed ] all_labels_df . head () .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } id breed label_idx 0 000bec180eb18c7604dcecc8fe0dba07 boston_bull 0 1 001513dfcb2ffafc82cccf4d8bbaba97 dingo 1 2 001cdf01b096e06d78e9e5112d419397 pekinese 2 3 00214f311d5d2247d5dfe4fe24b2303d bluetick 3 4 0021f9ceb3235effd7fcde7f7538ed62 golden_retriever 4 \u7531\u4e8e\u6211\u4eec\u7684\u6570\u636e\u96c6\u4e0d\u662f\u5b98\u65b9\u6307\u5b9a\u7684\u683c\u5f0f\uff0c\u6211\u4eec\u81ea\u5df1\u5b9a\u4e49\u4e00\u4e2a\u6570\u636e\u96c6: class DogDataset ( Dataset ): def __init__ ( self , labels_df , img_path , transform = None ): self . labels_df = labels_df self . img_path = img_path self . transform = transform def __len__ ( self ): return self . labels_df . shape [ 0 ] def __getitem__ ( self , idx ): image_name = os . path . join ( self . img_path , self . labels_df . id [ idx ]) + '.jpg' img = Image . open ( image_name ) label = self . labels_df . label_idx [ idx ] if self . transform : img = self . transform ( img ) return img , label \u5b9a\u4e49\u4e00\u4e9b\u8d85\u53c2\u6570\uff1a IMG_SIZE = 224 # resnet50\u7684\u8f93\u5165\u662f224\u7684\u6240\u4ee5\u9700\u8981\u5c06\u56fe\u7247\u7edf\u4e00\u5927\u5c0f BATCH_SIZE = 256 #\u8fd9\u4e2a\u6279\u6b21\u5927\u5c0f\u9700\u8981\u5360\u75284.6-5g\u7684\u663e\u5b58\uff0c\u5982\u679c\u4e0d\u591f\u7684\u5316\u53ef\u4ee5\u6539\u4e0b\u6279\u6b21\uff0c\u5982\u679c\u5185\u5b58\u8d85\u8fc710G\u53ef\u4ee5\u6539\u4e3a512 IMG_MEAN = [ 0.485 , 0.456 , 0.406 ] IMG_STD = [ 0.229 , 0.224 , 0.225 ] CUDA = torch . cuda . is_available () DEVICE = torch . device ( \"cuda\" if CUDA else \"cpu\" ) \u5b9a\u4e49\u8bad\u7ec3\u548c\u9a8c\u8bc1\u6570\u636e\u7684\u56fe\u7247\u53d8\u6362\u89c4\u5219\uff1a train_transforms = transforms . Compose ([ transforms . Resize ( IMG_SIZE ), transforms . RandomResizedCrop ( IMG_SIZE ), transforms . RandomHorizontalFlip (), transforms . RandomRotation ( 30 ), transforms . ToTensor (), transforms . Normalize ( IMG_MEAN , IMG_STD ) ]) val_transforms = transforms . Compose ([ transforms . Resize ( IMG_SIZE ), transforms . CenterCrop ( IMG_SIZE ), transforms . ToTensor (), transforms . Normalize ( IMG_MEAN , IMG_STD ) ]) \u6211\u4eec\u8fd9\u91cc\u53ea\u5206\u527210%\u7684\u6570\u636e\u4f5c\u4e3a\u8bad\u7ec3\u65f6\u7684\u9a8c\u8bc1\u6570\u636e\uff1a dataset_names = [ 'train' , 'valid' ] stratified_split = StratifiedShuffleSplit ( n_splits = 1 , test_size = 0.1 , random_state = 0 ) train_split_idx , val_split_idx = next ( iter ( stratified_split . split ( all_labels_df . id , all_labels_df . breed ))) train_df = all_labels_df . iloc [ train_split_idx ] . reset_index () val_df = all_labels_df . iloc [ val_split_idx ] . reset_index () print ( len ( train_df )) print ( len ( val_df )) 9199 1023 \u4f7f\u7528\u5b98\u65b9\u7684dataloader\u8f7d\u5165\u6570\u636e\uff1a image_transforms = { 'train' : train_transforms , 'valid' : val_transforms } train_dataset = DogDataset ( train_df , os . path . join ( DATA_ROOT , 'train' ), transform = image_transforms [ 'train' ]) val_dataset = DogDataset ( val_df , os . path . join ( DATA_ROOT , 'train' ), transform = image_transforms [ 'valid' ]) image_dataset = { 'train' : train_dataset , 'valid' : val_dataset } image_dataloader = { x : DataLoader ( image_dataset [ x ], batch_size = BATCH_SIZE , shuffle = True , num_workers = 0 ) for x in dataset_names } dataset_sizes = { x : len ( image_dataset [ x ]) for x in dataset_names } \u5f00\u59cb\u914d\u7f6e\u7f51\u7edc\uff0c\u7531\u4e8eImageNet\u662f\u8bc6\u522b1000\u4e2a\u7269\u4f53\uff0c\u6211\u4eec\u7684\u72d7\u7684\u5206\u7c7b\u4e00\u5171\u53ea\u6709120\uff0c\u6240\u4ee5\u9700\u8981\u5bf9\u6a21\u578b\u7684\u6700\u540e\u4e00\u5c42\u5168\u8fde\u63a5\u5c42\u8fdb\u884c\u5fae\u8c03\uff0c\u5c06\u8f93\u51fa\u4ece1000\u6539\u4e3a120\uff1a model_ft = models . resnet50 ( pretrained = True ) # \u8fd9\u91cc\u81ea\u52a8\u4e0b\u8f7d\u5b98\u65b9\u7684\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u5e76\u4e14 # \u5c06\u6240\u6709\u7684\u53c2\u6570\u5c42\u8fdb\u884c\u51bb\u7ed3 for param in model_ft . parameters (): param . requires_grad = False # \u8fd9\u91cc\u6253\u5370\u4e0b\u5168\u8fde\u63a5\u5c42\u7684\u4fe1\u606f print ( model_ft . fc ) num_fc_ftr = model_ft . fc . in_features #\u83b7\u53d6\u5230fc\u5c42\u7684\u8f93\u5165 model_ft . fc = nn . Linear ( num_fc_ftr , len ( breeds )) # \u5b9a\u4e49\u4e00\u4e2a\u65b0\u7684FC\u5c42 model_ft = model_ft . to ( DEVICE ) # \u653e\u5230\u8bbe\u5907\u4e2d print ( model_ft ) # \u6700\u540e\u518d\u6253\u5370\u4e00\u4e0b\u65b0\u7684\u6a21\u578b Linear(in_features=2048, out_features=1000, bias=True) ResNet( (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False) (layer1): Sequential( (0): Bottleneck( (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (downsample): Sequential( (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): Bottleneck( (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (2): Bottleneck( (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) ) (layer2): Sequential( (0): Bottleneck( (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (downsample): Sequential( (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): Bottleneck( (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (2): Bottleneck( (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (3): Bottleneck( (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) ) (layer3): Sequential( (0): Bottleneck( (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (downsample): Sequential( (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (2): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (3): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (4): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (5): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) ) (layer4): Sequential( (0): Bottleneck( (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (downsample): Sequential( (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): Bottleneck( (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (2): Bottleneck( (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) ) (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0) (fc): Linear(in_features=2048, out_features=120, bias=True) ) \u8bbe\u7f6e\u8bad\u7ec3\u53c2\u6570\uff1a criterion = nn . CrossEntropyLoss () optimizer = torch . optim . Adam ([ { 'params' : model_ft . fc . parameters ()} ], lr = 0.001 ) #\u6307\u5b9a \u65b0\u52a0\u7684fc\u5c42\u7684\u5b66\u4e60\u7387 \u5b9a\u4e49\u8bad\u7ec3\u51fd\u6570\uff1a def train ( model , device , train_loader , epoch ): model . train () for batch_idx , data in enumerate ( train_loader ): x , y = data x = x . to ( device ) y = y . to ( device ) optimizer . zero_grad () y_hat = model ( x ) loss = criterion ( y_hat , y ) loss . backward () optimizer . step () print ( 'Train Epoch: {} \\t Loss: {:.6f}' . format ( epoch , loss . item ())) \u5b9a\u4e49\u6d4b\u8bd5\u51fd\u6570\uff1a def test ( model , device , test_loader ): model . eval () test_loss = 0 correct = 0 with torch . no_grad (): for i , data in enumerate ( test_loader ): x , y = data x = x . to ( device ) y = y . to ( device ) optimizer . zero_grad () y_hat = model ( x ) test_loss += criterion ( y_hat , y ) . item () # sum up batch loss pred = y_hat . max ( 1 , keepdim = True )[ 1 ] # get the index of the max log-probability correct += pred . eq ( y . view_as ( pred )) . sum () . item () test_loss /= len ( test_loader . dataset ) print ( ' \\n Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%) \\n ' . format ( test_loss , correct , len ( val_dataset ), 100. * correct / len ( val_dataset ))) \u8bad\u7ec39\u6b21\uff0c\u770b\u770b\u6548\u679c\uff1a for epoch in range ( 1 , 10 ): % time train ( model = model_ft , device = DEVICE , train_loader = image_dataloader [ \"train\" ], epoch = epoch ) test ( model = model_ft , device = DEVICE , test_loader = image_dataloader [ \"valid\" ]) Train Epoch: 1 Loss: 2.775527 Wall time: 1min 13s Test set: Average loss: 0.0079, Accuracy: 700/1023 (68%) Train Epoch: 2 Loss: 1.965775 Wall time: 56.5 s Test set: Average loss: 0.0047, Accuracy: 779/1023 (76%) Train Epoch: 3 Loss: 1.798122 Wall time: 56.4 s Test set: Average loss: 0.0037, Accuracy: 790/1023 (77%) Train Epoch: 4 Loss: 1.596331 Wall time: 57.1 s Test set: Average loss: 0.0031, Accuracy: 814/1023 (80%) Train Epoch: 5 Loss: 1.502677 Wall time: 56.3 s Test set: Average loss: 0.0029, Accuracy: 822/1023 (80%) Train Epoch: 6 Loss: 1.430908 Wall time: 56.4 s Test set: Average loss: 0.0028, Accuracy: 815/1023 (80%) Train Epoch: 7 Loss: 1.466642 Wall time: 56.4 s Test set: Average loss: 0.0028, Accuracy: 824/1023 (81%) Train Epoch: 8 Loss: 1.368286 Wall time: 56.9 s Test set: Average loss: 0.0025, Accuracy: 840/1023 (82%) Train Epoch: 9 Loss: 1.348546 Wall time: 56.9 s Test set: Average loss: 0.0027, Accuracy: 814/1023 (80%) \u6211\u4eec\u770b\u5230\u53ea\u8bad\u7ec3\u4e869\u6b21\u5c31\u8fbe\u5230\u4e8680%\u7684\u51c6\u786e\u7387\uff0c\u6548\u679c\u8fd8\u662f\u53ef\u4ee5\u7684\u3002 \u4f46\u662f\u6bcf\u6b21\u8bad\u7ec3\u90fd\u9700\u8981\u5c06\u4e00\u5f20\u56fe\u7247\u5728\u5168\u90e8\u7f51\u7edc\u4e2d\u8fdb\u884c\u8ba1\u7b97\uff0c\u800c\u4e14\u8ba1\u7b97\u7684\u7ed3\u679c\u6bcf\u6b21\u90fd\u662f\u4e00\u6837\u7684\uff0c\u8fd9\u6837\u6d6a\u8d39\u4e86\u5f88\u591a\u8ba1\u7b97\u7684\u8d44\u6e90\u3002 \u4e0b\u9762\u6211\u4eec\u5c31\u5c06\u8fd9\u4e9b\u4e0d\u8fdb\u884c\u53cd\u5411\u4f20\u64ad\u6216\u8005\u8bf4\u4e0d\u66f4\u65b0\u7f51\u7edc\u6743\u91cd\u53c2\u6570\u5c42\u7684\u8ba1\u7b97\u7ed3\u679c\u4fdd\u5b58\u4e0b\u6765\uff0c\u8fd9\u6837\u6211\u4eec\u4ee5\u540e\u4f7f\u7528\u7684\u65f6\u5019\u5c31\u53ef\u4ee5\u76f4\u63a5\u5c06\u8fd9\u4e9b\u7ed3\u679c\u8f93\u5165\u5230FC\u5c42\u6216\u8005\u4ee5\u8fd9\u4e9b\u7ed3\u679c\u6784\u5efa\u65b0\u7684\u7f51\u7edc\u5c42\uff0c\u7701\u53bb\u4e86\u8ba1\u7b97\u7684\u65f6\u95f4\uff0c\u5e76\u4e14\u8fd9\u6837\u5982\u679c\u53ea\u8bad\u7ec3\u5168\u8fde\u63a5\u5c42\uff0cCPU\u5c31\u53ef\u4ee5\u5b8c\u6210\u4e86\u3002","title":"4.1.3 \u5fae\u8c03\u5b9e\u4f8b"},{"location":"tutorial/chapter04_advanced/4_1_fine-tuning/#414","text":"PyTorch\u8bba\u575b \u4e2d\u8bf4\u5230\u53ef\u4ee5\u4f7f\u7528\u81ea\u5df1\u624b\u52a8\u5b9e\u73b0\u6a21\u578b\u4e2d\u7684forward\u53c2\u6570\uff0c\u8fd9\u6837\u770b\u8d77\u6765\u662f\u5f88\u7b80\u4fbf\u7684\uff0c\u4f46\u662f\u8fd9\u6837\u5904\u7406\u8d77\u6765\u5f88\u9ebb\u70e6\uff0c\u4e0d\u5efa\u8bae\u8fd9\u6837\u4f7f\u7528\u3002 \u8fd9\u91cc\u6211\u4eec\u5c31\u8981\u91c7\u7528PyTorch\u6bd4\u8f83\u9ad8\u7ea7\u7684API\uff0chook\u6765\u5904\u7406\u4e86\uff0c\u6211\u4eec\u8981\u5148\u5b9a\u4e49\u4e00\u4e2ahook\u51fd\u6570 in_list = [] # \u8fd9\u91cc\u5b58\u653e\u6240\u6709\u7684\u8f93\u51fa def hook ( module , input , output ): #input\u662f\u4e00\u4e2atuple\u4ee3\u8868\u987a\u5e8f\u4ee3\u8868\u6bcf\u4e00\u4e2a\u8f93\u5165\u9879\uff0c\u6211\u4eec\u8fd9\u91cc\u53ea\u6709\u4e00\u9879\uff0c\u6240\u4ee5\u76f4\u63a5\u83b7\u53d6 #\u9700\u8981\u5168\u90e8\u7684\u53c2\u6570\u4fe1\u606f\u53ef\u4ee5\u4f7f\u7528\u8fd9\u4e2a\u6253\u5370 #for val in input: # print(\"input val:\",val) for i in range ( input [ 0 ] . size ( 0 )): in_list . append ( input [ 0 ][ i ] . cpu () . numpy ()) \u5728\u76f8\u5e94\u7684\u5c42\u6ce8\u518chook\u51fd\u6570\uff0c\u4fdd\u8bc1\u51fd\u6570\u80fd\u591f\u6b63\u5e38\u5de5\u4f5c\uff0c\u6211\u4eec\u8fd9\u91cc\u76f4\u63a5hook \u5168\u8fde\u63a5\u5c42\u524d\u9762\u7684pool\u5c42\uff0c\u83b7\u53d6pool\u5c42\u7684\u8f93\u5165\u6570\u636e\uff0c\u8fd9\u6837\u4f1a\u83b7\u5f97\u66f4\u591a\u7684\u7279\u5f81\uff1a model_ft . avgpool . register_forward_hook ( hook ) <torch.utils.hooks.RemovableHandle at 0x24812a5e978> \u5f00\u59cb\u83b7\u53d6\u8f93\u51fa\uff0c\u8fd9\u91cc\u6211\u4eec\u56e0\u4e3a\u4e0d\u9700\u8981\u53cd\u5411\u4f20\u64ad\uff0c\u6240\u4ee5\u76f4\u63a5\u53ef\u4ee5\u4f7f\u7528no_grad\u5d4c\u5957\uff1a %% time with torch . no_grad (): for batch_idx , data in enumerate ( image_dataloader [ \"train\" ]): x , y = data x = x . to ( DEVICE ) y = y . to ( DEVICE ) y_hat = model_ft ( x ) Wall time: 1min 23s features = np . array ( in_list ) np . save ( \"features\" , features ) \u8fd9\u6837\u518d\u8bad\u7ec3\u65f6\u6211\u4eec\u53ea\u9700\u5c06\u8fd9\u4e2a\u6570\u7ec4\u8bfb\u51fa\u6765\uff0c\u7136\u540e\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528\u8fd9\u4e2a\u6570\u7ec4\u518d\u8f93\u5165\u5230linear\u6216\u8005\u6211\u4eec\u524d\u9762\u8bb2\u5230\u7684sigmod\u5c42\u5c31\u53ef\u4ee5\u4e86\u3002 \u6211\u4eec\u5728\u8fd9\u91cc\u5728pool\u5c42\u524d\u83b7\u53d6\u4e86\u66f4\u591a\u7684\u7279\u5f81\uff0c\u53ef\u4ee5\u5c06\u8fd9\u4e9b\u7279\u5f81\u4f7f\u7528\u66f4\u9ad8\u7ea7\u7684\u5206\u7c7b\u5668\uff0c\u4f8b\u5982SVM\uff0c\u6811\u578b\u7684\u5206\u7c7b\u5668\u8fdb\u884c\u5206\u7c7b\u3002 \u4ee5\u4e0a\u5c31\u662f\u9488\u5bf9\u4e8e\u8ba1\u7b97\u673a\u89c6\u89c9\u65b9\u5411\u7684\u5fae\u8c03\u4ecb\u7ecd\uff0c\u5bf9\u4e8eNLP\u65b9\u5411\u6765\u8bb2fastai\u7684\u521b\u59cb\u4ebaJeremy \u5728\u4eca\u5e74\u51fa\u53d1\u5e03\u4e86ULMFiT\u53ef\u4ee5\u4f5c\u4e3a\u5f88\u597d\u7684\u53c2\u8003\u3002 \u5177\u4f53\u8bf7\u770b\u8fd9\u4e2a\u94fe\u63a5\uff1a Universal Language Model Fine-tuning for Text Classification","title":"4.1.4 \u56fa\u5b9a\u5c42\u7684\u5411\u91cf\u5bfc\u51fa"},{"location":"tutorial/chapter04_advanced/4_2_1_visdom/","text":"import torch import math import numpy as np from visdom import Visdom import time torch . __version__ '1.0.0' 4.2.1 \u4f7f\u7528Visdom\u5728 PyTorch \u4e2d\u8fdb\u884c\u53ef\u89c6\u5316 \u00b6 Visdom\u662fFacebook\u57282017\u5e74\u53d1\u5e03\u7684\u4e00\u6b3e\u9488\u5bf9PyTorch\u7684\u53ef\u89c6\u5316\u5de5\u5177\u3002 \u5b98\u7f51 ,visdom\u7531\u4e8e\u5176\u529f\u80fd\u7b80\u5355\uff0c\u4e00\u822c\u4f1a\u88ab\u5b9a\u4e49\u4e3a\u670d\u52a1\u5668\u7aef\u7684matplot\uff0c\u4e5f\u5c31\u662f\u8bf4\u6211\u4eec\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528python\u7684\u63a7\u5236\u53f0\u6a21\u5f0f\u8fdb\u884c\u5f00\u53d1\u5e76\u5728\u670d\u52a1\u5668\u4e0a\u6267\u884c\uff0c\u5c06\u4e00\u4e9b\u53ef\u89c6\u5316\u7684\u6570\u636e\u4f20\u9001\u5230Visdom\u670d\u52a1\u4e0a\uff0c\u901a\u8fc7Visdom\u670d\u52a1\u8fdb\u884c\u53ef\u89c6\u5316 \u5b89\u88c5 \u00b6 Visdom\u7684\u5b89\u88c5\u5f88\u7b80\u5355\uff0c\u76f4\u63a5\u4f7f\u7528\u547d\u4ee4 pip install visdom \u5b89\u88c5\u5373\u53ef\u3002 \u5728\u5b89\u88c5\u5b8c\u6210\u540e\uff0c\u4f7f\u7528\u547d\u4ee4 python -m visdom.server \u5728\u672c\u5730\u542f\u52a8\u670d\u52a1\u5668\uff0c\u542f\u52a8\u540e\u4f1a\u63d0\u793a It's Alive! You can navigate to http://localhost:8097 \u8fd9\u5c31\u8bf4\u660e\u670d\u52a1\u5df2\u7ecf\u53ef\u7528\uff0c\u6211\u4eec\u6253\u5f00\u6d4f\u89c8\u5668\uff0c\u8f93\u5165 http://localhost:8097 \u5373\u53ef\u770b\u5230\u9875\u9762\u3002 \u7aef\u53e38097\u662f\u9ed8\u8ba4\u7684\u7aef\u53e3\u53ef\u4ee5\u5728\u542f\u52a8\u547d\u4ee4\u540e\u52a0 -port \u53c2\u6570\u6307\u5b9a\u7aef\u53e3\uff0c\u5e38\u7528\u7684\u53c2\u6570\u8fd8\u6709 --hostname \uff0c -base_url \u7b49 \u5751 \u00b6 Visdom\u7684\u670d\u52a1\u5728\u542f\u52a8\u65f6\u4f1a\u81ea\u52a8\u4e0b\u8f7d\u4e00\u4e9b\u9759\u6001\u6587\u4ef6\uff0c\u8fd9\u91cc\u5751\u5c31\u6765\u4e86\uff0c\u56e0\u4e3a\u67d0\u4e9b\u65e0\u6cd5\u63cf\u8ff0\u7684\u539f\u56e0\uff0c\u5bfc\u81f4\u4e0b\u8f7d\u4f1a\u5931\u8d25\uff0c\u6bd4\u5982\u7c7b\u4f3c\u8fd9\u6837\u7684\u63d0\u793a ERROR:root:Error 404 while downloading https://unpkg.com/layout-bin-packer@1.4.0 \u5c31\u8bf4\u660e\u9759\u6001\u6587\u4ef6\u6ca1\u6709\u4e0b\u8f7d\u5b8c\u5168\uff0c\u8fd9\u6837\u6709\u53ef\u80fd\u5c31\u4f1a\u6253\u4e0d\u5f00\u6216\u8005\u9875\u9762\u4e2d\u6ca1\u6709\u83dc\u5355\u680f\uff0c\u90a3\u4e48\u9700\u8981\u624b\u52a8\u8fdb\u884c\u4e0b\u8f7d\uff0c\u8fd9\u91cc\u6211\u6253\u5305\u4e86\u4e00\u4efd\u6b63\u5e38\u7684\u9759\u6001\u6587\u4ef6\uff0c\u76f4\u63a5\u590d\u5236\u5230 Lib\\site-packages\\visdom \u4e2d\u5373\u53ef\u3002 \u5982\u679c\u4e0d\u77e5\u9053conda\u7684\u73af\u5883\u76ee\u5f55\u5728\u54ea\u91cc\uff0c\u53ef\u4ee5\u4f7f\u7528 conda env list \u67e5\u770b\u3002 \u611f\u8c22CSDN\u7684\u4f19\u4f34\u63d0\u4f9b\u7684\u7f3a\u5931\u6587\u4ef6\uff0c\u539f\u6587 \u8fd9\u91cc \u57fa\u672c\u6982\u5ff5 \u00b6 Environments \u00b6 Environments\u7684\u4f5c\u7528\u662f\u5bf9\u53ef\u89c6\u5316\u533a\u57df\u8fdb\u884c\u5206\u533a\uff0c\u6bcf\u4e2a\u7528\u6237\u90fd\u4f1a\u6709\u4e00\u4e2a\u53eb\u505amain\u7684\u9ed8\u8ba4\u5206\u533a\uff0c\u5982\u56fe\u6240\u793a: \u5728\u7a0b\u5e8f\u6307\u5b9a\u7684\u60c5\u51b5\u4e0b\uff0c\u9ed8\u8ba4\u7684\u56fe\u8868\u90fd\u4f1a\u653e\u5230\u8fd9\u91cc\u9762\u3002 Panes \u00b6 Panes\u662f\u4f5c\u4e3a\u6bcf\u4e00\u4e2a\u53ef\u89c6\u5316\u56fe\u8868\u7684\u5bb9\u5668\uff0c\u53ef\u4ee5\u4f7f\u7528\u751f\u6210\u7684\u56fe\u8868\uff0c\u56fe\u7247\uff0c\u6587\u672c\u8fdb\u884c\u586b\u5145\uff0c\u6211\u4eec\u53ef\u4ee5\u5bf9Panes\u8fdb\u884c\u62d6\u653e\uff0c\u5220\u9664\uff0c\u8c03\u6574\u5927\u5c0f\u548c\u9500\u6bc1\u7b49\u64cd\u4f5c\uff1a Panes\u548cEnvironments\u662f\u4e00\u5bf9\u591a\u7684\u5173\u7cfb\uff0c\u5373\u4e00\u4e2aEnvironments\u53ef\u4ee5\u5305\u542b\u591a\u4e2aPanes\u3002 VIEW \u00b6 \u5728\u5bf9Panes\u8fdb\u884c\u8c03\u6574\u540e\uff0c\u53ef\u4ee5\u901a\u8fc7VIEW\u5bf9\u72b6\u6001\u8fdb\u884c\u7ba1\u7406\uff1a \u53ef\u89c6\u5316\u63a5\u53e3 \u00b6 Visdom\u662f\u7531Plotly \u63d0\u4f9b\u7684\u53ef\u89c6\u5316\u652f\u6301\uff0c\u6240\u4ee5\u63d0\u4f9b\u4e00\u4e0b\u53ef\u89c6\u5316\u7684\u63a5\u53e3: - vis.scatter : 2D \u6216 3D \u6563\u70b9\u56fe - vis.line : \u7ebf\u56fe - vis.stem : \u830e\u53f6\u56fe - vis.heatmap : \u70ed\u529b\u56fe - vis.bar : \u6761\u5f62\u56fe - vis.histogram: \u76f4\u65b9\u56fe - vis.boxplot : \u7bb1\u578b\u56fe - vis.surf : \u8868\u9762\u56fe - vis.contour : \u8f6e\u5ed3\u56fe - vis.quiver : \u7ed8\u51fa\u4e8c\u7ef4\u77e2\u91cf\u573a - vis.image : \u56fe\u7247 - vis.text : \u6587\u672c - vis.mesh : \u7f51\u683c\u56fe - vis.save : \u5e8f\u5217\u5316\u72b6\u6001 \u4f7f\u7528 \u00b6 \u7ed8\u5236\u7b80\u5355\u7684\u56fe\u5f62 \u00b6 \u8fd9\u91cc\u6211\u4eec\u4f7f\u7528\u5b98\u65b9\u7684DEMO\u6765\u505a\u6837\u4f8b\uff1a env = Visdom () assert env . check_connection () #\u6d4b\u8bd5\u4e00\u4e0b\u94fe\u63a5\uff0c\u94fe\u63a5\u9519\u8bef\u7684\u8bdd\u4f1a\u62a5\u9519 \u8fd9\u91cc\u751f\u6210sin\u548ccos\u4e24\u6761\u66f2\u7ebf\u6570\u636e\uff1a Y = np . linspace ( 0 , 2 * math . pi , 70 ) X = np . column_stack (( np . sin ( Y ), np . cos ( Y ))) \u4f7f\u7528\u830e\u53f6\u56fe\u5c55\u793a\uff1a env . stem ( X = X , Y = Y , opts = dict ( legend = [ 'Sine' , 'Cosine' ]) ) 'window_36f18bc34b4992' \u53ef\u4ee5\u901a\u8fc7env\u53c2\u6570\u6307\u5b9aEnvironments\uff0c\u5982\u679c\u540d\u79f0\u5305\u542b\u4e86\u4e0b\u5212\u7ebf _ \u90a3\u4e48visdom\u4f1a\u8ddf\u6839\u636e\u4e0b\u5212\u7ebf\u5206\u5272\u5e76\u81ea\u52a8\u5206\u7ec4\uff1a envtest = Visdom ( env = 'test_mesh' ) assert envtest . check_connection () \u751f\u6210\u4e00\u4e2a\u7f51\u683c\u56fe\uff1a x = [ 0 , 0 , 1 , 1 , 0 , 0 , 1 , 1 ] y = [ 0 , 1 , 1 , 0 , 0 , 1 , 1 , 0 ] z = [ 0 , 0 , 0 , 0 , 1 , 1 , 1 , 1 ] X = np . c_ [ x , y , z ] i = [ 7 , 0 , 0 , 0 , 4 , 4 , 6 , 6 , 4 , 0 , 3 , 2 ] j = [ 3 , 4 , 1 , 2 , 5 , 6 , 5 , 2 , 0 , 1 , 6 , 3 ] k = [ 0 , 7 , 2 , 3 , 6 , 7 , 1 , 1 , 5 , 5 , 7 , 6 ] Y = np . c_ [ i , j , k ] envtest . mesh ( X = X , Y = Y , opts = dict ( opacity = 0.5 )) 'window_36f18bc533e990' \u66f4\u65b0\u635f\u5931\u51fd\u6570 \u00b6 \u5728\u8bad\u7ec3\u7684\u65f6\u5019\u6211\u4eec\u6bcf\u4e00\u6279\u6b21\u90fd\u4f1a\u6253\u5370\u4e00\u4e0b\u8bad\u7ec3\u7684\u635f\u5931\u548c\u6d4b\u8bd5\u7684\u51c6\u786e\u7387\uff0c\u8fd9\u6837\u5c55\u793a\u7684\u56fe\u8868\u662f\u9700\u8981\u52a8\u6001\u589e\u52a0\u6570\u636e\u7684\uff0c\u4e0b\u9762\u6211\u4eec\u6765\u6a21\u62df\u4e00\u4e0b\u8fd9\u79cd\u60c5\u51b5\uff1a x , y = 0 , 0 env2 = Visdom () pane1 = env2 . line ( X = np . array ([ x ]), Y = np . array ([ y ]), opts = dict ( title = 'dynamic data' )) for i in range ( 10 ): time . sleep ( 1 ) #\u6bcf\u9694\u4e00\u79d2\u949f\u6253\u5370\u4e00\u6b21\u6570\u636e x += i y = ( y + i ) * 1.5 print ( x , y ) env2 . line ( X = np . array ([ x ]), Y = np . array ([ y ]), win = pane1 , #win\u53c2\u6570\u786e\u8ba4\u4f7f\u7528\u54ea\u4e00\u4e2apane update = 'append' ) #\u6211\u4eec\u505a\u7684\u52a8\u4f5c\u662f\u8ffd\u52a0\uff0c\u9664\u4e86\u8ffd\u52a0\u610f\u5916\u8fd8\u6709\u5176\u4ed6\u65b9\u5f0f\uff0c\u8fd9\u91cc\u6211\u4eec\u4e0d\u505a\u4ecb\u7ecd\u4e86 0 0.0 1 1.5 3 5.25 6 12.375 10 24.5625 15 44.34375 21 75.515625 28 123.7734375 36 197.66015625 45 309.990234375 \u5728\u8fd0\u884c\u5b8c\u4e0a\u8ff0\u7a0b\u5e8f\u65f6\uff0c\u5207\u6362\u5230visdom\uff0c\u770b\u770b\u6548\u679c\u5427\ud83d\ude42 visdom\u7684\u57fa\u672c\u7528\u6cd5\u4ecb\u7ecd\u5b8c\u6bd5\uff0c\u4e0b\u4e00\u8282\u4ecb\u7ecd\u66f4\u52a0\u5f3a\u5927\u7684 tensorboardx\u3002","title":"Visdom"},{"location":"tutorial/chapter04_advanced/4_2_1_visdom/#421-visdom-pytorch","text":"Visdom\u662fFacebook\u57282017\u5e74\u53d1\u5e03\u7684\u4e00\u6b3e\u9488\u5bf9PyTorch\u7684\u53ef\u89c6\u5316\u5de5\u5177\u3002 \u5b98\u7f51 ,visdom\u7531\u4e8e\u5176\u529f\u80fd\u7b80\u5355\uff0c\u4e00\u822c\u4f1a\u88ab\u5b9a\u4e49\u4e3a\u670d\u52a1\u5668\u7aef\u7684matplot\uff0c\u4e5f\u5c31\u662f\u8bf4\u6211\u4eec\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528python\u7684\u63a7\u5236\u53f0\u6a21\u5f0f\u8fdb\u884c\u5f00\u53d1\u5e76\u5728\u670d\u52a1\u5668\u4e0a\u6267\u884c\uff0c\u5c06\u4e00\u4e9b\u53ef\u89c6\u5316\u7684\u6570\u636e\u4f20\u9001\u5230Visdom\u670d\u52a1\u4e0a\uff0c\u901a\u8fc7Visdom\u670d\u52a1\u8fdb\u884c\u53ef\u89c6\u5316","title":"4.2.1 \u4f7f\u7528Visdom\u5728 PyTorch \u4e2d\u8fdb\u884c\u53ef\u89c6\u5316"},{"location":"tutorial/chapter04_advanced/4_2_1_visdom/#_1","text":"Visdom\u7684\u5b89\u88c5\u5f88\u7b80\u5355\uff0c\u76f4\u63a5\u4f7f\u7528\u547d\u4ee4 pip install visdom \u5b89\u88c5\u5373\u53ef\u3002 \u5728\u5b89\u88c5\u5b8c\u6210\u540e\uff0c\u4f7f\u7528\u547d\u4ee4 python -m visdom.server \u5728\u672c\u5730\u542f\u52a8\u670d\u52a1\u5668\uff0c\u542f\u52a8\u540e\u4f1a\u63d0\u793a It's Alive! You can navigate to http://localhost:8097 \u8fd9\u5c31\u8bf4\u660e\u670d\u52a1\u5df2\u7ecf\u53ef\u7528\uff0c\u6211\u4eec\u6253\u5f00\u6d4f\u89c8\u5668\uff0c\u8f93\u5165 http://localhost:8097 \u5373\u53ef\u770b\u5230\u9875\u9762\u3002 \u7aef\u53e38097\u662f\u9ed8\u8ba4\u7684\u7aef\u53e3\u53ef\u4ee5\u5728\u542f\u52a8\u547d\u4ee4\u540e\u52a0 -port \u53c2\u6570\u6307\u5b9a\u7aef\u53e3\uff0c\u5e38\u7528\u7684\u53c2\u6570\u8fd8\u6709 --hostname \uff0c -base_url \u7b49","title":"\u5b89\u88c5"},{"location":"tutorial/chapter04_advanced/4_2_1_visdom/#_2","text":"Visdom\u7684\u670d\u52a1\u5728\u542f\u52a8\u65f6\u4f1a\u81ea\u52a8\u4e0b\u8f7d\u4e00\u4e9b\u9759\u6001\u6587\u4ef6\uff0c\u8fd9\u91cc\u5751\u5c31\u6765\u4e86\uff0c\u56e0\u4e3a\u67d0\u4e9b\u65e0\u6cd5\u63cf\u8ff0\u7684\u539f\u56e0\uff0c\u5bfc\u81f4\u4e0b\u8f7d\u4f1a\u5931\u8d25\uff0c\u6bd4\u5982\u7c7b\u4f3c\u8fd9\u6837\u7684\u63d0\u793a ERROR:root:Error 404 while downloading https://unpkg.com/layout-bin-packer@1.4.0 \u5c31\u8bf4\u660e\u9759\u6001\u6587\u4ef6\u6ca1\u6709\u4e0b\u8f7d\u5b8c\u5168\uff0c\u8fd9\u6837\u6709\u53ef\u80fd\u5c31\u4f1a\u6253\u4e0d\u5f00\u6216\u8005\u9875\u9762\u4e2d\u6ca1\u6709\u83dc\u5355\u680f\uff0c\u90a3\u4e48\u9700\u8981\u624b\u52a8\u8fdb\u884c\u4e0b\u8f7d\uff0c\u8fd9\u91cc\u6211\u6253\u5305\u4e86\u4e00\u4efd\u6b63\u5e38\u7684\u9759\u6001\u6587\u4ef6\uff0c\u76f4\u63a5\u590d\u5236\u5230 Lib\\site-packages\\visdom \u4e2d\u5373\u53ef\u3002 \u5982\u679c\u4e0d\u77e5\u9053conda\u7684\u73af\u5883\u76ee\u5f55\u5728\u54ea\u91cc\uff0c\u53ef\u4ee5\u4f7f\u7528 conda env list \u67e5\u770b\u3002 \u611f\u8c22CSDN\u7684\u4f19\u4f34\u63d0\u4f9b\u7684\u7f3a\u5931\u6587\u4ef6\uff0c\u539f\u6587 \u8fd9\u91cc","title":"\u5751"},{"location":"tutorial/chapter04_advanced/4_2_1_visdom/#_3","text":"","title":"\u57fa\u672c\u6982\u5ff5"},{"location":"tutorial/chapter04_advanced/4_2_1_visdom/#environments","text":"Environments\u7684\u4f5c\u7528\u662f\u5bf9\u53ef\u89c6\u5316\u533a\u57df\u8fdb\u884c\u5206\u533a\uff0c\u6bcf\u4e2a\u7528\u6237\u90fd\u4f1a\u6709\u4e00\u4e2a\u53eb\u505amain\u7684\u9ed8\u8ba4\u5206\u533a\uff0c\u5982\u56fe\u6240\u793a: \u5728\u7a0b\u5e8f\u6307\u5b9a\u7684\u60c5\u51b5\u4e0b\uff0c\u9ed8\u8ba4\u7684\u56fe\u8868\u90fd\u4f1a\u653e\u5230\u8fd9\u91cc\u9762\u3002","title":"Environments"},{"location":"tutorial/chapter04_advanced/4_2_1_visdom/#panes","text":"Panes\u662f\u4f5c\u4e3a\u6bcf\u4e00\u4e2a\u53ef\u89c6\u5316\u56fe\u8868\u7684\u5bb9\u5668\uff0c\u53ef\u4ee5\u4f7f\u7528\u751f\u6210\u7684\u56fe\u8868\uff0c\u56fe\u7247\uff0c\u6587\u672c\u8fdb\u884c\u586b\u5145\uff0c\u6211\u4eec\u53ef\u4ee5\u5bf9Panes\u8fdb\u884c\u62d6\u653e\uff0c\u5220\u9664\uff0c\u8c03\u6574\u5927\u5c0f\u548c\u9500\u6bc1\u7b49\u64cd\u4f5c\uff1a Panes\u548cEnvironments\u662f\u4e00\u5bf9\u591a\u7684\u5173\u7cfb\uff0c\u5373\u4e00\u4e2aEnvironments\u53ef\u4ee5\u5305\u542b\u591a\u4e2aPanes\u3002","title":"Panes"},{"location":"tutorial/chapter04_advanced/4_2_1_visdom/#view","text":"\u5728\u5bf9Panes\u8fdb\u884c\u8c03\u6574\u540e\uff0c\u53ef\u4ee5\u901a\u8fc7VIEW\u5bf9\u72b6\u6001\u8fdb\u884c\u7ba1\u7406\uff1a","title":"VIEW"},{"location":"tutorial/chapter04_advanced/4_2_1_visdom/#_4","text":"Visdom\u662f\u7531Plotly \u63d0\u4f9b\u7684\u53ef\u89c6\u5316\u652f\u6301\uff0c\u6240\u4ee5\u63d0\u4f9b\u4e00\u4e0b\u53ef\u89c6\u5316\u7684\u63a5\u53e3: - vis.scatter : 2D \u6216 3D \u6563\u70b9\u56fe - vis.line : \u7ebf\u56fe - vis.stem : \u830e\u53f6\u56fe - vis.heatmap : \u70ed\u529b\u56fe - vis.bar : \u6761\u5f62\u56fe - vis.histogram: \u76f4\u65b9\u56fe - vis.boxplot : \u7bb1\u578b\u56fe - vis.surf : \u8868\u9762\u56fe - vis.contour : \u8f6e\u5ed3\u56fe - vis.quiver : \u7ed8\u51fa\u4e8c\u7ef4\u77e2\u91cf\u573a - vis.image : \u56fe\u7247 - vis.text : \u6587\u672c - vis.mesh : \u7f51\u683c\u56fe - vis.save : \u5e8f\u5217\u5316\u72b6\u6001","title":"\u53ef\u89c6\u5316\u63a5\u53e3"},{"location":"tutorial/chapter04_advanced/4_2_1_visdom/#_5","text":"","title":"\u4f7f\u7528"},{"location":"tutorial/chapter04_advanced/4_2_1_visdom/#_6","text":"\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528\u5b98\u65b9\u7684DEMO\u6765\u505a\u6837\u4f8b\uff1a env = Visdom () assert env . check_connection () #\u6d4b\u8bd5\u4e00\u4e0b\u94fe\u63a5\uff0c\u94fe\u63a5\u9519\u8bef\u7684\u8bdd\u4f1a\u62a5\u9519 \u8fd9\u91cc\u751f\u6210sin\u548ccos\u4e24\u6761\u66f2\u7ebf\u6570\u636e\uff1a Y = np . linspace ( 0 , 2 * math . pi , 70 ) X = np . column_stack (( np . sin ( Y ), np . cos ( Y ))) \u4f7f\u7528\u830e\u53f6\u56fe\u5c55\u793a\uff1a env . stem ( X = X , Y = Y , opts = dict ( legend = [ 'Sine' , 'Cosine' ]) ) 'window_36f18bc34b4992' \u53ef\u4ee5\u901a\u8fc7env\u53c2\u6570\u6307\u5b9aEnvironments\uff0c\u5982\u679c\u540d\u79f0\u5305\u542b\u4e86\u4e0b\u5212\u7ebf _ \u90a3\u4e48visdom\u4f1a\u8ddf\u6839\u636e\u4e0b\u5212\u7ebf\u5206\u5272\u5e76\u81ea\u52a8\u5206\u7ec4\uff1a envtest = Visdom ( env = 'test_mesh' ) assert envtest . check_connection () \u751f\u6210\u4e00\u4e2a\u7f51\u683c\u56fe\uff1a x = [ 0 , 0 , 1 , 1 , 0 , 0 , 1 , 1 ] y = [ 0 , 1 , 1 , 0 , 0 , 1 , 1 , 0 ] z = [ 0 , 0 , 0 , 0 , 1 , 1 , 1 , 1 ] X = np . c_ [ x , y , z ] i = [ 7 , 0 , 0 , 0 , 4 , 4 , 6 , 6 , 4 , 0 , 3 , 2 ] j = [ 3 , 4 , 1 , 2 , 5 , 6 , 5 , 2 , 0 , 1 , 6 , 3 ] k = [ 0 , 7 , 2 , 3 , 6 , 7 , 1 , 1 , 5 , 5 , 7 , 6 ] Y = np . c_ [ i , j , k ] envtest . mesh ( X = X , Y = Y , opts = dict ( opacity = 0.5 )) 'window_36f18bc533e990'","title":"\u7ed8\u5236\u7b80\u5355\u7684\u56fe\u5f62"},{"location":"tutorial/chapter04_advanced/4_2_1_visdom/#_7","text":"\u5728\u8bad\u7ec3\u7684\u65f6\u5019\u6211\u4eec\u6bcf\u4e00\u6279\u6b21\u90fd\u4f1a\u6253\u5370\u4e00\u4e0b\u8bad\u7ec3\u7684\u635f\u5931\u548c\u6d4b\u8bd5\u7684\u51c6\u786e\u7387\uff0c\u8fd9\u6837\u5c55\u793a\u7684\u56fe\u8868\u662f\u9700\u8981\u52a8\u6001\u589e\u52a0\u6570\u636e\u7684\uff0c\u4e0b\u9762\u6211\u4eec\u6765\u6a21\u62df\u4e00\u4e0b\u8fd9\u79cd\u60c5\u51b5\uff1a x , y = 0 , 0 env2 = Visdom () pane1 = env2 . line ( X = np . array ([ x ]), Y = np . array ([ y ]), opts = dict ( title = 'dynamic data' )) for i in range ( 10 ): time . sleep ( 1 ) #\u6bcf\u9694\u4e00\u79d2\u949f\u6253\u5370\u4e00\u6b21\u6570\u636e x += i y = ( y + i ) * 1.5 print ( x , y ) env2 . line ( X = np . array ([ x ]), Y = np . array ([ y ]), win = pane1 , #win\u53c2\u6570\u786e\u8ba4\u4f7f\u7528\u54ea\u4e00\u4e2apane update = 'append' ) #\u6211\u4eec\u505a\u7684\u52a8\u4f5c\u662f\u8ffd\u52a0\uff0c\u9664\u4e86\u8ffd\u52a0\u610f\u5916\u8fd8\u6709\u5176\u4ed6\u65b9\u5f0f\uff0c\u8fd9\u91cc\u6211\u4eec\u4e0d\u505a\u4ecb\u7ecd\u4e86 0 0.0 1 1.5 3 5.25 6 12.375 10 24.5625 15 44.34375 21 75.515625 28 123.7734375 36 197.66015625 45 309.990234375 \u5728\u8fd0\u884c\u5b8c\u4e0a\u8ff0\u7a0b\u5e8f\u65f6\uff0c\u5207\u6362\u5230visdom\uff0c\u770b\u770b\u6548\u679c\u5427\ud83d\ude42 visdom\u7684\u57fa\u672c\u7528\u6cd5\u4ecb\u7ecd\u5b8c\u6bd5\uff0c\u4e0b\u4e00\u8282\u4ecb\u7ecd\u66f4\u52a0\u5f3a\u5927\u7684 tensorboardx\u3002","title":"\u66f4\u65b0\u635f\u5931\u51fd\u6570"},{"location":"tutorial/chapter04_advanced/4_2_2_tensorboardx/","text":"import torch import numpy as np import torch.nn as nn import torch.nn.functional as F from PIL import Image from torchvision import transforms from torchvision import models , datasets torch . __version__ '1.0.0' 4.2.2 \u4f7f\u7528Tensorboard\u5728 PyTorch \u4e2d\u8fdb\u884c\u53ef\u89c6\u5316 \u00b6 Tensorboard \u7b80\u4ecb \u00b6 Tensorboard\u662ftensorflow\u5185\u7f6e\u7684\u4e00\u4e2a\u53ef\u89c6\u5316\u5de5\u5177\uff0c\u5b83\u901a\u8fc7\u5c06tensorflow\u7a0b\u5e8f\u8f93\u51fa\u7684\u65e5\u5fd7\u6587\u4ef6\u7684\u4fe1\u606f\u53ef\u89c6\u5316\u4f7f\u5f97tensorflow\u7a0b\u5e8f\u7684\u7406\u89e3\u3001\u8c03\u8bd5\u548c\u4f18\u5316\u66f4\u52a0\u7b80\u5355\u9ad8\u6548\u3002 Tensorboard\u7684\u53ef\u89c6\u5316\u4f9d\u8d56\u4e8etensorflow\u7a0b\u5e8f\u8fd0\u884c\u8f93\u51fa\u7684\u65e5\u5fd7\u6587\u4ef6\uff0c\u56e0\u800ctensorboard\u548ctensorflow\u7a0b\u5e8f\u5728\u4e0d\u540c\u7684\u8fdb\u7a0b\u4e2d\u8fd0\u884c\u3002 TensorBoard\u7ed9\u6211\u4eec\u63d0\u4f9b\u4e86\u6781\u5176\u65b9\u4fbf\u800c\u5f3a\u5927\u7684\u53ef\u89c6\u5316\u73af\u5883\u3002\u5b83\u53ef\u4ee5\u5e2e\u52a9\u6211\u4eec\u7406\u89e3\u6574\u4e2a\u795e\u7ecf\u7f51\u7edc\u7684\u5b66\u4e60\u8fc7\u7a0b\u3001\u6570\u636e\u7684\u5206\u5e03\u3001\u6027\u80fd\u74f6\u9888\u7b49\u7b49\u3002 tensorboard\u867d\u7136\u662ftensorflow\u5185\u7f6e\u7684\u53ef\u89c6\u5316\u5de5\u5177\uff0c\u4f46\u662f\u4ed6\u4eec\u8dd1\u5728\u4e0d\u540c\u7684\u8fdb\u7a0b\u4e2d\uff0c\u6240\u4ee5Github\u4e0a\u5df2\u7ecf\u6709\u5927\u795e\u5c06tensorboard\u5e94\u7528\u5230Pytorch\u4e2d \u94fe\u63a5\u5728\u8fd9\u91cc Tensorboard \u5b89\u88c5 \u00b6 \u9996\u5148\u9700\u8981\u5b89\u88c5tensorboard pip install tensorboard \u7136\u540e\u518d\u5b89\u88c5tensorboardx pip install tensorboardx \u5b89\u88c5\u5b8c\u6210\u540e\u4e0e visdom\u4e00\u6837\u6267\u884c\u72ec\u7acb\u7684\u547d\u4ee4 tensorboard --logdir logs \u5373\u53ef\u542f\u52a8\uff0c\u9ed8\u8ba4\u7684\u7aef\u53e3\u662f 6006,\u5728\u6d4f\u89c8\u5668\u4e2d\u6253\u5f00 http://localhost:6006/ \u5373\u53ef\u770b\u5230web\u9875\u9762\u3002 \u8fd9\u91cc\u8981\u8bf4\u660e\u7684\u662f\uff0c\u5fae\u8f6f\u7684Edge\u6d4f\u89c8\u5668css\u4f1a\u65e0\u6cd5\u52a0\u8f7d\uff0c\u4f7f\u7528chrome\u6b63\u5e38\u663e\u793a\u3002 \u9875\u9762 \u00b6 \u4e0evisdom\u4e0d\u540c\uff0ctensorboard\u9488\u5bf9\u4e0d\u540c\u7684\u7c7b\u578b\u4eba\u4e3a\u7684\u533a\u5206\u591a\u4e2a\u6807\u7b7e\uff0c\u6bcf\u4e00\u4e2a\u6807\u7b7e\u9875\u9762\u4ee3\u8868\u4e0d\u540c\u7684\u7c7b\u578b\u3002 \u4e0b\u9762\u6211\u4eec\u6839\u636e\u4e0d\u540c\u7684\u9875\u9762\u529f\u80fd\u505a\u4e2a\u7b80\u5355\u7684\u4ecb\u7ecd\uff0c\u66f4\u591a\u8be6\u7ec6\u5185\u5bb9\u8bf7\u53c2\u8003\u5b98\u7f51\u3002 SCALAR \u00b6 \u5bf9\u6807\u91cf\u6570\u636e\u8fdb\u884c\u6c47\u603b\u548c\u8bb0\u5f55\uff0c\u901a\u5e38\u7528\u6765\u53ef\u89c6\u5316\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u968f\u7740\u8fed\u4ee3\u6b21\u6570\u51c6\u786e\u7387(val acc)\u3001\u635f\u5931\u503c(train/test loss)\u3001\u5b66\u4e60\u7387(learning rate)\u3001\u6bcf\u4e00\u5c42\u7684\u6743\u91cd\u548c\u504f\u7f6e\u7684\u7edf\u8ba1\u91cf(mean\u3001std\u3001max/min)\u7b49\u7684\u53d8\u5316\u66f2\u7ebf IMAGES \u00b6 \u53ef\u89c6\u5316\u5f53\u524d\u8f6e\u8bad\u7ec3\u4f7f\u7528\u7684\u8bad\u7ec3/\u6d4b\u8bd5\u56fe\u7247\u6216\u8005 feature maps GRAPHS \u00b6 \u53ef\u89c6\u5316\u8ba1\u7b97\u56fe\u7684\u7ed3\u6784\u53ca\u8ba1\u7b97\u56fe\u4e0a\u7684\u4fe1\u606f\uff0c\u901a\u5e38\u7528\u6765\u5c55\u793a\u7f51\u7edc\u7684\u7ed3\u6784 HISTOGRAMS \u00b6 \u53ef\u89c6\u5316\u5f20\u91cf\u7684\u53d6\u503c\u5206\u5e03\uff0c\u8bb0\u5f55\u53d8\u91cf\u7684\u76f4\u65b9\u56fe(\u7edf\u8ba1\u5f20\u91cf\u968f\u7740\u8fed\u4ee3\u8f6e\u6570\u7684\u53d8\u5316\u60c5\u51b5\uff09 PROJECTOR \u00b6 \u5168\u79f0Embedding Projector \u9ad8\u7ef4\u5411\u91cf\u8fdb\u884c\u53ef\u89c6\u5316 \u4f7f\u7528 \u00b6 \u5728\u4f7f\u7528\u524d\u8bf7\u5148\u53bb\u786e\u8ba4\u6267\u884c tensorboard --logdir logs \u5e76\u4fdd\u8bc1 http://localhost:6006/ \u9875\u9762\u80fd\u591f\u6b63\u5e38\u6253\u5f00 \u56fe\u50cf\u5c55\u793a \u00b6 \u9996\u5148\u4ecb\u7ecd\u6bd4\u8f83\u7b80\u5355\u7684\u529f\u80fd\uff0c\u67e5\u770b\u6211\u4eec\u8bad\u7ec3\u96c6\u548c\u6570\u636e\u96c6\u4e2d\u7684\u56fe\u50cf\uff0c\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528\u73b0\u6210\u7684\u56fe\u50cf\u4f5c\u4e3a\u5c55\u793a\u3002\u8fd9\u91cc\u4f7f\u7528wikipedia\u4e0a\u7684\u4e00\u5f20\u732b\u7684\u56fe\u7247 \u8fd9\u91cc \u5f15\u5165 tensorboardX \u5305\uff1a from tensorboardX import SummaryWriter cat_img = Image . open ( 'img/1280px-Felis_silvestris_catus_lying_on_rice_straw.jpg' ) cat_img . size (1280, 853) \u8fd9\u662f\u4e00\u5f201280x853\u7684\u56fe\uff0c\u6211\u4eec\u5148\u628a\u5979\u53d8\u6210224x224\u7684\u56fe\u7247\uff0c\u56e0\u4e3a\u540e\u9762\u8981\u4f7f\u7528\u7684\u662fvgg16\uff1a transform_224 = transforms . Compose ([ transforms . Resize ( 224 ), # \u8fd9\u91cc\u8981\u8bf4\u660e\u4e0b Scale \u5df2\u7ecf\u8fc7\u671f\u4e86\uff0c\u4f7f\u7528Resize transforms . CenterCrop ( 224 ), transforms . ToTensor (), ]) cat_img_224 = transform_224 ( cat_img ) \u5c06\u56fe\u7247\u5c55\u793a\u5728tebsorboard\u4e2d\uff1a writer = SummaryWriter ( log_dir = './logs' , comment = 'cat image' ) # \u8fd9\u91cc\u7684logs\u8981\u4e0e--logdir\u7684\u53c2\u6570\u4e00\u6837 writer . add_image ( \"cat\" , cat_img_224 ) writer . close () # \u6267\u884cclose\u7acb\u5373\u5237\u65b0\uff0c\u5426\u5219\u5c06\u6bcf120\u79d2\u81ea\u52a8\u5237\u65b0 \u6d4f\u89c8\u5668\u8bbf\u95ee http://localhost:6006/#images \u5373\u53ef\u770b\u5230\u732b\u7684\u56fe\u7247\u3002 \u66f4\u65b0\u635f\u5931\u51fd\u6570 \u00b6 \u66f4\u65b0\u635f\u5931\u51fd\u6570\u548c\u8bad\u7ec3\u6279\u6b21\u6211\u4eec\u4e0evisdom\u4e00\u6837\u4f7f\u7528\u6a21\u62df\u5c55\u793a\uff0c\u8fd9\u91cc\u7528\u5230\u7684\u662ftensorboard\u7684SCALAR\u9875\u9762\uff1a x = torch . FloatTensor ([ 100 ]) y = torch . FloatTensor ([ 500 ]) for epoch in range ( 100 ): x /= 1.5 y /= 1.5 loss = y - x with SummaryWriter ( log_dir = './logs' , comment = 'train' ) as writer : #\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528python\u7684with\u8bed\u6cd5\uff0c\u81ea\u52a8\u8c03\u7528close\u65b9\u6cd5 writer . add_histogram ( 'his/x' , x , epoch ) writer . add_histogram ( 'his/y' , y , epoch ) writer . add_scalar ( 'data/x' , x , epoch ) writer . add_scalar ( 'data/y' , y , epoch ) writer . add_scalar ( 'data/loss' , loss , epoch ) writer . add_scalars ( 'data/data_group' , { 'x' : x , 'y' : y , 'loss' : loss }, epoch ) \u6d4f\u89c8\u5668\u8bbf\u95ee http://localhost:6006/#scalars \u5373\u53ef\u770b\u5230\u56fe\u5f62\u3002 \u4f7f\u7528PROJECTOR\u5bf9\u9ad8\u7ef4\u5411\u91cf\u53ef\u89c6\u5316 \u00b6 PROJECTOR\u7684\u7684\u539f\u7406\u662f\u901a\u8fc7PCA\uff0cT-SNE\u7b49\u65b9\u6cd5\u5c06\u9ad8\u7ef4\u5411\u91cf\u6295\u5f71\u5230\u4e09\u7ef4\u5750\u6807\u7cfb\uff08\u964d\u7ef4\u5ea6\uff09\u3002Embedding Projector\u4ece\u6a21\u578b\u8fd0\u884c\u8fc7\u7a0b\u4e2d\u4fdd\u5b58\u7684checkpoint\u6587\u4ef6\u4e2d\u8bfb\u53d6\u6570\u636e\uff0c\u9ed8\u8ba4\u4f7f\u7528\u4e3b\u6210\u5206\u5206\u6790\u6cd5\uff08PCA\uff09\u5c06\u9ad8\u7ef4\u6570\u636e\u6295\u5f71\u52303D\u7a7a\u95f4\u4e2d\uff0c\u4e5f\u53ef\u4ee5\u901a\u8fc7\u8bbe\u7f6e\u8bbe\u7f6e\u9009\u62e9T-SNE\u6295\u5f71\u65b9\u6cd5\uff0c\u8fd9\u91cc\u505a\u4e00\u4e2a\u7b80\u5355\u7684\u5c55\u793a\u3002 \u6211\u4eec\u8fd8\u662f\u7528\u7b2c\u4e09\u7ae0\u7684mnist\u4ee3\u7801\uff1a BATCH_SIZE = 512 EPOCHS = 20 train_loader = torch . utils . data . DataLoader ( datasets . MNIST ( 'data' , train = True , download = True , transform = transforms . Compose ([ transforms . ToTensor (), transforms . Normalize (( 0.1307 ,), ( 0.3081 ,)) ])), batch_size = BATCH_SIZE , shuffle = True ) class ConvNet ( nn . Module ): def __init__ ( self ): super () . __init__ () # 1,28x28 self . conv1 = nn . Conv2d ( 1 , 10 , 5 ) # 10, 24x24 self . conv2 = nn . Conv2d ( 10 , 20 , 3 ) # 128, 10x10 self . fc1 = nn . Linear ( 20 * 10 * 10 , 500 ) self . fc2 = nn . Linear ( 500 , 10 ) def forward ( self , x ): in_size = x . size ( 0 ) out = self . conv1 ( x ) #24 out = F . relu ( out ) out = F . max_pool2d ( out , 2 , 2 ) #12 out = self . conv2 ( out ) #10 out = F . relu ( out ) out = out . view ( in_size , - 1 ) out = self . fc1 ( out ) out = F . relu ( out ) out = self . fc2 ( out ) out = F . log_softmax ( out , dim = 1 ) return out model = ConvNet () optimizer = torch . optim . Adam ( model . parameters ()) def train ( model , train_loader , optimizer , epoch ): n_iter = 0 model . train () for batch_idx , ( data , target ) in enumerate ( train_loader ): optimizer . zero_grad () output = model ( data ) loss = F . nll_loss ( output , target ) loss . backward () optimizer . step () if ( batch_idx + 1 ) % 30 == 0 : n_iter = n_iter + 1 print ( 'Train Epoch: {} [{}/{} ({:.0f}%)] \\t Loss: {:.6f}' . format ( epoch , batch_idx * len ( data ), len ( train_loader . dataset ), 100. * batch_idx / len ( train_loader ), loss . item ())) #\u4e3b\u8981\u589e\u52a0\u4e86\u4e00\u4e0b\u5185\u5bb9 out = torch . cat (( output . data , torch . ones ( len ( output ), 1 )), 1 ) # \u56e0\u4e3a\u662f\u6295\u5f71\u52303D\u7684\u7a7a\u95f4\uff0c\u6240\u4ee5\u6211\u4eec\u53ea\u9700\u89813\u4e2a\u7ef4\u5ea6 with SummaryWriter ( log_dir = './logs' , comment = 'mnist' ) as writer : #\u4f7f\u7528add_embedding\u65b9\u6cd5\u8fdb\u884c\u53ef\u89c6\u5316\u5c55\u793a writer . add_embedding ( out , metadata = target . data , label_img = data . data , global_step = n_iter ) \u8fd9\u91cc\u8282\u7701\u65f6\u95f4\uff0c\u53ea\u8bad\u7ec3\u4e00\u6b21\uff1a train ( model , train_loader , optimizer , 0 ) Train Epoch: 0 [14848/60000 (25%)] Loss: 0.271775 warning: Embedding dir exists, did you set global_step for add_embedding()? Train Epoch: 0 [30208/60000 (50%)] Loss: 0.175213 warning: Embedding dir exists, did you set global_step for add_embedding()? Train Epoch: 0 [45568/60000 (75%)] Loss: 0.115128 warning: Embedding dir exists, did you set global_step for add_embedding()? \u6253\u5f00 http://localhost:6006/#projector \u5373\u53ef\u770b\u5230\u6548\u679c\u3002 \u7ed8\u5236\u7f51\u7edc\u7ed3\u6784 \u00b6 \u5728pytorch\u4e2d\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528print\u76f4\u63a5\u6253\u5370\u51fa\u7f51\u7edc\u7684\u7ed3\u6784\uff0c\u4f46\u662f\u8fd9\u79cd\u65b9\u6cd5\u53ef\u89c6\u5316\u6548\u679c\u4e0d\u597d\uff0c\u8fd9\u91cc\u4f7f\u7528tensorboard\u7684GRAPHS\u6765\u5b9e\u73b0\u7f51\u7edc\u7ed3\u6784\u7684\u53ef\u89c6\u5316\u3002 \u7531\u4e8epytorch\u4f7f\u7528\u7684\u662f\u52a8\u6001\u56fe\u8ba1\u7b97\uff0c\u6240\u4ee5\u6211\u4eec\u8fd9\u91cc\u8981\u624b\u52a8\u8fdb\u884c\u4e00\u6b21\u524d\u5411\u7684\u4f20\u64ad. \u4f7f\u7528Pytorch\u5df2\u7ecf\u6784\u5efa\u597d\u7684\u6a21\u578b\u8fdb\u884c\u5c55\u793a\uff1a vgg16 = models . vgg16 ( pretrained = True ) # \u8fd9\u91cc\u4e0b\u8f7d\u9884\u8bad\u7ec3\u597d\u7684\u6a21\u578b print ( vgg16 ) # \u6253\u5370\u4e00\u4e0b\u8fd9\u4e2a\u6a21\u578b VGG( (features): Sequential( (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): ReLU(inplace) (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (3): ReLU(inplace) (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (6): ReLU(inplace) (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (8): ReLU(inplace) (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (11): ReLU(inplace) (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (13): ReLU(inplace) (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (15): ReLU(inplace) (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (18): ReLU(inplace) (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (20): ReLU(inplace) (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (22): ReLU(inplace) (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (25): ReLU(inplace) (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (27): ReLU(inplace) (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (29): ReLU(inplace) (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) ) (classifier): Sequential( (0): Linear(in_features=25088, out_features=4096, bias=True) (1): ReLU(inplace) (2): Dropout(p=0.5) (3): Linear(in_features=4096, out_features=4096, bias=True) (4): ReLU(inplace) (5): Dropout(p=0.5) (6): Linear(in_features=4096, out_features=1000, bias=True) ) ) \u5728\u524d\u5411\u4f20\u64ad\u524d\uff0c\u5148\u8981\u628a\u56fe\u7247\u505a\u4e00\u4e9b\u8c03\u6574\uff1a transform_2 = transforms . Compose ([ transforms . Resize ( 224 ), transforms . CenterCrop (( 224 , 224 )), transforms . ToTensor (), transforms . Normalize ( mean = [ 0.485 , 0.456 , 0.406 ], std = [ 0.229 , 0.224 , 0.225 ]) ]) \u4f7f\u7528\u4e0a\u4e00\u5f20\u732b\u7684\u56fe\u7247\u8fdb\u884c\u524d\u5411\u4f20\u64ad\uff1a vgg16_input = transform_2 ( cat_img )[ np . newaxis ] # \u56e0\u4e3apytorch\u7684\u662f\u5206\u6279\u6b21\u8fdb\u884c\u7684\uff0c\u6240\u4ee5\u6211\u4eec\u8fd9\u91cc\u5efa\u7acb\u4e00\u4e2a\u6279\u6b21\u4e3a1\u7684\u6570\u636e\u96c6 vgg16_input . shape torch.Size([1, 3, 224, 224]) \u5f00\u59cb\u524d\u5411\u4f20\u64ad\uff0c\u6253\u5370\u8f93\u51fa\u503c\uff1a out = vgg16 ( vgg16_input ) _ , preds = torch . max ( out . data , 1 ) label = preds . numpy ()[ 0 ] label 287 \u5c06\u7ed3\u6784\u56fe\u5728tensorboard\u8fdb\u884c\u5c55\u793a\uff1a with SummaryWriter ( log_dir = './logs' , comment = 'vgg16' ) as writer : writer . add_graph ( vgg16 , ( vgg16_input ,)) \u6253\u5f00tensorboard\u627e\u5230graphs\u5c31\u53ef\u4ee5\u770b\u5230vgg\u6a21\u578b\u5177\u4f53\u7684\u67b6\u6784\u4e86\u3002","title":"TensorBoardX"},{"location":"tutorial/chapter04_advanced/4_2_2_tensorboardx/#422-tensorboard-pytorch","text":"","title":"4.2.2 \u4f7f\u7528Tensorboard\u5728 PyTorch \u4e2d\u8fdb\u884c\u53ef\u89c6\u5316"},{"location":"tutorial/chapter04_advanced/4_2_2_tensorboardx/#tensorboard","text":"Tensorboard\u662ftensorflow\u5185\u7f6e\u7684\u4e00\u4e2a\u53ef\u89c6\u5316\u5de5\u5177\uff0c\u5b83\u901a\u8fc7\u5c06tensorflow\u7a0b\u5e8f\u8f93\u51fa\u7684\u65e5\u5fd7\u6587\u4ef6\u7684\u4fe1\u606f\u53ef\u89c6\u5316\u4f7f\u5f97tensorflow\u7a0b\u5e8f\u7684\u7406\u89e3\u3001\u8c03\u8bd5\u548c\u4f18\u5316\u66f4\u52a0\u7b80\u5355\u9ad8\u6548\u3002 Tensorboard\u7684\u53ef\u89c6\u5316\u4f9d\u8d56\u4e8etensorflow\u7a0b\u5e8f\u8fd0\u884c\u8f93\u51fa\u7684\u65e5\u5fd7\u6587\u4ef6\uff0c\u56e0\u800ctensorboard\u548ctensorflow\u7a0b\u5e8f\u5728\u4e0d\u540c\u7684\u8fdb\u7a0b\u4e2d\u8fd0\u884c\u3002 TensorBoard\u7ed9\u6211\u4eec\u63d0\u4f9b\u4e86\u6781\u5176\u65b9\u4fbf\u800c\u5f3a\u5927\u7684\u53ef\u89c6\u5316\u73af\u5883\u3002\u5b83\u53ef\u4ee5\u5e2e\u52a9\u6211\u4eec\u7406\u89e3\u6574\u4e2a\u795e\u7ecf\u7f51\u7edc\u7684\u5b66\u4e60\u8fc7\u7a0b\u3001\u6570\u636e\u7684\u5206\u5e03\u3001\u6027\u80fd\u74f6\u9888\u7b49\u7b49\u3002 tensorboard\u867d\u7136\u662ftensorflow\u5185\u7f6e\u7684\u53ef\u89c6\u5316\u5de5\u5177\uff0c\u4f46\u662f\u4ed6\u4eec\u8dd1\u5728\u4e0d\u540c\u7684\u8fdb\u7a0b\u4e2d\uff0c\u6240\u4ee5Github\u4e0a\u5df2\u7ecf\u6709\u5927\u795e\u5c06tensorboard\u5e94\u7528\u5230Pytorch\u4e2d \u94fe\u63a5\u5728\u8fd9\u91cc","title":"Tensorboard \u7b80\u4ecb"},{"location":"tutorial/chapter04_advanced/4_2_2_tensorboardx/#tensorboard_1","text":"\u9996\u5148\u9700\u8981\u5b89\u88c5tensorboard pip install tensorboard \u7136\u540e\u518d\u5b89\u88c5tensorboardx pip install tensorboardx \u5b89\u88c5\u5b8c\u6210\u540e\u4e0e visdom\u4e00\u6837\u6267\u884c\u72ec\u7acb\u7684\u547d\u4ee4 tensorboard --logdir logs \u5373\u53ef\u542f\u52a8\uff0c\u9ed8\u8ba4\u7684\u7aef\u53e3\u662f 6006,\u5728\u6d4f\u89c8\u5668\u4e2d\u6253\u5f00 http://localhost:6006/ \u5373\u53ef\u770b\u5230web\u9875\u9762\u3002 \u8fd9\u91cc\u8981\u8bf4\u660e\u7684\u662f\uff0c\u5fae\u8f6f\u7684Edge\u6d4f\u89c8\u5668css\u4f1a\u65e0\u6cd5\u52a0\u8f7d\uff0c\u4f7f\u7528chrome\u6b63\u5e38\u663e\u793a\u3002","title":"Tensorboard \u5b89\u88c5"},{"location":"tutorial/chapter04_advanced/4_2_2_tensorboardx/#_1","text":"\u4e0evisdom\u4e0d\u540c\uff0ctensorboard\u9488\u5bf9\u4e0d\u540c\u7684\u7c7b\u578b\u4eba\u4e3a\u7684\u533a\u5206\u591a\u4e2a\u6807\u7b7e\uff0c\u6bcf\u4e00\u4e2a\u6807\u7b7e\u9875\u9762\u4ee3\u8868\u4e0d\u540c\u7684\u7c7b\u578b\u3002 \u4e0b\u9762\u6211\u4eec\u6839\u636e\u4e0d\u540c\u7684\u9875\u9762\u529f\u80fd\u505a\u4e2a\u7b80\u5355\u7684\u4ecb\u7ecd\uff0c\u66f4\u591a\u8be6\u7ec6\u5185\u5bb9\u8bf7\u53c2\u8003\u5b98\u7f51\u3002","title":"\u9875\u9762"},{"location":"tutorial/chapter04_advanced/4_2_2_tensorboardx/#scalar","text":"\u5bf9\u6807\u91cf\u6570\u636e\u8fdb\u884c\u6c47\u603b\u548c\u8bb0\u5f55\uff0c\u901a\u5e38\u7528\u6765\u53ef\u89c6\u5316\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u968f\u7740\u8fed\u4ee3\u6b21\u6570\u51c6\u786e\u7387(val acc)\u3001\u635f\u5931\u503c(train/test loss)\u3001\u5b66\u4e60\u7387(learning rate)\u3001\u6bcf\u4e00\u5c42\u7684\u6743\u91cd\u548c\u504f\u7f6e\u7684\u7edf\u8ba1\u91cf(mean\u3001std\u3001max/min)\u7b49\u7684\u53d8\u5316\u66f2\u7ebf","title":"SCALAR"},{"location":"tutorial/chapter04_advanced/4_2_2_tensorboardx/#images","text":"\u53ef\u89c6\u5316\u5f53\u524d\u8f6e\u8bad\u7ec3\u4f7f\u7528\u7684\u8bad\u7ec3/\u6d4b\u8bd5\u56fe\u7247\u6216\u8005 feature maps","title":"IMAGES"},{"location":"tutorial/chapter04_advanced/4_2_2_tensorboardx/#graphs","text":"\u53ef\u89c6\u5316\u8ba1\u7b97\u56fe\u7684\u7ed3\u6784\u53ca\u8ba1\u7b97\u56fe\u4e0a\u7684\u4fe1\u606f\uff0c\u901a\u5e38\u7528\u6765\u5c55\u793a\u7f51\u7edc\u7684\u7ed3\u6784","title":"GRAPHS"},{"location":"tutorial/chapter04_advanced/4_2_2_tensorboardx/#histograms","text":"\u53ef\u89c6\u5316\u5f20\u91cf\u7684\u53d6\u503c\u5206\u5e03\uff0c\u8bb0\u5f55\u53d8\u91cf\u7684\u76f4\u65b9\u56fe(\u7edf\u8ba1\u5f20\u91cf\u968f\u7740\u8fed\u4ee3\u8f6e\u6570\u7684\u53d8\u5316\u60c5\u51b5\uff09","title":"HISTOGRAMS"},{"location":"tutorial/chapter04_advanced/4_2_2_tensorboardx/#projector","text":"\u5168\u79f0Embedding Projector \u9ad8\u7ef4\u5411\u91cf\u8fdb\u884c\u53ef\u89c6\u5316","title":"PROJECTOR"},{"location":"tutorial/chapter04_advanced/4_2_2_tensorboardx/#_2","text":"\u5728\u4f7f\u7528\u524d\u8bf7\u5148\u53bb\u786e\u8ba4\u6267\u884c tensorboard --logdir logs \u5e76\u4fdd\u8bc1 http://localhost:6006/ \u9875\u9762\u80fd\u591f\u6b63\u5e38\u6253\u5f00","title":"\u4f7f\u7528"},{"location":"tutorial/chapter04_advanced/4_2_2_tensorboardx/#_3","text":"\u9996\u5148\u4ecb\u7ecd\u6bd4\u8f83\u7b80\u5355\u7684\u529f\u80fd\uff0c\u67e5\u770b\u6211\u4eec\u8bad\u7ec3\u96c6\u548c\u6570\u636e\u96c6\u4e2d\u7684\u56fe\u50cf\uff0c\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528\u73b0\u6210\u7684\u56fe\u50cf\u4f5c\u4e3a\u5c55\u793a\u3002\u8fd9\u91cc\u4f7f\u7528wikipedia\u4e0a\u7684\u4e00\u5f20\u732b\u7684\u56fe\u7247 \u8fd9\u91cc \u5f15\u5165 tensorboardX \u5305\uff1a from tensorboardX import SummaryWriter cat_img = Image . open ( 'img/1280px-Felis_silvestris_catus_lying_on_rice_straw.jpg' ) cat_img . size (1280, 853) \u8fd9\u662f\u4e00\u5f201280x853\u7684\u56fe\uff0c\u6211\u4eec\u5148\u628a\u5979\u53d8\u6210224x224\u7684\u56fe\u7247\uff0c\u56e0\u4e3a\u540e\u9762\u8981\u4f7f\u7528\u7684\u662fvgg16\uff1a transform_224 = transforms . Compose ([ transforms . Resize ( 224 ), # \u8fd9\u91cc\u8981\u8bf4\u660e\u4e0b Scale \u5df2\u7ecf\u8fc7\u671f\u4e86\uff0c\u4f7f\u7528Resize transforms . CenterCrop ( 224 ), transforms . ToTensor (), ]) cat_img_224 = transform_224 ( cat_img ) \u5c06\u56fe\u7247\u5c55\u793a\u5728tebsorboard\u4e2d\uff1a writer = SummaryWriter ( log_dir = './logs' , comment = 'cat image' ) # \u8fd9\u91cc\u7684logs\u8981\u4e0e--logdir\u7684\u53c2\u6570\u4e00\u6837 writer . add_image ( \"cat\" , cat_img_224 ) writer . close () # \u6267\u884cclose\u7acb\u5373\u5237\u65b0\uff0c\u5426\u5219\u5c06\u6bcf120\u79d2\u81ea\u52a8\u5237\u65b0 \u6d4f\u89c8\u5668\u8bbf\u95ee http://localhost:6006/#images \u5373\u53ef\u770b\u5230\u732b\u7684\u56fe\u7247\u3002","title":"\u56fe\u50cf\u5c55\u793a"},{"location":"tutorial/chapter04_advanced/4_2_2_tensorboardx/#_4","text":"\u66f4\u65b0\u635f\u5931\u51fd\u6570\u548c\u8bad\u7ec3\u6279\u6b21\u6211\u4eec\u4e0evisdom\u4e00\u6837\u4f7f\u7528\u6a21\u62df\u5c55\u793a\uff0c\u8fd9\u91cc\u7528\u5230\u7684\u662ftensorboard\u7684SCALAR\u9875\u9762\uff1a x = torch . FloatTensor ([ 100 ]) y = torch . FloatTensor ([ 500 ]) for epoch in range ( 100 ): x /= 1.5 y /= 1.5 loss = y - x with SummaryWriter ( log_dir = './logs' , comment = 'train' ) as writer : #\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528python\u7684with\u8bed\u6cd5\uff0c\u81ea\u52a8\u8c03\u7528close\u65b9\u6cd5 writer . add_histogram ( 'his/x' , x , epoch ) writer . add_histogram ( 'his/y' , y , epoch ) writer . add_scalar ( 'data/x' , x , epoch ) writer . add_scalar ( 'data/y' , y , epoch ) writer . add_scalar ( 'data/loss' , loss , epoch ) writer . add_scalars ( 'data/data_group' , { 'x' : x , 'y' : y , 'loss' : loss }, epoch ) \u6d4f\u89c8\u5668\u8bbf\u95ee http://localhost:6006/#scalars \u5373\u53ef\u770b\u5230\u56fe\u5f62\u3002","title":"\u66f4\u65b0\u635f\u5931\u51fd\u6570"},{"location":"tutorial/chapter04_advanced/4_2_2_tensorboardx/#projector_1","text":"PROJECTOR\u7684\u7684\u539f\u7406\u662f\u901a\u8fc7PCA\uff0cT-SNE\u7b49\u65b9\u6cd5\u5c06\u9ad8\u7ef4\u5411\u91cf\u6295\u5f71\u5230\u4e09\u7ef4\u5750\u6807\u7cfb\uff08\u964d\u7ef4\u5ea6\uff09\u3002Embedding Projector\u4ece\u6a21\u578b\u8fd0\u884c\u8fc7\u7a0b\u4e2d\u4fdd\u5b58\u7684checkpoint\u6587\u4ef6\u4e2d\u8bfb\u53d6\u6570\u636e\uff0c\u9ed8\u8ba4\u4f7f\u7528\u4e3b\u6210\u5206\u5206\u6790\u6cd5\uff08PCA\uff09\u5c06\u9ad8\u7ef4\u6570\u636e\u6295\u5f71\u52303D\u7a7a\u95f4\u4e2d\uff0c\u4e5f\u53ef\u4ee5\u901a\u8fc7\u8bbe\u7f6e\u8bbe\u7f6e\u9009\u62e9T-SNE\u6295\u5f71\u65b9\u6cd5\uff0c\u8fd9\u91cc\u505a\u4e00\u4e2a\u7b80\u5355\u7684\u5c55\u793a\u3002 \u6211\u4eec\u8fd8\u662f\u7528\u7b2c\u4e09\u7ae0\u7684mnist\u4ee3\u7801\uff1a BATCH_SIZE = 512 EPOCHS = 20 train_loader = torch . utils . data . DataLoader ( datasets . MNIST ( 'data' , train = True , download = True , transform = transforms . Compose ([ transforms . ToTensor (), transforms . Normalize (( 0.1307 ,), ( 0.3081 ,)) ])), batch_size = BATCH_SIZE , shuffle = True ) class ConvNet ( nn . Module ): def __init__ ( self ): super () . __init__ () # 1,28x28 self . conv1 = nn . Conv2d ( 1 , 10 , 5 ) # 10, 24x24 self . conv2 = nn . Conv2d ( 10 , 20 , 3 ) # 128, 10x10 self . fc1 = nn . Linear ( 20 * 10 * 10 , 500 ) self . fc2 = nn . Linear ( 500 , 10 ) def forward ( self , x ): in_size = x . size ( 0 ) out = self . conv1 ( x ) #24 out = F . relu ( out ) out = F . max_pool2d ( out , 2 , 2 ) #12 out = self . conv2 ( out ) #10 out = F . relu ( out ) out = out . view ( in_size , - 1 ) out = self . fc1 ( out ) out = F . relu ( out ) out = self . fc2 ( out ) out = F . log_softmax ( out , dim = 1 ) return out model = ConvNet () optimizer = torch . optim . Adam ( model . parameters ()) def train ( model , train_loader , optimizer , epoch ): n_iter = 0 model . train () for batch_idx , ( data , target ) in enumerate ( train_loader ): optimizer . zero_grad () output = model ( data ) loss = F . nll_loss ( output , target ) loss . backward () optimizer . step () if ( batch_idx + 1 ) % 30 == 0 : n_iter = n_iter + 1 print ( 'Train Epoch: {} [{}/{} ({:.0f}%)] \\t Loss: {:.6f}' . format ( epoch , batch_idx * len ( data ), len ( train_loader . dataset ), 100. * batch_idx / len ( train_loader ), loss . item ())) #\u4e3b\u8981\u589e\u52a0\u4e86\u4e00\u4e0b\u5185\u5bb9 out = torch . cat (( output . data , torch . ones ( len ( output ), 1 )), 1 ) # \u56e0\u4e3a\u662f\u6295\u5f71\u52303D\u7684\u7a7a\u95f4\uff0c\u6240\u4ee5\u6211\u4eec\u53ea\u9700\u89813\u4e2a\u7ef4\u5ea6 with SummaryWriter ( log_dir = './logs' , comment = 'mnist' ) as writer : #\u4f7f\u7528add_embedding\u65b9\u6cd5\u8fdb\u884c\u53ef\u89c6\u5316\u5c55\u793a writer . add_embedding ( out , metadata = target . data , label_img = data . data , global_step = n_iter ) \u8fd9\u91cc\u8282\u7701\u65f6\u95f4\uff0c\u53ea\u8bad\u7ec3\u4e00\u6b21\uff1a train ( model , train_loader , optimizer , 0 ) Train Epoch: 0 [14848/60000 (25%)] Loss: 0.271775 warning: Embedding dir exists, did you set global_step for add_embedding()? Train Epoch: 0 [30208/60000 (50%)] Loss: 0.175213 warning: Embedding dir exists, did you set global_step for add_embedding()? Train Epoch: 0 [45568/60000 (75%)] Loss: 0.115128 warning: Embedding dir exists, did you set global_step for add_embedding()? \u6253\u5f00 http://localhost:6006/#projector \u5373\u53ef\u770b\u5230\u6548\u679c\u3002","title":"\u4f7f\u7528PROJECTOR\u5bf9\u9ad8\u7ef4\u5411\u91cf\u53ef\u89c6\u5316"},{"location":"tutorial/chapter04_advanced/4_2_2_tensorboardx/#_5","text":"\u5728pytorch\u4e2d\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528print\u76f4\u63a5\u6253\u5370\u51fa\u7f51\u7edc\u7684\u7ed3\u6784\uff0c\u4f46\u662f\u8fd9\u79cd\u65b9\u6cd5\u53ef\u89c6\u5316\u6548\u679c\u4e0d\u597d\uff0c\u8fd9\u91cc\u4f7f\u7528tensorboard\u7684GRAPHS\u6765\u5b9e\u73b0\u7f51\u7edc\u7ed3\u6784\u7684\u53ef\u89c6\u5316\u3002 \u7531\u4e8epytorch\u4f7f\u7528\u7684\u662f\u52a8\u6001\u56fe\u8ba1\u7b97\uff0c\u6240\u4ee5\u6211\u4eec\u8fd9\u91cc\u8981\u624b\u52a8\u8fdb\u884c\u4e00\u6b21\u524d\u5411\u7684\u4f20\u64ad. \u4f7f\u7528Pytorch\u5df2\u7ecf\u6784\u5efa\u597d\u7684\u6a21\u578b\u8fdb\u884c\u5c55\u793a\uff1a vgg16 = models . vgg16 ( pretrained = True ) # \u8fd9\u91cc\u4e0b\u8f7d\u9884\u8bad\u7ec3\u597d\u7684\u6a21\u578b print ( vgg16 ) # \u6253\u5370\u4e00\u4e0b\u8fd9\u4e2a\u6a21\u578b VGG( (features): Sequential( (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): ReLU(inplace) (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (3): ReLU(inplace) (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (6): ReLU(inplace) (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (8): ReLU(inplace) (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (11): ReLU(inplace) (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (13): ReLU(inplace) (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (15): ReLU(inplace) (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (18): ReLU(inplace) (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (20): ReLU(inplace) (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (22): ReLU(inplace) (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (25): ReLU(inplace) (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (27): ReLU(inplace) (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (29): ReLU(inplace) (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) ) (classifier): Sequential( (0): Linear(in_features=25088, out_features=4096, bias=True) (1): ReLU(inplace) (2): Dropout(p=0.5) (3): Linear(in_features=4096, out_features=4096, bias=True) (4): ReLU(inplace) (5): Dropout(p=0.5) (6): Linear(in_features=4096, out_features=1000, bias=True) ) ) \u5728\u524d\u5411\u4f20\u64ad\u524d\uff0c\u5148\u8981\u628a\u56fe\u7247\u505a\u4e00\u4e9b\u8c03\u6574\uff1a transform_2 = transforms . Compose ([ transforms . Resize ( 224 ), transforms . CenterCrop (( 224 , 224 )), transforms . ToTensor (), transforms . Normalize ( mean = [ 0.485 , 0.456 , 0.406 ], std = [ 0.229 , 0.224 , 0.225 ]) ]) \u4f7f\u7528\u4e0a\u4e00\u5f20\u732b\u7684\u56fe\u7247\u8fdb\u884c\u524d\u5411\u4f20\u64ad\uff1a vgg16_input = transform_2 ( cat_img )[ np . newaxis ] # \u56e0\u4e3apytorch\u7684\u662f\u5206\u6279\u6b21\u8fdb\u884c\u7684\uff0c\u6240\u4ee5\u6211\u4eec\u8fd9\u91cc\u5efa\u7acb\u4e00\u4e2a\u6279\u6b21\u4e3a1\u7684\u6570\u636e\u96c6 vgg16_input . shape torch.Size([1, 3, 224, 224]) \u5f00\u59cb\u524d\u5411\u4f20\u64ad\uff0c\u6253\u5370\u8f93\u51fa\u503c\uff1a out = vgg16 ( vgg16_input ) _ , preds = torch . max ( out . data , 1 ) label = preds . numpy ()[ 0 ] label 287 \u5c06\u7ed3\u6784\u56fe\u5728tensorboard\u8fdb\u884c\u5c55\u793a\uff1a with SummaryWriter ( log_dir = './logs' , comment = 'vgg16' ) as writer : writer . add_graph ( vgg16 , ( vgg16_input ,)) \u6253\u5f00tensorboard\u627e\u5230graphs\u5c31\u53ef\u4ee5\u770b\u5230vgg\u6a21\u578b\u5177\u4f53\u7684\u67b6\u6784\u4e86\u3002","title":"\u7ed8\u5236\u7f51\u7edc\u7ed3\u6784"},{"location":"tutorial/chapter04_advanced/4_2_3_cnn-visualizing/","text":"% load_ext autoreload % autoreload 2 import torch import numpy as np import torch.nn as nn import torch.nn.functional as F from PIL import Image from torchvision import transforms from torchvision import models , datasets import matplotlib.pyplot as plt torch . __version__ '1.0.0' 4.2.3 \u53ef\u89c6\u5316\u7406\u89e3\u5377\u79ef\u795e\u7ecf\u7f51\u7edc \u00b6 \u5728\u4e0a\u4e00\u8282\u4e2d\u6211\u4eec\u5df2\u7ecf\u901a\u8fc7\u4e00\u4e2a\u9884\u8bad\u7ec3\u7684VGG16\u6a21\u578b\u5bf9\u4e00\u5f20\u56fe\u7247\u8fdb\u884c\u4e86\u5206\u7c7b\uff0c\u4e0b\u9762\u6211\u4eec\u7c98\u8d34\u4e0a\u4e00\u8282\u7684\u4ee3\u7801\uff1a cat_img = Image . open ( 'img/1280px-Felis_silvestris_catus_lying_on_rice_straw.jpg' ) transform_224 = transforms . Compose ([ transforms . Resize ( 224 ), transforms . CenterCrop (( 224 , 224 )), transforms . ToTensor (), transforms . Normalize ( mean = [ 0.485 , 0.456 , 0.406 ], std = [ 0.229 , 0.224 , 0.225 ]) ]) cat_img_224 = transform_224 ( cat_img ) \u4e0a\u9762\u7684\u4ee3\u7801\u662f\u6211\u4eec\u8bfb\u53d6\u4e86\u4e00\u5f20\u56fe\u7247\uff0c\u5e76\u5bf9\u56fe\u7247\u8fdb\u884c\u4e86\u4e00\u4e9b\u9884\u5904\u7406\uff0c\u4e0b\u9762\u6211\u4eec\u6765\u521b\u5efavgg16\u7684\u9884\u8bad\u7ec3\u597d\u7f51\u7edc\u6a21\u578b\uff1a net = models . vgg16 ( pretrained = True ) # \u4fee\u6539\u8fd9\u91cc\u53ef\u4ee5\u66f4\u6362\u5176\u4ed6\u4e0e\u8bad\u7ec3\u7684\u6a21\u578b inputs = cat_img_224 [ np . newaxis ] #\u8fd9\u4e24\u4e2a\u65b9\u6cd5\u90fd\u53ef\u4ee5cat_img_224[None,::] \u8fdb\u884c\u4e00\u6b21\u524d\u5411\u7684\u4f20\u64ad\uff0c\u770b\u770b\u5f97\u5230\u4e86\u4ec0\u4e48\u7ed3\u679c\uff1a out = net ( inputs ) _ , preds = torch . max ( out . data , 1 ) preds label = preds . numpy ()[ 0 ] label 287 \u6211\u4eec\u770b\u5230\u4e86\uff0c\u8fd9\u91cc\u8fd4\u56de\u7684\u662f285\uff0c\u4ee3\u7801\u51e0\u4e4e\u4e00\u6837\uff0c\u4f46\u662f\u8fd4\u56de\u7684\u7ed3\u679c\u4e0e\u4e0a\u4e00\u8282\u7684\u6837\u4f8b\u6709\u5dee\u522b\uff0c\u8fd9\u662f\u4ec0\u4e48\u539f\u56e0\u5462\uff1f \u9996\u5148\u6211\u4eec\u5148\u770b\u4e00\u4e0b\u8fd9\u4e2a\u6570\u5b57\u7684\u542b\u4e49\uff0c\u6211\u4eec\u4f7f\u7528\u7684\u662f\u901a\u8fc7imagenet\u6765\u4f5c\u4e3a\u9884\u8bad\u7ec3\u7684\u6a21\u578b\uff0cimagenet\u91cc\u9762\u67091000\u4e2a\u5206\u7c7b\uff0c\u6211\u4eec\u5982\u4f55\u53bb\u627e\u8fd9\u4e2a\u542b\u4e49\u5462\uff1f \u6709\u597d\u5fc3\u4eba\u5df2\u7ecf\u7ed9\u6211\u4eec\u51c6\u5907\u597d\u4e86 \u8fd9\u4e2a\u8fde\u63a5 \u6211\u4eec\u627e\u4e00\u4e0b 285: 'Egyptian cat', \u8bf4\u660e\u8bc6\u522b\u51fa\u4e86\u662f\u4e00\u53ea\u732b\uff0c\u79cd\u7c7b\u8fd8\u662f\u57c3\u53ca\u732b\uff0c\u5e94\u8be5\u8fd8\u662f\u6bd4\u8f83\u51c6\u786e\u7684\uff0c\u4f46\u662f\u8fd9\u5f20\u56fe\u7247\u662f\u6211\u7279\u610f\u5bfb\u627e\u7684\uff0c\u91cc\u9762\u5305\u542b\u4e86\u5f88\u591a\u9690\u85cf\u7684\u7ec6\u8282\uff0c\u8fd9\u91cc\u5c31\u4e0d\u591a\u4ecb\u7ecd\u4e86\uff0c\u5927\u5bb6\u5982\u679c\u6709\u5174\u8da3\uff0c\u53ef\u4ee5\u6362\u4e00\u4e2a\u6a21\u578b\uff0c\u6216\u8005\u4fee\u6539\u4e0btransforms\u65b9\u6cd5\uff0c\u770b\u770b\u6a21\u578b\u90fd\u4f1a\u8bc6\u522b\u51fa\u6765\u662f\u4ec0\u4e48\u7c7b\u522b\u3002 \u6ce8\uff1a\u4e0d\u540c\u7684\u9884\u8bad\u7ec3\u6743\u91cd\u4e5f\u4f1a\u51fa\u73b0\u4e0d\u540c\u7684\u7ed3\u679c\uff0c\u6211\u6d4b\u8bd5\u51fa\u73b0\u8fc7277\uff0c282\uff0c287\u7b49\u7ed3\u679c \u4e0b\u9762\u6211\u4eec\u5f00\u59cb\u8fdb\u5165\u6b63\u9898\uff0c\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u53ef\u89c6\u5316\u3002 \u80cc\u666f \u00b6 CNN\u6a21\u578b\u867d\u7136\u5728\u56fe\u50cf\u5904\u7406\u4e0a\u8868\u73b0\u51fa\u975e\u5e38\u826f\u597d\u7684\u6027\u80fd\u548c\u51c6\u786e\u6027\uff0c\u4f46\u4e00\u76f4\u4ee5\u6765\u90fd\u88ab\u8ba4\u4e3a\u662f\u4e00\u4e2a\u9ed1\u76d2\u6a21\u578b\uff0c\u4eba\u4eec\u65e0\u6cd5\u4e86\u89e3\u91cc\u9762\u7684\u5de5\u4f5c\u673a\u5236\u3002 \u9488\u5bf9\u8fd9\u4e2a\u95ee\u9898\uff0c\u7814\u7a76\u4eba\u5458\u9664\u4e86\u4ece\u7406\u8bba\u5c42\u9762\u53bb\u5bfb\u627e\u89e3\u91ca\u5916\uff0c\u4e5f\u63d0\u51fa\u4e86\u4e00\u4e9b\u53ef\u89c6\u5316\u7684\u65b9\u6cd5\u76f4\u89c2\u5730\u7406\u89e3CNN\u7684\u5185\u90e8\u673a\u7406\uff0c\u6bd5\u7adf\u773c\u89c1\u4e3a\u5b9e\uff0c\u770b\u5230\u4e86\u5927\u5bb6\u5c31\u76f8\u4fe1\u4e86\u3002 \u8fd9\u91cc\u4ecb\u7ecd\u4e24\u7c7b\u65b9\u6cd5\uff0c\u4e00\u79cd\u662f\u57fa\u4e8eDeconvolution, \u53e6\u4e00\u79cd\u5219\u662f\u57fa\u4e8e\u53cd\u5411\u4f20\u64ad\u7684\u65b9\u6cd5\u3002\u6211\u4eec\u4e3b\u8981\u4f7f\u7528\u4ee3\u7801\u5b9e\u73b0\u57fa\u4e8e\u53cd\u5411\u4f20\u64ad\u7684\u65b9\u6cd5\u7684\u53ef\u89c6\u5316\u3002 \u57fa\u4e8eDeconvolution\u7684\u65b9\u6cd5 \u00b6 Visualizing and Understanding Convolutional Networks \u4e3b\u8981\u662f\u5c06\u6fc0\u6d3b\u51fd\u6570\u7684\u7279\u5f81\u6620\u5c04\u56de\u50cf\u7d20\u7a7a\u95f4\uff0c\u6765\u63ed\u793a\u4ec0\u4e48\u6837\u7684\u8f93\u5165\u6a21\u5f0f\u80fd\u591f\u4ea7\u751f\u7279\u5b9a\u7684\u8f93\u51fa,\u56e0\u4e3a\u7f51\u7edc\u662f\u6709\u5c42\u7ea7\u5173\u7cfb\u7684\uff0c\u6240\u4ee5\u8d8a\u9760\u8fd1\u8f93\u51fa\u7684\u5c42\u7ea7\u5b66\u5230\u7684\u7279\u5f81\u8d8a\u62bd\u8c61\uff0c\u4e0e\u5b9e\u9645\u4efb\u52a1\u8d8a\u76f8\u5173\uff0c\u8fd9\u91cc\u5c31\u4e0d\u591a\u4ecb\u7ecd\u4e86\uff0c \u8fd9\u91cc \u6709\u4e00\u4e2a\u4f7f\u7528 keras\u7684\u5b9e\u73b0\uff0c\u6709\u5174\u8da3\u7684\u53ef\u4ee5\u770b\u770b\u3002 \u57fa\u4e8eBackpropagation\u7684\u65b9\u6cd5 \u00b6 \u53e6\u5916\u4e00\u7c7b\u7684\u5b9e\u73b0\u5c31\u662f\u57fa\u4e8eBackpropagation\u7684\u65b9\u6cd5\uff0c\u8fd9\u91cc\u6211\u4eec\u4e3b\u8981\u8fdb\u884c\u4ecb\u7ecd\uff0c\u5728\u4ecb\u7ecd\u4e4b\u524d\uff0c\u6211\u4eec\u9996\u5148\u8981\u5f15\u7528\u4e00\u4e0b\u522b\u4eba\u5199\u7684\u4ee3\u7801 pytorch-cnn-visualizations ,\u5c06\u8fd9\u4e2a\u4ee3\u7801\u7684src\u76ee\u5f55\u653e\u5230\u4e0e\u8fd9\u4e2anotebook\u540c\u7ea7\u522b\u76ee\u5f55\u4e0b\uff0c\u6211\u4eec\u540e\u9762\u4f1a\u76f4\u63a5\u8c03\u7528\u4ed6\u7684\u4ee3\u7801\u8fdb\u884c\u6f14\u793a\u64cd\u4f5c\u3002 \u9996\u5148\uff0c\u6211\u4eec\u505a\u4e00\u4e9b\u51c6\u5907\u5de5\u4f5c\uff1a import sys sys . path . insert ( 0 , './src/' ) def rgb2gray ( rgb ): return np . dot ( rgb [ ... ,: 3 ], [ 0.299 , 0.587 , 0.114 ]) def rescale_grads ( map , gradtype = \"all\" ): if ( gradtype == \"pos\" ): map = ( np . maximum ( 0 , map ) / map . max ()) elif gradtype == \"neg\" : map = ( np . maximum ( 0 , - map ) / - map . min ()) else : map = map - map . min () map /= map . max () return map Guided-Backpropagation \u00b6 \u8fd9\u4e2a\u65b9\u6cd5\u6765\u81ea\u4e8eICLR-2015 \u7684\u6587\u7ae0 \u300aStriving for Simplicity: The All Convolutional Net\u300b \uff0c\u6587\u4e2d\u63d0\u51fa\u4e86\u4f7f\u7528stride convolution \u66ff\u4ee3pooling \u64cd\u4f5c\uff0c\u8fd9\u6837\u6574\u4e2a\u7ed3\u6784\u90fd\u53ea\u6709\u5377\u79ef\u64cd\u4f5c\u3002\u4f5c\u8005\u4e3a\u4e86\u7814\u7a76\u8fd9\u79cd\u7ed3\u6784\u7684\u6709\u6548\u6027\uff0c\u63d0\u51fa\u4e86guided-backpropagation\u7684\u65b9\u6cd5\u3002 \u5927\u81f4\u7684\u65b9\u6cd5\u4e3a\uff1a\u9009\u62e9\u67d0\u4e00\u79cd\u8f93\u51fa\u6a21\u5f0f\uff0c\u7136\u540e\u901a\u8fc7\u53cd\u5411\u4f20\u64ad\u8ba1\u7b97\u8f93\u51fa\u5bf9\u8f93\u5165\u7684\u68af\u5ea6\u3002\u8fd9\u79cd\u65b9\u5f0f\u4e0e\u4e0a\u4e00\u79cddeconvnet\u7684\u65b9\u5f0f\u7684\u552f\u4e00\u533a\u522b\u5728\u4e8e\u5bf9ReLU\u68af\u5ea6\u7684\u5904\u7406\u3002 ReLU\u5728\u53cd\u5411\u4f20\u64ad\u7684\u8ba1\u7b97\u91c7\u7528\u7684\u524d\u5411\u4f20\u64ad\u7684\u7279\u5f81\u4f5c\u4e3a\u95e8\u9600\uff0c\u800cdeconvnet\u91c7\u7528\u7684\u662f\u68af\u5ea6\u503c\uff0cguided-backpropagation\u5219\u5c06\u4e24\u8005\u7ec4\u5408\u5728\u4e00\u8d77\u4f7f\u7528\uff0c\u8fd9\u6837\u6709\u52a9\u4e8e\u5f97\u5230\u7684\u91cd\u6784\u90fd\u662f\u6b63\u6570\u3002 \u8fd9\u6bb5\u8bdd\u53ef\u80fd\u6709\u70b9\u7ed5\uff0c\u5177\u4f53\u7ec6\u8282\u8fd8\u662f\u770b\u8bba\u6587\u5427,\u6211\u4eec\u8fd9\u91cc\u53ea\u5173\u6ce8\u5982\u4f55\u5b9e\u73b0\u3002 inputs . requires_grad = True # \u8fd9\u53e5\u8bdd\u5fc5\u987b\u8981\u6709\uff0c\u5426\u5219\u4f1a\u62a5\u9519 from guided_backprop import GuidedBackprop #\u8fd9\u91cc\u76f4\u63a5\u5f15\u7528\u5199\u597d\u7684\u65b9\u6cd5\uff0c\u5728src\uff0c\u76ee\u5f55\u627e\u60f3\u5bf9\u5e94\u7684\u6587\u4ef6 GB = GuidedBackprop ( net ) gp_grads = GB . generate_gradients ( inputs , label ) gp_grads = np . moveaxis ( gp_grads , 0 , - 1 ) #\u6211\u4eec\u5206\u522b\u8ba1\u7b97\u4e09\u7c7b\u7684gp ag = rescale_grads ( gp_grads , gradtype = \"all\" ) pg = rescale_grads ( gp_grads , gradtype = \"pos\" ) ng = rescale_grads ( gp_grads , gradtype = \"neg\" ) \u4e0b\u9762\u6211\u4eec\u4f7f\u7528matplotlib\u770b\u770b\u7ed3\u679c\uff1a plt . imshow ( cat_img ) <matplotlib.image.AxesImage at 0x23d840392e8> plt . imshow ( ag ) <matplotlib.image.AxesImage at 0x23d8441c7f0> plt . imshow ( ng ) <matplotlib.image.AxesImage at 0x23d84487080> plt . imshow ( ag ) <matplotlib.image.AxesImage at 0x23d854b44e0> \u4e0a\u9762\u4e09\u5f20\u56fe\u662frbg\u4e09\u4e2a\u901a\u9053\u7684\u5c55\u793a\u7ed3\u679c\uff0c\u4e0b\u9762\u6211\u4eec\u5408\u5e76\u6210\u4e00\u4e2a\u901a\u9053\u518d\u770b\u4e00\u4e0b\uff1a gag = rgb2gray ( ag ) plt . imshow ( gag ) <matplotlib.image.AxesImage at 0x23d8550fe80> gpg = rgb2gray ( pg ) plt . imshow ( gpg ) <matplotlib.image.AxesImage at 0x23d85576710> gng = rgb2gray ( ng ) plt . imshow ( gng ) <matplotlib.image.AxesImage at 0x23d855d4fd0> CAM\uff08Class Activation Map\uff09 \u00b6 \u8fd9\u4e2a\u65b9\u6cd5\u4e25\u683c\u6765\u8bf4\u4e0d\u662f\u57fa\u4e8e\u68af\u5ea6\u7684\uff0c\u4f46\u662f\u540e\u9762\u6211\u4eec\u4f1a\u5c06\u53cd\u5411\u4f20\u64ad\u4e0eCAM\u6574\u5408\uff0c\u6240\u4ee5\u7b80\u5355\u7684\u5bf9CAM\u505a\u4e2a\u8bf4\u660e\u3002 CAM \u6765\u81eaCVPR 2016 \u300aLearning Deep Features for Discriminative Localization\u300b \uff0c\u4f5c\u8005\u5728\u7814\u7a76global average pooling\uff08GAP\uff09\u65f6\uff0c\u53d1\u73b0GAP\u4e0d\u6b62\u4f5c\u4e3a\u4e00\u79cd\u6b63\u5219\uff0c\u51cf\u8f7b\u8fc7\u62df\u5408\uff0c\u5728\u7a0d\u52a0\u6539\u8fdb\u540e\uff0c\u53ef\u4ee5\u4f7f\u5f97CNN\u5177\u6709\u5b9a\u4f4d\u7684\u80fd\u529b\uff0cCAM\uff08class activation map\uff09\u662f\u6307\u8f93\u5165\u4e2d\u7684\u4ec0\u4e48\u533a\u57df\u80fd\u591f\u6307\u793aCNN\u8fdb\u884c\u6b63\u786e\u7684\u8bc6\u522b\u3002 \u901a\u5e38\u7279\u5f81\u56fe\u4e0a\u6bcf\u4e2a\u4f4d\u7f6e\u7684\u503c\u5728\u5b58\u5728\u5176\u611f\u77e5\u91ce\u91cc\u9762\u67d0\u79cd\u6a21\u5f0f\u65f6\u88ab\u6fc0\u6d3b\uff0c\u6700\u540e\u7684class activation map\u662f\u8fd9\u4e9b\u6a21\u5f0f\u7684\u7ebf\u6027\u7ec4\u5408\uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u4e0a\u91c7\u6837\uff0c\u5c06class activation map \u8fd8\u539f\u5230\u4e0e\u539f\u56fe\u4e00\u6837\u7684\u5927\u5c0f\uff0c\u901a\u8fc7\u53e0\u52a0\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u77e5\u9053\u54ea\u4e9b\u533a\u57df\u662f\u4e0e\u6700\u540e\u5206\u7c7b\u7ed3\u679c\u606f\u606f\u76f8\u5173\u7684\u90e8\u5206\u3002 \u8fd9\u91cc\u5c31\u4e0d\u4ecb\u7ecd\u4e86\u3002 Grad-CAM \u00b6 Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization \u987e\u540d\u601d\u4e49 Grad-CAM\u7684\u52a0\u6743\u7cfb\u6570\u662f\u901a\u8fc7\u53cd\u5411\u4f20\u64ad\u5f97\u5230\u7684\uff0c\u800cCAM\u7684\u7279\u5f81\u52a0\u6743\u7cfb\u6570\u662f\u5206\u7c7b\u5668\u7684\u6743\u503c\u3002 Grad-CAM \u4e0e CAM\u76f8\u6bd4\uff0c\u5b83\u7684\u4f18\u70b9\u662f\u9002\u7528\u7684\u8303\u56f4\u66f4\u5e7f\uff0cGrad-CAM\u5bf9\u5404\u7c7b\u7ed3\u6784\uff0c\u5404\u79cd\u4efb\u52a1\u90fd\u53ef\u4ee5\u4f7f\u7528\u3002\u8fd9\u4e24\u79cd\u65b9\u6cd5\u4e5f\u53ef\u4ee5\u5e94\u7528\u4e8e\u8fdb\u884c\u5f31\u76d1\u7763\u4e0b\u7684\u76ee\u6807\u68c0\u6d4b\uff0c\u540e\u7eed\u4e5f\u6709\u76f8\u5173\u5de5\u4f5c\u57fa\u4e8e\u5b83\u4eec\u8fdb\u884c\u6539\u8fdb\u6765\u505a\u5f31\u76d1\u7763\u76ee\u6807\u68c0\u6d4b\u3002 import math from gradcam import GradCam from guided_gradcam import guided_grad_cam from guided_backprop import GuidedBackprop nlayers = len ( net . features . _modules . items ()) - 1 print ( nlayers ) # \u6253\u5370\u4e00\u4e0b\u4e00\u5171\u6709\u591a\u5c11\u5c42 cam_list = [] #\u4e0b\u9762\u6211\u4eec\u5faa\u73af\u6bcf\u4e00\u5c42 for layer in range ( nlayers ): #GradCam grad_cam = GradCam ( net , target_layer = layer ) cam = grad_cam . generate_cam ( inputs , label ) #GuidedBackprop GBP = GuidedBackprop ( net ) guided_grads = GBP . generate_gradients ( inputs , label ) # Guided Grad cam cam_gb = guided_grad_cam ( cam , guided_grads ) cam_list . append ( rgb2gray ( np . moveaxis ( cam_gb , 0 , - 1 ))) 30 \u6211\u4eec\u9009\u4e2a\u56fe\uff0c\u770b\u770b\u6548\u679c\uff1a plt . imshow ( cam_list [ 0 ]) <matplotlib.image.AxesImage at 0x23d858b7588> \u5728 Visualizing and Understanding Convolutional Networks \u4e2d\u4f5c\u8005\u8fd8\u7ed9\u51fa\u4e86\u5176\u4ed6\u4e0d\u540c\u7684\u65b9\u6cd5\uff0c\u8fd9\u91cc\u5c31\u4e0d\u8be6\u7ec6\u8bf4\u660e\u4e86\u3002 \u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u5728\u4f7f\u7528 Visualizing and Understanding Convolutional Networks\u7684\u65f6\u5019\uff0c\u5bf9\u7f51\u7edc\u6a21\u578b\u662f\u6709\u8981\u6c42\u7684\uff0c\u8981\u6c42\u7f51\u7edc\u5c06\u6a21\u578b\u5305\u542b\u540d\u4e3afeatures\u7684\u7ec4\u5408\u5c42\uff0c\u8fd9\u90e8\u5206\u662f\u4ee3\u7801\u4e2d\u5199\u6b7b\u7684\uff0c\u6240\u4ee5\u5728pytorch\u7684\u5185\u7f6e\u6a21\u578b\u4e2d\uff0cvgg\u3001alexnet\u3001densenet\u3001squeezenet\u662f\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528\u7684\uff0cinception(googlenet)\u548cresnet\u6ca1\u6709\u540d\u4e3afeatures\u7684\u7ec4\u5408\u5c42\uff0c\u5982\u679c\u8981\u4f7f\u7528\u7684\u8bdd\u662f\u9700\u8981\u5bf9\u4ee3\u7801\u8fdb\u884c\u4fee\u6539\u7684\u3002","title":"CNN Visualizing"},{"location":"tutorial/chapter04_advanced/4_2_3_cnn-visualizing/#423","text":"\u5728\u4e0a\u4e00\u8282\u4e2d\u6211\u4eec\u5df2\u7ecf\u901a\u8fc7\u4e00\u4e2a\u9884\u8bad\u7ec3\u7684VGG16\u6a21\u578b\u5bf9\u4e00\u5f20\u56fe\u7247\u8fdb\u884c\u4e86\u5206\u7c7b\uff0c\u4e0b\u9762\u6211\u4eec\u7c98\u8d34\u4e0a\u4e00\u8282\u7684\u4ee3\u7801\uff1a cat_img = Image . open ( 'img/1280px-Felis_silvestris_catus_lying_on_rice_straw.jpg' ) transform_224 = transforms . Compose ([ transforms . Resize ( 224 ), transforms . CenterCrop (( 224 , 224 )), transforms . ToTensor (), transforms . Normalize ( mean = [ 0.485 , 0.456 , 0.406 ], std = [ 0.229 , 0.224 , 0.225 ]) ]) cat_img_224 = transform_224 ( cat_img ) \u4e0a\u9762\u7684\u4ee3\u7801\u662f\u6211\u4eec\u8bfb\u53d6\u4e86\u4e00\u5f20\u56fe\u7247\uff0c\u5e76\u5bf9\u56fe\u7247\u8fdb\u884c\u4e86\u4e00\u4e9b\u9884\u5904\u7406\uff0c\u4e0b\u9762\u6211\u4eec\u6765\u521b\u5efavgg16\u7684\u9884\u8bad\u7ec3\u597d\u7f51\u7edc\u6a21\u578b\uff1a net = models . vgg16 ( pretrained = True ) # \u4fee\u6539\u8fd9\u91cc\u53ef\u4ee5\u66f4\u6362\u5176\u4ed6\u4e0e\u8bad\u7ec3\u7684\u6a21\u578b inputs = cat_img_224 [ np . newaxis ] #\u8fd9\u4e24\u4e2a\u65b9\u6cd5\u90fd\u53ef\u4ee5cat_img_224[None,::] \u8fdb\u884c\u4e00\u6b21\u524d\u5411\u7684\u4f20\u64ad\uff0c\u770b\u770b\u5f97\u5230\u4e86\u4ec0\u4e48\u7ed3\u679c\uff1a out = net ( inputs ) _ , preds = torch . max ( out . data , 1 ) preds label = preds . numpy ()[ 0 ] label 287 \u6211\u4eec\u770b\u5230\u4e86\uff0c\u8fd9\u91cc\u8fd4\u56de\u7684\u662f285\uff0c\u4ee3\u7801\u51e0\u4e4e\u4e00\u6837\uff0c\u4f46\u662f\u8fd4\u56de\u7684\u7ed3\u679c\u4e0e\u4e0a\u4e00\u8282\u7684\u6837\u4f8b\u6709\u5dee\u522b\uff0c\u8fd9\u662f\u4ec0\u4e48\u539f\u56e0\u5462\uff1f \u9996\u5148\u6211\u4eec\u5148\u770b\u4e00\u4e0b\u8fd9\u4e2a\u6570\u5b57\u7684\u542b\u4e49\uff0c\u6211\u4eec\u4f7f\u7528\u7684\u662f\u901a\u8fc7imagenet\u6765\u4f5c\u4e3a\u9884\u8bad\u7ec3\u7684\u6a21\u578b\uff0cimagenet\u91cc\u9762\u67091000\u4e2a\u5206\u7c7b\uff0c\u6211\u4eec\u5982\u4f55\u53bb\u627e\u8fd9\u4e2a\u542b\u4e49\u5462\uff1f \u6709\u597d\u5fc3\u4eba\u5df2\u7ecf\u7ed9\u6211\u4eec\u51c6\u5907\u597d\u4e86 \u8fd9\u4e2a\u8fde\u63a5 \u6211\u4eec\u627e\u4e00\u4e0b 285: 'Egyptian cat', \u8bf4\u660e\u8bc6\u522b\u51fa\u4e86\u662f\u4e00\u53ea\u732b\uff0c\u79cd\u7c7b\u8fd8\u662f\u57c3\u53ca\u732b\uff0c\u5e94\u8be5\u8fd8\u662f\u6bd4\u8f83\u51c6\u786e\u7684\uff0c\u4f46\u662f\u8fd9\u5f20\u56fe\u7247\u662f\u6211\u7279\u610f\u5bfb\u627e\u7684\uff0c\u91cc\u9762\u5305\u542b\u4e86\u5f88\u591a\u9690\u85cf\u7684\u7ec6\u8282\uff0c\u8fd9\u91cc\u5c31\u4e0d\u591a\u4ecb\u7ecd\u4e86\uff0c\u5927\u5bb6\u5982\u679c\u6709\u5174\u8da3\uff0c\u53ef\u4ee5\u6362\u4e00\u4e2a\u6a21\u578b\uff0c\u6216\u8005\u4fee\u6539\u4e0btransforms\u65b9\u6cd5\uff0c\u770b\u770b\u6a21\u578b\u90fd\u4f1a\u8bc6\u522b\u51fa\u6765\u662f\u4ec0\u4e48\u7c7b\u522b\u3002 \u6ce8\uff1a\u4e0d\u540c\u7684\u9884\u8bad\u7ec3\u6743\u91cd\u4e5f\u4f1a\u51fa\u73b0\u4e0d\u540c\u7684\u7ed3\u679c\uff0c\u6211\u6d4b\u8bd5\u51fa\u73b0\u8fc7277\uff0c282\uff0c287\u7b49\u7ed3\u679c \u4e0b\u9762\u6211\u4eec\u5f00\u59cb\u8fdb\u5165\u6b63\u9898\uff0c\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u53ef\u89c6\u5316\u3002","title":"4.2.3 \u53ef\u89c6\u5316\u7406\u89e3\u5377\u79ef\u795e\u7ecf\u7f51\u7edc"},{"location":"tutorial/chapter04_advanced/4_2_3_cnn-visualizing/#_1","text":"CNN\u6a21\u578b\u867d\u7136\u5728\u56fe\u50cf\u5904\u7406\u4e0a\u8868\u73b0\u51fa\u975e\u5e38\u826f\u597d\u7684\u6027\u80fd\u548c\u51c6\u786e\u6027\uff0c\u4f46\u4e00\u76f4\u4ee5\u6765\u90fd\u88ab\u8ba4\u4e3a\u662f\u4e00\u4e2a\u9ed1\u76d2\u6a21\u578b\uff0c\u4eba\u4eec\u65e0\u6cd5\u4e86\u89e3\u91cc\u9762\u7684\u5de5\u4f5c\u673a\u5236\u3002 \u9488\u5bf9\u8fd9\u4e2a\u95ee\u9898\uff0c\u7814\u7a76\u4eba\u5458\u9664\u4e86\u4ece\u7406\u8bba\u5c42\u9762\u53bb\u5bfb\u627e\u89e3\u91ca\u5916\uff0c\u4e5f\u63d0\u51fa\u4e86\u4e00\u4e9b\u53ef\u89c6\u5316\u7684\u65b9\u6cd5\u76f4\u89c2\u5730\u7406\u89e3CNN\u7684\u5185\u90e8\u673a\u7406\uff0c\u6bd5\u7adf\u773c\u89c1\u4e3a\u5b9e\uff0c\u770b\u5230\u4e86\u5927\u5bb6\u5c31\u76f8\u4fe1\u4e86\u3002 \u8fd9\u91cc\u4ecb\u7ecd\u4e24\u7c7b\u65b9\u6cd5\uff0c\u4e00\u79cd\u662f\u57fa\u4e8eDeconvolution, \u53e6\u4e00\u79cd\u5219\u662f\u57fa\u4e8e\u53cd\u5411\u4f20\u64ad\u7684\u65b9\u6cd5\u3002\u6211\u4eec\u4e3b\u8981\u4f7f\u7528\u4ee3\u7801\u5b9e\u73b0\u57fa\u4e8e\u53cd\u5411\u4f20\u64ad\u7684\u65b9\u6cd5\u7684\u53ef\u89c6\u5316\u3002","title":"\u80cc\u666f"},{"location":"tutorial/chapter04_advanced/4_2_3_cnn-visualizing/#deconvolution","text":"Visualizing and Understanding Convolutional Networks \u4e3b\u8981\u662f\u5c06\u6fc0\u6d3b\u51fd\u6570\u7684\u7279\u5f81\u6620\u5c04\u56de\u50cf\u7d20\u7a7a\u95f4\uff0c\u6765\u63ed\u793a\u4ec0\u4e48\u6837\u7684\u8f93\u5165\u6a21\u5f0f\u80fd\u591f\u4ea7\u751f\u7279\u5b9a\u7684\u8f93\u51fa,\u56e0\u4e3a\u7f51\u7edc\u662f\u6709\u5c42\u7ea7\u5173\u7cfb\u7684\uff0c\u6240\u4ee5\u8d8a\u9760\u8fd1\u8f93\u51fa\u7684\u5c42\u7ea7\u5b66\u5230\u7684\u7279\u5f81\u8d8a\u62bd\u8c61\uff0c\u4e0e\u5b9e\u9645\u4efb\u52a1\u8d8a\u76f8\u5173\uff0c\u8fd9\u91cc\u5c31\u4e0d\u591a\u4ecb\u7ecd\u4e86\uff0c \u8fd9\u91cc \u6709\u4e00\u4e2a\u4f7f\u7528 keras\u7684\u5b9e\u73b0\uff0c\u6709\u5174\u8da3\u7684\u53ef\u4ee5\u770b\u770b\u3002","title":"\u57fa\u4e8eDeconvolution\u7684\u65b9\u6cd5"},{"location":"tutorial/chapter04_advanced/4_2_3_cnn-visualizing/#backpropagation","text":"\u53e6\u5916\u4e00\u7c7b\u7684\u5b9e\u73b0\u5c31\u662f\u57fa\u4e8eBackpropagation\u7684\u65b9\u6cd5\uff0c\u8fd9\u91cc\u6211\u4eec\u4e3b\u8981\u8fdb\u884c\u4ecb\u7ecd\uff0c\u5728\u4ecb\u7ecd\u4e4b\u524d\uff0c\u6211\u4eec\u9996\u5148\u8981\u5f15\u7528\u4e00\u4e0b\u522b\u4eba\u5199\u7684\u4ee3\u7801 pytorch-cnn-visualizations ,\u5c06\u8fd9\u4e2a\u4ee3\u7801\u7684src\u76ee\u5f55\u653e\u5230\u4e0e\u8fd9\u4e2anotebook\u540c\u7ea7\u522b\u76ee\u5f55\u4e0b\uff0c\u6211\u4eec\u540e\u9762\u4f1a\u76f4\u63a5\u8c03\u7528\u4ed6\u7684\u4ee3\u7801\u8fdb\u884c\u6f14\u793a\u64cd\u4f5c\u3002 \u9996\u5148\uff0c\u6211\u4eec\u505a\u4e00\u4e9b\u51c6\u5907\u5de5\u4f5c\uff1a import sys sys . path . insert ( 0 , './src/' ) def rgb2gray ( rgb ): return np . dot ( rgb [ ... ,: 3 ], [ 0.299 , 0.587 , 0.114 ]) def rescale_grads ( map , gradtype = \"all\" ): if ( gradtype == \"pos\" ): map = ( np . maximum ( 0 , map ) / map . max ()) elif gradtype == \"neg\" : map = ( np . maximum ( 0 , - map ) / - map . min ()) else : map = map - map . min () map /= map . max () return map","title":"\u57fa\u4e8eBackpropagation\u7684\u65b9\u6cd5"},{"location":"tutorial/chapter04_advanced/4_2_3_cnn-visualizing/#guided-backpropagation","text":"\u8fd9\u4e2a\u65b9\u6cd5\u6765\u81ea\u4e8eICLR-2015 \u7684\u6587\u7ae0 \u300aStriving for Simplicity: The All Convolutional Net\u300b \uff0c\u6587\u4e2d\u63d0\u51fa\u4e86\u4f7f\u7528stride convolution \u66ff\u4ee3pooling \u64cd\u4f5c\uff0c\u8fd9\u6837\u6574\u4e2a\u7ed3\u6784\u90fd\u53ea\u6709\u5377\u79ef\u64cd\u4f5c\u3002\u4f5c\u8005\u4e3a\u4e86\u7814\u7a76\u8fd9\u79cd\u7ed3\u6784\u7684\u6709\u6548\u6027\uff0c\u63d0\u51fa\u4e86guided-backpropagation\u7684\u65b9\u6cd5\u3002 \u5927\u81f4\u7684\u65b9\u6cd5\u4e3a\uff1a\u9009\u62e9\u67d0\u4e00\u79cd\u8f93\u51fa\u6a21\u5f0f\uff0c\u7136\u540e\u901a\u8fc7\u53cd\u5411\u4f20\u64ad\u8ba1\u7b97\u8f93\u51fa\u5bf9\u8f93\u5165\u7684\u68af\u5ea6\u3002\u8fd9\u79cd\u65b9\u5f0f\u4e0e\u4e0a\u4e00\u79cddeconvnet\u7684\u65b9\u5f0f\u7684\u552f\u4e00\u533a\u522b\u5728\u4e8e\u5bf9ReLU\u68af\u5ea6\u7684\u5904\u7406\u3002 ReLU\u5728\u53cd\u5411\u4f20\u64ad\u7684\u8ba1\u7b97\u91c7\u7528\u7684\u524d\u5411\u4f20\u64ad\u7684\u7279\u5f81\u4f5c\u4e3a\u95e8\u9600\uff0c\u800cdeconvnet\u91c7\u7528\u7684\u662f\u68af\u5ea6\u503c\uff0cguided-backpropagation\u5219\u5c06\u4e24\u8005\u7ec4\u5408\u5728\u4e00\u8d77\u4f7f\u7528\uff0c\u8fd9\u6837\u6709\u52a9\u4e8e\u5f97\u5230\u7684\u91cd\u6784\u90fd\u662f\u6b63\u6570\u3002 \u8fd9\u6bb5\u8bdd\u53ef\u80fd\u6709\u70b9\u7ed5\uff0c\u5177\u4f53\u7ec6\u8282\u8fd8\u662f\u770b\u8bba\u6587\u5427,\u6211\u4eec\u8fd9\u91cc\u53ea\u5173\u6ce8\u5982\u4f55\u5b9e\u73b0\u3002 inputs . requires_grad = True # \u8fd9\u53e5\u8bdd\u5fc5\u987b\u8981\u6709\uff0c\u5426\u5219\u4f1a\u62a5\u9519 from guided_backprop import GuidedBackprop #\u8fd9\u91cc\u76f4\u63a5\u5f15\u7528\u5199\u597d\u7684\u65b9\u6cd5\uff0c\u5728src\uff0c\u76ee\u5f55\u627e\u60f3\u5bf9\u5e94\u7684\u6587\u4ef6 GB = GuidedBackprop ( net ) gp_grads = GB . generate_gradients ( inputs , label ) gp_grads = np . moveaxis ( gp_grads , 0 , - 1 ) #\u6211\u4eec\u5206\u522b\u8ba1\u7b97\u4e09\u7c7b\u7684gp ag = rescale_grads ( gp_grads , gradtype = \"all\" ) pg = rescale_grads ( gp_grads , gradtype = \"pos\" ) ng = rescale_grads ( gp_grads , gradtype = \"neg\" ) \u4e0b\u9762\u6211\u4eec\u4f7f\u7528matplotlib\u770b\u770b\u7ed3\u679c\uff1a plt . imshow ( cat_img ) <matplotlib.image.AxesImage at 0x23d840392e8> plt . imshow ( ag ) <matplotlib.image.AxesImage at 0x23d8441c7f0> plt . imshow ( ng ) <matplotlib.image.AxesImage at 0x23d84487080> plt . imshow ( ag ) <matplotlib.image.AxesImage at 0x23d854b44e0> \u4e0a\u9762\u4e09\u5f20\u56fe\u662frbg\u4e09\u4e2a\u901a\u9053\u7684\u5c55\u793a\u7ed3\u679c\uff0c\u4e0b\u9762\u6211\u4eec\u5408\u5e76\u6210\u4e00\u4e2a\u901a\u9053\u518d\u770b\u4e00\u4e0b\uff1a gag = rgb2gray ( ag ) plt . imshow ( gag ) <matplotlib.image.AxesImage at 0x23d8550fe80> gpg = rgb2gray ( pg ) plt . imshow ( gpg ) <matplotlib.image.AxesImage at 0x23d85576710> gng = rgb2gray ( ng ) plt . imshow ( gng ) <matplotlib.image.AxesImage at 0x23d855d4fd0>","title":"Guided-Backpropagation"},{"location":"tutorial/chapter04_advanced/4_2_3_cnn-visualizing/#camclass-activation-map","text":"\u8fd9\u4e2a\u65b9\u6cd5\u4e25\u683c\u6765\u8bf4\u4e0d\u662f\u57fa\u4e8e\u68af\u5ea6\u7684\uff0c\u4f46\u662f\u540e\u9762\u6211\u4eec\u4f1a\u5c06\u53cd\u5411\u4f20\u64ad\u4e0eCAM\u6574\u5408\uff0c\u6240\u4ee5\u7b80\u5355\u7684\u5bf9CAM\u505a\u4e2a\u8bf4\u660e\u3002 CAM \u6765\u81eaCVPR 2016 \u300aLearning Deep Features for Discriminative Localization\u300b \uff0c\u4f5c\u8005\u5728\u7814\u7a76global average pooling\uff08GAP\uff09\u65f6\uff0c\u53d1\u73b0GAP\u4e0d\u6b62\u4f5c\u4e3a\u4e00\u79cd\u6b63\u5219\uff0c\u51cf\u8f7b\u8fc7\u62df\u5408\uff0c\u5728\u7a0d\u52a0\u6539\u8fdb\u540e\uff0c\u53ef\u4ee5\u4f7f\u5f97CNN\u5177\u6709\u5b9a\u4f4d\u7684\u80fd\u529b\uff0cCAM\uff08class activation map\uff09\u662f\u6307\u8f93\u5165\u4e2d\u7684\u4ec0\u4e48\u533a\u57df\u80fd\u591f\u6307\u793aCNN\u8fdb\u884c\u6b63\u786e\u7684\u8bc6\u522b\u3002 \u901a\u5e38\u7279\u5f81\u56fe\u4e0a\u6bcf\u4e2a\u4f4d\u7f6e\u7684\u503c\u5728\u5b58\u5728\u5176\u611f\u77e5\u91ce\u91cc\u9762\u67d0\u79cd\u6a21\u5f0f\u65f6\u88ab\u6fc0\u6d3b\uff0c\u6700\u540e\u7684class activation map\u662f\u8fd9\u4e9b\u6a21\u5f0f\u7684\u7ebf\u6027\u7ec4\u5408\uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u4e0a\u91c7\u6837\uff0c\u5c06class activation map \u8fd8\u539f\u5230\u4e0e\u539f\u56fe\u4e00\u6837\u7684\u5927\u5c0f\uff0c\u901a\u8fc7\u53e0\u52a0\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u77e5\u9053\u54ea\u4e9b\u533a\u57df\u662f\u4e0e\u6700\u540e\u5206\u7c7b\u7ed3\u679c\u606f\u606f\u76f8\u5173\u7684\u90e8\u5206\u3002 \u8fd9\u91cc\u5c31\u4e0d\u4ecb\u7ecd\u4e86\u3002","title":"CAM\uff08Class Activation Map\uff09"},{"location":"tutorial/chapter04_advanced/4_2_3_cnn-visualizing/#grad-cam","text":"Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization \u987e\u540d\u601d\u4e49 Grad-CAM\u7684\u52a0\u6743\u7cfb\u6570\u662f\u901a\u8fc7\u53cd\u5411\u4f20\u64ad\u5f97\u5230\u7684\uff0c\u800cCAM\u7684\u7279\u5f81\u52a0\u6743\u7cfb\u6570\u662f\u5206\u7c7b\u5668\u7684\u6743\u503c\u3002 Grad-CAM \u4e0e CAM\u76f8\u6bd4\uff0c\u5b83\u7684\u4f18\u70b9\u662f\u9002\u7528\u7684\u8303\u56f4\u66f4\u5e7f\uff0cGrad-CAM\u5bf9\u5404\u7c7b\u7ed3\u6784\uff0c\u5404\u79cd\u4efb\u52a1\u90fd\u53ef\u4ee5\u4f7f\u7528\u3002\u8fd9\u4e24\u79cd\u65b9\u6cd5\u4e5f\u53ef\u4ee5\u5e94\u7528\u4e8e\u8fdb\u884c\u5f31\u76d1\u7763\u4e0b\u7684\u76ee\u6807\u68c0\u6d4b\uff0c\u540e\u7eed\u4e5f\u6709\u76f8\u5173\u5de5\u4f5c\u57fa\u4e8e\u5b83\u4eec\u8fdb\u884c\u6539\u8fdb\u6765\u505a\u5f31\u76d1\u7763\u76ee\u6807\u68c0\u6d4b\u3002 import math from gradcam import GradCam from guided_gradcam import guided_grad_cam from guided_backprop import GuidedBackprop nlayers = len ( net . features . _modules . items ()) - 1 print ( nlayers ) # \u6253\u5370\u4e00\u4e0b\u4e00\u5171\u6709\u591a\u5c11\u5c42 cam_list = [] #\u4e0b\u9762\u6211\u4eec\u5faa\u73af\u6bcf\u4e00\u5c42 for layer in range ( nlayers ): #GradCam grad_cam = GradCam ( net , target_layer = layer ) cam = grad_cam . generate_cam ( inputs , label ) #GuidedBackprop GBP = GuidedBackprop ( net ) guided_grads = GBP . generate_gradients ( inputs , label ) # Guided Grad cam cam_gb = guided_grad_cam ( cam , guided_grads ) cam_list . append ( rgb2gray ( np . moveaxis ( cam_gb , 0 , - 1 ))) 30 \u6211\u4eec\u9009\u4e2a\u56fe\uff0c\u770b\u770b\u6548\u679c\uff1a plt . imshow ( cam_list [ 0 ]) <matplotlib.image.AxesImage at 0x23d858b7588> \u5728 Visualizing and Understanding Convolutional Networks \u4e2d\u4f5c\u8005\u8fd8\u7ed9\u51fa\u4e86\u5176\u4ed6\u4e0d\u540c\u7684\u65b9\u6cd5\uff0c\u8fd9\u91cc\u5c31\u4e0d\u8be6\u7ec6\u8bf4\u660e\u4e86\u3002 \u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u5728\u4f7f\u7528 Visualizing and Understanding Convolutional Networks\u7684\u65f6\u5019\uff0c\u5bf9\u7f51\u7edc\u6a21\u578b\u662f\u6709\u8981\u6c42\u7684\uff0c\u8981\u6c42\u7f51\u7edc\u5c06\u6a21\u578b\u5305\u542b\u540d\u4e3afeatures\u7684\u7ec4\u5408\u5c42\uff0c\u8fd9\u90e8\u5206\u662f\u4ee3\u7801\u4e2d\u5199\u6b7b\u7684\uff0c\u6240\u4ee5\u5728pytorch\u7684\u5185\u7f6e\u6a21\u578b\u4e2d\uff0cvgg\u3001alexnet\u3001densenet\u3001squeezenet\u662f\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528\u7684\uff0cinception(googlenet)\u548cresnet\u6ca1\u6709\u540d\u4e3afeatures\u7684\u7ec4\u5408\u5c42\uff0c\u5982\u679c\u8981\u4f7f\u7528\u7684\u8bdd\u662f\u9700\u8981\u5bf9\u4ee3\u7801\u8fdb\u884c\u4fee\u6539\u7684\u3002","title":"Grad-CAM"},{"location":"tutorial/chapter04_advanced/4_3_multiply-gpu-parallel-training/","text":"import torch import torchvision torch . __version__ '1.0.0' 4.3 \u591aGPU\u5e76\u884c\u8bad\u7ec3 \u00b6 \u5728\u6211\u4eec\u8fdb\u884c\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u7684\u65f6\u5019\uff0c\u56e0\u4e3a\u8ba1\u7b97\u91cf\u5de8\u5927\u6240\u4ee5\u5355\u4e2aGPU\u8fd0\u7b97\u4f1a\u4f7f\u5f97\u8ba1\u7b97\u65f6\u95f4\u5f88\u957f\uff0c\u4f7f\u5f97\u6211\u4eec\u4e0d\u80fd\u591f\u53ca\u65f6\u7684\u5f97\u5230\u7ed3\u679c\uff0c\u4f8b\u5982\u6211\u4eec\u5982\u679c\u4f7f\u7528\u4f46GPU\u4f7f\u7528ImageNet\u7684\u6570\u636e\u8bad\u7ec3\u4e00\u4e2a\u5206\u7c7b\u5668\uff0c\u53ef\u80fd\u4f1a\u82b1\u8d39\u4e00\u5468\u751a\u81f3\u4e00\u4e2a\u6708\u7684\u65f6\u95f4\u3002\u6240\u4ee5\u5728Pytorch\u4e2d\u5f15\u5165\u4e86\u591aGPU\u8ba1\u7b97\u7684\u673a\u5236\uff0c\u8fd9\u6837\u4f7f\u5f97\u8bad\u7ec3\u901f\u5ea6\u53ef\u4ee5\u6307\u6570\u7ea7\u7684\u589e\u957f\u3002 stanford\u5927\u5b66\u7684 DAWNBench \u5c31\u8bb0\u5f55\u4e86\u76ee\u524d\u4e3a\u6b62\u7684\u4e00\u4e9b\u4f7f\u7528\u591aGPU\u8ba1\u7b97\u7684\u8bb0\u5f55\u548c\u5b9e\u73b0\u4ee3\u7801\uff0c\u6709\u5174\u8da3\u7684\u53ef\u4ee5\u770b\u770b\u3002 \u8fd9\u7ae0\u91cc\u9762\u6211\u4eec\u8981\u4ecb\u7ecd\u7684\u4e09\u4e2a\u65b9\u5f0f\u6765\u4f7f\u7528\u591aGPU\u52a0\u901f\u3002 4.3.1 torch.nn.DataParalle \u00b6 \u4e00\u822c\u60c5\u51b5\u4e0b\u6211\u4eec\u90fd\u4f1a\u4f7f\u7528\u4e00\u53f0\u4e3b\u673a\u5e26\u591a\u4e2a\u663e\u5361\uff0c\u8fd9\u6837\u662f\u4e00\u4e2a\u6700\u8282\u7701\u9884\u7b97\u7684\u65b9\u6848\uff0c\u5728Pytorch\u4e2d\u4e3a\u6211\u4eec\u63d0\u4f9b\u4e86\u4e00\u4e2a\u975e\u5e38\u7b80\u5355\u7684\u65b9\u6cd5\u6765\u652f\u6301\u4f46\u4e3b\u673a\u591aGPU\uff0c\u90a3\u5c31 torch.nn.DataParalle \u6211\u4eec\u53ea\u8981\u5c06\u6211\u4eec\u81ea\u5df1\u7684\u6a21\u578b\u4f5c\u4e3a\u53c2\u6570\uff0c\u76f4\u63a5\u4f20\u5165\u5373\u53ef\uff0c\u5269\u4e0b\u7684\u4e8b\u60c5PyTorch\u90fd\u4e3a\u6211\u4eec\u505a\u4e86\u3002 #\u4f7f\u7528\u5185\u7f6e\u7684\u4e00\u4e2a\u6a21\u578b\uff0c\u6211\u4eec\u8fd9\u91cc\u4ee5resnet50\u4e3a\u4f8b model = torchvision . models . resnet50 () #\u6a21\u578b\u4f7f\u7528\u591aGPU mdp = torch . nn . DataParallel ( model ) mdp DataParallel( (module): ResNet( (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False) (layer1): Sequential( (0): Bottleneck( (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (downsample): Sequential( (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): Bottleneck( (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (2): Bottleneck( (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) ) (layer2): Sequential( (0): Bottleneck( (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (downsample): Sequential( (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): Bottleneck( (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (2): Bottleneck( (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (3): Bottleneck( (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) ) (layer3): Sequential( (0): Bottleneck( (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (downsample): Sequential( (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (2): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (3): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (4): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (5): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) ) (layer4): Sequential( (0): Bottleneck( (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (downsample): Sequential( (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): Bottleneck( (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (2): Bottleneck( (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) ) (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0) (fc): Linear(in_features=2048, out_features=1000, bias=True) ) ) \u53ea\u8981\u8fd9\u6837\u4e00\u4e2a\u7b80\u5355\u7684\u5305\u88f9\uff0cPytorch\u5df2\u7ecf\u4e3a\u6211\u4eec\u505a\u4e86\u5f88\u591a\u590d\u6742\u7684\u5de5\u4f5c\u3002\u6211\u4eec\u53ea\u9700\u8981\u589e\u5927\u6211\u4eec\u8bad\u7ec3\u7684batch_size(\u4e00\u822c\u8ba1\u7b97\u4e3aN\u500d\uff0cN\u4e3a\u663e\u5361\u6570\u91cf)\uff0c\u5176\u4ed6\u4ee3\u7801\u4e0d\u9700\u8981\u4efb\u4f55\u6539\u52a8\u3002 \u867d\u7136\u4ee3\u7801\u4e0d\u9700\u8981\u505a\u66f4\u6539\uff0c\u4f46\u662fbatch size\u592a\u5927\u4e86\u8bad\u7ec3\u6536\u655b\u4f1a\u5f88\u6162\uff0c\u6240\u4ee5\u8fd8\u8981\u628a\u5b66\u4e60\u7387\u8c03\u5927\u4e00\u70b9\u3002\u5927\u5b66\u7387\u4e5f\u4f1a\u4f7f\u5f97\u6a21\u578b\u7684\u8bad\u7ec3\u5728\u65e9\u671f\u7684\u9636\u6bb5\u53d8\u5f97\u5341\u5206\u4e0d\u7a33\u5b9a\uff0c\u6240\u4ee5\u8fd9\u91cc\u9700\u8981\u4e00\u4e2a\u5b66\u4e60\u7387\u7684\u70ed\u8eab\uff08warm up\uff09 \u6765\u7a33\u5b9a\u68af\u5ea6\u7684\u4e0b\u964d\uff0c\u7136\u540e\u5728\u9010\u6b65\u7684\u63d0\u9ad8\u5b66\u4e60\u7387\u3002 \u8fd9\u79cd\u70ed\u8eab\u53ea\u6709\u5728\u8d85\u7ea7\u5927\u7684\u6279\u6b21\u4e0b\u624d\u9700\u8981\u8fdb\u884c\uff0c\u4e00\u822c\u6211\u4eec\u8fd9\u79cd\u4e00\u673a4\u5361\u6216\u8005\u8bf4\u5728batch size \u5c0f\u4e8e 5000\uff08\u4e2a\u4eba\u6d4b\u8bd5\uff09\u57fa\u672c\u4e0a\u662f\u4e0d\u9700\u8981\u7684\u3002\u4f8b\u5982\u6700\u8fd1\u5bcc\u58eb\u901a\u4f7f\u75282048\u4e2aGPU,74\u79d2\u8bad\u7ec3\u5b8c\u6210resnet50\u7684\u5b9e\u9a8c\u4e2d\u4f7f\u7528\u7684batch size \u4e3a 81920 arivx \u8fd9\u79cd\u8d85\u5927\u7684size\u624d\u9700\u8981\u3002 DataParallel\u7684\u5e76\u884c\u5904\u7406\u673a\u5236\u662f\uff0c\u9996\u5148\u5c06\u6a21\u578b\u52a0\u8f7d\u5230\u4e3b GPU \u4e0a(\u9ed8\u8ba4\u7684\u7b2c\u4e00\u4e2aGPU\uff0cGPU0\u4e3a\u4e3bGPU)\uff0c\u7136\u540e\u518d\u5c06\u6a21\u578b\u590d\u5236\u5230\u5404\u4e2a\u6307\u5b9a\u7684\u4ece GPU \u4e2d\uff0c\u7136\u540e\u5c06\u8f93\u5165\u6570\u636e\u6309 batch \u7ef4\u5ea6\u8fdb\u884c\u5212\u5206\uff0c\u5177\u4f53\u6765\u8bf4\u5c31\u662f\u6bcf\u4e2a GPU \u5206\u914d\u5230\u7684\u6570\u636e batch \u6570\u91cf\u662f\u603b\u8f93\u5165\u6570\u636e\u7684 batch \u9664\u4ee5\u6307\u5b9a GPU \u4e2a\u6570\u3002\u6bcf\u4e2a GPU \u5c06\u9488\u5bf9\u5404\u81ea\u7684\u8f93\u5165\u6570\u636e\u72ec\u7acb\u8fdb\u884c forward \u8ba1\u7b97\uff0c\u6700\u540e\u5c06\u5404\u4e2a GPU \u7684 loss \u8fdb\u884c\u6c42\u548c\uff0c\u518d\u7528\u53cd\u5411\u4f20\u64ad\u66f4\u65b0\u5355\u4e2a GPU \u4e0a\u7684\u6a21\u578b\u53c2\u6570\uff0c\u518d\u5c06\u66f4\u65b0\u540e\u7684\u6a21\u578b\u53c2\u6570\u590d\u5236\u5230\u5269\u4f59\u6307\u5b9a\u7684 GPU \u4e2d\uff0c\u8fd9\u6837\u5c31\u5b8c\u6210\u4e86\u4e00\u6b21\u8fed\u4ee3\u8ba1\u7b97\u3002 DataParallel\u5176\u5b9e\u4e5f\u662f\u4e00\u4e2ann.Model\u6240\u4ee5\u6211\u4eec\u53ef\u4ee5\u4fdd\u5b58\u6743\u91cd\u7684\u65b9\u6cd5\u548c\u4e00\u822c\u7684nn.Model\u6ca1\u6709\u533a\u522b\uff0c\u53ea\u4e0d\u8fc7\u5982\u679c\u4f60\u60f3\u4f7f\u7528\u5355\u5361\u6216\u8005cpu\u4f5c\u4e3a\u63a8\u7406\u7684\u65f6\u5019\u9700\u8981\u4ece\u91cc\u9762\u8bfb\u51fa\u539f\u59cb\u7684model\u3002 #\u83b7\u53d6\u5230\u539f\u59cb\u7684model m = mdp . module m ResNet( (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False) (layer1): Sequential( (0): Bottleneck( (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (downsample): Sequential( (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): Bottleneck( (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (2): Bottleneck( (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) ) (layer2): Sequential( (0): Bottleneck( (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (downsample): Sequential( (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): Bottleneck( (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (2): Bottleneck( (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (3): Bottleneck( (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) ) (layer3): Sequential( (0): Bottleneck( (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (downsample): Sequential( (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (2): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (3): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (4): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (5): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) ) (layer4): Sequential( (0): Bottleneck( (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (downsample): Sequential( (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): Bottleneck( (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (2): Bottleneck( (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) ) (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0) (fc): Linear(in_features=2048, out_features=1000, bias=True) ) DataParallel\u4f1a\u5c06\u5b9a\u4e49\u7684\u7f51\u7edc\u6a21\u578b\u53c2\u6570\u9ed8\u8ba4\u653e\u5728GPU 0\u4e0a\uff0c\u6240\u4ee5dataparallel\u5b9e\u8d28\u662f\u53ef\u4ee5\u770b\u505a\u628a\u8bad\u7ec3\u53c2\u6570\u4eceGPU\u62f7\u8d1d\u5230\u5176\u4ed6\u7684GPU\u540c\u65f6\u8bad\u7ec3\uff0c\u8fd9\u6837\u4f1a\u5bfc\u81f4\u5185\u5b58\u548cGPU\u4f7f\u7528\u7387\u51fa\u73b0\u5f88\u4e25\u91cd\u7684\u8d1f\u8f7d\u4e0d\u5747\u8861\u73b0\u8c61\uff0c\u5373GPU 0\u7684\u4f7f\u7528\u5185\u5b58\u548c\u4f7f\u7528\u7387\u4f1a\u5927\u5927\u8d85\u51fa\u5176\u4ed6\u663e\u5361\u7684\u4f7f\u7528\u5185\u5b58\uff0c\u56e0\u4e3a\u5728\u8fd9\u91ccGPU0\u4f5c\u4e3amaster\u6765\u8fdb\u884c\u68af\u5ea6\u7684\u6c47\u603b\u548c\u6a21\u578b\u7684\u66f4\u65b0\uff0c\u518d\u5c06\u8ba1\u7b97\u4efb\u52a1\u4e0b\u53d1\u7ed9\u5176\u4ed6GPU\uff0c\u6240\u4ee5\u4ed6\u7684\u5185\u5b58\u548c\u4f7f\u7528\u7387\u4f1a\u6bd4\u5176\u4ed6\u7684\u9ad8\u3002 \u6240\u4ee5\u6211\u4eec\u4f7f\u7528\u65b0\u7684torch.distributed\u6765\u6784\u5efa\u66f4\u4e3a\u540c\u6b65\u7684\u5206\u5e03\u5f0f\u8fd0\u7b97\u3002\u4f7f\u7528torch.distributed\u4e0d\u4ec5\u53ef\u4ee5\u652f\u6301\u5355\u673a\u8fd8\u53ef\u4ee5\u652f\u6301\u591a\u4e2a\u4e3b\u673a\uff0c\u591a\u4e2aGPU\u8fdb\u884c\u8ba1\u7b97\u3002 4.3.2 torch.distributed \u00b6 torch.distributed \u76f8\u5bf9\u4e8e torch.nn.DataParalle \u662f\u4e00\u4e2a\u5e95\u5c42\u7684API\uff0c\u6240\u4ee5\u6211\u4eec\u8981\u4fee\u6539\u6211\u4eec\u7684\u4ee3\u7801\uff0c\u4f7f\u5176\u80fd\u591f\u72ec\u7acb\u7684\u5728\u673a\u5668\uff08\u8282\u70b9\uff09\u4e2d\u8fd0\u884c\u3002\u6211\u4eec\u60f3\u8981\u5b8c\u5168\u5b9e\u73b0\u5206\u5e03\u5f0f\uff0c\u5e76\u4e14\u5728\u6bcf\u4e2a\u7ed3\u70b9\u7684\u6bcf\u4e2aGPU\u4e0a\u72ec\u7acb\u8fd0\u884c\u8fdb\u7a0b\uff0c\u8fd9\u4e00\u5171\u9700\u8981N\u4e2a\u8fdb\u7a0b\u3002N\u662f\u6211\u4eec\u7684GPU\u603b\u6570\uff0c\u8fd9\u91cc\u6211\u4eec\u4ee54\u6765\u8ba1\u7b97\u3002 \u9996\u5148 \u521d\u59cb\u5316\u5206\u5e03\u5f0f\u540e\u7aef\uff0c\u5c01\u88c5\u6a21\u578b\u4ee5\u53ca\u51c6\u5907\u6570\u636e\uff0c\u8fd9\u4e9b\u6570\u636e\u7528\u4e8e\u5728\u72ec\u7acb\u7684\u6570\u636e\u5b50\u96c6\u4e2d\u8bad\u7ec3\u8fdb\u7a0b\u3002\u4fee\u6539\u540e\u7684\u4ee3\u7801\u5982\u4e0b\uff1a # \u4ee5\u4e0b\u811a\u672c\u5728jupyter notebook\u6267\u884c\u80af\u5b9a\u4f1a\u4e0d\u6210\u529f\uff0c\u8bf7\u4fdd\u5b58\u6210py\u6587\u4ef6\u540e\u6d4b\u8bd5 from torch.utils.data.distributed import DistributedSampler from torch.utils.data import DataLoader # \u8fd9\u91cc\u7684node_rank\u662f\u672c\u5730GPU\u7684\u6807\u8bc6 parser = argparse . ArgumentParser () parser . add_argument ( \"--node_rank\" , type = int ) args = parser . parse_args () # \u4f7f\u7528Nvdea\u7684nccl\u6765\u521d\u59cb\u5316\u8282\u70b9 torch . distributed . init_process_group ( backend = 'nccl' ) # \u5c01\u88c5\u5206\u914d\u7ed9\u5f53\u524d\u8fdb\u7a0b\u7684GPU\u4e0a\u7684\u6a21\u578b device = torch . device ( 'cuda' , arg . local_rank ) model = model . to ( device ) distrib_model = torch . nn . parallel . DistributedDataParallel ( model , device_ids = [ args . node_rank ], output_device = args . node_rank ) # \u5c06\u6570\u636e\u52a0\u8f7d\u9650\u5236\u4e3a\u6570\u636e\u96c6\u7684\u5b50\u96c6\uff08\u4e0d\u5305\u62ec\u5f53\u524d\u8fdb\u7a0b\uff09 sampler = DistributedSampler ( dataset ) dataloader = DataLoader ( dataset , sampler = sampler ) for inputs , labels in dataloader : predictions = distrib_model ( inputs . to ( device )) # \u6b63\u5411\u4f20\u64ad loss = loss_function ( predictions , labels . to ( device )) # \u8ba1\u7b97\u635f\u5931 loss . backward () # \u53cd\u5411\u4f20\u64ad optimizer . step () # \u4f18\u5316 \u5728\u8fd0\u884c\u65f6\u6211\u4eec\u4e5f\u4e0d\u80fd\u7b80\u5355\u7684\u4f7f\u7528 python \u6587\u4ef6\u540d \u6765\u6267\u884c\u4e86\uff0c\u6211\u4eec\u8fd9\u91cc\u9700\u8981\u4f7f\u7528PyTorch\u4e2d\u4e3a\u6211\u4eec\u51c6\u5907\u597d\u7684torch.distributed.launch\u8fd0\u884c\u811a\u672c\u3002\u5b83\u80fd\u81ea\u52a8\u8fdb\u884c\u73af\u5883\u53d8\u91cf\u7684\u8bbe\u7f6e\uff0c\u5e76\u4f7f\u7528\u6b63\u786e\u7684node_rank\u53c2\u6570\u8c03\u7528\u811a\u672c\u3002 \u8fd9\u91cc\u6211\u4eec\u8981\u51c6\u5907\u4e00\u53f0\u673a\u5668\u4f5c\u4e3amaster\uff0c\u6240\u6709\u7684\u673a\u5668\u90fd\u8981\u6c42\u80fd\u5bf9\u5b83\u8fdb\u884c\u8bbf\u95ee\u3002\u56e0\u6b64\uff0c\u5b83\u9700\u8981\u62e5\u6709\u4e00\u4e2a\u53ef\u4ee5\u8bbf\u95ee\u7684IP\u5730\u5740\uff08\u793a\u4f8b\u4e2d\u4e3a\uff1a196.168.100.100\uff09\u4ee5\u53ca\u4e00\u4e2a\u5f00\u653e\u7684\u7aef\u53e3\uff08\u793a\u4f8b\u4e2d\u4e3a\uff1a6666\uff09\u3002\u6211\u4eec\u5c06\u4f7f\u7528torch.distributed.launch\u5728\u7b2c\u4e00\u53f0\u673a\u5668\u4e0a\u8fd0\u884c\u811a\u672c\uff1a python -m torch.distributed.launch --nproc_per_node = 2 --nnodes = 2 --node_rank = 0 --master_addr = \"192.168.100.100\" --master_port = 6666 \u6587\u4ef6\u540d ( --arg1 --arg2 \u7b49\u5176\u4ed6\u53c2\u6570 ) \u7b2c\u4e8c\u53f0\u4e3b\u673a\u4e0a\u53ea\u9700\u8981\u66f4\u6539 --node_rank=0 \u5373\u53ef \u5f88\u6709\u53ef\u80fd\u4f60\u5728\u8fd0\u884c\u7684\u65f6\u5019\u62a5\u9519\uff0c\u90a3\u662f\u56e0\u4e3a\u6211\u4eec\u6ca1\u6709\u8bbe\u7f6eNCCL socket\u7f51\u7edc\u63a5\u53e3\u3002 \u6211\u4eec\u4ee5\u7f51\u5361\u540d\u4e3aens3\u4e3a\u4f8b\uff0c\u8f93\u5165\uff1a export NCCL_SOCKET_IFNAME = ens3 ens3\u8fd9\u4e2a\u540d\u79f0\uff0c\u53ef\u4ee5\u4f7f\u7528ifconfig\u547d\u4ee4\u67e5\u770b\u786e\u8ba4\u3002 \u53c2\u6570\u8bf4\u660e\uff1a --nproc_per_node \uff1a \u4e3b\u673a\u4e2d\u5305\u542b\u7684GPU\u603b\u6570 --nnodes \uff1a \u603b\u8ba1\u7684\u4e3b\u673a\u6570 --node_rank \uff1a\u4e3b\u673a\u4e2d\u7684GPU\u6807\u8bc6 \u5176\u4ed6\u4e00\u4e9b\u53c2\u6570\u53ef\u4ee5\u67e5\u770b \u5b98\u65b9\u7684\u6587\u6863 torch.distributed \u4e0d\u4ec5\u652f\u6301nccl\u8fd8\u652f\u6301\u5176\u4ed6\u7684\u4e24\u4e2a\u540e\u7aef gloo\u548cmpi\uff0c\u5177\u4f53\u7684\u5bf9\u6bd4\u8fd9\u91cc\u5c31\u4e0d\u7ec6\u8bf4\u4e86\uff0c\u8bf7\u67e5\u770b \u5b98\u65b9\u7684\u6587\u6863 4.3.3 torch.utils.checkpoint \u00b6 \u5728\u6211\u4eec\u8bad\u7ec3\u65f6\uff0c\u53ef\u80fd\u4f1a\u9047\u5230\uff08\u76ee\u524d\u6211\u8fd8\u6ca1\u9047\u5230\uff09\u8bad\u7ec3\u96c6\u7684\u5355\u4e2a\u6837\u672c\u6bd4\u5185\u5b58\u8fd8\u8981\u5927\u6839\u672c\u8f7d\u5165\u4e0d\u4e86\uff0c\u90a3\u6211\u6211\u4eec\u5982\u4f55\u6765\u8bad\u7ec3\u5462\uff1f pytorch\u4e3a\u6211\u4eec\u63d0\u4f9b\u4e86\u68af\u5ea6\u68c0\u67e5\u70b9\uff08gradient-checkpointing\uff09\u8282\u7701\u8ba1\u7b97\u8d44\u6e90\uff0c\u68af\u5ea6\u68c0\u67e5\u70b9\u4f1a\u5c06\u6211\u4eec\u8fde\u7eed\u8ba1\u7b97\u7684\u5143\u6b63\u5411\u548c\u5143\u53cd\u5411\u4f20\u64ad\u5207\u5206\u6210\u7247\u6bb5\u3002\u4f46\u7531\u4e8e\u9700\u8981\u589e\u52a0\u989d\u5916\u7684\u8ba1\u7b97\u4ee5\u51cf\u5c11\u5185\u5b58\u9700\u6c42\uff0c\u8be5\u65b9\u6cd5\u6548\u7387\u4f1a\u6709\u4e00\u4e9b\u4e0b\u964d\uff0c\u4f46\u662f\u5b83\u5728\u67d0\u4e9b\u793a\u4f8b\u4e2d\u6709\u8f83\u4e3a\u660e\u663e\u7684\u4f18\u52bf\uff0c\u6bd4\u5982\u5728\u957f\u5e8f\u5217\u4e0a\u8bad\u7ec3RNN\u6a21\u578b\uff0c\u8fd9\u4e2a\u7531\u4e8e\u590d\u73b0\u96be\u5ea6\u8f83\u5927 \u5c31\u4e0d\u4ecb\u7ecd\u4e86\uff0c\u5b98\u65b9\u6587\u6863\u5728 \u8fd9\u91cc \u9047\u5230\u8fd9\u79cd\u60c5\u51b5\u7684\u670b\u53cb\u53ef\u4ee5\u67e5\u770b\u4e0b\u5b98\u65b9\u7684\u89e3\u51b3\u65b9\u6848\u3002","title":"Parallel"},{"location":"tutorial/chapter04_advanced/4_3_multiply-gpu-parallel-training/#43-gpu","text":"\u5728\u6211\u4eec\u8fdb\u884c\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u7684\u65f6\u5019\uff0c\u56e0\u4e3a\u8ba1\u7b97\u91cf\u5de8\u5927\u6240\u4ee5\u5355\u4e2aGPU\u8fd0\u7b97\u4f1a\u4f7f\u5f97\u8ba1\u7b97\u65f6\u95f4\u5f88\u957f\uff0c\u4f7f\u5f97\u6211\u4eec\u4e0d\u80fd\u591f\u53ca\u65f6\u7684\u5f97\u5230\u7ed3\u679c\uff0c\u4f8b\u5982\u6211\u4eec\u5982\u679c\u4f7f\u7528\u4f46GPU\u4f7f\u7528ImageNet\u7684\u6570\u636e\u8bad\u7ec3\u4e00\u4e2a\u5206\u7c7b\u5668\uff0c\u53ef\u80fd\u4f1a\u82b1\u8d39\u4e00\u5468\u751a\u81f3\u4e00\u4e2a\u6708\u7684\u65f6\u95f4\u3002\u6240\u4ee5\u5728Pytorch\u4e2d\u5f15\u5165\u4e86\u591aGPU\u8ba1\u7b97\u7684\u673a\u5236\uff0c\u8fd9\u6837\u4f7f\u5f97\u8bad\u7ec3\u901f\u5ea6\u53ef\u4ee5\u6307\u6570\u7ea7\u7684\u589e\u957f\u3002 stanford\u5927\u5b66\u7684 DAWNBench \u5c31\u8bb0\u5f55\u4e86\u76ee\u524d\u4e3a\u6b62\u7684\u4e00\u4e9b\u4f7f\u7528\u591aGPU\u8ba1\u7b97\u7684\u8bb0\u5f55\u548c\u5b9e\u73b0\u4ee3\u7801\uff0c\u6709\u5174\u8da3\u7684\u53ef\u4ee5\u770b\u770b\u3002 \u8fd9\u7ae0\u91cc\u9762\u6211\u4eec\u8981\u4ecb\u7ecd\u7684\u4e09\u4e2a\u65b9\u5f0f\u6765\u4f7f\u7528\u591aGPU\u52a0\u901f\u3002","title":"4.3 \u591aGPU\u5e76\u884c\u8bad\u7ec3"},{"location":"tutorial/chapter04_advanced/4_3_multiply-gpu-parallel-training/#431-torchnndataparalle","text":"\u4e00\u822c\u60c5\u51b5\u4e0b\u6211\u4eec\u90fd\u4f1a\u4f7f\u7528\u4e00\u53f0\u4e3b\u673a\u5e26\u591a\u4e2a\u663e\u5361\uff0c\u8fd9\u6837\u662f\u4e00\u4e2a\u6700\u8282\u7701\u9884\u7b97\u7684\u65b9\u6848\uff0c\u5728Pytorch\u4e2d\u4e3a\u6211\u4eec\u63d0\u4f9b\u4e86\u4e00\u4e2a\u975e\u5e38\u7b80\u5355\u7684\u65b9\u6cd5\u6765\u652f\u6301\u4f46\u4e3b\u673a\u591aGPU\uff0c\u90a3\u5c31 torch.nn.DataParalle \u6211\u4eec\u53ea\u8981\u5c06\u6211\u4eec\u81ea\u5df1\u7684\u6a21\u578b\u4f5c\u4e3a\u53c2\u6570\uff0c\u76f4\u63a5\u4f20\u5165\u5373\u53ef\uff0c\u5269\u4e0b\u7684\u4e8b\u60c5PyTorch\u90fd\u4e3a\u6211\u4eec\u505a\u4e86\u3002 #\u4f7f\u7528\u5185\u7f6e\u7684\u4e00\u4e2a\u6a21\u578b\uff0c\u6211\u4eec\u8fd9\u91cc\u4ee5resnet50\u4e3a\u4f8b model = torchvision . models . resnet50 () #\u6a21\u578b\u4f7f\u7528\u591aGPU mdp = torch . nn . DataParallel ( model ) mdp DataParallel( (module): ResNet( (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False) (layer1): Sequential( (0): Bottleneck( (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (downsample): Sequential( (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): Bottleneck( (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (2): Bottleneck( (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) ) (layer2): Sequential( (0): Bottleneck( (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (downsample): Sequential( (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): Bottleneck( (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (2): Bottleneck( (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (3): Bottleneck( (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) ) (layer3): Sequential( (0): Bottleneck( (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (downsample): Sequential( (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (2): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (3): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (4): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (5): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) ) (layer4): Sequential( (0): Bottleneck( (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (downsample): Sequential( (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): Bottleneck( (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (2): Bottleneck( (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) ) (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0) (fc): Linear(in_features=2048, out_features=1000, bias=True) ) ) \u53ea\u8981\u8fd9\u6837\u4e00\u4e2a\u7b80\u5355\u7684\u5305\u88f9\uff0cPytorch\u5df2\u7ecf\u4e3a\u6211\u4eec\u505a\u4e86\u5f88\u591a\u590d\u6742\u7684\u5de5\u4f5c\u3002\u6211\u4eec\u53ea\u9700\u8981\u589e\u5927\u6211\u4eec\u8bad\u7ec3\u7684batch_size(\u4e00\u822c\u8ba1\u7b97\u4e3aN\u500d\uff0cN\u4e3a\u663e\u5361\u6570\u91cf)\uff0c\u5176\u4ed6\u4ee3\u7801\u4e0d\u9700\u8981\u4efb\u4f55\u6539\u52a8\u3002 \u867d\u7136\u4ee3\u7801\u4e0d\u9700\u8981\u505a\u66f4\u6539\uff0c\u4f46\u662fbatch size\u592a\u5927\u4e86\u8bad\u7ec3\u6536\u655b\u4f1a\u5f88\u6162\uff0c\u6240\u4ee5\u8fd8\u8981\u628a\u5b66\u4e60\u7387\u8c03\u5927\u4e00\u70b9\u3002\u5927\u5b66\u7387\u4e5f\u4f1a\u4f7f\u5f97\u6a21\u578b\u7684\u8bad\u7ec3\u5728\u65e9\u671f\u7684\u9636\u6bb5\u53d8\u5f97\u5341\u5206\u4e0d\u7a33\u5b9a\uff0c\u6240\u4ee5\u8fd9\u91cc\u9700\u8981\u4e00\u4e2a\u5b66\u4e60\u7387\u7684\u70ed\u8eab\uff08warm up\uff09 \u6765\u7a33\u5b9a\u68af\u5ea6\u7684\u4e0b\u964d\uff0c\u7136\u540e\u5728\u9010\u6b65\u7684\u63d0\u9ad8\u5b66\u4e60\u7387\u3002 \u8fd9\u79cd\u70ed\u8eab\u53ea\u6709\u5728\u8d85\u7ea7\u5927\u7684\u6279\u6b21\u4e0b\u624d\u9700\u8981\u8fdb\u884c\uff0c\u4e00\u822c\u6211\u4eec\u8fd9\u79cd\u4e00\u673a4\u5361\u6216\u8005\u8bf4\u5728batch size \u5c0f\u4e8e 5000\uff08\u4e2a\u4eba\u6d4b\u8bd5\uff09\u57fa\u672c\u4e0a\u662f\u4e0d\u9700\u8981\u7684\u3002\u4f8b\u5982\u6700\u8fd1\u5bcc\u58eb\u901a\u4f7f\u75282048\u4e2aGPU,74\u79d2\u8bad\u7ec3\u5b8c\u6210resnet50\u7684\u5b9e\u9a8c\u4e2d\u4f7f\u7528\u7684batch size \u4e3a 81920 arivx \u8fd9\u79cd\u8d85\u5927\u7684size\u624d\u9700\u8981\u3002 DataParallel\u7684\u5e76\u884c\u5904\u7406\u673a\u5236\u662f\uff0c\u9996\u5148\u5c06\u6a21\u578b\u52a0\u8f7d\u5230\u4e3b GPU \u4e0a(\u9ed8\u8ba4\u7684\u7b2c\u4e00\u4e2aGPU\uff0cGPU0\u4e3a\u4e3bGPU)\uff0c\u7136\u540e\u518d\u5c06\u6a21\u578b\u590d\u5236\u5230\u5404\u4e2a\u6307\u5b9a\u7684\u4ece GPU \u4e2d\uff0c\u7136\u540e\u5c06\u8f93\u5165\u6570\u636e\u6309 batch \u7ef4\u5ea6\u8fdb\u884c\u5212\u5206\uff0c\u5177\u4f53\u6765\u8bf4\u5c31\u662f\u6bcf\u4e2a GPU \u5206\u914d\u5230\u7684\u6570\u636e batch \u6570\u91cf\u662f\u603b\u8f93\u5165\u6570\u636e\u7684 batch \u9664\u4ee5\u6307\u5b9a GPU \u4e2a\u6570\u3002\u6bcf\u4e2a GPU \u5c06\u9488\u5bf9\u5404\u81ea\u7684\u8f93\u5165\u6570\u636e\u72ec\u7acb\u8fdb\u884c forward \u8ba1\u7b97\uff0c\u6700\u540e\u5c06\u5404\u4e2a GPU \u7684 loss \u8fdb\u884c\u6c42\u548c\uff0c\u518d\u7528\u53cd\u5411\u4f20\u64ad\u66f4\u65b0\u5355\u4e2a GPU \u4e0a\u7684\u6a21\u578b\u53c2\u6570\uff0c\u518d\u5c06\u66f4\u65b0\u540e\u7684\u6a21\u578b\u53c2\u6570\u590d\u5236\u5230\u5269\u4f59\u6307\u5b9a\u7684 GPU \u4e2d\uff0c\u8fd9\u6837\u5c31\u5b8c\u6210\u4e86\u4e00\u6b21\u8fed\u4ee3\u8ba1\u7b97\u3002 DataParallel\u5176\u5b9e\u4e5f\u662f\u4e00\u4e2ann.Model\u6240\u4ee5\u6211\u4eec\u53ef\u4ee5\u4fdd\u5b58\u6743\u91cd\u7684\u65b9\u6cd5\u548c\u4e00\u822c\u7684nn.Model\u6ca1\u6709\u533a\u522b\uff0c\u53ea\u4e0d\u8fc7\u5982\u679c\u4f60\u60f3\u4f7f\u7528\u5355\u5361\u6216\u8005cpu\u4f5c\u4e3a\u63a8\u7406\u7684\u65f6\u5019\u9700\u8981\u4ece\u91cc\u9762\u8bfb\u51fa\u539f\u59cb\u7684model\u3002 #\u83b7\u53d6\u5230\u539f\u59cb\u7684model m = mdp . module m ResNet( (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False) (layer1): Sequential( (0): Bottleneck( (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (downsample): Sequential( (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): Bottleneck( (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (2): Bottleneck( (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) ) (layer2): Sequential( (0): Bottleneck( (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (downsample): Sequential( (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): Bottleneck( (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (2): Bottleneck( (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (3): Bottleneck( (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) ) (layer3): Sequential( (0): Bottleneck( (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (downsample): Sequential( (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (2): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (3): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (4): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (5): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) ) (layer4): Sequential( (0): Bottleneck( (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (downsample): Sequential( (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): Bottleneck( (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (2): Bottleneck( (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) ) (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0) (fc): Linear(in_features=2048, out_features=1000, bias=True) ) DataParallel\u4f1a\u5c06\u5b9a\u4e49\u7684\u7f51\u7edc\u6a21\u578b\u53c2\u6570\u9ed8\u8ba4\u653e\u5728GPU 0\u4e0a\uff0c\u6240\u4ee5dataparallel\u5b9e\u8d28\u662f\u53ef\u4ee5\u770b\u505a\u628a\u8bad\u7ec3\u53c2\u6570\u4eceGPU\u62f7\u8d1d\u5230\u5176\u4ed6\u7684GPU\u540c\u65f6\u8bad\u7ec3\uff0c\u8fd9\u6837\u4f1a\u5bfc\u81f4\u5185\u5b58\u548cGPU\u4f7f\u7528\u7387\u51fa\u73b0\u5f88\u4e25\u91cd\u7684\u8d1f\u8f7d\u4e0d\u5747\u8861\u73b0\u8c61\uff0c\u5373GPU 0\u7684\u4f7f\u7528\u5185\u5b58\u548c\u4f7f\u7528\u7387\u4f1a\u5927\u5927\u8d85\u51fa\u5176\u4ed6\u663e\u5361\u7684\u4f7f\u7528\u5185\u5b58\uff0c\u56e0\u4e3a\u5728\u8fd9\u91ccGPU0\u4f5c\u4e3amaster\u6765\u8fdb\u884c\u68af\u5ea6\u7684\u6c47\u603b\u548c\u6a21\u578b\u7684\u66f4\u65b0\uff0c\u518d\u5c06\u8ba1\u7b97\u4efb\u52a1\u4e0b\u53d1\u7ed9\u5176\u4ed6GPU\uff0c\u6240\u4ee5\u4ed6\u7684\u5185\u5b58\u548c\u4f7f\u7528\u7387\u4f1a\u6bd4\u5176\u4ed6\u7684\u9ad8\u3002 \u6240\u4ee5\u6211\u4eec\u4f7f\u7528\u65b0\u7684torch.distributed\u6765\u6784\u5efa\u66f4\u4e3a\u540c\u6b65\u7684\u5206\u5e03\u5f0f\u8fd0\u7b97\u3002\u4f7f\u7528torch.distributed\u4e0d\u4ec5\u53ef\u4ee5\u652f\u6301\u5355\u673a\u8fd8\u53ef\u4ee5\u652f\u6301\u591a\u4e2a\u4e3b\u673a\uff0c\u591a\u4e2aGPU\u8fdb\u884c\u8ba1\u7b97\u3002","title":"4.3.1 torch.nn.DataParalle"},{"location":"tutorial/chapter04_advanced/4_3_multiply-gpu-parallel-training/#432-torchdistributed","text":"torch.distributed \u76f8\u5bf9\u4e8e torch.nn.DataParalle \u662f\u4e00\u4e2a\u5e95\u5c42\u7684API\uff0c\u6240\u4ee5\u6211\u4eec\u8981\u4fee\u6539\u6211\u4eec\u7684\u4ee3\u7801\uff0c\u4f7f\u5176\u80fd\u591f\u72ec\u7acb\u7684\u5728\u673a\u5668\uff08\u8282\u70b9\uff09\u4e2d\u8fd0\u884c\u3002\u6211\u4eec\u60f3\u8981\u5b8c\u5168\u5b9e\u73b0\u5206\u5e03\u5f0f\uff0c\u5e76\u4e14\u5728\u6bcf\u4e2a\u7ed3\u70b9\u7684\u6bcf\u4e2aGPU\u4e0a\u72ec\u7acb\u8fd0\u884c\u8fdb\u7a0b\uff0c\u8fd9\u4e00\u5171\u9700\u8981N\u4e2a\u8fdb\u7a0b\u3002N\u662f\u6211\u4eec\u7684GPU\u603b\u6570\uff0c\u8fd9\u91cc\u6211\u4eec\u4ee54\u6765\u8ba1\u7b97\u3002 \u9996\u5148 \u521d\u59cb\u5316\u5206\u5e03\u5f0f\u540e\u7aef\uff0c\u5c01\u88c5\u6a21\u578b\u4ee5\u53ca\u51c6\u5907\u6570\u636e\uff0c\u8fd9\u4e9b\u6570\u636e\u7528\u4e8e\u5728\u72ec\u7acb\u7684\u6570\u636e\u5b50\u96c6\u4e2d\u8bad\u7ec3\u8fdb\u7a0b\u3002\u4fee\u6539\u540e\u7684\u4ee3\u7801\u5982\u4e0b\uff1a # \u4ee5\u4e0b\u811a\u672c\u5728jupyter notebook\u6267\u884c\u80af\u5b9a\u4f1a\u4e0d\u6210\u529f\uff0c\u8bf7\u4fdd\u5b58\u6210py\u6587\u4ef6\u540e\u6d4b\u8bd5 from torch.utils.data.distributed import DistributedSampler from torch.utils.data import DataLoader # \u8fd9\u91cc\u7684node_rank\u662f\u672c\u5730GPU\u7684\u6807\u8bc6 parser = argparse . ArgumentParser () parser . add_argument ( \"--node_rank\" , type = int ) args = parser . parse_args () # \u4f7f\u7528Nvdea\u7684nccl\u6765\u521d\u59cb\u5316\u8282\u70b9 torch . distributed . init_process_group ( backend = 'nccl' ) # \u5c01\u88c5\u5206\u914d\u7ed9\u5f53\u524d\u8fdb\u7a0b\u7684GPU\u4e0a\u7684\u6a21\u578b device = torch . device ( 'cuda' , arg . local_rank ) model = model . to ( device ) distrib_model = torch . nn . parallel . DistributedDataParallel ( model , device_ids = [ args . node_rank ], output_device = args . node_rank ) # \u5c06\u6570\u636e\u52a0\u8f7d\u9650\u5236\u4e3a\u6570\u636e\u96c6\u7684\u5b50\u96c6\uff08\u4e0d\u5305\u62ec\u5f53\u524d\u8fdb\u7a0b\uff09 sampler = DistributedSampler ( dataset ) dataloader = DataLoader ( dataset , sampler = sampler ) for inputs , labels in dataloader : predictions = distrib_model ( inputs . to ( device )) # \u6b63\u5411\u4f20\u64ad loss = loss_function ( predictions , labels . to ( device )) # \u8ba1\u7b97\u635f\u5931 loss . backward () # \u53cd\u5411\u4f20\u64ad optimizer . step () # \u4f18\u5316 \u5728\u8fd0\u884c\u65f6\u6211\u4eec\u4e5f\u4e0d\u80fd\u7b80\u5355\u7684\u4f7f\u7528 python \u6587\u4ef6\u540d \u6765\u6267\u884c\u4e86\uff0c\u6211\u4eec\u8fd9\u91cc\u9700\u8981\u4f7f\u7528PyTorch\u4e2d\u4e3a\u6211\u4eec\u51c6\u5907\u597d\u7684torch.distributed.launch\u8fd0\u884c\u811a\u672c\u3002\u5b83\u80fd\u81ea\u52a8\u8fdb\u884c\u73af\u5883\u53d8\u91cf\u7684\u8bbe\u7f6e\uff0c\u5e76\u4f7f\u7528\u6b63\u786e\u7684node_rank\u53c2\u6570\u8c03\u7528\u811a\u672c\u3002 \u8fd9\u91cc\u6211\u4eec\u8981\u51c6\u5907\u4e00\u53f0\u673a\u5668\u4f5c\u4e3amaster\uff0c\u6240\u6709\u7684\u673a\u5668\u90fd\u8981\u6c42\u80fd\u5bf9\u5b83\u8fdb\u884c\u8bbf\u95ee\u3002\u56e0\u6b64\uff0c\u5b83\u9700\u8981\u62e5\u6709\u4e00\u4e2a\u53ef\u4ee5\u8bbf\u95ee\u7684IP\u5730\u5740\uff08\u793a\u4f8b\u4e2d\u4e3a\uff1a196.168.100.100\uff09\u4ee5\u53ca\u4e00\u4e2a\u5f00\u653e\u7684\u7aef\u53e3\uff08\u793a\u4f8b\u4e2d\u4e3a\uff1a6666\uff09\u3002\u6211\u4eec\u5c06\u4f7f\u7528torch.distributed.launch\u5728\u7b2c\u4e00\u53f0\u673a\u5668\u4e0a\u8fd0\u884c\u811a\u672c\uff1a python -m torch.distributed.launch --nproc_per_node = 2 --nnodes = 2 --node_rank = 0 --master_addr = \"192.168.100.100\" --master_port = 6666 \u6587\u4ef6\u540d ( --arg1 --arg2 \u7b49\u5176\u4ed6\u53c2\u6570 ) \u7b2c\u4e8c\u53f0\u4e3b\u673a\u4e0a\u53ea\u9700\u8981\u66f4\u6539 --node_rank=0 \u5373\u53ef \u5f88\u6709\u53ef\u80fd\u4f60\u5728\u8fd0\u884c\u7684\u65f6\u5019\u62a5\u9519\uff0c\u90a3\u662f\u56e0\u4e3a\u6211\u4eec\u6ca1\u6709\u8bbe\u7f6eNCCL socket\u7f51\u7edc\u63a5\u53e3\u3002 \u6211\u4eec\u4ee5\u7f51\u5361\u540d\u4e3aens3\u4e3a\u4f8b\uff0c\u8f93\u5165\uff1a export NCCL_SOCKET_IFNAME = ens3 ens3\u8fd9\u4e2a\u540d\u79f0\uff0c\u53ef\u4ee5\u4f7f\u7528ifconfig\u547d\u4ee4\u67e5\u770b\u786e\u8ba4\u3002 \u53c2\u6570\u8bf4\u660e\uff1a --nproc_per_node \uff1a \u4e3b\u673a\u4e2d\u5305\u542b\u7684GPU\u603b\u6570 --nnodes \uff1a \u603b\u8ba1\u7684\u4e3b\u673a\u6570 --node_rank \uff1a\u4e3b\u673a\u4e2d\u7684GPU\u6807\u8bc6 \u5176\u4ed6\u4e00\u4e9b\u53c2\u6570\u53ef\u4ee5\u67e5\u770b \u5b98\u65b9\u7684\u6587\u6863 torch.distributed \u4e0d\u4ec5\u652f\u6301nccl\u8fd8\u652f\u6301\u5176\u4ed6\u7684\u4e24\u4e2a\u540e\u7aef gloo\u548cmpi\uff0c\u5177\u4f53\u7684\u5bf9\u6bd4\u8fd9\u91cc\u5c31\u4e0d\u7ec6\u8bf4\u4e86\uff0c\u8bf7\u67e5\u770b \u5b98\u65b9\u7684\u6587\u6863","title":"4.3.2 torch.distributed"},{"location":"tutorial/chapter04_advanced/4_3_multiply-gpu-parallel-training/#433-torchutilscheckpoint","text":"\u5728\u6211\u4eec\u8bad\u7ec3\u65f6\uff0c\u53ef\u80fd\u4f1a\u9047\u5230\uff08\u76ee\u524d\u6211\u8fd8\u6ca1\u9047\u5230\uff09\u8bad\u7ec3\u96c6\u7684\u5355\u4e2a\u6837\u672c\u6bd4\u5185\u5b58\u8fd8\u8981\u5927\u6839\u672c\u8f7d\u5165\u4e0d\u4e86\uff0c\u90a3\u6211\u6211\u4eec\u5982\u4f55\u6765\u8bad\u7ec3\u5462\uff1f pytorch\u4e3a\u6211\u4eec\u63d0\u4f9b\u4e86\u68af\u5ea6\u68c0\u67e5\u70b9\uff08gradient-checkpointing\uff09\u8282\u7701\u8ba1\u7b97\u8d44\u6e90\uff0c\u68af\u5ea6\u68c0\u67e5\u70b9\u4f1a\u5c06\u6211\u4eec\u8fde\u7eed\u8ba1\u7b97\u7684\u5143\u6b63\u5411\u548c\u5143\u53cd\u5411\u4f20\u64ad\u5207\u5206\u6210\u7247\u6bb5\u3002\u4f46\u7531\u4e8e\u9700\u8981\u589e\u52a0\u989d\u5916\u7684\u8ba1\u7b97\u4ee5\u51cf\u5c11\u5185\u5b58\u9700\u6c42\uff0c\u8be5\u65b9\u6cd5\u6548\u7387\u4f1a\u6709\u4e00\u4e9b\u4e0b\u964d\uff0c\u4f46\u662f\u5b83\u5728\u67d0\u4e9b\u793a\u4f8b\u4e2d\u6709\u8f83\u4e3a\u660e\u663e\u7684\u4f18\u52bf\uff0c\u6bd4\u5982\u5728\u957f\u5e8f\u5217\u4e0a\u8bad\u7ec3RNN\u6a21\u578b\uff0c\u8fd9\u4e2a\u7531\u4e8e\u590d\u73b0\u96be\u5ea6\u8f83\u5927 \u5c31\u4e0d\u4ecb\u7ecd\u4e86\uff0c\u5b98\u65b9\u6587\u6863\u5728 \u8fd9\u91cc \u9047\u5230\u8fd9\u79cd\u60c5\u51b5\u7684\u670b\u53cb\u53ef\u4ee5\u67e5\u770b\u4e0b\u5b98\u65b9\u7684\u89e3\u51b3\u65b9\u6848\u3002","title":"4.3.3 torch.utils.checkpoint"},{"location":"tutorial/chapter04_advanced/4_4_fastai/","text":"import fastai from fastai import * from fastai.vision import * import torch print ( torch . __version__ ) print ( fastai . __version__ ) 1.0.0 1.0.45 4.4 fastai \u00b6 4.4.1 fastai\u4ecb\u7ecd \u00b6 fastai\u5e93 \u00b6 fastai\u5c06\u8bad\u7ec3\u4e00\u4e2a\u51c6\u786e\u7684\u795e\u7ecf\u7f51\u7edc\u53d8\u5f97\u5341\u5206\u7b80\u5355\u3002fastai\u5e93\u662f\u57fa\u4e8e\u4ed6\u7684\u521b\u59cb\u4ebaJeremy Howard \u7b49\u4eba\u5f00\u53d1\u7684 Deep Learning \u8bfe\u7a0b\u6df1\u5ea6\u5b66\u4e60\u7684\u7814\u7a76\uff0c\u4e3a\u8ba1\u7b97\u673a\u89c6\u89c9\u3001\u6587\u672c\u3001\u8868\u683c\u6570\u636e\u3001\u65f6\u95f4\u5e8f\u5217\u3001\u534f\u540c\u8fc7\u6ee4\u7b49\u5e38\u89c1\u6df1\u5ea6\u5b66\u4e60\u5e94\u7528\u63d0\u4f9b\u5355\u4e00\u3001\u4e00\u81f4\u754c\u9762\u7684\u6df1\u5ea6\u5b66\u4e60\u5e93\uff0c\u53ef\u4ee5\u505a\u5230\u5f00\u7bb1\u5373\u7528\u3002\u8fd9\u610f\u5473\u7740\uff0c\u5982\u679c\u4f60\u5df2\u7ecf\u5b66\u4f1a\u7528fastai\u521b\u5efa\u5b9e\u7528\u7684\u8ba1\u7b97\u673a\u89c6\u89c9\uff08CV\uff09\u6a21\u578b\uff0c\u90a3\u4f60\u5c31\u53ef\u4ee5\u7528\u540c\u6837\u7684\u65b9\u6cd5\u521b\u5efa\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u6a21\u578b\uff0c\u6216\u662f\u5176\u4ed6\u6a21\u578b\u3002 fastai \u662f\u76ee\u524d\u628a\u6613\u7528\u6027\u548c\u529f\u80fd\u90fd\u505a\u5230\u4e86\u6781\u81f4\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u6b63\u5982Jeremy\u6240\u8bf4\u7684\uff1a\u5982\u679c\u4e00\u4e2a\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u9700\u8981\u5199\u4e2a\u6559\u7a0b\u7ed9\u4f60\uff0c\u90a3\u5b83\u7684\u6613\u7528\u6027\u8fd8\u4e0d\u591f\u597d\u3002Jeremy \u8bf4\u8fd9\u8bdd\uff0c\u4e0d\u662f\u4e3a\u4e86\u5938\u81ea\u5df1\uff0c\u56e0\u4e3a\u4ed6\u751a\u81f3\u505a\u4e86\u4e2a MOOC \u51fa\u6765\u3002\u4ed6\u81ea\u5df1\u8bc4\u4ef7\u8bf4\u76ee\u524d fastai \u7684\u6613\u7528\u6027\u4f9d\u7136\u4e0d\u7b97\u6210\u529f\u3002\u4f46\u5728\u6211\u770b\u6765\u5b83\u7684\u95e8\u69db\u6781\u4f4e\uff0c\u4f60\u53ef\u4ee5\u5f88\u8f7b\u6613\u7528\u51e0\u53e5\u8bdd\u5199\u4e2a\u56fe\u7247\u5206\u7c7b\u6a21\u578b\u51fa\u6765\uff0c\u4eba\u4eba\u90fd\u80fd\u7acb\u5373\u4e0a\u624b\uff0c\u4f60\u751a\u81f3\u4e0d\u9700\u8981\u77e5\u9053\u6df1\u5ea6\u5b66\u4e60\u7684\u7406\u8bba\u3002 fast.ai\u8bfe\u7a0b \u00b6 \u4e0a\u9762\u8bf4\u5230\u4e86\u8bfe\u7a0b\uff0c\u8fd9\u91cc\u5bf9fast.ai\u7684\u8bfe\u7a0b\u505a\u4e00\u4e2a\u7b80\u5355\u7684\u4ecb\u7ecd\uff1a \u8bfe\u7a0b\u662f\u7531kaggle\u8d5b\u4e8b\u8001\u53f8\u673a\uff0c\u8fde\u7eed\u4e24\u5e74\u51a0\u519bJeremy Howard \u548c Rachel Tomas \u8054\u5408\u521b\u529e\uff0c\u65e8\u5728\u8ba9\u66f4\u591a\u4eba\u80fd\u63a5\u53d7\u6df1\u5ea6\u5b66\u4e60\u7684\u8bfe\u7a0b\uff0c\u800c\u4e14\u662f\u5b8c\u5168\u514d\u8d39\uff01\u771f\u7684\u662f\u4e1a\u754c\u826f\u5fc3\uff0c\u8fd9\u4e24\u5e74\u6df1\u5ea6\u5b66\u4e60\u706b\u4e86\u8d77\u6765\uff0c\u56fd\u5185\u6709\u57f9\u8bad\u673a\u6784\u63a8\u51fa\u6536\u8d39\u8bfe\u7a0b\u4e86\uff0c\u6559\u5b66\u6c34\u5e73\u53c2\u5dee\u4e0d\u9f50\u3002\u800cJeremy\u548cRachel\u63a8\u51fa\u7684\u8bfe\u7a0b\uff0c\u6070\u6070\u63d0\u73b0\u4e86\u4ed6\u4eec\u7684\u6559\u80b2\u7406\u5ff5\uff1a Make deep learning uncool ! \uff08\u8ba9\u6df1\u5ea6\u5b66\u4e60\u53d8\u5f97\u6ca1\u90a3\u4e48\u9ad8\u5927\u4e0a\uff09 Fast.ai\u7ed9\u4eba\u7684\u5370\u8c61\u4e00\u76f4\u5f88\u201c\u63a5\u5730\u6c14\u201d\uff1a - \u7814\u7a76\u5982\u4f55\u5feb\u901f\u3001\u53ef\u9760\u5730\u628a\u6700\u5148\u8fdb\u7684\u6df1\u5ea6\u5b66\u4e60\u5e94\u7528\u4e8e\u5b9e\u9645\u95ee\u9898\u3002 - \u63d0\u4f9bFast.ai\u5e93\uff0c\u5b83\u4e0d\u4ec5\u662f\u8ba9\u65b0\u624b\u5feb\u901f\u6784\u5efa\u6df1\u5ea6\u5b66\u4e60\u5b9e\u73b0\u7684\u5de5\u5177\u5305\uff0c\u4e5f\u662f\u63d0\u4f9b\u6700\u4f73\u5b9e\u8df5\u7684\u4e00\u4e2a\u5f3a\u5927\u800c\u4fbf\u6377\u7684\u8d44\u6e90\u3002 - \u8bfe\u7a0b\u5185\u5bb9\u7b80\u6d01\u6613\u61c2\uff0c\u4ee5\u4fbf\u5c3d\u53ef\u80fd\u591a\u7684\u4eba\u4ece\u7814\u7a76\u6210\u679c\u548c\u8f6f\u4ef6\u4e2d\u6536\u76ca\u3002 Github \u00b6 \u8fd9\u4e2a\u5b98\u65b9\u7684Github\u5305\u542b\u4e86fastai\u7684\u6240\u6709\u5185\u5bb9 https://github.com/fastai 4.4.2 fastai\u5b9e\u8df5 \u00b6 MNIST \u00b6 \u6211\u4eec\u8fd8\u662f\u4ee5\u6700\u7b80\u5355\u7684MNIST\u6765\u5165\u624b\u770b\u770bfastai\u90fd\u4e3a\u6211\u4eec\u505a\u4e86\u4ec0\u4e48\u3002 # \u4f7f\u7528fastai\u5185\u7f6e\u7684MNIST\u6570\u636e\u96c6\uff0c\u8fd9\u91cc\u4f1a\u4ecefastai\u7684\u670d\u52a1\u5668\u4e0b\u8f7d path = untar_data ( URLs . MNIST_SAMPLE ) URLs.MNIST_SAMPLE \u53ea\u63d0\u4f9b\u4e863\u548c7 \u4e24\u4e2a\u5206\u7c7b\u7684\u6570\u636e\uff0c\u8fd9\u4e2a\u662f\u7528\u6765\u505a\u6f14\u793a\u7684\uff0c\u6211\u4eec\u6b63\u597d\u4e5f\u505a\u4e2a\u6f14\u793a\u3002 \u8fd9\u91cc\u5982\u679c\u4e0b\u8f7d\u5f88\u6162\u7684\u8bdd\uff0c\u90a3\u4e48\u6211\u4eec\u53ef\u4ee5\u624b\u52a8\u8fdb\u884c\u64cd\u4f5c\uff08\u5efa\u8bae\u8fd9\u6837\uff0c\u6bd4\u7a0b\u5e8f\u4e0b\u8f7d\u5feb\u5f88\u591a\u800c\u4e14\u7a33\u5b9a\uff09\u3002 #\u8fdb\u5165\u6211\u4eec\u7528\u6237\u76ee\u5f55\uff0c\u521b\u5efa\u4ee5\u4e0b\u7684\u76ee\u5f55 mkdir -p ~/.fastai/data cd ~/.fastai/data # \u4e0b\u8f7d\u89e3\u538b wget -c http://files.fast.ai/data/examples/mnist_sample.tgz tar -zxvf mnist_sample.tgz \u5b8c\u6210\u540e\u91cd\u65b0\u6267\u884c\u4e0a\u9762\u7684\u547d\u4ee4\u5373\u53ef\u3002 #\u4f7f\u7528ImageDataBunch\u4ece\u521a\u624d\u7684\u76ee\u5f55\u4e2d\u5c06\u8bfb\u5165\u6570\u636e data = ImageDataBunch . from_folder ( path ) # \u53ef\u4ee5\u770b\u4e00\u4e0bdata\u91cc\u9762\u6709\u4ec0\u4e48\uff1f data ImageDataBunch; Train: LabelList (12396 items) x: ImageItemList Image (3, 28, 28),Image (3, 28, 28),Image (3, 28, 28),Image (3, 28, 28),Image (3, 28, 28) y: CategoryList 7,7,7,7,7 Path: /Users/tant/.fastai/data/mnist_sample; Valid: LabelList (2038 items) x: ImageItemList Image (3, 28, 28),Image (3, 28, 28),Image (3, 28, 28),Image (3, 28, 28),Image (3, 28, 28) y: CategoryList 7,7,7,7,7 Path: /Users/tant/.fastai/data/mnist_sample; Test: None # \u4f7f\u7528cnn_learner\u6765\u521b\u5efa\u4e00\u4e2alearn\uff0c\u8fd9\u91cc\u6a21\u578b\u6211\u4eec\u9009\u62e9resnet18\uff0c\u4f7f\u7528\u7684\u8ba1\u91cf\u65b9\u6cd5\u662faccuracy\u51c6\u786e\u7387 learn = create_cnn ( data , models . resnet18 , metrics = accuracy ) #\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528train_ds\u6765\u8bbf\u95ee\u6570\u636e\u96c6\u91cc\u9762\u7684\u6570\u636e img , label = data . train_ds [ 0 ] print ( label ) img 7 #\u6216\u8005\u6211\u4eec\u76f4\u63a5\u4f7f\u7528show_batch\u65b9\u6cd5\uff0c\u8fde\u6807\u7b7e\u90fd\u7ed9\u6211\u4eec\u81ea\u52a8\u751f\u6210\u597d\u4e86 data . show_batch ( rows = 3 , figsize = ( 6 , 6 )) \u8fd9\u91cc\u4e5f\u662f\u76f4\u63a5\u4e0b\u8f7dPyTorch\u5b98\u65b9\u63d0\u4f9b\u7684resnet18\u4e0e\u8bad\u7ec3\u6a21\u578b\uff1a wget -P /Users/tant/.torch/models/ https://download.pytorch.org/models/resnet18-5c106cde.pth # \u4f7f\u7528learn\u7684fit\u65b9\u6cd5\u5c31\u53ef\u4ee5\u8fdb\u884c\u8bad\u7ec3\u4e86\uff0c\u8bad\u7ec3\u4e00\u904d learn . fit ( 1 ) Total time: 02:21 epoch train_loss valid_loss accuracy 1 0.130960 0.086702 0.969087 \u7ecf\u8fc7\u4e0a\u9762\u7684\u8bad\u7ec3\uff0c\u4f60\u4e00\u5b9a\u4f1a\u5f88\u7eb3\u95f7\uff1a - \u6ca1\u6709\u544a\u8bc9\u6a21\u578b\u7c7b\u522b\u6709\u51e0\u4e2a - \u6ca1\u6709\u6307\u5b9a\u4efb\u52a1\u8fc1\u79fb\u4e4b\u540e\u63a5\u7eed\u7684\u51e0\u4e2a\u5c42\u6b21\u7684\u6570\u91cf\u3001\u5927\u5c0f\u3001\u6fc0\u6d3b\u51fd\u6570 - \u6ca1\u6709\u544a\u8bc9\u7f51\u7edc\u635f\u5931\u51fd\u6570\u662f\u4ec0\u4e48 \u6211\u51e0\u4e4e\u6ca1\u6709\u63d0\u4f9b\u4efb\u4f55\u7684\u4fe1\u606f\uff0c\u7f51\u7edc\u5c31\u5f00\u59cb\u8bad\u7ec3\u4e86\uff1f \u5bf9\uff0c\u4e0d\u9700\u8981\u3002 \u56e0\u4e3a fastai \u6839\u636e\u4f60\u8f93\u5165\u7684\u4e0a\u8ff0\u201c\u6570\u636e\u201d\u3001\u201c\u6a21\u578b\u7ed3\u6784\u201d\u548c\u201c\u635f\u5931\u5ea6\u91cf\u201d\u4fe1\u606f\uff0c\u81ea\u52a8\u5e2e\u4f60\u628a\u8fd9\u4e9b\u95f2\u4e03\u6742\u516b\u7684\u4e8b\u60c5\u9ed8\u9ed8\u641e\u5b9a\u4e86\u3002 \u4e0b\u9762\u518d\u4ecb\u7ecd\u4e00\u4e9b\u8bad\u7ec3\u7684\u9ad8\u7ea7\u7528\u6cd5\uff1a #\u4ece\u65b0\u751f\u6210\u4e00\u4e2a\u6570\u636e\u96c6 learn2 = create_cnn ( data , models . resnet18 , metrics = accuracy , callback_fns = ShowGraph ) \u8fd9\u91cc\u6211\u4eec\u4f7f\u7528fit_one_cycle\u65b9\u6cd5\u3002 fit_one_cycle\u4f7f\u7528\u7684\u662f\u4e00\u79cd\u5468\u671f\u6027\u5b66\u4e60\u7387\uff0c\u4ece\u8f83\u5c0f\u7684\u5b66\u4e60\u7387\u5f00\u59cb\u5b66\u4e60\uff0c\u7f13\u6162\u63d0\u9ad8\u81f3\u8f83\u9ad8\u7684\u5b66\u4e60\u7387\uff0c\u7136\u540e\u518d\u6162\u6162\u4e0b\u964d\uff0c\u5468\u800c\u590d\u59cb\uff0c\u6bcf\u4e2a\u5468\u671f\u7684\u957f\u5ea6\u7565\u5fae\u7f29\u77ed\uff0c\u5728\u8bad\u7ec3\u7684\u6700\u540e\u90e8\u5206\uff0c\u5141\u8bb8\u5b66\u4e60\u7387\u6bd4\u4e4b\u524d\u7684\u6700\u5c0f\u503c\u964d\u5f97\u66f4\u4f4e\u3002\u8fd9\u4e0d\u4ec5\u53ef\u4ee5\u52a0\u901f\u8bad\u7ec3\uff0c\u8fd8\u6709\u52a9\u4e8e\u9632\u6b62\u6a21\u578b\u843d\u5165\u635f\u5931\u5e73\u9762\u7684\u9661\u5ced\u533a\u57df\uff0c\u4f7f\u6a21\u578b\u66f4\u503e\u5411\u4e8e\u5bfb\u627e\u66f4\u5e73\u5766\u7684\u6781\u5c0f\u503c\uff0c\u4ece\u800c\u7f13\u89e3\u8fc7\u62df\u5408\u73b0\u8c61\u3002 learn2 . fit_one_cycle ( 1 ) Total time: 02:21 epoch train_loss valid_loss accuracy 1 0.167809 0.118627 0.956330 \u6211\u4eec\u4f7f\u7528\u5185\u7f6eShowGraph\u7684\u65b9\u6cd5\u76f4\u63a5\u6253\u5370\u8bad\u7ec3\u7684\u72b6\u6001\uff0c\u5982\u679c\u6211\u4eec\u9700\u8981\u66f4\u8be6\u7ec6\u7684\u72b6\u6001\uff0c\u53ef\u4ee5\u76f4\u63a5\u8c03\u7528\u4e00\u4e0b\u7684\u65b9\u6cd5\uff1a # \u5b66\u4e60\u7387\u7684\u53d8\u66f4 learn2 . recorder . plot_lr () #\u635f\u5931 learn2 . recorder . plot_losses () # \u6211\u4eec\u4e5f\u53ef\u4ee5\u4f7f\u7528lr_find()\u627e\u5230\u635f\u5931\u4ecd\u5728\u660e\u663e\u6539\u5584\u6700\u9ad8\u5b66\u4e60\u7387 learn2 . lr_find () learn2 . recorder . plot () LR Finder is complete, type {learner_name}.recorder.plot() to see the graph. Min numerical gradient: 6.31E-07 4.4.3 fastai\u6587\u6863\u7ffb\u8bd1 \u00b6 \u7531\u4e8efastai\u7684\u4e2d\u6587\u8d44\u6599\u5f88\u5c11\u800c\u4e14\u76ee\u524d\u5b98\u65b9\u53ea\u63d0\u4f9b\u82f1\u6587\u7684\u6587\u6863\uff0c\u6240\u4ee5\u5982\u679c\u8c01\u6709\u5174\u8da3\u4e00\u8d77\u7ffb\u8bd1\u7684\u8bdd\u53ef\u4ee5\u8054\u7cfb\u6211\uff0c\u5982\u679c\u4eba\u6570\u591f\u4e86\u7684\u8bdd\u53ef\u4ee5\u7ec4\u4e2a\u56e2\u961f\u4e00\u8d77\u7ffb\u8bd1\u3002","title":"FastAI"},{"location":"tutorial/chapter04_advanced/4_4_fastai/#44-fastai","text":"","title":"4.4 fastai"},{"location":"tutorial/chapter04_advanced/4_4_fastai/#441-fastai","text":"","title":"4.4.1 fastai\u4ecb\u7ecd"},{"location":"tutorial/chapter04_advanced/4_4_fastai/#fastai","text":"fastai\u5c06\u8bad\u7ec3\u4e00\u4e2a\u51c6\u786e\u7684\u795e\u7ecf\u7f51\u7edc\u53d8\u5f97\u5341\u5206\u7b80\u5355\u3002fastai\u5e93\u662f\u57fa\u4e8e\u4ed6\u7684\u521b\u59cb\u4ebaJeremy Howard \u7b49\u4eba\u5f00\u53d1\u7684 Deep Learning \u8bfe\u7a0b\u6df1\u5ea6\u5b66\u4e60\u7684\u7814\u7a76\uff0c\u4e3a\u8ba1\u7b97\u673a\u89c6\u89c9\u3001\u6587\u672c\u3001\u8868\u683c\u6570\u636e\u3001\u65f6\u95f4\u5e8f\u5217\u3001\u534f\u540c\u8fc7\u6ee4\u7b49\u5e38\u89c1\u6df1\u5ea6\u5b66\u4e60\u5e94\u7528\u63d0\u4f9b\u5355\u4e00\u3001\u4e00\u81f4\u754c\u9762\u7684\u6df1\u5ea6\u5b66\u4e60\u5e93\uff0c\u53ef\u4ee5\u505a\u5230\u5f00\u7bb1\u5373\u7528\u3002\u8fd9\u610f\u5473\u7740\uff0c\u5982\u679c\u4f60\u5df2\u7ecf\u5b66\u4f1a\u7528fastai\u521b\u5efa\u5b9e\u7528\u7684\u8ba1\u7b97\u673a\u89c6\u89c9\uff08CV\uff09\u6a21\u578b\uff0c\u90a3\u4f60\u5c31\u53ef\u4ee5\u7528\u540c\u6837\u7684\u65b9\u6cd5\u521b\u5efa\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u6a21\u578b\uff0c\u6216\u662f\u5176\u4ed6\u6a21\u578b\u3002 fastai \u662f\u76ee\u524d\u628a\u6613\u7528\u6027\u548c\u529f\u80fd\u90fd\u505a\u5230\u4e86\u6781\u81f4\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u6b63\u5982Jeremy\u6240\u8bf4\u7684\uff1a\u5982\u679c\u4e00\u4e2a\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u9700\u8981\u5199\u4e2a\u6559\u7a0b\u7ed9\u4f60\uff0c\u90a3\u5b83\u7684\u6613\u7528\u6027\u8fd8\u4e0d\u591f\u597d\u3002Jeremy \u8bf4\u8fd9\u8bdd\uff0c\u4e0d\u662f\u4e3a\u4e86\u5938\u81ea\u5df1\uff0c\u56e0\u4e3a\u4ed6\u751a\u81f3\u505a\u4e86\u4e2a MOOC \u51fa\u6765\u3002\u4ed6\u81ea\u5df1\u8bc4\u4ef7\u8bf4\u76ee\u524d fastai \u7684\u6613\u7528\u6027\u4f9d\u7136\u4e0d\u7b97\u6210\u529f\u3002\u4f46\u5728\u6211\u770b\u6765\u5b83\u7684\u95e8\u69db\u6781\u4f4e\uff0c\u4f60\u53ef\u4ee5\u5f88\u8f7b\u6613\u7528\u51e0\u53e5\u8bdd\u5199\u4e2a\u56fe\u7247\u5206\u7c7b\u6a21\u578b\u51fa\u6765\uff0c\u4eba\u4eba\u90fd\u80fd\u7acb\u5373\u4e0a\u624b\uff0c\u4f60\u751a\u81f3\u4e0d\u9700\u8981\u77e5\u9053\u6df1\u5ea6\u5b66\u4e60\u7684\u7406\u8bba\u3002","title":"fastai\u5e93"},{"location":"tutorial/chapter04_advanced/4_4_fastai/#fastai_1","text":"\u4e0a\u9762\u8bf4\u5230\u4e86\u8bfe\u7a0b\uff0c\u8fd9\u91cc\u5bf9fast.ai\u7684\u8bfe\u7a0b\u505a\u4e00\u4e2a\u7b80\u5355\u7684\u4ecb\u7ecd\uff1a \u8bfe\u7a0b\u662f\u7531kaggle\u8d5b\u4e8b\u8001\u53f8\u673a\uff0c\u8fde\u7eed\u4e24\u5e74\u51a0\u519bJeremy Howard \u548c Rachel Tomas \u8054\u5408\u521b\u529e\uff0c\u65e8\u5728\u8ba9\u66f4\u591a\u4eba\u80fd\u63a5\u53d7\u6df1\u5ea6\u5b66\u4e60\u7684\u8bfe\u7a0b\uff0c\u800c\u4e14\u662f\u5b8c\u5168\u514d\u8d39\uff01\u771f\u7684\u662f\u4e1a\u754c\u826f\u5fc3\uff0c\u8fd9\u4e24\u5e74\u6df1\u5ea6\u5b66\u4e60\u706b\u4e86\u8d77\u6765\uff0c\u56fd\u5185\u6709\u57f9\u8bad\u673a\u6784\u63a8\u51fa\u6536\u8d39\u8bfe\u7a0b\u4e86\uff0c\u6559\u5b66\u6c34\u5e73\u53c2\u5dee\u4e0d\u9f50\u3002\u800cJeremy\u548cRachel\u63a8\u51fa\u7684\u8bfe\u7a0b\uff0c\u6070\u6070\u63d0\u73b0\u4e86\u4ed6\u4eec\u7684\u6559\u80b2\u7406\u5ff5\uff1a Make deep learning uncool ! \uff08\u8ba9\u6df1\u5ea6\u5b66\u4e60\u53d8\u5f97\u6ca1\u90a3\u4e48\u9ad8\u5927\u4e0a\uff09 Fast.ai\u7ed9\u4eba\u7684\u5370\u8c61\u4e00\u76f4\u5f88\u201c\u63a5\u5730\u6c14\u201d\uff1a - \u7814\u7a76\u5982\u4f55\u5feb\u901f\u3001\u53ef\u9760\u5730\u628a\u6700\u5148\u8fdb\u7684\u6df1\u5ea6\u5b66\u4e60\u5e94\u7528\u4e8e\u5b9e\u9645\u95ee\u9898\u3002 - \u63d0\u4f9bFast.ai\u5e93\uff0c\u5b83\u4e0d\u4ec5\u662f\u8ba9\u65b0\u624b\u5feb\u901f\u6784\u5efa\u6df1\u5ea6\u5b66\u4e60\u5b9e\u73b0\u7684\u5de5\u5177\u5305\uff0c\u4e5f\u662f\u63d0\u4f9b\u6700\u4f73\u5b9e\u8df5\u7684\u4e00\u4e2a\u5f3a\u5927\u800c\u4fbf\u6377\u7684\u8d44\u6e90\u3002 - \u8bfe\u7a0b\u5185\u5bb9\u7b80\u6d01\u6613\u61c2\uff0c\u4ee5\u4fbf\u5c3d\u53ef\u80fd\u591a\u7684\u4eba\u4ece\u7814\u7a76\u6210\u679c\u548c\u8f6f\u4ef6\u4e2d\u6536\u76ca\u3002","title":"fast.ai\u8bfe\u7a0b"},{"location":"tutorial/chapter04_advanced/4_4_fastai/#github","text":"\u8fd9\u4e2a\u5b98\u65b9\u7684Github\u5305\u542b\u4e86fastai\u7684\u6240\u6709\u5185\u5bb9 https://github.com/fastai","title":"Github"},{"location":"tutorial/chapter04_advanced/4_4_fastai/#442-fastai","text":"","title":"4.4.2 fastai\u5b9e\u8df5"},{"location":"tutorial/chapter04_advanced/4_4_fastai/#mnist","text":"\u6211\u4eec\u8fd8\u662f\u4ee5\u6700\u7b80\u5355\u7684MNIST\u6765\u5165\u624b\u770b\u770bfastai\u90fd\u4e3a\u6211\u4eec\u505a\u4e86\u4ec0\u4e48\u3002 # \u4f7f\u7528fastai\u5185\u7f6e\u7684MNIST\u6570\u636e\u96c6\uff0c\u8fd9\u91cc\u4f1a\u4ecefastai\u7684\u670d\u52a1\u5668\u4e0b\u8f7d path = untar_data ( URLs . MNIST_SAMPLE ) URLs.MNIST_SAMPLE \u53ea\u63d0\u4f9b\u4e863\u548c7 \u4e24\u4e2a\u5206\u7c7b\u7684\u6570\u636e\uff0c\u8fd9\u4e2a\u662f\u7528\u6765\u505a\u6f14\u793a\u7684\uff0c\u6211\u4eec\u6b63\u597d\u4e5f\u505a\u4e2a\u6f14\u793a\u3002 \u8fd9\u91cc\u5982\u679c\u4e0b\u8f7d\u5f88\u6162\u7684\u8bdd\uff0c\u90a3\u4e48\u6211\u4eec\u53ef\u4ee5\u624b\u52a8\u8fdb\u884c\u64cd\u4f5c\uff08\u5efa\u8bae\u8fd9\u6837\uff0c\u6bd4\u7a0b\u5e8f\u4e0b\u8f7d\u5feb\u5f88\u591a\u800c\u4e14\u7a33\u5b9a\uff09\u3002 #\u8fdb\u5165\u6211\u4eec\u7528\u6237\u76ee\u5f55\uff0c\u521b\u5efa\u4ee5\u4e0b\u7684\u76ee\u5f55 mkdir -p ~/.fastai/data cd ~/.fastai/data # \u4e0b\u8f7d\u89e3\u538b wget -c http://files.fast.ai/data/examples/mnist_sample.tgz tar -zxvf mnist_sample.tgz \u5b8c\u6210\u540e\u91cd\u65b0\u6267\u884c\u4e0a\u9762\u7684\u547d\u4ee4\u5373\u53ef\u3002 #\u4f7f\u7528ImageDataBunch\u4ece\u521a\u624d\u7684\u76ee\u5f55\u4e2d\u5c06\u8bfb\u5165\u6570\u636e data = ImageDataBunch . from_folder ( path ) # \u53ef\u4ee5\u770b\u4e00\u4e0bdata\u91cc\u9762\u6709\u4ec0\u4e48\uff1f data ImageDataBunch; Train: LabelList (12396 items) x: ImageItemList Image (3, 28, 28),Image (3, 28, 28),Image (3, 28, 28),Image (3, 28, 28),Image (3, 28, 28) y: CategoryList 7,7,7,7,7 Path: /Users/tant/.fastai/data/mnist_sample; Valid: LabelList (2038 items) x: ImageItemList Image (3, 28, 28),Image (3, 28, 28),Image (3, 28, 28),Image (3, 28, 28),Image (3, 28, 28) y: CategoryList 7,7,7,7,7 Path: /Users/tant/.fastai/data/mnist_sample; Test: None # \u4f7f\u7528cnn_learner\u6765\u521b\u5efa\u4e00\u4e2alearn\uff0c\u8fd9\u91cc\u6a21\u578b\u6211\u4eec\u9009\u62e9resnet18\uff0c\u4f7f\u7528\u7684\u8ba1\u91cf\u65b9\u6cd5\u662faccuracy\u51c6\u786e\u7387 learn = create_cnn ( data , models . resnet18 , metrics = accuracy ) #\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528train_ds\u6765\u8bbf\u95ee\u6570\u636e\u96c6\u91cc\u9762\u7684\u6570\u636e img , label = data . train_ds [ 0 ] print ( label ) img 7 #\u6216\u8005\u6211\u4eec\u76f4\u63a5\u4f7f\u7528show_batch\u65b9\u6cd5\uff0c\u8fde\u6807\u7b7e\u90fd\u7ed9\u6211\u4eec\u81ea\u52a8\u751f\u6210\u597d\u4e86 data . show_batch ( rows = 3 , figsize = ( 6 , 6 )) \u8fd9\u91cc\u4e5f\u662f\u76f4\u63a5\u4e0b\u8f7dPyTorch\u5b98\u65b9\u63d0\u4f9b\u7684resnet18\u4e0e\u8bad\u7ec3\u6a21\u578b\uff1a wget -P /Users/tant/.torch/models/ https://download.pytorch.org/models/resnet18-5c106cde.pth # \u4f7f\u7528learn\u7684fit\u65b9\u6cd5\u5c31\u53ef\u4ee5\u8fdb\u884c\u8bad\u7ec3\u4e86\uff0c\u8bad\u7ec3\u4e00\u904d learn . fit ( 1 ) Total time: 02:21 epoch train_loss valid_loss accuracy 1 0.130960 0.086702 0.969087 \u7ecf\u8fc7\u4e0a\u9762\u7684\u8bad\u7ec3\uff0c\u4f60\u4e00\u5b9a\u4f1a\u5f88\u7eb3\u95f7\uff1a - \u6ca1\u6709\u544a\u8bc9\u6a21\u578b\u7c7b\u522b\u6709\u51e0\u4e2a - \u6ca1\u6709\u6307\u5b9a\u4efb\u52a1\u8fc1\u79fb\u4e4b\u540e\u63a5\u7eed\u7684\u51e0\u4e2a\u5c42\u6b21\u7684\u6570\u91cf\u3001\u5927\u5c0f\u3001\u6fc0\u6d3b\u51fd\u6570 - \u6ca1\u6709\u544a\u8bc9\u7f51\u7edc\u635f\u5931\u51fd\u6570\u662f\u4ec0\u4e48 \u6211\u51e0\u4e4e\u6ca1\u6709\u63d0\u4f9b\u4efb\u4f55\u7684\u4fe1\u606f\uff0c\u7f51\u7edc\u5c31\u5f00\u59cb\u8bad\u7ec3\u4e86\uff1f \u5bf9\uff0c\u4e0d\u9700\u8981\u3002 \u56e0\u4e3a fastai \u6839\u636e\u4f60\u8f93\u5165\u7684\u4e0a\u8ff0\u201c\u6570\u636e\u201d\u3001\u201c\u6a21\u578b\u7ed3\u6784\u201d\u548c\u201c\u635f\u5931\u5ea6\u91cf\u201d\u4fe1\u606f\uff0c\u81ea\u52a8\u5e2e\u4f60\u628a\u8fd9\u4e9b\u95f2\u4e03\u6742\u516b\u7684\u4e8b\u60c5\u9ed8\u9ed8\u641e\u5b9a\u4e86\u3002 \u4e0b\u9762\u518d\u4ecb\u7ecd\u4e00\u4e9b\u8bad\u7ec3\u7684\u9ad8\u7ea7\u7528\u6cd5\uff1a #\u4ece\u65b0\u751f\u6210\u4e00\u4e2a\u6570\u636e\u96c6 learn2 = create_cnn ( data , models . resnet18 , metrics = accuracy , callback_fns = ShowGraph ) \u8fd9\u91cc\u6211\u4eec\u4f7f\u7528fit_one_cycle\u65b9\u6cd5\u3002 fit_one_cycle\u4f7f\u7528\u7684\u662f\u4e00\u79cd\u5468\u671f\u6027\u5b66\u4e60\u7387\uff0c\u4ece\u8f83\u5c0f\u7684\u5b66\u4e60\u7387\u5f00\u59cb\u5b66\u4e60\uff0c\u7f13\u6162\u63d0\u9ad8\u81f3\u8f83\u9ad8\u7684\u5b66\u4e60\u7387\uff0c\u7136\u540e\u518d\u6162\u6162\u4e0b\u964d\uff0c\u5468\u800c\u590d\u59cb\uff0c\u6bcf\u4e2a\u5468\u671f\u7684\u957f\u5ea6\u7565\u5fae\u7f29\u77ed\uff0c\u5728\u8bad\u7ec3\u7684\u6700\u540e\u90e8\u5206\uff0c\u5141\u8bb8\u5b66\u4e60\u7387\u6bd4\u4e4b\u524d\u7684\u6700\u5c0f\u503c\u964d\u5f97\u66f4\u4f4e\u3002\u8fd9\u4e0d\u4ec5\u53ef\u4ee5\u52a0\u901f\u8bad\u7ec3\uff0c\u8fd8\u6709\u52a9\u4e8e\u9632\u6b62\u6a21\u578b\u843d\u5165\u635f\u5931\u5e73\u9762\u7684\u9661\u5ced\u533a\u57df\uff0c\u4f7f\u6a21\u578b\u66f4\u503e\u5411\u4e8e\u5bfb\u627e\u66f4\u5e73\u5766\u7684\u6781\u5c0f\u503c\uff0c\u4ece\u800c\u7f13\u89e3\u8fc7\u62df\u5408\u73b0\u8c61\u3002 learn2 . fit_one_cycle ( 1 ) Total time: 02:21 epoch train_loss valid_loss accuracy 1 0.167809 0.118627 0.956330 \u6211\u4eec\u4f7f\u7528\u5185\u7f6eShowGraph\u7684\u65b9\u6cd5\u76f4\u63a5\u6253\u5370\u8bad\u7ec3\u7684\u72b6\u6001\uff0c\u5982\u679c\u6211\u4eec\u9700\u8981\u66f4\u8be6\u7ec6\u7684\u72b6\u6001\uff0c\u53ef\u4ee5\u76f4\u63a5\u8c03\u7528\u4e00\u4e0b\u7684\u65b9\u6cd5\uff1a # \u5b66\u4e60\u7387\u7684\u53d8\u66f4 learn2 . recorder . plot_lr () #\u635f\u5931 learn2 . recorder . plot_losses () # \u6211\u4eec\u4e5f\u53ef\u4ee5\u4f7f\u7528lr_find()\u627e\u5230\u635f\u5931\u4ecd\u5728\u660e\u663e\u6539\u5584\u6700\u9ad8\u5b66\u4e60\u7387 learn2 . lr_find () learn2 . recorder . plot () LR Finder is complete, type {learner_name}.recorder.plot() to see the graph. Min numerical gradient: 6.31E-07","title":"MNIST"},{"location":"tutorial/chapter04_advanced/4_4_fastai/#443-fastai","text":"\u7531\u4e8efastai\u7684\u4e2d\u6587\u8d44\u6599\u5f88\u5c11\u800c\u4e14\u76ee\u524d\u5b98\u65b9\u53ea\u63d0\u4f9b\u82f1\u6587\u7684\u6587\u6863\uff0c\u6240\u4ee5\u5982\u679c\u8c01\u6709\u5174\u8da3\u4e00\u8d77\u7ffb\u8bd1\u7684\u8bdd\u53ef\u4ee5\u8054\u7cfb\u6211\uff0c\u5982\u679c\u4eba\u6570\u591f\u4e86\u7684\u8bdd\u53ef\u4ee5\u7ec4\u4e2a\u56e2\u961f\u4e00\u8d77\u7ffb\u8bd1\u3002","title":"4.4.3 fastai\u6587\u6863\u7ffb\u8bd1"},{"location":"tutorial/chapter05_application/5_1_kaggle/","text":"5.1 kaggle\u4ecb\u7ecd \u00b6 5.1.1 Kaggle \u00b6 \u5e73\u53f0\u7b80\u4ecb \u00b6 Kaggle\u662f\u7531\u8054\u5408\u521b\u59cb\u4eba\u3001\u9996\u5e2d\u6267\u884c\u5b98\u5b89\u4e1c\u5c3c\u00b7\u9ad8\u5fb7\u5e03\u5362\u59c6\uff08Anthony Goldbloom\uff092010\u5e74\u5728\u58a8\u5c14\u672c\u521b\u7acb\u7684\uff0c\u4e3b\u8981\u4e3a\u5f00\u53d1\u5546\u548c\u6570\u636e\u79d1\u5b66\u5bb6\u63d0\u4f9b\u4e3e\u529e\u673a\u5668\u5b66\u4e60\u7ade\u8d5b\u3001\u6258\u7ba1\u6570\u636e\u5e93\u3001\u7f16\u5199\u548c\u5206\u4eab\u4ee3\u7801\u7684\u5e73\u53f0\u3002\u8be5\u5e73\u53f0\u5df2\u7ecf\u5438\u5f15\u4e8680\u4e07\u540d\u6570\u636e\u79d1\u5b66\u5bb6\u7684\u5173\u6ce8\uff0c\u8fd9\u4e9b\u7528\u6237\u8d44\u6e90\u6216\u8bb8\u6b63\u662f\u5438\u5f15\u8c37\u6b4c\u7684\u4e3b\u8981\u56e0\u7d20\u3002 \u672c\u6bb5\u6458\u81ea \u767e\u5ea6\u767e\u79d1 \u901a\u4fd7\u7684\u8bf4\uff0cKaggle\u4e0a\u9762\u6709\u7740\u5404\u79cd\u9ad8\u8d28\u91cf\u7684\u6570\u636e\u96c6\uff0c\u5e76\u4e14\u57fa\u4e8e\u8fd9\u4e9b\u6570\u636e\u96c6\u4f1a\u6709\u4e00\u4e9b\u5927\u7684\u516c\u53f8\u8fdb\u884c\u8d5e\u52a9\uff0c\u6765\u4e3e\u529e\u4e00\u4e9b\u7b97\u6cd5\u7684\u7ade\u8d5b\uff0c\u5728\u7ade\u8d5b\u65f6\u8fd8\u53ef\u901a\u8fc7\u793e\u533a\u8fdb\u884c\u8ba8\u8bba\uff08\u5305\u62ec\u6bd4\u8d5b\u4e2d\u7684\u5206\u4eab\u3001\u7b54\u7591\uff0c\u548c\u6bd4\u8d5b\u540e\u7684top solution\u5206\u4eab\uff09\u3002\u8fd9\u6837\u5c31\u4f7f\u5f97\u5168\u7403\u7684\u9876\u5c16\u9ad8\u624b\u4f1a\u5bf9\u53c2\u52a0\u6bd4\u8d5b\u4ea7\u751f\u5174\u8da3\uff0c\u56e0\u4e3a\u6536\u83b7\u5230\u7684\u4e0d\u4ec5\u6709\u5956\u91d1\u8fd8\u6709\u540d\u6c14\u3002\u540c\u65f6kaggle\u5bf9\u840c\u65b0\u4e5f\u5f88\u53cb\u597d\uff0c\u5728\u793e\u533a\u4e2d\u53ef\u4ee5\u5b66\u5230\u5f88\u591a\u7684\u77e5\u8bc6\u548c\u89e3\u51b3\u65b9\u6848\uff08top solution\uff09\u3002 \u6bd4\u8d5b\u4ecb\u7ecd \u00b6 kaggle \u7f51\u7ad9\u662f\u7eaf\u82f1\u6587\u7684\uff0c\u6211\u4eec\u53ef\u4ee5\u628a\u6bd4\u8d5b\u5206\u4e3a2\u7c7b: \u7ade\u8d5bcompetitions\uff1a\u7ade\u8d5b\u7684\u76ee\u7684\u5f88\u7b80\u5355\uff0c\u5c31\u662f\u8981\u6c42\u5728\u6307\u5b9a\u65f6\u95f4\u5185\uff08\u4e00\u822c\u662f2-3\u4e2a\u6708\uff09\u4f7f\u7528\u51fa\u9898\u65b9\u7684\u6570\u636e\u5b8c\u6210\u6307\u5b9a\u7684\u4efb\u52a1\uff0c\u5982\u679c\u6709\u5e78\u8d62\u5f97\u6bd4\u8d5b\uff0c\u4e0d\u4f46\u53ef\u4ee5\u83b7\u5f97\u5956\u91d1\uff0c\u6a21\u578b\u4e5f\u53ef\u80fd\u4f1a\u88ab\u7ade\u8d5b\u8d5e\u52a9\u5546\u5e94\u7528\u5230\u5546\u4e1a\u5b9e\u8df5\u4e2d\u3001\u83b7\u5956\u8005\u76f4\u63a5\u8fdb\u5165\u8d5e\u52a9\u4f01\u4e1a\u5de5\u4f5c\u6216\u8005\u83b7\u5f97\u4e00\u4e9b\u91cd\u5927\u4f1a\u8bae\u9080\u8bf7\u3001\u53d1\u8868\u8bba\u6587\u7b49 \u6570\u636e\u96c6datasets\uff1a\u6570\u636e\u96c6\u662f\u8d5e\u52a9\u5546\u4e3a\u4e86\u89e3\u51b3\u67d0\u4e9b\u95ee\u9898\uff0c\u514d\u8d39\u516c\u5f00\u4e86\u81ea\u5df1\u7684\u5185\u90e8\u7684\u4e00\u4e9b\u8131\u654f\u7684\u6570\u636e\uff0c\u6240\u6709\u4eba\u90fd\u53ef\u4ee5\u4f7f\u7528\u8fd9\u4e9b\u6570\u636e\u96c6\u8fdb\u884c\u7814\u7a76\uff0c\u6765\u6539\u8fdb\u73b0\u6709\u7684\u6a21\u578b\u6216\u8005\u4f18\u5316\u73b0\u6709\u95ee\u9898\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u662f\u8fd9\u4e9b\u6a21\u578b\u6216\u89e3\u51b3\u65b9\u6848\u53ef\u4ee5\u4e0d\u516c\u5f00\uff0c\u6240\u4ee5\u8fd9\u90e8\u5206\u662f\u4e0d\u63d0\u4f9b\u5956\u91d1\u7684\uff0c\u53ea\u662f\u80fd\u591f\u4e0e\u522b\u4eba\u7684\u65b9\u6848\u505a\u5bf9\u6bd4\u3002 5.1.2 Kaggle\u677f\u5757\u4ecb\u7ecd \u00b6 Data \u00b6 \u8fd9\u4e2a\u4e0d\u7528\u591a\u4ecb\u7ecd\uff0c\u5c31\u662f\u6211\u4eec\u6240\u4f7f\u7528\u7684\u6570\u636e\u3002 \u8fd9\u4e2a\u6a21\u5757\u9700\u8981\u8ba4\u503c\u9605\u8bfb\uff0c\u5b83\u4ecb\u7ecd\u6570\u636e\u7684\u4ea7\u751f\u65b9\u5f0f\u3001\u5b58\u50a8\u5f62\u5f0f\u3001\u6bcf\u4e2a\u5b57\u6bb5\u7684\u542b\u4e49\u7b49\u3002\u5982\u679c\u6570\u636e\u89c4\u6a21\u5f88\u5927\uff0c\u4f60\u6ca1\u6709\u5185\u5b58\u8db3\u591f\u5927\u7684\u670d\u52a1\u5668\u53ef\u4ee5hold\u4f4f\uff0c\u53ef\u80fd\u5c31\u6ca1\u6cd5\u6253\u8fd9\u4e2a\u6bd4\u8d5b\u6216\u8005\u4f7f\u7528\u8fd9\u4e2a\u6570\u636e\u96c6\uff1b\u6211\u4eec\u8fd8\u8981\u6ce8\u610f\u4ed6\u7684\u6570\u636e\u7c7b\u578b\u4ec0\u4e48\uff0c\u6bd4\u5982\u56fe\u50cf\u6570\u636e\u90a3\u5c31\u5f97\u7528\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff0c\u5982\u679c\u5bf9\u8fd9\u65b9\u9762\u4e0d\u719f\u6216\u8005\u6ca1\u6709GPU\u53ef\u7528\uff0c\u80af\u5b9a\u662f\u6ca1\u6709\u529e\u6cd5\u53c2\u52a0\u8fd9\u4e2a\u6bd4\u8d5b\uff0c\u4e0d\u8981\u5984\u60f3\u4f7f\u7528GPU\u6765\u505aCNN\u8ba1\u7b97\uff0c\u81f3\u5c11\u76ee\u524d\u6765\u8bf4\u662f\u4e0d\u53ef\u80fd\u7684\u3002 \u6211\u4eec\u53ef\u5c06 kaggle \u5e73\u53f0\u4e0a\u7684\u6bd4\u8d5b\u5206\u6210\u4e00\u4e0b4\u7c7b\uff1a \u6316\u6398\uff1a\u9762\u5bf9\u7684\u662f\u7ed3\u6784\u5316\u6570\u636e\uff0c\u4e5f\u5c31\u662f\u8868\u683c\u6570\u636e\uff0c\u5305\u62ec\u4e86\u5404\u5f0f\u5404\u6837\u7684\u9884\u6d4b\u95ee\u9898(\u9884\u6d4b\u9500\u91cf\u3001\u70b9\u51fb\u7387\u3001\u63a8\u8350\u6392\u5e8f\u7b49)\uff0c\u4e3b\u8981\u7684\u5171\u6027\u5c31\u662f\u7406\u89e3\u6570\u636e\uff0c\u7406\u89e3\u95ee\u9898\uff0c\u4ece\u6570\u636e\u4e2d\u627e\u5230\u6709\u7528\u7684\u4fe1\u606f\u7528\u6765\u9884\u6d4b\uff0c\u8fd9\u7c7b\u95ee\u9898\u80dc\u8d1f\u66f4\u591a\u7684\u662f\u5728\u7279\u5f81\u4e0a\uff0c\u6240\u4ee5\u8fd9\u90e8\u5206\u662f\u6811\u5f62\u6a21\u578b\u7684\u5929\u4e0b\u6bd4\u5982\u6709\u540d\u7684xgboost\u3002 \u56fe\u50cf\uff1a\u56fe\u50cf\u7684\u8bdd\u90a3\u80af\u5b9a\u9700\u8981CNN\u4e86\uff0c\u8fd9\u90e8\u5206\u867d\u7136\u53ef\u4ee5\u7528\u8fc1\u79fb\u5b66\u4e60\u6765\u505a\uff0c\u4f46\u662f\u8981\u60f3\u83b7\u5f97\u6392\u540d\u5927\u91cf\u7684\u7b97\u529b\u4e5f\u662f\u5fc5\u987b\u7684\uff0c\u56e0\u4e3a\u8981\u9a8c\u8bc1\u5fae\u8c03\u7684\u6b21\u6570\u4e5f\u4f1a\u5f88\u591a\u3002 \u8bed\u97f3\uff1a\u8fd9\u90e8\u5206\u4e0d\u592a\u4e86\u89e3\uff0c\u5c31\u4e0d\u732e\u4e11\u4e86 NLP \uff1aBERT\u51fa\u6765\u4ee5\u540e\u5404\u79cd\u9884\u8bad\u7ec3\u7684\u6743\u91cd\u4f1a\u5bf9\u8fd9\u65b9\u9762\u7684\u6bd4\u8d5b\u5e2e\u52a9\u5f88\u5927 Rules \u00b6 \u6bd4\u8d5b\u89c4\u5219\u3002\u8fd9\u4e2a\u5fc5\u987b\u8981\u770b\uff0c\u65e0\u8bba\u662f\u840c\u65b0\u8fd8\u662f\u5927\u795e\uff0c\u6bd4\u8d5b\u7684\u89c4\u5219\u8fd8\u662f\u8981\u9075\u5b88\u7684\u3002 \u63d0\u4ea4\u6b21\u6570\uff1a\u8fd9\u91cc\u4f1a\u5199\u660e\u6bcf\u5929\u5141\u8bb8\u7684\u6700\u5927\u63d0\u4ea4\u6b21\u6570\uff0c\u4e00\u822c\u662f 5\u6b21\uff0c\u5047\u5982\u4e00\u4e2a\u6bd4\u8d5b\u6301\u7eed\u65f6\u95f4\u662f\u4e09\u4e2a\u6708\uff0c\u90a3\u4e48\u603b\u63d0\u4ea4\u6b21\u6570\u5dee\u4e0d\u591a\u5c31\u662f 5\u00d790=450 \u6b21\u3002 \u5f88\u591a\u4eba\u4e3a\u4e86\u8eb2\u8fc7\u63d0\u4ea4\u6b21\u6570\u7684\u9650\u5236\u6216\u8005\u201c\u8282\u7701\u63d0\u4ea4\u6b21\u6570\u201d\uff0c\u4e13\u95e8\u6ce8\u518c\u4e86\u5c0f\u53f7\uff0c\u8fd9\u88ab\u79f0\u4e3a multiple accounts\uff0c\u662f\u4f1a\u88ab kaggle \u7684\u53cd\u4f5c\u5f0a\u7cfb\u7edf\u4fa6\u5bdf\u51fa\u6765\u7684\u3002\u5728\u6bd4\u8d5b\u7ed3\u675f\u540e\uff0c\u4f1a\u5148\u516c\u5e03\u521d\u6b65\u6392\u540d\uff0c\u7136\u540e kaggle \u5e73\u53f0\u53cd\u4f5c\u5f0a\u7cfb\u7edf\u5f00\u59cb\u8fd0\u884c\uff0c\u5927\u7ea6\u4e24\u4e09\u5929\u540e\uff0c\u51e1\u662f\u88ab\u5224\u4e3a\u4f5c\u5f0a\u7684\u961f\u4f0d\u76f4\u63a5\u4ece\u6392\u540d\u4e2d\u79fb\u9664\uff0c\u51e0\u4e2a\u6708\u7684\u52aa\u529b\u5c31\u6253\u6c34\u6f02\u4e86\uff01\u6240\u4ee5\u8fd9\u4e2a\u64cd\u4f5c\u4e00\u5b9a\u8981\u7981\u6b62\u3002 \u53e6\u4e00\u4e2a\u662f\u7ec4\u5916\u79c1\u81ea\u5206\u4eab\u4ee3\u7801\u548c\u7ed3\u679c\uff0c\u8fd9\u4e5f\u662f\u660e\u4ee4\u7981\u6b62\u7684\u3002\u7ec4\u961f\u4e4b\u540e\u961f\u5458\u4e4b\u95f4\u53ef\u4ee5\u5206\u4eab\uff0c\u6216\u8005\u901a\u8fc7\u516c\u5f00\u7684 kernel\u6216discussion\u533a\u5206\u4eab\u3002\u540c\u6837\uff0c\u5982\u679c\u88ab\u68c0\u6d4b\u51fa\u4e0d\u540c\u961f\u4f0d\u6216\u4e2a\u4eba\u95f4\u6709\u76f8\u4f3c\u7684\u7ed3\u679c\uff0c\u4e5f\u4f1a\u88ab\u79fb\u9664\u6700\u7ec8\u699c\u5355\u3002 Team \u00b6 \u5728\u53c2\u52a0\u6bd4\u8d5b\u7684\u65f6\u5019\u53ef\u4ee5\u5411\u522b\u4eba\u53d1\u8d77\u7ec4\u961f\u9080\u8bf7\uff0c\u6216\u8005\u63a5\u53d7\u522b\u4eba\u7684\u9080\u8bf7\uff0c\u4e09\u4e2a\u81ed\u76ae\u5320\u9876\u4e2a\u8bf8\u845b\u4eae\uff0c\u7ec4\u961f\u7684\u597d\u5904\u5c31\u4e0d\u7528\u8bf4\u4e86\uff0c\u6bcf\u4e2a\u961f\u4f0d\u6700\u591a4\u4e2a\u4eba\uff0c\u5e76\u4e14\u662f\u53ef\u4ee5\u5171\u4eab\u4ee3\u7801\u7684\uff0c\u8fd9\u6837\u76f8\u5f53\u4e8e\u7b97\u529b\u63d0\u9ad8\u4e864\u500d\u3002 \u53e6\u5916\u5c31\u662f\u4e00\u5b9a\u8981\u7ed9\u961f\u4f0d\u8d77\u4e2a\u9a9a\u6c14\u7684\u540d\u5b57\u3002 Kernels \u00b6 \u3002\u3002\u3002(\u4e0d\u77e5\u9053\u600e\u4e48\u7ffb\u8bd1\uff0c\u603b\u4e4b\u5c31\u662f\u6838\u5fc3\u4ee3\u7801)\u3002\u652f\u6301 Python \u8bed\u8a00\u7684\u811a\u672c .py \u548c .ipynb\uff0c\u548c R \u8bed\u8a00\u7684\u811a\u672c .R \u548c .ipynb\u3002 \u5206 public kernel \u548c private kernel\u3002 public kernel\u662f\u516c\u5f00\u7684\uff0c\u5927\u5bb6\u90fd\u53ef\u4ee5\u770b\u5230\uff0c\u4ece\u8fd9\u91cc\u53ef\u4ee5\u5b66\u5230\u975e\u5e38\u591a\u7684\u4e1c\u897f\uff0c\u5f53\u7136\u4f60\u81ea\u5df1\u4e5f\u53ef\u4ee5\u901a\u8fc7\u516c\u5f00\u81ea\u5df1\u7684 kernel \u5206\u4eab\u89e3\u51b3\u65b9\u6848\u6216\u89c2\u70b9\u3002 private kernel\u662f\u4f60\u81ea\u5df1\u7684\uff0c\u522b\u4eba\u770b\u4e0d\u89c1\uff0c\u4f60\u53ef\u4ee5\u5206\u4eab\u7ed9\u7ec4\u5185\u6210\u5458\u3002 \u4e3a\u65b9\u4fbf\u5927\u5bb6\u6253\u6bd4\u8d5b\uff0ckaggle \u63d0\u4f9b\u4e86\u4e00\u4e9b\u8fd0\u7b97\u8d44\u6e90\u3002kaggle \u7528\u6237\u7684\u6bcf\u4e2a kernel \u53ef\u4ee5\u6709 16G \u7684\u5185\u5b58\u548c 4 \u6838CPU\uff0c\u8fd9\u8db3\u591f\u6253\u591a\u6570\u6bd4\u8d5b\u4e86\u3002\u53e6\u5916\uff0c\u63d0\u4f9b\u4e86 GPU\uff0c\u5728\u65b0\u5efa kernel \u7684\u65f6\u5019\u53ef\u4ee5\u9009\u62e9\u5f00\u542f GPU\uff0c\u4f46\u5f53\u6253\u5f00 GPU \u65f6\uff0cCPU \u548c\u5185\u5b58\u8d44\u6e90\u4f1a\u5c11\u4e00\u4e9b\uff0c\u8fd9\u4e2a\u540e\u9762\u7684\u8585\u7f8a\u6bdb\u6307\u5357\u4e2d\u4f1a\u8be6\u7ec6\u4ecb\u7ecd\u3002 Discussion \u00b6 \u8ba8\u8bba\u533a\uff0c\u8fd9\u4e2a\u533a\u5927\u5bb6\u4f1a\u5206\u4eab\u89c2\u70b9\u3001\u8ba8\u8bba\u95ee\u9898\u3001\u751a\u81f3\u5bfb\u627e\u7ec4\u961f\u961f\u53cb\u3002 kaggle \u7684\u5206\u4eab\u6c1b\u56f4\u975e\u5e38\u597d\uff0c\u5bf9\u840c\u65b0\u4e5f\u975e\u5e38\u53cb\u597d\u3002\u5728\u6574\u4e2a\u6bd4\u8d5b\u8fdb\u7a0b\u4e2d\u5927\u5bb6\u4e0d\u65ad\u5730\u5206\u4eab\u81ea\u5df1\u7684\u65b0\u53d1\u73b0\uff0c\u5f88\u591a\u6709\u7528\u7684\u4fe1\u606f\u90fd\u662f\u5728\u8fd9\u91cc\u83b7\u53d6\u7684\u3002 \u5bf9\u4e8e\u4e00\u4e2a\u65b0\u624b\u800c\u8a00\uff0c\u6bcf\u5929\u505a\u597d kernel \u533a\u548c discussion\u533a\u7684\u8ddf\u8e2a\uff0c\u6709\u5145\u8db3\u7684\u65f6\u95f4\u5c1d\u8bd5\u4ed6\u4eec\u7684\u60f3\u6cd5\uff0c\u5e94\u8be5\u53ef\u4ee5\u83b7\u5f97\u4e00\u4e2a\u4e0d\u9519\u7684\u6392\u540d\u3002 \u6bd4\u8d5b\u7ed3\u675f\u540e\uff0c\u4e00\u4e9b\u5927\u725b\u751a\u81f3\u4f1a\u5c06\u81ea\u5df1\u83b7\u80dc\u7528\u5230\u7684\u65b9\u6cd5\u3001\u5c0f\u6280\u5de7\uff08tricks\uff09\u5168\u90e8\u5206\u4eab\u51fa\u6765\u3002 Leaderboard \u00b6 \u6392\u540d\u533a\uff0c\u5206 public LB \u548c private LB\u3002\u6bd4\u8d5b\u65b9\u4f1a\u5c06 test \u6570\u636e\u96c6\u4e2d\u4e00\u90e8\u5206(\u6bd4\u5982 30%)\u62ff\u51fa\u6765\u505a\u4e3a public LB \u8bc4\u5206\u548c\u6392\u540d\uff0c\u5269\u4e0b\u7684\u90e8\u5206\u4f5c\u4e3a private LB\uff08\u4e5f\u5c31\u662f\u6700\u7ec8\u7ed3\u679c\uff09\u7684\u8bc4\u5206\u548c\u6392\u540d\u3002 \u4f60\u6bcf\u5929\u90fd\u53ef\u4ee5\u63d0\u4ea4\u5e76\u67e5\u770b\u81ea\u5df1\u7684\u7b54\u6848\u5728 public LB \u7684\u5f97\u5206\u548c\u6392\u540d\u60c5\u51b5\uff0c\u5728\u6bd4\u8d5b\u7ed3\u675f\u524d\u9700\u8981\u9009\u62e9\u4e24\u4e2a\u63d0\u4ea4\u4f5c\u4e3a\u81ea\u5df1\u7684\u6700\u7ec8\u7b54\u6848\uff0c\u6bd4\u8d5b\u7ed3\u675f\u540e\uff0c\u5e73\u53f0\u4f1a\u8ba1\u7b97\u4f60\u7684\u7b54\u6848\u7684 private LB \u5f97\u5206\u5e76\u81ea\u52a8\u6311\u9009\u5f97\u5206\u9ad8\u7684\u4e00\u4e2a\u4f5c\u4e3a\u4f60\u7684\u6700\u7ec8\u6210\u7ee9\u3002 \u5728\u8ba8\u8bba\u533a\u4f60\u4f1a\u7ecf\u5e38\u542c\u5230\u5927\u5bb6\u8ba8\u8bba CV score\u3001LB score\uff0c\u6307\u7684\u5c31\u662f\u4f60\u6a21\u578b\u672c\u5730\u4ea4\u53c9\u9a8c\u8bc1\u7684\u5f97\u5206\u548c\u63d0\u4ea4\u540e\u7684 public LB \u5f97\u5206\u3002 shake up\uff1apublic LB \u5f97\u5206\u53ef\u80fd\u4f1a\u548c private LB \u5f97\u5206\u5dee\u522b\u5f88\u5927\uff0c\u6bd4\u8d5b\u7ed3\u679c\u516c\u5e03\u524d\u4f60\u53ef\u80fd\u6392\u540d\u524d\u5341\uff0c\u6bd4\u8d5b\u7ed3\u679c\u516c\u5e03\u540e\u53d1\u73b0\u81ea\u5df1\u8dcc\u5230\u4e0a\u5343\u540d\u4e86\uff0c\u8fd9\u5c31\u662f\u6240\u8c13\u7684 shake up\uff0c\u4e00\u822c\u662f\u6a21\u578b\u8fc7\u62df\u5408\u4e86\uff0c\u8fd9\u4e2a\u9700\u8981\u5728\u8bad\u7ec3\u7684\u65f6\u5019\u5c31\u8981\u6ce8\u610f\u3002 5.1.3 Kaggle\u7ade\u8d5b\u7684\u6392\u540d\u673a\u5236 \u00b6 \u4e00\u822c\u60c5\u51b5\u4e0b\uff0c\u90fd\u662f\u4ee5\u51c6\u786e\u7387\u4e3a\u5bfc\u5411\u7684\u6392\u540d\uff0c\u6bd5\u7adf\u6211\u4eec\u7684\u6a21\u578b\u8ba1\u7b97\u7684\u51c6\u786e\u662f\u7b2c\u4e00\u6807\u51c6\u3002 \u9488\u5bf9\u4e8e\u6bd4\u8d5b\u800c\u8a00\uff0c\u5728\u6bd4\u8d5b\u7ed3\u675f\u4e4b\u524d\uff0c\u53c2\u8d5b\u8005\u6bcf\u5929\u6700\u591a\u53ef\u4ee5\u63d0\u4ea45\u6b21\u6d4b\u8bd5\u96c6\u7684\u9884\u6d4b\u7ed3\u679c\u3002\u6bcf\u4e00\u6b21\u63d0\u4ea4\u7ed3\u679c\u90fd\u4f1a\u83b7\u5f97\u6700\u65b0\u7684\u4e34\u65f6\u6392\u540d\u6210\u7ee9\uff0c\u76f4\u81f3\u6bd4\u8d5b\u7ed3\u675f\u83b7\u5f97\u6700\u7ec8\u6392\u540d\uff0cKaggle\u5c06\u53c2\u8d5b\u8005\u6bcf\u6b21\u63d0\u4ea4\u7684\u7ed3\u679c\u53d6\u51fa25%-33%\uff0c\u5e76\u4f9d\u7167\u51c6\u786e\u7387\u8fdb\u884c\u4e34\u65f6\u6392\u540d\u3002\u5728\u6bd4\u8d5b\u7ed3\u675f\u65f6\uff0c\u53c2\u8d5b\u8005\u53ef\u4ee5\u6307\u5b9a\u51e0\u4e2a\u5df2\u7ecf\u63d0\u4ea4\u7684\u7ed3\u679c\uff0cKaggle\u4ece\u4e2d\u53bb\u9664\u4e4b\u524d\u7528\u4e8e\u4e34\u65f6\u6392\u540d\u7684\u90e8\u5206\uff0c\u7528\u5269\u4f59\u6570\u636e\u7684\u51c6\u786e\u7387\u7efc\u5408\u5f97\u5230\u6700\u7ec8\u6392\u540d\u3002 \u6240\u4ee5\uff0c\u6bd4\u8d5b\u8fc7\u7a0b\u4e2d\u7528\u4e8e\u6700\u7ec8\u6392\u540d\u7684\u90a3\u90e8\u5206\u6570\u636e\uff0c\u53c2\u8d5b\u8005\u662f\u59cb\u7ec8\u5f97\u4e0d\u5230\u5173\u4e8e\u51c6\u786e\u7387\u7684\u53cd\u9988\u7684\u3002\u8fd9\u6837\u4e00\u5b9a\u7a0b\u5ea6\u907f\u514d\u53c2\u8d5b\u6a21\u578b\u7684\u8fc7\u62df\u5408\uff0c\u4fdd\u8bc1\u8bc4\u9009\u51fa\u517c\u987e\u51c6\u786e\u7387\u548c\u6cdb\u5316\u80fd\u529b\u7684\u6a21\u578b\u3002 5.1.4 Kaggle\u8585\u7f8a\u6bdb\u6307\u5357 \u00b6 Kaggle\u63d0\u4f9b\u514d\u8d39\u8bbf\u95ee\u5185\u6838\u4e2d\u7684NVidia K80 GPU\u3002\u6211\u7684\u4e2a\u4eba\u7406\u89e3\u76f8\u5f53\u4e8e1060\u6216\u80051070\u7684\u6c34\u5e73\u5427\u3002 \u6211\u4eec\u53ef\u4ee5\u5728Kernel\u7684\u754c\u9762\u53f3\u4fa7\u5e95\u7aef\uff0cSetting\u9009\u9879\u4e2d\u5c06GPU\u5f00\u542f\uff0c\u8fd9\u6837\u5c31\u53ef\u4ee5\u4f7f\u7528\u514d\u8d39\u7684GPU\u8d44\u6e90\u4e86\u3002 Kaggle\u53ea\u63d0\u4f9b6\u5c0f\u65f6\u7684\u8fde\u7eedGPU\u4f7f\u7528\u65f6\u95f4\uff08\u5370\u8c61\u4e2d\uff0c\u5f85\u786e\u8ba4\uff09\uff0c\u867d\u7136\u5bf9\u4e8e\u5927\u6570\u636e\u91cf\u8ba1\u7b97\u6765\u8bf4\u6839\u672c\u5c31\u4e0d\u591f\u7528\uff0c\u4f46\u662f\u5bf9\u4e8e\u7814\u7a76\uff0c\u8fd9\u4e9b\u5df2\u7ecf\u591f\u4e86\uff0c\u4f8b\u5982\u6211\u4eec\u5728\u56fe\u50cf\u8bc6\u522b\u4e2d\u7ecf\u5e38\u7528\u5230\u7684CIFAR-10 \u56fe\u7247\u5206\u7c7b\uff0c\u4e00\u822c\u8bad\u7ec32\u4e2a\u5c0f\u65f6\u5de6\u53f3\u5c31\u80fd\u591f\u5f97\u5230\u6bd4\u8f83\u51c6\u786e\u7684\u6a21\u578b\u4e86\uff0c\u8fd9\u5bf9\u4e8e\u5165\u95e8\u5b66\u4e60\u6765\u8bf4\u5df2\u7ecf\u591f\u7528\u4e86\u3002 5.1.5 \u5176\u4ed6\u7684\u4e00\u4e9b\u6570\u636e\u7ade\u8d5b\u5e73\u53f0 \u00b6 \u9664\u4e86Kaggle\uff0c\u5176\u5b9e\u8fd8\u6709\u4e0d\u5c11\u7c7b\u4f3c\u7684\u5e73\u53f0\uff1b DrivenData CrowdANALYTIX InnoCentive TundIT Codalab Analytics Vidhya CrowdAI Numerai Data Science Challenge KDD Cup \u5929\u6c60 \u817e\u8baf\u5e7f\u544a\u7b97\u6cd5\u5927\u8d5b","title":"5.1 Kaggle"},{"location":"tutorial/chapter05_application/5_1_kaggle/#51-kaggle","text":"","title":"5.1 kaggle\u4ecb\u7ecd"},{"location":"tutorial/chapter05_application/5_1_kaggle/#511-kaggle","text":"","title":"5.1.1 Kaggle"},{"location":"tutorial/chapter05_application/5_1_kaggle/#_1","text":"Kaggle\u662f\u7531\u8054\u5408\u521b\u59cb\u4eba\u3001\u9996\u5e2d\u6267\u884c\u5b98\u5b89\u4e1c\u5c3c\u00b7\u9ad8\u5fb7\u5e03\u5362\u59c6\uff08Anthony Goldbloom\uff092010\u5e74\u5728\u58a8\u5c14\u672c\u521b\u7acb\u7684\uff0c\u4e3b\u8981\u4e3a\u5f00\u53d1\u5546\u548c\u6570\u636e\u79d1\u5b66\u5bb6\u63d0\u4f9b\u4e3e\u529e\u673a\u5668\u5b66\u4e60\u7ade\u8d5b\u3001\u6258\u7ba1\u6570\u636e\u5e93\u3001\u7f16\u5199\u548c\u5206\u4eab\u4ee3\u7801\u7684\u5e73\u53f0\u3002\u8be5\u5e73\u53f0\u5df2\u7ecf\u5438\u5f15\u4e8680\u4e07\u540d\u6570\u636e\u79d1\u5b66\u5bb6\u7684\u5173\u6ce8\uff0c\u8fd9\u4e9b\u7528\u6237\u8d44\u6e90\u6216\u8bb8\u6b63\u662f\u5438\u5f15\u8c37\u6b4c\u7684\u4e3b\u8981\u56e0\u7d20\u3002 \u672c\u6bb5\u6458\u81ea \u767e\u5ea6\u767e\u79d1 \u901a\u4fd7\u7684\u8bf4\uff0cKaggle\u4e0a\u9762\u6709\u7740\u5404\u79cd\u9ad8\u8d28\u91cf\u7684\u6570\u636e\u96c6\uff0c\u5e76\u4e14\u57fa\u4e8e\u8fd9\u4e9b\u6570\u636e\u96c6\u4f1a\u6709\u4e00\u4e9b\u5927\u7684\u516c\u53f8\u8fdb\u884c\u8d5e\u52a9\uff0c\u6765\u4e3e\u529e\u4e00\u4e9b\u7b97\u6cd5\u7684\u7ade\u8d5b\uff0c\u5728\u7ade\u8d5b\u65f6\u8fd8\u53ef\u901a\u8fc7\u793e\u533a\u8fdb\u884c\u8ba8\u8bba\uff08\u5305\u62ec\u6bd4\u8d5b\u4e2d\u7684\u5206\u4eab\u3001\u7b54\u7591\uff0c\u548c\u6bd4\u8d5b\u540e\u7684top solution\u5206\u4eab\uff09\u3002\u8fd9\u6837\u5c31\u4f7f\u5f97\u5168\u7403\u7684\u9876\u5c16\u9ad8\u624b\u4f1a\u5bf9\u53c2\u52a0\u6bd4\u8d5b\u4ea7\u751f\u5174\u8da3\uff0c\u56e0\u4e3a\u6536\u83b7\u5230\u7684\u4e0d\u4ec5\u6709\u5956\u91d1\u8fd8\u6709\u540d\u6c14\u3002\u540c\u65f6kaggle\u5bf9\u840c\u65b0\u4e5f\u5f88\u53cb\u597d\uff0c\u5728\u793e\u533a\u4e2d\u53ef\u4ee5\u5b66\u5230\u5f88\u591a\u7684\u77e5\u8bc6\u548c\u89e3\u51b3\u65b9\u6848\uff08top solution\uff09\u3002","title":"\u5e73\u53f0\u7b80\u4ecb"},{"location":"tutorial/chapter05_application/5_1_kaggle/#_2","text":"kaggle \u7f51\u7ad9\u662f\u7eaf\u82f1\u6587\u7684\uff0c\u6211\u4eec\u53ef\u4ee5\u628a\u6bd4\u8d5b\u5206\u4e3a2\u7c7b: \u7ade\u8d5bcompetitions\uff1a\u7ade\u8d5b\u7684\u76ee\u7684\u5f88\u7b80\u5355\uff0c\u5c31\u662f\u8981\u6c42\u5728\u6307\u5b9a\u65f6\u95f4\u5185\uff08\u4e00\u822c\u662f2-3\u4e2a\u6708\uff09\u4f7f\u7528\u51fa\u9898\u65b9\u7684\u6570\u636e\u5b8c\u6210\u6307\u5b9a\u7684\u4efb\u52a1\uff0c\u5982\u679c\u6709\u5e78\u8d62\u5f97\u6bd4\u8d5b\uff0c\u4e0d\u4f46\u53ef\u4ee5\u83b7\u5f97\u5956\u91d1\uff0c\u6a21\u578b\u4e5f\u53ef\u80fd\u4f1a\u88ab\u7ade\u8d5b\u8d5e\u52a9\u5546\u5e94\u7528\u5230\u5546\u4e1a\u5b9e\u8df5\u4e2d\u3001\u83b7\u5956\u8005\u76f4\u63a5\u8fdb\u5165\u8d5e\u52a9\u4f01\u4e1a\u5de5\u4f5c\u6216\u8005\u83b7\u5f97\u4e00\u4e9b\u91cd\u5927\u4f1a\u8bae\u9080\u8bf7\u3001\u53d1\u8868\u8bba\u6587\u7b49 \u6570\u636e\u96c6datasets\uff1a\u6570\u636e\u96c6\u662f\u8d5e\u52a9\u5546\u4e3a\u4e86\u89e3\u51b3\u67d0\u4e9b\u95ee\u9898\uff0c\u514d\u8d39\u516c\u5f00\u4e86\u81ea\u5df1\u7684\u5185\u90e8\u7684\u4e00\u4e9b\u8131\u654f\u7684\u6570\u636e\uff0c\u6240\u6709\u4eba\u90fd\u53ef\u4ee5\u4f7f\u7528\u8fd9\u4e9b\u6570\u636e\u96c6\u8fdb\u884c\u7814\u7a76\uff0c\u6765\u6539\u8fdb\u73b0\u6709\u7684\u6a21\u578b\u6216\u8005\u4f18\u5316\u73b0\u6709\u95ee\u9898\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u662f\u8fd9\u4e9b\u6a21\u578b\u6216\u89e3\u51b3\u65b9\u6848\u53ef\u4ee5\u4e0d\u516c\u5f00\uff0c\u6240\u4ee5\u8fd9\u90e8\u5206\u662f\u4e0d\u63d0\u4f9b\u5956\u91d1\u7684\uff0c\u53ea\u662f\u80fd\u591f\u4e0e\u522b\u4eba\u7684\u65b9\u6848\u505a\u5bf9\u6bd4\u3002","title":"\u6bd4\u8d5b\u4ecb\u7ecd"},{"location":"tutorial/chapter05_application/5_1_kaggle/#512-kaggle","text":"","title":"5.1.2 Kaggle\u677f\u5757\u4ecb\u7ecd"},{"location":"tutorial/chapter05_application/5_1_kaggle/#data","text":"\u8fd9\u4e2a\u4e0d\u7528\u591a\u4ecb\u7ecd\uff0c\u5c31\u662f\u6211\u4eec\u6240\u4f7f\u7528\u7684\u6570\u636e\u3002 \u8fd9\u4e2a\u6a21\u5757\u9700\u8981\u8ba4\u503c\u9605\u8bfb\uff0c\u5b83\u4ecb\u7ecd\u6570\u636e\u7684\u4ea7\u751f\u65b9\u5f0f\u3001\u5b58\u50a8\u5f62\u5f0f\u3001\u6bcf\u4e2a\u5b57\u6bb5\u7684\u542b\u4e49\u7b49\u3002\u5982\u679c\u6570\u636e\u89c4\u6a21\u5f88\u5927\uff0c\u4f60\u6ca1\u6709\u5185\u5b58\u8db3\u591f\u5927\u7684\u670d\u52a1\u5668\u53ef\u4ee5hold\u4f4f\uff0c\u53ef\u80fd\u5c31\u6ca1\u6cd5\u6253\u8fd9\u4e2a\u6bd4\u8d5b\u6216\u8005\u4f7f\u7528\u8fd9\u4e2a\u6570\u636e\u96c6\uff1b\u6211\u4eec\u8fd8\u8981\u6ce8\u610f\u4ed6\u7684\u6570\u636e\u7c7b\u578b\u4ec0\u4e48\uff0c\u6bd4\u5982\u56fe\u50cf\u6570\u636e\u90a3\u5c31\u5f97\u7528\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff0c\u5982\u679c\u5bf9\u8fd9\u65b9\u9762\u4e0d\u719f\u6216\u8005\u6ca1\u6709GPU\u53ef\u7528\uff0c\u80af\u5b9a\u662f\u6ca1\u6709\u529e\u6cd5\u53c2\u52a0\u8fd9\u4e2a\u6bd4\u8d5b\uff0c\u4e0d\u8981\u5984\u60f3\u4f7f\u7528GPU\u6765\u505aCNN\u8ba1\u7b97\uff0c\u81f3\u5c11\u76ee\u524d\u6765\u8bf4\u662f\u4e0d\u53ef\u80fd\u7684\u3002 \u6211\u4eec\u53ef\u5c06 kaggle \u5e73\u53f0\u4e0a\u7684\u6bd4\u8d5b\u5206\u6210\u4e00\u4e0b4\u7c7b\uff1a \u6316\u6398\uff1a\u9762\u5bf9\u7684\u662f\u7ed3\u6784\u5316\u6570\u636e\uff0c\u4e5f\u5c31\u662f\u8868\u683c\u6570\u636e\uff0c\u5305\u62ec\u4e86\u5404\u5f0f\u5404\u6837\u7684\u9884\u6d4b\u95ee\u9898(\u9884\u6d4b\u9500\u91cf\u3001\u70b9\u51fb\u7387\u3001\u63a8\u8350\u6392\u5e8f\u7b49)\uff0c\u4e3b\u8981\u7684\u5171\u6027\u5c31\u662f\u7406\u89e3\u6570\u636e\uff0c\u7406\u89e3\u95ee\u9898\uff0c\u4ece\u6570\u636e\u4e2d\u627e\u5230\u6709\u7528\u7684\u4fe1\u606f\u7528\u6765\u9884\u6d4b\uff0c\u8fd9\u7c7b\u95ee\u9898\u80dc\u8d1f\u66f4\u591a\u7684\u662f\u5728\u7279\u5f81\u4e0a\uff0c\u6240\u4ee5\u8fd9\u90e8\u5206\u662f\u6811\u5f62\u6a21\u578b\u7684\u5929\u4e0b\u6bd4\u5982\u6709\u540d\u7684xgboost\u3002 \u56fe\u50cf\uff1a\u56fe\u50cf\u7684\u8bdd\u90a3\u80af\u5b9a\u9700\u8981CNN\u4e86\uff0c\u8fd9\u90e8\u5206\u867d\u7136\u53ef\u4ee5\u7528\u8fc1\u79fb\u5b66\u4e60\u6765\u505a\uff0c\u4f46\u662f\u8981\u60f3\u83b7\u5f97\u6392\u540d\u5927\u91cf\u7684\u7b97\u529b\u4e5f\u662f\u5fc5\u987b\u7684\uff0c\u56e0\u4e3a\u8981\u9a8c\u8bc1\u5fae\u8c03\u7684\u6b21\u6570\u4e5f\u4f1a\u5f88\u591a\u3002 \u8bed\u97f3\uff1a\u8fd9\u90e8\u5206\u4e0d\u592a\u4e86\u89e3\uff0c\u5c31\u4e0d\u732e\u4e11\u4e86 NLP \uff1aBERT\u51fa\u6765\u4ee5\u540e\u5404\u79cd\u9884\u8bad\u7ec3\u7684\u6743\u91cd\u4f1a\u5bf9\u8fd9\u65b9\u9762\u7684\u6bd4\u8d5b\u5e2e\u52a9\u5f88\u5927","title":"Data"},{"location":"tutorial/chapter05_application/5_1_kaggle/#rules","text":"\u6bd4\u8d5b\u89c4\u5219\u3002\u8fd9\u4e2a\u5fc5\u987b\u8981\u770b\uff0c\u65e0\u8bba\u662f\u840c\u65b0\u8fd8\u662f\u5927\u795e\uff0c\u6bd4\u8d5b\u7684\u89c4\u5219\u8fd8\u662f\u8981\u9075\u5b88\u7684\u3002 \u63d0\u4ea4\u6b21\u6570\uff1a\u8fd9\u91cc\u4f1a\u5199\u660e\u6bcf\u5929\u5141\u8bb8\u7684\u6700\u5927\u63d0\u4ea4\u6b21\u6570\uff0c\u4e00\u822c\u662f 5\u6b21\uff0c\u5047\u5982\u4e00\u4e2a\u6bd4\u8d5b\u6301\u7eed\u65f6\u95f4\u662f\u4e09\u4e2a\u6708\uff0c\u90a3\u4e48\u603b\u63d0\u4ea4\u6b21\u6570\u5dee\u4e0d\u591a\u5c31\u662f 5\u00d790=450 \u6b21\u3002 \u5f88\u591a\u4eba\u4e3a\u4e86\u8eb2\u8fc7\u63d0\u4ea4\u6b21\u6570\u7684\u9650\u5236\u6216\u8005\u201c\u8282\u7701\u63d0\u4ea4\u6b21\u6570\u201d\uff0c\u4e13\u95e8\u6ce8\u518c\u4e86\u5c0f\u53f7\uff0c\u8fd9\u88ab\u79f0\u4e3a multiple accounts\uff0c\u662f\u4f1a\u88ab kaggle \u7684\u53cd\u4f5c\u5f0a\u7cfb\u7edf\u4fa6\u5bdf\u51fa\u6765\u7684\u3002\u5728\u6bd4\u8d5b\u7ed3\u675f\u540e\uff0c\u4f1a\u5148\u516c\u5e03\u521d\u6b65\u6392\u540d\uff0c\u7136\u540e kaggle \u5e73\u53f0\u53cd\u4f5c\u5f0a\u7cfb\u7edf\u5f00\u59cb\u8fd0\u884c\uff0c\u5927\u7ea6\u4e24\u4e09\u5929\u540e\uff0c\u51e1\u662f\u88ab\u5224\u4e3a\u4f5c\u5f0a\u7684\u961f\u4f0d\u76f4\u63a5\u4ece\u6392\u540d\u4e2d\u79fb\u9664\uff0c\u51e0\u4e2a\u6708\u7684\u52aa\u529b\u5c31\u6253\u6c34\u6f02\u4e86\uff01\u6240\u4ee5\u8fd9\u4e2a\u64cd\u4f5c\u4e00\u5b9a\u8981\u7981\u6b62\u3002 \u53e6\u4e00\u4e2a\u662f\u7ec4\u5916\u79c1\u81ea\u5206\u4eab\u4ee3\u7801\u548c\u7ed3\u679c\uff0c\u8fd9\u4e5f\u662f\u660e\u4ee4\u7981\u6b62\u7684\u3002\u7ec4\u961f\u4e4b\u540e\u961f\u5458\u4e4b\u95f4\u53ef\u4ee5\u5206\u4eab\uff0c\u6216\u8005\u901a\u8fc7\u516c\u5f00\u7684 kernel\u6216discussion\u533a\u5206\u4eab\u3002\u540c\u6837\uff0c\u5982\u679c\u88ab\u68c0\u6d4b\u51fa\u4e0d\u540c\u961f\u4f0d\u6216\u4e2a\u4eba\u95f4\u6709\u76f8\u4f3c\u7684\u7ed3\u679c\uff0c\u4e5f\u4f1a\u88ab\u79fb\u9664\u6700\u7ec8\u699c\u5355\u3002","title":"Rules"},{"location":"tutorial/chapter05_application/5_1_kaggle/#team","text":"\u5728\u53c2\u52a0\u6bd4\u8d5b\u7684\u65f6\u5019\u53ef\u4ee5\u5411\u522b\u4eba\u53d1\u8d77\u7ec4\u961f\u9080\u8bf7\uff0c\u6216\u8005\u63a5\u53d7\u522b\u4eba\u7684\u9080\u8bf7\uff0c\u4e09\u4e2a\u81ed\u76ae\u5320\u9876\u4e2a\u8bf8\u845b\u4eae\uff0c\u7ec4\u961f\u7684\u597d\u5904\u5c31\u4e0d\u7528\u8bf4\u4e86\uff0c\u6bcf\u4e2a\u961f\u4f0d\u6700\u591a4\u4e2a\u4eba\uff0c\u5e76\u4e14\u662f\u53ef\u4ee5\u5171\u4eab\u4ee3\u7801\u7684\uff0c\u8fd9\u6837\u76f8\u5f53\u4e8e\u7b97\u529b\u63d0\u9ad8\u4e864\u500d\u3002 \u53e6\u5916\u5c31\u662f\u4e00\u5b9a\u8981\u7ed9\u961f\u4f0d\u8d77\u4e2a\u9a9a\u6c14\u7684\u540d\u5b57\u3002","title":"Team"},{"location":"tutorial/chapter05_application/5_1_kaggle/#kernels","text":"\u3002\u3002\u3002(\u4e0d\u77e5\u9053\u600e\u4e48\u7ffb\u8bd1\uff0c\u603b\u4e4b\u5c31\u662f\u6838\u5fc3\u4ee3\u7801)\u3002\u652f\u6301 Python \u8bed\u8a00\u7684\u811a\u672c .py \u548c .ipynb\uff0c\u548c R \u8bed\u8a00\u7684\u811a\u672c .R \u548c .ipynb\u3002 \u5206 public kernel \u548c private kernel\u3002 public kernel\u662f\u516c\u5f00\u7684\uff0c\u5927\u5bb6\u90fd\u53ef\u4ee5\u770b\u5230\uff0c\u4ece\u8fd9\u91cc\u53ef\u4ee5\u5b66\u5230\u975e\u5e38\u591a\u7684\u4e1c\u897f\uff0c\u5f53\u7136\u4f60\u81ea\u5df1\u4e5f\u53ef\u4ee5\u901a\u8fc7\u516c\u5f00\u81ea\u5df1\u7684 kernel \u5206\u4eab\u89e3\u51b3\u65b9\u6848\u6216\u89c2\u70b9\u3002 private kernel\u662f\u4f60\u81ea\u5df1\u7684\uff0c\u522b\u4eba\u770b\u4e0d\u89c1\uff0c\u4f60\u53ef\u4ee5\u5206\u4eab\u7ed9\u7ec4\u5185\u6210\u5458\u3002 \u4e3a\u65b9\u4fbf\u5927\u5bb6\u6253\u6bd4\u8d5b\uff0ckaggle \u63d0\u4f9b\u4e86\u4e00\u4e9b\u8fd0\u7b97\u8d44\u6e90\u3002kaggle \u7528\u6237\u7684\u6bcf\u4e2a kernel \u53ef\u4ee5\u6709 16G \u7684\u5185\u5b58\u548c 4 \u6838CPU\uff0c\u8fd9\u8db3\u591f\u6253\u591a\u6570\u6bd4\u8d5b\u4e86\u3002\u53e6\u5916\uff0c\u63d0\u4f9b\u4e86 GPU\uff0c\u5728\u65b0\u5efa kernel \u7684\u65f6\u5019\u53ef\u4ee5\u9009\u62e9\u5f00\u542f GPU\uff0c\u4f46\u5f53\u6253\u5f00 GPU \u65f6\uff0cCPU \u548c\u5185\u5b58\u8d44\u6e90\u4f1a\u5c11\u4e00\u4e9b\uff0c\u8fd9\u4e2a\u540e\u9762\u7684\u8585\u7f8a\u6bdb\u6307\u5357\u4e2d\u4f1a\u8be6\u7ec6\u4ecb\u7ecd\u3002","title":"Kernels"},{"location":"tutorial/chapter05_application/5_1_kaggle/#discussion","text":"\u8ba8\u8bba\u533a\uff0c\u8fd9\u4e2a\u533a\u5927\u5bb6\u4f1a\u5206\u4eab\u89c2\u70b9\u3001\u8ba8\u8bba\u95ee\u9898\u3001\u751a\u81f3\u5bfb\u627e\u7ec4\u961f\u961f\u53cb\u3002 kaggle \u7684\u5206\u4eab\u6c1b\u56f4\u975e\u5e38\u597d\uff0c\u5bf9\u840c\u65b0\u4e5f\u975e\u5e38\u53cb\u597d\u3002\u5728\u6574\u4e2a\u6bd4\u8d5b\u8fdb\u7a0b\u4e2d\u5927\u5bb6\u4e0d\u65ad\u5730\u5206\u4eab\u81ea\u5df1\u7684\u65b0\u53d1\u73b0\uff0c\u5f88\u591a\u6709\u7528\u7684\u4fe1\u606f\u90fd\u662f\u5728\u8fd9\u91cc\u83b7\u53d6\u7684\u3002 \u5bf9\u4e8e\u4e00\u4e2a\u65b0\u624b\u800c\u8a00\uff0c\u6bcf\u5929\u505a\u597d kernel \u533a\u548c discussion\u533a\u7684\u8ddf\u8e2a\uff0c\u6709\u5145\u8db3\u7684\u65f6\u95f4\u5c1d\u8bd5\u4ed6\u4eec\u7684\u60f3\u6cd5\uff0c\u5e94\u8be5\u53ef\u4ee5\u83b7\u5f97\u4e00\u4e2a\u4e0d\u9519\u7684\u6392\u540d\u3002 \u6bd4\u8d5b\u7ed3\u675f\u540e\uff0c\u4e00\u4e9b\u5927\u725b\u751a\u81f3\u4f1a\u5c06\u81ea\u5df1\u83b7\u80dc\u7528\u5230\u7684\u65b9\u6cd5\u3001\u5c0f\u6280\u5de7\uff08tricks\uff09\u5168\u90e8\u5206\u4eab\u51fa\u6765\u3002","title":"Discussion"},{"location":"tutorial/chapter05_application/5_1_kaggle/#leaderboard","text":"\u6392\u540d\u533a\uff0c\u5206 public LB \u548c private LB\u3002\u6bd4\u8d5b\u65b9\u4f1a\u5c06 test \u6570\u636e\u96c6\u4e2d\u4e00\u90e8\u5206(\u6bd4\u5982 30%)\u62ff\u51fa\u6765\u505a\u4e3a public LB \u8bc4\u5206\u548c\u6392\u540d\uff0c\u5269\u4e0b\u7684\u90e8\u5206\u4f5c\u4e3a private LB\uff08\u4e5f\u5c31\u662f\u6700\u7ec8\u7ed3\u679c\uff09\u7684\u8bc4\u5206\u548c\u6392\u540d\u3002 \u4f60\u6bcf\u5929\u90fd\u53ef\u4ee5\u63d0\u4ea4\u5e76\u67e5\u770b\u81ea\u5df1\u7684\u7b54\u6848\u5728 public LB \u7684\u5f97\u5206\u548c\u6392\u540d\u60c5\u51b5\uff0c\u5728\u6bd4\u8d5b\u7ed3\u675f\u524d\u9700\u8981\u9009\u62e9\u4e24\u4e2a\u63d0\u4ea4\u4f5c\u4e3a\u81ea\u5df1\u7684\u6700\u7ec8\u7b54\u6848\uff0c\u6bd4\u8d5b\u7ed3\u675f\u540e\uff0c\u5e73\u53f0\u4f1a\u8ba1\u7b97\u4f60\u7684\u7b54\u6848\u7684 private LB \u5f97\u5206\u5e76\u81ea\u52a8\u6311\u9009\u5f97\u5206\u9ad8\u7684\u4e00\u4e2a\u4f5c\u4e3a\u4f60\u7684\u6700\u7ec8\u6210\u7ee9\u3002 \u5728\u8ba8\u8bba\u533a\u4f60\u4f1a\u7ecf\u5e38\u542c\u5230\u5927\u5bb6\u8ba8\u8bba CV score\u3001LB score\uff0c\u6307\u7684\u5c31\u662f\u4f60\u6a21\u578b\u672c\u5730\u4ea4\u53c9\u9a8c\u8bc1\u7684\u5f97\u5206\u548c\u63d0\u4ea4\u540e\u7684 public LB \u5f97\u5206\u3002 shake up\uff1apublic LB \u5f97\u5206\u53ef\u80fd\u4f1a\u548c private LB \u5f97\u5206\u5dee\u522b\u5f88\u5927\uff0c\u6bd4\u8d5b\u7ed3\u679c\u516c\u5e03\u524d\u4f60\u53ef\u80fd\u6392\u540d\u524d\u5341\uff0c\u6bd4\u8d5b\u7ed3\u679c\u516c\u5e03\u540e\u53d1\u73b0\u81ea\u5df1\u8dcc\u5230\u4e0a\u5343\u540d\u4e86\uff0c\u8fd9\u5c31\u662f\u6240\u8c13\u7684 shake up\uff0c\u4e00\u822c\u662f\u6a21\u578b\u8fc7\u62df\u5408\u4e86\uff0c\u8fd9\u4e2a\u9700\u8981\u5728\u8bad\u7ec3\u7684\u65f6\u5019\u5c31\u8981\u6ce8\u610f\u3002","title":"Leaderboard"},{"location":"tutorial/chapter05_application/5_1_kaggle/#513-kaggle","text":"\u4e00\u822c\u60c5\u51b5\u4e0b\uff0c\u90fd\u662f\u4ee5\u51c6\u786e\u7387\u4e3a\u5bfc\u5411\u7684\u6392\u540d\uff0c\u6bd5\u7adf\u6211\u4eec\u7684\u6a21\u578b\u8ba1\u7b97\u7684\u51c6\u786e\u662f\u7b2c\u4e00\u6807\u51c6\u3002 \u9488\u5bf9\u4e8e\u6bd4\u8d5b\u800c\u8a00\uff0c\u5728\u6bd4\u8d5b\u7ed3\u675f\u4e4b\u524d\uff0c\u53c2\u8d5b\u8005\u6bcf\u5929\u6700\u591a\u53ef\u4ee5\u63d0\u4ea45\u6b21\u6d4b\u8bd5\u96c6\u7684\u9884\u6d4b\u7ed3\u679c\u3002\u6bcf\u4e00\u6b21\u63d0\u4ea4\u7ed3\u679c\u90fd\u4f1a\u83b7\u5f97\u6700\u65b0\u7684\u4e34\u65f6\u6392\u540d\u6210\u7ee9\uff0c\u76f4\u81f3\u6bd4\u8d5b\u7ed3\u675f\u83b7\u5f97\u6700\u7ec8\u6392\u540d\uff0cKaggle\u5c06\u53c2\u8d5b\u8005\u6bcf\u6b21\u63d0\u4ea4\u7684\u7ed3\u679c\u53d6\u51fa25%-33%\uff0c\u5e76\u4f9d\u7167\u51c6\u786e\u7387\u8fdb\u884c\u4e34\u65f6\u6392\u540d\u3002\u5728\u6bd4\u8d5b\u7ed3\u675f\u65f6\uff0c\u53c2\u8d5b\u8005\u53ef\u4ee5\u6307\u5b9a\u51e0\u4e2a\u5df2\u7ecf\u63d0\u4ea4\u7684\u7ed3\u679c\uff0cKaggle\u4ece\u4e2d\u53bb\u9664\u4e4b\u524d\u7528\u4e8e\u4e34\u65f6\u6392\u540d\u7684\u90e8\u5206\uff0c\u7528\u5269\u4f59\u6570\u636e\u7684\u51c6\u786e\u7387\u7efc\u5408\u5f97\u5230\u6700\u7ec8\u6392\u540d\u3002 \u6240\u4ee5\uff0c\u6bd4\u8d5b\u8fc7\u7a0b\u4e2d\u7528\u4e8e\u6700\u7ec8\u6392\u540d\u7684\u90a3\u90e8\u5206\u6570\u636e\uff0c\u53c2\u8d5b\u8005\u662f\u59cb\u7ec8\u5f97\u4e0d\u5230\u5173\u4e8e\u51c6\u786e\u7387\u7684\u53cd\u9988\u7684\u3002\u8fd9\u6837\u4e00\u5b9a\u7a0b\u5ea6\u907f\u514d\u53c2\u8d5b\u6a21\u578b\u7684\u8fc7\u62df\u5408\uff0c\u4fdd\u8bc1\u8bc4\u9009\u51fa\u517c\u987e\u51c6\u786e\u7387\u548c\u6cdb\u5316\u80fd\u529b\u7684\u6a21\u578b\u3002","title":"5.1.3 Kaggle\u7ade\u8d5b\u7684\u6392\u540d\u673a\u5236"},{"location":"tutorial/chapter05_application/5_1_kaggle/#514-kaggle","text":"Kaggle\u63d0\u4f9b\u514d\u8d39\u8bbf\u95ee\u5185\u6838\u4e2d\u7684NVidia K80 GPU\u3002\u6211\u7684\u4e2a\u4eba\u7406\u89e3\u76f8\u5f53\u4e8e1060\u6216\u80051070\u7684\u6c34\u5e73\u5427\u3002 \u6211\u4eec\u53ef\u4ee5\u5728Kernel\u7684\u754c\u9762\u53f3\u4fa7\u5e95\u7aef\uff0cSetting\u9009\u9879\u4e2d\u5c06GPU\u5f00\u542f\uff0c\u8fd9\u6837\u5c31\u53ef\u4ee5\u4f7f\u7528\u514d\u8d39\u7684GPU\u8d44\u6e90\u4e86\u3002 Kaggle\u53ea\u63d0\u4f9b6\u5c0f\u65f6\u7684\u8fde\u7eedGPU\u4f7f\u7528\u65f6\u95f4\uff08\u5370\u8c61\u4e2d\uff0c\u5f85\u786e\u8ba4\uff09\uff0c\u867d\u7136\u5bf9\u4e8e\u5927\u6570\u636e\u91cf\u8ba1\u7b97\u6765\u8bf4\u6839\u672c\u5c31\u4e0d\u591f\u7528\uff0c\u4f46\u662f\u5bf9\u4e8e\u7814\u7a76\uff0c\u8fd9\u4e9b\u5df2\u7ecf\u591f\u4e86\uff0c\u4f8b\u5982\u6211\u4eec\u5728\u56fe\u50cf\u8bc6\u522b\u4e2d\u7ecf\u5e38\u7528\u5230\u7684CIFAR-10 \u56fe\u7247\u5206\u7c7b\uff0c\u4e00\u822c\u8bad\u7ec32\u4e2a\u5c0f\u65f6\u5de6\u53f3\u5c31\u80fd\u591f\u5f97\u5230\u6bd4\u8f83\u51c6\u786e\u7684\u6a21\u578b\u4e86\uff0c\u8fd9\u5bf9\u4e8e\u5165\u95e8\u5b66\u4e60\u6765\u8bf4\u5df2\u7ecf\u591f\u7528\u4e86\u3002","title":"5.1.4 Kaggle\u8585\u7f8a\u6bdb\u6307\u5357"},{"location":"tutorial/chapter05_application/5_1_kaggle/#515","text":"\u9664\u4e86Kaggle\uff0c\u5176\u5b9e\u8fd8\u6709\u4e0d\u5c11\u7c7b\u4f3c\u7684\u5e73\u53f0\uff1b DrivenData CrowdANALYTIX InnoCentive TundIT Codalab Analytics Vidhya CrowdAI Numerai Data Science Challenge KDD Cup \u5929\u6c60 \u817e\u8baf\u5e7f\u544a\u7b97\u6cd5\u5927\u8d5b","title":"5.1.5 \u5176\u4ed6\u7684\u4e00\u4e9b\u6570\u636e\u7ade\u8d5b\u5e73\u53f0"},{"location":"tutorial/chapter05_application/readme/","text":"Chapter05 Application \u00b6 Content \u00b6 5.1 Kaggle \u00b6 Kaggle 5.2 \u7ed3\u6784\u5316\u6570\u636e \u00b6 5.3 Computer Vision \u00b6 Detection \u00b6 Segmentation \u00b6 Recognition \u00b6 GAN \u00b6 Others \u00b6 5.4 \u81ea\u7136\u8bed\u8a00\u5904\u7406 \u00b6 5.5 \u534f\u540c\u8fc7\u6ee4 \u00b6","title":"5.5 \u534f\u540c\u8fc7\u6ee4"},{"location":"tutorial/chapter05_application/readme/#chapter05-application","text":"","title":"Chapter05 Application"},{"location":"tutorial/chapter05_application/readme/#content","text":"","title":"Content"},{"location":"tutorial/chapter05_application/readme/#51-kaggle","text":"Kaggle","title":"5.1 Kaggle"},{"location":"tutorial/chapter05_application/readme/#52","text":"","title":"5.2 \u7ed3\u6784\u5316\u6570\u636e"},{"location":"tutorial/chapter05_application/readme/#53-computer-vision","text":"","title":"5.3 Computer Vision"},{"location":"tutorial/chapter05_application/readme/#detection","text":"","title":"Detection"},{"location":"tutorial/chapter05_application/readme/#segmentation","text":"","title":"Segmentation"},{"location":"tutorial/chapter05_application/readme/#recognition","text":"","title":"Recognition"},{"location":"tutorial/chapter05_application/readme/#gan","text":"","title":"GAN"},{"location":"tutorial/chapter05_application/readme/#others","text":"","title":"Others"},{"location":"tutorial/chapter05_application/readme/#54","text":"","title":"5.4 \u81ea\u7136\u8bed\u8a00\u5904\u7406"},{"location":"tutorial/chapter05_application/readme/#55","text":"","title":"5.5 \u534f\u540c\u8fc7\u6ee4"}]}