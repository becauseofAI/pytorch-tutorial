{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"PyTorch Tutorial \u00b6 Introduction \u00b6 PyTorch Tutorial for Deep Learning Research and Product. Note It is still at a very early stage and is being written gradually.","title":"Introduction"},{"location":"#pytorch-tutorial","text":"","title":" PyTorch Tutorial "},{"location":"#introduction","text":"PyTorch Tutorial for Deep Learning Research and Product. Note It is still at a very early stage and is being written gradually.","title":"Introduction"},{"location":"about/","text":"Author \u00b6 becauseofAI Contact \u00b6 Email: helloai777@gmail.com License \u00b6 Apache-2.0","title":"About"},{"location":"about/#author","text":"becauseofAI","title":"Author"},{"location":"about/#contact","text":"Email: helloai777@gmail.com","title":"Contact"},{"location":"about/#license","text":"Apache-2.0","title":"License"},{"location":"chapter01_getting-started/","text":"PyTorch \u4e2d\u6587\u624b\u518c\u7b2c\u4e00\u7ae0 \uff1a PyTorch\u5165\u95e8 \u00b6 \u76ee\u5f55 \u00b6 PyTorch \u7b80\u4ecb PyTorch \u73af\u5883\u642d\u5efa PyTorch \u6df1\u5ea6\u5b66\u4e60\uff1a60\u5206\u949f\u5feb\u901f\u5165\u95e8\uff08\u5b98\u65b9\uff09 \u5f20\u91cf Autograd\uff1a\u81ea\u52a8\u6c42\u5bfc \u795e\u7ecf\u7f51\u7edc \u8bad\u7ec3\u4e00\u4e2a\u5206\u7c7b\u5668 \u9009\u8bfb\uff1a\u6570\u636e\u5e76\u884c\u5904\u7406\uff08\u591aGPU\uff09 \u76f8\u5173\u8d44\u6e90\u4ecb\u7ecd","title":"PyTorch \u4e2d\u6587\u624b\u518c\u7b2c\u4e00\u7ae0 \uff1a PyTorch\u5165\u95e8"},{"location":"chapter01_getting-started/#pytorch-pytorch","text":"","title":"PyTorch \u4e2d\u6587\u624b\u518c\u7b2c\u4e00\u7ae0 \uff1a PyTorch\u5165\u95e8"},{"location":"chapter01_getting-started/#_1","text":"PyTorch \u7b80\u4ecb PyTorch \u73af\u5883\u642d\u5efa PyTorch \u6df1\u5ea6\u5b66\u4e60\uff1a60\u5206\u949f\u5feb\u901f\u5165\u95e8\uff08\u5b98\u65b9\uff09 \u5f20\u91cf Autograd\uff1a\u81ea\u52a8\u6c42\u5bfc \u795e\u7ecf\u7f51\u7edc \u8bad\u7ec3\u4e00\u4e2a\u5206\u7c7b\u5668 \u9009\u8bfb\uff1a\u6570\u636e\u5e76\u884c\u5904\u7406\uff08\u591aGPU\uff09 \u76f8\u5173\u8d44\u6e90\u4ecb\u7ecd","title":"\u76ee\u5f55"},{"location":"chapter01_getting-started/1_1_pytorch-introduction/","text":"Pytorch \u7b80\u4ecb \u00b6 PyTorch\u7684\u7531\u6765 \u00b6 \u5f88\u591a\u4eba\u90fd\u4f1a\u62ffPyTorch\u548cGoogle\u7684Tensorflow\u8fdb\u884c\u6bd4\u8f83\uff0c\u8fd9\u4e2a\u80af\u5b9a\u662f\u6ca1\u6709\u95ee\u9898\u7684\uff0c\u56e0\u4e3a\u4ed6\u4eec\u662f\u6700\u706b\u7684\u4e24\u4e2a\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u4e86\u3002\u4f46\u662f\u8bf4\u5230PyTorch\uff0c\u5176\u5b9e\u5e94\u8be5\u5148\u8bf4 Torch \u3002 Torch\u662f\u4ec0\u4e48\uff1f \u00b6 Torch\u82f1\u8bd1\u4e2d\uff1a\u706b\u70ac A Tensor library like Numpy, unlike Numpy it has strong GPU support. Lua is a wrapper for Torch (Yes! you need to have a good understanding of Lua), and for that you will need LuaRocks package manager. Torch\u662f\u4e00\u4e2a\u4e0eNumpy\u7c7b\u4f3c\u7684\u5f20\u91cf\uff08Tensor\uff09\u64cd\u4f5c\u5e93\uff0c\u4e0eNumpy\u4e0d\u540c\u7684\u662fTorch\u5bf9GPU\u652f\u6301\u7684\u5f88\u597d\uff0cLua\u662fTorch\u3002 [1] Torch is not going anywhere. PyTorch and Torch use the same C libraries that contain all the performance: TH, THC, THNN, THCUNN and they will continue to be shared. We still and will have continued engineering on Torch itself, and we have no immediate plan to remove that. PyTorch\u548cTorch\u4f7f\u7528\u5305\u542b\u6240\u6709\u76f8\u540c\u6027\u80fd\u7684C\u5e93\uff1aTH, THC, THNN, THCUNN\uff0c\u5e76\u4e14\u5b83\u4eec\u5c06\u7ee7\u7eed\u5171\u4eab\u8fd9\u4e9b\u5e93\u3002 \u8fd9\u6837\u7684\u56de\u7b54\u5c31\u5f88\u660e\u786e\u4e86\uff0c\u5176\u5b9ePyTorch\u548cTorch\u90fd\u4f7f\u7528\u7684\u662f\u76f8\u540c\u7684\u5e95\u5c42\uff0c\u53ea\u662f\u4f7f\u7528\u4e86\u4e0d\u540c\u7684\u4e0a\u5c42\u5305\u88c5\u8bed\u8a00\u3002 LUA\u867d\u7136\u5feb\uff0c\u4f46\u662f\u592a\u5c0f\u4f17\u4e86\uff0c\u6240\u4ee5\u624d\u4f1a\u6709PyTorch\u7684\u51fa\u73b0\u3002 [2] \u91cd\u65b0\u4ecb\u7ecd PyTorch \u00b6 PyTorch is an open source machine learning library for Python, based on Torch, used for applications such as natural language processing. It is primarily developed by Facebook's artificial-intelligence research group, and Uber's \"Pyro\" software for probabilistic programming is built on it. PyTorch\u662f\u4e00\u4e2a\u57fa\u4e8eTorch\u7684Python\u5f00\u6e90\u673a\u5668\u5b66\u4e60\u5e93\uff0c\u7528\u4e8e\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7b49\u5e94\u7528\u7a0b\u5e8f\u3002 \u5b83\u4e3b\u8981\u7531Facebook\u7684\u4eba\u5de5\u667a\u80fd\u7814\u7a76\u5c0f\u7ec4\u5f00\u53d1\u3002Uber\u7684\"Pyro\"\u4e5f\u662f\u4f7f\u7528\u7684\u8fd9\u4e2a\u5e93\u3002 [3] PyTorch is a Python package that provides two high-level features: - Tensor computation (like NumPy) with strong GPU acceleration - Deep neural networks built on a tape-based autograd system You can reuse your favorite Python packages such as NumPy, SciPy and Cython to extend PyTorch when needed. PyTorch\u662f\u4e00\u4e2aPython\u5305\uff0c\u63d0\u4f9b\u4e24\u4e2a\u9ad8\u7ea7\u529f\u80fd\uff1a * \u5177\u6709\u5f3a\u5927\u7684GPU\u52a0\u901f\u7684\u5f20\u91cf\u8ba1\u7b97\uff08\u5982NumPy\uff09 * \u5305\u542b\u81ea\u52a8\u6c42\u5bfc\u7cfb\u7edf\u7684\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc \u4efb\u4f55\u65f6\u5019\uff0c\u4f60\u53ef\u4ee5\u7528\u4f60\u559c\u6b22\u7684Python\u5305\uff0c\u5982NumPy\u3001SciPy \u548c Cython\u53bb\u6269\u5c55PyTorch\u3002 [4] \u5bf9\u6bd4PyTorch\u548cTensorflow \u00b6 \u6ca1\u6709\u597d\u7684\u6846\u67b6\uff0c\u53ea\u6709\u5408\u9002\u7684\u6846\u67b6\uff0c \u8fd9\u7bc7\u77e5\u4e4e\u6587\u7ae0 \u6709\u4e2a\u7b80\u5355\u7684\u5bf9\u6bd4\uff0c2019\u5e746\u670825\u65e5[\u673a\u5668\u4e4b\u5fc3]\u7ffb\u8bd1\u7684 PyTorch\u548cKeras\u7684\u6700\u65b0\u5bf9\u6bd4 \uff0c\u6240\u4ee5\u8fd9\u91cc\u5c31\u4e0d\u8be6\u7ec6\u518d\u8bf4\u4e86\u3002 \u5e76\u4e14\u6280\u672f\u662f\u53d1\u5c55\u7684\uff0c\u77e5\u4e4e\u4e0a\u7684\u5bf9\u6bd4\u4e5f\u4e0d\u662f\u7edd\u5bf9\u7684\uff0c\u6bd4\u5982Tensorflow\u57281.5\u7248\u7684\u65f6\u5019\u5c31\u5f15\u5165\u4e86Eager Execution\u673a\u5236\u5b9e\u73b0\u4e86\u52a8\u6001\u56fe\uff0cPyTorch\u7684\u53ef\u89c6\u5316,windows\u652f\u6301\uff0c\u6cbf\u7ef4\u7ffb\u8f6c\u5f20\u91cf\u7b49\u95ee\u9898\u90fd\u5df2\u7ecf\u4e0d\u662f\u95ee\u9898\u4e86\u3002 \u518d\u6b21\u603b\u7ed3 \u00b6 PyTorch\u7b97\u662f\u76f8\u5f53\u7b80\u6d01\u4f18\u96c5\u4e14\u9ad8\u6548\u5feb\u901f\u7684\u6846\u67b6 \u8bbe\u8ba1\u8ffd\u6c42\u6700\u5c11\u7684\u5c01\u88c5\uff0c\u5c3d\u91cf\u907f\u514d\u91cd\u590d\u9020\u8f6e\u5b50 \u7b97\u662f\u6240\u6709\u7684\u6846\u67b6\u4e2d\u9762\u5411\u5bf9\u8c61\u8bbe\u8ba1\u7684\u6700\u4f18\u96c5\u7684\u4e00\u4e2a\uff0c\u8bbe\u8ba1\u6700\u7b26\u5408\u4eba\u4eec\u7684\u601d\u7ef4\uff0c\u5b83\u8ba9\u7528\u6237\u5c3d\u53ef\u80fd\u5730\u4e13\u6ce8\u4e8e\u5b9e\u73b0\u81ea\u5df1\u7684\u60f3\u6cd5 \u5927\u4f6c\u652f\u6301\uff0c\u4e0egoogle\u7684Tensorflow\u7c7b\u4f3c\uff0cFAIR\u7684\u652f\u6301\u8db3\u4ee5\u786e\u4fddPyTorch\u83b7\u5f97\u6301\u7eed\u7684\u5f00\u53d1\u66f4\u65b0 \u4e0d\u9519\u7684\u7684\u6587\u6863\uff08\u76f8\u6bd4FB\u7684\u5176\u4ed6\u9879\u76ee\uff0cPyTorch\u7684\u6587\u6863\u7b80\u76f4\u7b97\u662f\u5b8c\u5584\u4e86\uff0c\u53c2\u8003Thrift\uff09\uff0cPyTorch\u4f5c\u8005\u4eb2\u81ea\u7ef4\u62a4\u7684\u8bba\u575b \u4f9b\u7528\u6237\u4ea4\u6d41\u548c\u6c42\u6559\u95ee\u9898 \u5165\u95e8\u7b80\u5355","title":"1.1 PyTorch Tntroduction"},{"location":"chapter01_getting-started/1_1_pytorch-introduction/#pytorch","text":"","title":"Pytorch \u7b80\u4ecb"},{"location":"chapter01_getting-started/1_1_pytorch-introduction/#pytorch_1","text":"\u5f88\u591a\u4eba\u90fd\u4f1a\u62ffPyTorch\u548cGoogle\u7684Tensorflow\u8fdb\u884c\u6bd4\u8f83\uff0c\u8fd9\u4e2a\u80af\u5b9a\u662f\u6ca1\u6709\u95ee\u9898\u7684\uff0c\u56e0\u4e3a\u4ed6\u4eec\u662f\u6700\u706b\u7684\u4e24\u4e2a\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u4e86\u3002\u4f46\u662f\u8bf4\u5230PyTorch\uff0c\u5176\u5b9e\u5e94\u8be5\u5148\u8bf4 Torch \u3002","title":"PyTorch\u7684\u7531\u6765"},{"location":"chapter01_getting-started/1_1_pytorch-introduction/#torch","text":"Torch\u82f1\u8bd1\u4e2d\uff1a\u706b\u70ac A Tensor library like Numpy, unlike Numpy it has strong GPU support. Lua is a wrapper for Torch (Yes! you need to have a good understanding of Lua), and for that you will need LuaRocks package manager. Torch\u662f\u4e00\u4e2a\u4e0eNumpy\u7c7b\u4f3c\u7684\u5f20\u91cf\uff08Tensor\uff09\u64cd\u4f5c\u5e93\uff0c\u4e0eNumpy\u4e0d\u540c\u7684\u662fTorch\u5bf9GPU\u652f\u6301\u7684\u5f88\u597d\uff0cLua\u662fTorch\u3002 [1] Torch is not going anywhere. PyTorch and Torch use the same C libraries that contain all the performance: TH, THC, THNN, THCUNN and they will continue to be shared. We still and will have continued engineering on Torch itself, and we have no immediate plan to remove that. PyTorch\u548cTorch\u4f7f\u7528\u5305\u542b\u6240\u6709\u76f8\u540c\u6027\u80fd\u7684C\u5e93\uff1aTH, THC, THNN, THCUNN\uff0c\u5e76\u4e14\u5b83\u4eec\u5c06\u7ee7\u7eed\u5171\u4eab\u8fd9\u4e9b\u5e93\u3002 \u8fd9\u6837\u7684\u56de\u7b54\u5c31\u5f88\u660e\u786e\u4e86\uff0c\u5176\u5b9ePyTorch\u548cTorch\u90fd\u4f7f\u7528\u7684\u662f\u76f8\u540c\u7684\u5e95\u5c42\uff0c\u53ea\u662f\u4f7f\u7528\u4e86\u4e0d\u540c\u7684\u4e0a\u5c42\u5305\u88c5\u8bed\u8a00\u3002 LUA\u867d\u7136\u5feb\uff0c\u4f46\u662f\u592a\u5c0f\u4f17\u4e86\uff0c\u6240\u4ee5\u624d\u4f1a\u6709PyTorch\u7684\u51fa\u73b0\u3002 [2]","title":"Torch\u662f\u4ec0\u4e48\uff1f"},{"location":"chapter01_getting-started/1_1_pytorch-introduction/#pytorch_2","text":"PyTorch is an open source machine learning library for Python, based on Torch, used for applications such as natural language processing. It is primarily developed by Facebook's artificial-intelligence research group, and Uber's \"Pyro\" software for probabilistic programming is built on it. PyTorch\u662f\u4e00\u4e2a\u57fa\u4e8eTorch\u7684Python\u5f00\u6e90\u673a\u5668\u5b66\u4e60\u5e93\uff0c\u7528\u4e8e\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7b49\u5e94\u7528\u7a0b\u5e8f\u3002 \u5b83\u4e3b\u8981\u7531Facebook\u7684\u4eba\u5de5\u667a\u80fd\u7814\u7a76\u5c0f\u7ec4\u5f00\u53d1\u3002Uber\u7684\"Pyro\"\u4e5f\u662f\u4f7f\u7528\u7684\u8fd9\u4e2a\u5e93\u3002 [3] PyTorch is a Python package that provides two high-level features: - Tensor computation (like NumPy) with strong GPU acceleration - Deep neural networks built on a tape-based autograd system You can reuse your favorite Python packages such as NumPy, SciPy and Cython to extend PyTorch when needed. PyTorch\u662f\u4e00\u4e2aPython\u5305\uff0c\u63d0\u4f9b\u4e24\u4e2a\u9ad8\u7ea7\u529f\u80fd\uff1a * \u5177\u6709\u5f3a\u5927\u7684GPU\u52a0\u901f\u7684\u5f20\u91cf\u8ba1\u7b97\uff08\u5982NumPy\uff09 * \u5305\u542b\u81ea\u52a8\u6c42\u5bfc\u7cfb\u7edf\u7684\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc \u4efb\u4f55\u65f6\u5019\uff0c\u4f60\u53ef\u4ee5\u7528\u4f60\u559c\u6b22\u7684Python\u5305\uff0c\u5982NumPy\u3001SciPy \u548c Cython\u53bb\u6269\u5c55PyTorch\u3002 [4]","title":"\u91cd\u65b0\u4ecb\u7ecd PyTorch"},{"location":"chapter01_getting-started/1_1_pytorch-introduction/#pytorchtensorflow","text":"\u6ca1\u6709\u597d\u7684\u6846\u67b6\uff0c\u53ea\u6709\u5408\u9002\u7684\u6846\u67b6\uff0c \u8fd9\u7bc7\u77e5\u4e4e\u6587\u7ae0 \u6709\u4e2a\u7b80\u5355\u7684\u5bf9\u6bd4\uff0c2019\u5e746\u670825\u65e5[\u673a\u5668\u4e4b\u5fc3]\u7ffb\u8bd1\u7684 PyTorch\u548cKeras\u7684\u6700\u65b0\u5bf9\u6bd4 \uff0c\u6240\u4ee5\u8fd9\u91cc\u5c31\u4e0d\u8be6\u7ec6\u518d\u8bf4\u4e86\u3002 \u5e76\u4e14\u6280\u672f\u662f\u53d1\u5c55\u7684\uff0c\u77e5\u4e4e\u4e0a\u7684\u5bf9\u6bd4\u4e5f\u4e0d\u662f\u7edd\u5bf9\u7684\uff0c\u6bd4\u5982Tensorflow\u57281.5\u7248\u7684\u65f6\u5019\u5c31\u5f15\u5165\u4e86Eager Execution\u673a\u5236\u5b9e\u73b0\u4e86\u52a8\u6001\u56fe\uff0cPyTorch\u7684\u53ef\u89c6\u5316,windows\u652f\u6301\uff0c\u6cbf\u7ef4\u7ffb\u8f6c\u5f20\u91cf\u7b49\u95ee\u9898\u90fd\u5df2\u7ecf\u4e0d\u662f\u95ee\u9898\u4e86\u3002","title":"\u5bf9\u6bd4PyTorch\u548cTensorflow"},{"location":"chapter01_getting-started/1_1_pytorch-introduction/#_1","text":"PyTorch\u7b97\u662f\u76f8\u5f53\u7b80\u6d01\u4f18\u96c5\u4e14\u9ad8\u6548\u5feb\u901f\u7684\u6846\u67b6 \u8bbe\u8ba1\u8ffd\u6c42\u6700\u5c11\u7684\u5c01\u88c5\uff0c\u5c3d\u91cf\u907f\u514d\u91cd\u590d\u9020\u8f6e\u5b50 \u7b97\u662f\u6240\u6709\u7684\u6846\u67b6\u4e2d\u9762\u5411\u5bf9\u8c61\u8bbe\u8ba1\u7684\u6700\u4f18\u96c5\u7684\u4e00\u4e2a\uff0c\u8bbe\u8ba1\u6700\u7b26\u5408\u4eba\u4eec\u7684\u601d\u7ef4\uff0c\u5b83\u8ba9\u7528\u6237\u5c3d\u53ef\u80fd\u5730\u4e13\u6ce8\u4e8e\u5b9e\u73b0\u81ea\u5df1\u7684\u60f3\u6cd5 \u5927\u4f6c\u652f\u6301\uff0c\u4e0egoogle\u7684Tensorflow\u7c7b\u4f3c\uff0cFAIR\u7684\u652f\u6301\u8db3\u4ee5\u786e\u4fddPyTorch\u83b7\u5f97\u6301\u7eed\u7684\u5f00\u53d1\u66f4\u65b0 \u4e0d\u9519\u7684\u7684\u6587\u6863\uff08\u76f8\u6bd4FB\u7684\u5176\u4ed6\u9879\u76ee\uff0cPyTorch\u7684\u6587\u6863\u7b80\u76f4\u7b97\u662f\u5b8c\u5584\u4e86\uff0c\u53c2\u8003Thrift\uff09\uff0cPyTorch\u4f5c\u8005\u4eb2\u81ea\u7ef4\u62a4\u7684\u8bba\u575b \u4f9b\u7528\u6237\u4ea4\u6d41\u548c\u6c42\u6559\u95ee\u9898 \u5165\u95e8\u7b80\u5355","title":"\u518d\u6b21\u603b\u7ed3"},{"location":"chapter01_getting-started/1_3_deep-learning-with-pytorch-60-minute-blitz/","text":"PyTorch \u6df1\u5ea6\u5b66\u4e60\uff1a60\u5206\u949f\u5feb\u901f\u5165\u95e8 \uff08\u5b98\u65b9\u4e2d\u6587\u7248\uff09 \u00b6 \u5b98\u65b9\u8fde\u63a5 Deep Learning with PyTorch: A 60 Minute Blitz \u76ee\u5f55 \u00b6 \u5f20\u91cf \u81ea\u52a8\u6c42\u5bfc \u795e\u7ecf\u7f51\u7edc \u8bad\u7ec3\u4e00\u4e2a\u5206\u7c7b\u5668 \u6570\u636e\u5e76\u884c","title":"1.3 PyTorch 60 Minute Blitz"},{"location":"chapter01_getting-started/1_3_deep-learning-with-pytorch-60-minute-blitz/#pytorch-60","text":"\u5b98\u65b9\u8fde\u63a5 Deep Learning with PyTorch: A 60 Minute Blitz","title":"PyTorch \u6df1\u5ea6\u5b66\u4e60\uff1a60\u5206\u949f\u5feb\u901f\u5165\u95e8 \uff08\u5b98\u65b9\u4e2d\u6587\u7248\uff09"},{"location":"chapter01_getting-started/1_3_deep-learning-with-pytorch-60-minute-blitz/#_1","text":"\u5f20\u91cf \u81ea\u52a8\u6c42\u5bfc \u795e\u7ecf\u7f51\u7edc \u8bad\u7ec3\u4e00\u4e2a\u5206\u7c7b\u5668 \u6570\u636e\u5e76\u884c","title":"\u76ee\u5f55"},{"location":"chapter02_basics/","text":"Pytorch \u624b\u518c\u7b2c\u4e8c\u7ae0 \uff1a \u57fa\u7840 \u00b6 \u76ee\u5f55 \u00b6 \u7b2c\u4e00\u8282 PyTorch \u57fa\u7840 \u00b6 \u5f20\u91cf \u81ea\u52a8\u6c42\u5bfc \u795e\u7ecf\u7f51\u7edc\u5305nn\u548c\u4f18\u5316\u5668optm \u6570\u636e\u7684\u52a0\u8f7d\u548c\u9884\u5904\u7406 \u7b2c\u4e8c\u8282 \u6df1\u5ea6\u5b66\u4e60\u57fa\u7840\u53ca\u6570\u5b66\u539f\u7406 \u00b6 \u6df1\u5ea6\u5b66\u4e60\u57fa\u7840\u53ca\u6570\u5b66\u539f\u7406 \u7b2c\u4e09\u8282 \u795e\u7ecf\u7f51\u7edc\u7b80\u4ecb \u00b6 \u795e\u7ecf\u7f51\u7edc\u7b80\u4ecb \u7b2c\u56db\u8282 \u5377\u79ef\u795e\u7ecf\u7f51\u7edc \u00b6 \u5377\u79ef\u795e\u7ecf\u7f51\u7edc \u7b2c\u4e94\u8282 \u5faa\u73af\u795e\u7ecf\u7f51\u7edc \u00b6 \u5faa\u73af\u795e\u7ecf\u7f51\u7edc","title":"Pytorch \u624b\u518c\u7b2c\u4e8c\u7ae0 \uff1a \u57fa\u7840"},{"location":"chapter02_basics/#pytorch","text":"","title":"Pytorch \u624b\u518c\u7b2c\u4e8c\u7ae0 \uff1a \u57fa\u7840"},{"location":"chapter02_basics/#_1","text":"","title":"\u76ee\u5f55"},{"location":"chapter02_basics/#pytorch_1","text":"\u5f20\u91cf \u81ea\u52a8\u6c42\u5bfc \u795e\u7ecf\u7f51\u7edc\u5305nn\u548c\u4f18\u5316\u5668optm \u6570\u636e\u7684\u52a0\u8f7d\u548c\u9884\u5904\u7406","title":"\u7b2c\u4e00\u8282 PyTorch \u57fa\u7840"},{"location":"chapter02_basics/#_2","text":"\u6df1\u5ea6\u5b66\u4e60\u57fa\u7840\u53ca\u6570\u5b66\u539f\u7406","title":"\u7b2c\u4e8c\u8282 \u6df1\u5ea6\u5b66\u4e60\u57fa\u7840\u53ca\u6570\u5b66\u539f\u7406"},{"location":"chapter02_basics/#_3","text":"\u795e\u7ecf\u7f51\u7edc\u7b80\u4ecb","title":"\u7b2c\u4e09\u8282 \u795e\u7ecf\u7f51\u7edc\u7b80\u4ecb"},{"location":"chapter02_basics/#_4","text":"\u5377\u79ef\u795e\u7ecf\u7f51\u7edc","title":"\u7b2c\u56db\u8282 \u5377\u79ef\u795e\u7ecf\u7f51\u7edc"},{"location":"chapter02_basics/#_5","text":"\u5faa\u73af\u795e\u7ecf\u7f51\u7edc","title":"\u7b2c\u4e94\u8282 \u5faa\u73af\u795e\u7ecf\u7f51\u7edc"},{"location":"chapter02_basics/2_1_pytorch-basics-tensor/","text":"PyTorch \u57fa\u7840 : \u5f20\u91cf \u00b6 \u5728\u7b2c\u4e00\u7ae0\u4e2d\u6211\u4eec\u5df2\u7ecf\u901a\u8fc7\u5b98\u65b9\u7684\u5165\u95e8\u6559\u7a0b\u5bf9PyTorch\u6709\u4e86\u4e00\u5b9a\u7684\u4e86\u89e3\uff0c\u8fd9\u4e00\u7ae0\u4f1a\u8be6\u7ec6\u4ecb\u7ecdPyTorch \u91cc\u9762\u7684\u57fa\u7840\u77e5\u8bc6\u3002 \u5168\u90e8\u638c\u63e1\u4e86\u8fd9\u4e9b\u57fa\u7840\u77e5\u8bc6\uff0c\u5728\u540e\u9762\u7684\u5e94\u7528\u4e2d\u624d\u80fd\u66f4\u52a0\u5feb\u901f\u8fdb\u9636\uff0c\u5982\u679c\u4f60\u5df2\u7ecf\u5bf9PyTorch\u6709\u4e00\u5b9a\u7684\u4e86\u89e3\uff0c\u53ef\u4ee5\u8df3\u8fc7\u6b64\u7ae0 # \u9996\u5148\u8981\u5f15\u5165\u76f8\u5173\u7684\u5305 import torch import numpy as np #\u6253\u5370\u4e00\u4e0b\u7248\u672c torch . __version__ '1.0.0' \u5f20\u91cf(Tensor) \u00b6 \u5f20\u91cf\u7684\u82f1\u6587\u662fTensor\uff0c\u5b83\u662fPyTorch\u91cc\u9762\u57fa\u7840\u7684\u8fd0\u7b97\u5355\u4f4d,\u4e0eNumpy\u7684ndarray\u76f8\u540c\u90fd\u8868\u793a\u7684\u662f\u4e00\u4e2a\u591a\u7ef4\u7684\u77e9\u9635\u3002 \u4e0endarray\u7684\u6700\u5927\u533a\u522b\u5c31\u662f\uff0cPyTorch\u7684Tensor\u53ef\u4ee5\u5728 GPU \u4e0a\u8fd0\u884c\uff0c\u800c numpy \u7684 ndarray \u53ea\u80fd\u5728 CPU \u4e0a\u8fd0\u884c\uff0c\u5728GPU\u4e0a\u8fd0\u884c\u5927\u5927\u52a0\u5feb\u4e86\u8fd0\u7b97\u901f\u5ea6\u3002 \u4e0b\u9762\u6211\u4eec\u751f\u6210\u4e00\u4e2a\u7b80\u5355\u7684\u5f20\u91cf x = torch . rand ( 2 , 3 ) x tensor([[0.6904, 0.7419, 0.8010], [0.1722, 0.2442, 0.8181]]) \u4ee5\u4e0a\u751f\u6210\u4e86\u4e00\u4e2a\uff0c2\u884c3\u5217\u7684\u7684\u77e9\u9635\uff0c\u6211\u4eec\u770b\u4e00\u4e0b\u4ed6\u7684\u5927\u5c0f\uff1a # \u53ef\u4ee5\u4f7f\u7528\u4e0enumpy\u76f8\u540c\u7684shape\u5c5e\u6027\u67e5\u770b print ( x . shape ) # \u4e5f\u53ef\u4ee5\u4f7f\u7528size()\u51fd\u6570\uff0c\u8fd4\u56de\u7684\u7ed3\u679c\u90fd\u662f\u76f8\u540c\u7684 print ( x . size ()) torch.Size([2, 3]) torch.Size([2, 3]) \u5f20\u91cf\uff08Tensor\uff09\u662f\u4e00\u4e2a\u5b9a\u4e49\u5728\u4e00\u4e9b\u5411\u91cf\u7a7a\u95f4\u548c\u4e00\u4e9b\u5bf9\u5076\u7a7a\u95f4\u7684\u7b1b\u5361\u513f\u79ef\u4e0a\u7684\u591a\u91cd\u7ebf\u6027\u6620\u5c04\uff0c\u5176\u5750\u6807\u662f|n|\u7ef4\u7a7a\u95f4\u5185\uff0c\u6709|n|\u4e2a\u5206\u91cf\u7684\u4e00\u79cd\u91cf\uff0c \u5176\u4e2d\u6bcf\u4e2a\u5206\u91cf\u90fd\u662f\u5750\u6807\u7684\u51fd\u6570\uff0c \u800c\u5728\u5750\u6807\u53d8\u6362\u65f6\uff0c\u8fd9\u4e9b\u5206\u91cf\u4e5f\u4f9d\u7167\u67d0\u4e9b\u89c4\u5219\u4f5c\u7ebf\u6027\u53d8\u6362\u3002r\u79f0\u4e3a\u8be5\u5f20\u91cf\u7684\u79e9\u6216\u9636\uff08\u4e0e\u77e9\u9635\u7684\u79e9\u548c\u9636\u5747\u65e0\u5173\u7cfb\uff09\u3002 (\u6765\u81ea\u767e\u5ea6\u767e\u79d1) \u4e0b\u9762\u6211\u4eec\u6765\u751f\u6210\u4e00\u4e9b\u591a\u7ef4\u7684\u5f20\u91cf\uff1a y = torch . rand ( 2 , 3 , 4 , 5 ) print ( y . size ()) y torch.Size([2, 3, 4, 5]) tensor([[[[0.9071, 0.0616, 0.0006, 0.6031, 0.0714], [0.6592, 0.9700, 0.0253, 0.0726, 0.5360], [0.5416, 0.1138, 0.9592, 0.6779, 0.6501], [0.0546, 0.8287, 0.7748, 0.4352, 0.9232]], [[0.0730, 0.4228, 0.7407, 0.4099, 0.1482], [0.5408, 0.9156, 0.6554, 0.5787, 0.9775], [0.4262, 0.3644, 0.1993, 0.4143, 0.5757], [0.9307, 0.8839, 0.8462, 0.0933, 0.6688]], [[0.4447, 0.0929, 0.9882, 0.5392, 0.1159], [0.4790, 0.5115, 0.4005, 0.9486, 0.0054], [0.8955, 0.8097, 0.1227, 0.2250, 0.5830], [0.8483, 0.2070, 0.1067, 0.4727, 0.5095]]], [[[0.9438, 0.2601, 0.2885, 0.5457, 0.7528], [0.2971, 0.2171, 0.3910, 0.1924, 0.2570], [0.7491, 0.9749, 0.2703, 0.2198, 0.9472], [0.1216, 0.6647, 0.8809, 0.0125, 0.5513]], [[0.0870, 0.6622, 0.7252, 0.4783, 0.0160], [0.7832, 0.6050, 0.7469, 0.7947, 0.8052], [0.1755, 0.4489, 0.0602, 0.8073, 0.3028], [0.9937, 0.6780, 0.9425, 0.0059, 0.0451]], [[0.3851, 0.8742, 0.5932, 0.4899, 0.8354], [0.8577, 0.3705, 0.0229, 0.7097, 0.7557], [0.1505, 0.3527, 0.0843, 0.0088, 0.8741], [0.6041, 0.8797, 0.6189, 0.9495, 0.1479]]]]) \u5728\u540c\u6784\u7684\u610f\u4e49\u4e0b\uff0c\u7b2c\u96f6\u9636\u5f20\u91cf \uff08r = 0\uff09 \u4e3a\u6807\u91cf \uff08Scalar\uff09\uff0c\u7b2c\u4e00\u9636\u5f20\u91cf \uff08r = 1\uff09 \u4e3a\u5411\u91cf \uff08Vector\uff09\uff0c \u7b2c\u4e8c\u9636\u5f20\u91cf \uff08r = 2\uff09 \u5219\u6210\u4e3a\u77e9\u9635 \uff08Matrix\uff09\uff0c\u7b2c\u4e09\u9636\u4ee5\u4e0a\u7684\u7edf\u79f0\u4e3a\u591a\u7ef4\u5f20\u91cf\u3002 \u5176\u4e2d\u8981\u7279\u522b\u6ce8\u610f\u7684\u5c31\u662f\u6807\u91cf\uff0c\u6211\u4eec\u5148\u751f\u6210\u4e00\u4e2a\u6807\u91cf\uff1a #\u6211\u4eec\u76f4\u63a5\u4f7f\u7528\u73b0\u6709\u6570\u5b57\u751f\u6210 scalar = torch . tensor ( 3.1433223 ) print ( scalar ) #\u6253\u5370\u6807\u91cf\u7684\u5927\u5c0f scalar . size () tensor(3.1433) torch.Size([]) \u5bf9\u4e8e\u6807\u91cf\uff0c\u6211\u4eec\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528 .item() \u4ece\u4e2d\u53d6\u51fa\u5176\u5bf9\u5e94\u7684python\u5bf9\u8c61\u7684\u6570\u503c scalar . item () 3.143322229385376 \u7279\u522b\u7684\uff1a\u5982\u679c\u5f20\u91cf\u4e2d\u53ea\u6709\u4e00\u4e2a\u5143\u7d20\u7684tensor\u4e5f\u53ef\u4ee5\u8c03\u7528 tensor.item \u65b9\u6cd5 tensor = torch . tensor ([ 3.1433223 ]) print ( tensor ) tensor . size () tensor([3.1433]) torch.Size([1]) tensor . item () 3.143322229385376 \u57fa\u672c\u7c7b\u578b \u00b6 Tensor\u7684\u57fa\u672c\u6570\u636e\u7c7b\u578b\u6709\u4e94\u79cd\uff1a - 32\u4f4d\u6d6e\u70b9\u578b\uff1atorch.FloatTensor\u3002 (\u9ed8\u8ba4) - 64\u4f4d\u6574\u578b\uff1atorch.LongTensor\u3002 - 32\u4f4d\u6574\u578b\uff1atorch.IntTensor\u3002 - 16\u4f4d\u6574\u578b\uff1atorch.ShortTensor\u3002 - 64\u4f4d\u6d6e\u70b9\u578b\uff1atorch.DoubleTensor\u3002 \u9664\u4ee5\u4e0a\u6570\u5b57\u7c7b\u578b\u5916\uff0c\u8fd8\u6709 byte\u548cchart\u578b long = tensor . long () long tensor([3]) half = tensor . half () half tensor([3.1426], dtype=torch.float16) int_t = tensor . int () int_t tensor([3], dtype=torch.int32) flo = tensor . float () flo tensor([3.1433]) short = tensor . short () short tensor([3], dtype=torch.int16) ch = tensor . char () ch tensor([3], dtype=torch.int8) bt = tensor . byte () bt tensor([3], dtype=torch.uint8) Numpy\u8f6c\u6362 \u00b6 \u4f7f\u7528numpy\u65b9\u6cd5\u5c06Tensor\u8f6c\u4e3andarray a = torch . randn (( 3 , 2 )) # tensor\u8f6c\u5316\u4e3anumpy numpy_a = a . numpy () print ( numpy_a ) [[ 0.46819344 1.3774964 ] [ 0.9491934 1.4543315 ] [-0.42792308 0.99790514]] numpy\u8f6c\u5316\u4e3aTensor torch_a = torch . from_numpy ( numpy_a ) torch_a tensor([[ 0.4682, 1.3775], [ 0.9492, 1.4543], [-0.4279, 0.9979]]) Tensor\u548cnumpy\u5bf9\u8c61\u5171\u4eab\u5185\u5b58\uff0c\u6240\u4ee5\u4ed6\u4eec\u4e4b\u95f4\u7684\u8f6c\u6362\u5f88\u5feb\uff0c\u800c\u4e14\u51e0\u4e4e\u4e0d\u4f1a\u6d88\u8017\u4ec0\u4e48\u8d44\u6e90\u3002\u4f46\u8fd9\u4e5f\u610f\u5473\u7740\uff0c\u5982\u679c\u5176\u4e2d\u4e00\u4e2a\u53d8\u4e86\uff0c\u53e6\u5916\u4e00\u4e2a\u4e5f\u4f1a\u968f\u4e4b\u6539\u53d8\u3002 \u8bbe\u5907\u95f4\u8f6c\u6362 \u00b6 \u4e00\u822c\u60c5\u51b5\u4e0b\u53ef\u4ee5\u4f7f\u7528.cuda\u65b9\u6cd5\u5c06tensor\u79fb\u52a8\u5230gpu\uff0c\u8fd9\u6b65\u64cd\u4f5c\u9700\u8981cuda\u8bbe\u5907\u652f\u6301 cpu_a = torch . rand ( 4 , 3 ) cpu_a . type () 'torch.FloatTensor' gpu_a = cpu_a . cuda () gpu_a . type () 'torch.cuda.FloatTensor' \u4f7f\u7528.cpu\u65b9\u6cd5\u5c06tensor\u79fb\u52a8\u5230cpu cpu_b = gpu_a . cpu () cpu_b . type () 'torch.FloatTensor' \u5982\u679c\u6211\u4eec\u6709\u591aGPU\u7684\u60c5\u51b5\uff0c\u53ef\u4ee5\u4f7f\u7528to\u65b9\u6cd5\u6765\u786e\u5b9a\u4f7f\u7528\u90a3\u4e2a\u8bbe\u5907\uff0c\u8fd9\u91cc\u53ea\u505a\u4e2a\u7b80\u5355\u7684\u5b9e\u4f8b\uff1a #\u4f7f\u7528torch.cuda.is_available()\u6765\u786e\u5b9a\u662f\u5426\u6709cuda\u8bbe\u5907 device = torch . device ( \"cuda\" if torch . cuda . is_available () else \"cpu\" ) print ( device ) #\u5c06tensor\u4f20\u9001\u5230\u8bbe\u5907 gpu_b = cpu_b . to ( device ) gpu_b . type () cuda 'torch.cuda.FloatTensor' \u521d\u59cb\u5316 \u00b6 Pytorch\u4e2d\u6709\u8bb8\u591a\u9ed8\u8ba4\u7684\u521d\u59cb\u5316\u65b9\u6cd5\u53ef\u4ee5\u4f7f\u7528 # \u4f7f\u7528[0,1]\u5747\u5300\u5206\u5e03\u968f\u673a\u521d\u59cb\u5316\u4e8c\u7ef4\u6570\u7ec4 rnd = torch . rand ( 5 , 3 ) rnd tensor([[0.3804, 0.0297, 0.5241], [0.4111, 0.8887, 0.4642], [0.7302, 0.5913, 0.7182], [0.3048, 0.8055, 0.2176], [0.6195, 0.1620, 0.7726]]) ##\u521d\u59cb\u5316\uff0c\u4f7f\u75281\u586b\u5145 one = torch . ones ( 2 , 2 ) one tensor([[1., 1.], [1., 1.]]) ##\u521d\u59cb\u5316\uff0c\u4f7f\u75280\u586b\u5145 zero = torch . zeros ( 2 , 2 ) zero tensor([[0., 0.], [0., 0.]]) #\u521d\u59cb\u5316\u4e00\u4e2a\u5355\u4f4d\u77e9\u9635\uff0c\u5373\u5bf9\u89d2\u7ebf\u4e3a1 \u5176\u4ed6\u4e3a0 eye = torch . eye ( 2 , 2 ) eye tensor([[1., 0.], [0., 1.]]) \u5e38\u7528\u65b9\u6cd5 \u00b6 PyTorch\u4e2d\u5bf9\u5f20\u91cf\u7684\u64cd\u4f5capi \u548c NumPy \u975e\u5e38\u76f8\u4f3c\uff0c\u5982\u679c\u719f\u6089 NumPy \u4e2d\u7684\u64cd\u4f5c\uff0c\u90a3\u4e48 \u4ed6\u4eec\u4e8c\u8005 \u57fa\u672c\u662f\u4e00\u81f4\u7684\uff1a x = torch . randn ( 3 , 3 ) print ( x ) tensor([[ 0.6922, -0.4824, 0.8594], [ 0.4509, -0.8155, -0.0368], [ 1.3533, 0.5545, -0.0509]]) # \u6cbf\u7740\u884c\u53d6\u6700\u5927\u503c max_value , max_idx = torch . max ( x , dim = 1 ) print ( max_value , max_idx ) tensor([0.8594, 0.4509, 1.3533]) tensor([2, 0, 0]) # \u6bcf\u884c x \u6c42\u548c sum_x = torch . sum ( x , dim = 1 ) print ( sum_x ) tensor([ 1.0692, -0.4014, 1.8568]) y = torch . randn ( 3 , 3 ) z = x + y print ( z ) tensor([[-0.3821, -2.6932, -1.3884], [ 0.7468, -0.7697, -0.0883], [ 0.7688, -1.3485, 0.7517]]) \u6b63\u5982\u5b98\u65b960\u5206\u949f\u6559\u7a0b\u4e2d\u6240\u8bf4\uff0c\u4ee5_\u4e3a\u7ed3\u5c3e\u7684\uff0c\u5747\u4f1a\u6539\u53d8\u8c03\u7528\u503c # add \u5b8c\u6210\u540ex\u7684\u503c\u6539\u53d8\u4e86 x . add_ ( y ) print ( x ) tensor([[-0.3821, -2.6932, -1.3884], [ 0.7468, -0.7697, -0.0883], [ 0.7688, -1.3485, 0.7517]]) \u5f20\u91cf\u7684\u57fa\u672c\u64cd\u4f5c\u90fd\u4ecb\u7ecd\u7684\u7684\u5dee\u4e0d\u591a\u4e86\uff0c\u4e0b\u4e00\u7ae0\u4ecb\u7ecdPyTorch\u7684\u81ea\u52a8\u6c42\u5bfc\u673a\u5236","title":"2.1 Tensor"},{"location":"chapter02_basics/2_1_pytorch-basics-tensor/#pytorch","text":"\u5728\u7b2c\u4e00\u7ae0\u4e2d\u6211\u4eec\u5df2\u7ecf\u901a\u8fc7\u5b98\u65b9\u7684\u5165\u95e8\u6559\u7a0b\u5bf9PyTorch\u6709\u4e86\u4e00\u5b9a\u7684\u4e86\u89e3\uff0c\u8fd9\u4e00\u7ae0\u4f1a\u8be6\u7ec6\u4ecb\u7ecdPyTorch \u91cc\u9762\u7684\u57fa\u7840\u77e5\u8bc6\u3002 \u5168\u90e8\u638c\u63e1\u4e86\u8fd9\u4e9b\u57fa\u7840\u77e5\u8bc6\uff0c\u5728\u540e\u9762\u7684\u5e94\u7528\u4e2d\u624d\u80fd\u66f4\u52a0\u5feb\u901f\u8fdb\u9636\uff0c\u5982\u679c\u4f60\u5df2\u7ecf\u5bf9PyTorch\u6709\u4e00\u5b9a\u7684\u4e86\u89e3\uff0c\u53ef\u4ee5\u8df3\u8fc7\u6b64\u7ae0 # \u9996\u5148\u8981\u5f15\u5165\u76f8\u5173\u7684\u5305 import torch import numpy as np #\u6253\u5370\u4e00\u4e0b\u7248\u672c torch . __version__ '1.0.0'","title":"PyTorch \u57fa\u7840 : \u5f20\u91cf"},{"location":"chapter02_basics/2_1_pytorch-basics-tensor/#tensor","text":"\u5f20\u91cf\u7684\u82f1\u6587\u662fTensor\uff0c\u5b83\u662fPyTorch\u91cc\u9762\u57fa\u7840\u7684\u8fd0\u7b97\u5355\u4f4d,\u4e0eNumpy\u7684ndarray\u76f8\u540c\u90fd\u8868\u793a\u7684\u662f\u4e00\u4e2a\u591a\u7ef4\u7684\u77e9\u9635\u3002 \u4e0endarray\u7684\u6700\u5927\u533a\u522b\u5c31\u662f\uff0cPyTorch\u7684Tensor\u53ef\u4ee5\u5728 GPU \u4e0a\u8fd0\u884c\uff0c\u800c numpy \u7684 ndarray \u53ea\u80fd\u5728 CPU \u4e0a\u8fd0\u884c\uff0c\u5728GPU\u4e0a\u8fd0\u884c\u5927\u5927\u52a0\u5feb\u4e86\u8fd0\u7b97\u901f\u5ea6\u3002 \u4e0b\u9762\u6211\u4eec\u751f\u6210\u4e00\u4e2a\u7b80\u5355\u7684\u5f20\u91cf x = torch . rand ( 2 , 3 ) x tensor([[0.6904, 0.7419, 0.8010], [0.1722, 0.2442, 0.8181]]) \u4ee5\u4e0a\u751f\u6210\u4e86\u4e00\u4e2a\uff0c2\u884c3\u5217\u7684\u7684\u77e9\u9635\uff0c\u6211\u4eec\u770b\u4e00\u4e0b\u4ed6\u7684\u5927\u5c0f\uff1a # \u53ef\u4ee5\u4f7f\u7528\u4e0enumpy\u76f8\u540c\u7684shape\u5c5e\u6027\u67e5\u770b print ( x . shape ) # \u4e5f\u53ef\u4ee5\u4f7f\u7528size()\u51fd\u6570\uff0c\u8fd4\u56de\u7684\u7ed3\u679c\u90fd\u662f\u76f8\u540c\u7684 print ( x . size ()) torch.Size([2, 3]) torch.Size([2, 3]) \u5f20\u91cf\uff08Tensor\uff09\u662f\u4e00\u4e2a\u5b9a\u4e49\u5728\u4e00\u4e9b\u5411\u91cf\u7a7a\u95f4\u548c\u4e00\u4e9b\u5bf9\u5076\u7a7a\u95f4\u7684\u7b1b\u5361\u513f\u79ef\u4e0a\u7684\u591a\u91cd\u7ebf\u6027\u6620\u5c04\uff0c\u5176\u5750\u6807\u662f|n|\u7ef4\u7a7a\u95f4\u5185\uff0c\u6709|n|\u4e2a\u5206\u91cf\u7684\u4e00\u79cd\u91cf\uff0c \u5176\u4e2d\u6bcf\u4e2a\u5206\u91cf\u90fd\u662f\u5750\u6807\u7684\u51fd\u6570\uff0c \u800c\u5728\u5750\u6807\u53d8\u6362\u65f6\uff0c\u8fd9\u4e9b\u5206\u91cf\u4e5f\u4f9d\u7167\u67d0\u4e9b\u89c4\u5219\u4f5c\u7ebf\u6027\u53d8\u6362\u3002r\u79f0\u4e3a\u8be5\u5f20\u91cf\u7684\u79e9\u6216\u9636\uff08\u4e0e\u77e9\u9635\u7684\u79e9\u548c\u9636\u5747\u65e0\u5173\u7cfb\uff09\u3002 (\u6765\u81ea\u767e\u5ea6\u767e\u79d1) \u4e0b\u9762\u6211\u4eec\u6765\u751f\u6210\u4e00\u4e9b\u591a\u7ef4\u7684\u5f20\u91cf\uff1a y = torch . rand ( 2 , 3 , 4 , 5 ) print ( y . size ()) y torch.Size([2, 3, 4, 5]) tensor([[[[0.9071, 0.0616, 0.0006, 0.6031, 0.0714], [0.6592, 0.9700, 0.0253, 0.0726, 0.5360], [0.5416, 0.1138, 0.9592, 0.6779, 0.6501], [0.0546, 0.8287, 0.7748, 0.4352, 0.9232]], [[0.0730, 0.4228, 0.7407, 0.4099, 0.1482], [0.5408, 0.9156, 0.6554, 0.5787, 0.9775], [0.4262, 0.3644, 0.1993, 0.4143, 0.5757], [0.9307, 0.8839, 0.8462, 0.0933, 0.6688]], [[0.4447, 0.0929, 0.9882, 0.5392, 0.1159], [0.4790, 0.5115, 0.4005, 0.9486, 0.0054], [0.8955, 0.8097, 0.1227, 0.2250, 0.5830], [0.8483, 0.2070, 0.1067, 0.4727, 0.5095]]], [[[0.9438, 0.2601, 0.2885, 0.5457, 0.7528], [0.2971, 0.2171, 0.3910, 0.1924, 0.2570], [0.7491, 0.9749, 0.2703, 0.2198, 0.9472], [0.1216, 0.6647, 0.8809, 0.0125, 0.5513]], [[0.0870, 0.6622, 0.7252, 0.4783, 0.0160], [0.7832, 0.6050, 0.7469, 0.7947, 0.8052], [0.1755, 0.4489, 0.0602, 0.8073, 0.3028], [0.9937, 0.6780, 0.9425, 0.0059, 0.0451]], [[0.3851, 0.8742, 0.5932, 0.4899, 0.8354], [0.8577, 0.3705, 0.0229, 0.7097, 0.7557], [0.1505, 0.3527, 0.0843, 0.0088, 0.8741], [0.6041, 0.8797, 0.6189, 0.9495, 0.1479]]]]) \u5728\u540c\u6784\u7684\u610f\u4e49\u4e0b\uff0c\u7b2c\u96f6\u9636\u5f20\u91cf \uff08r = 0\uff09 \u4e3a\u6807\u91cf \uff08Scalar\uff09\uff0c\u7b2c\u4e00\u9636\u5f20\u91cf \uff08r = 1\uff09 \u4e3a\u5411\u91cf \uff08Vector\uff09\uff0c \u7b2c\u4e8c\u9636\u5f20\u91cf \uff08r = 2\uff09 \u5219\u6210\u4e3a\u77e9\u9635 \uff08Matrix\uff09\uff0c\u7b2c\u4e09\u9636\u4ee5\u4e0a\u7684\u7edf\u79f0\u4e3a\u591a\u7ef4\u5f20\u91cf\u3002 \u5176\u4e2d\u8981\u7279\u522b\u6ce8\u610f\u7684\u5c31\u662f\u6807\u91cf\uff0c\u6211\u4eec\u5148\u751f\u6210\u4e00\u4e2a\u6807\u91cf\uff1a #\u6211\u4eec\u76f4\u63a5\u4f7f\u7528\u73b0\u6709\u6570\u5b57\u751f\u6210 scalar = torch . tensor ( 3.1433223 ) print ( scalar ) #\u6253\u5370\u6807\u91cf\u7684\u5927\u5c0f scalar . size () tensor(3.1433) torch.Size([]) \u5bf9\u4e8e\u6807\u91cf\uff0c\u6211\u4eec\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528 .item() \u4ece\u4e2d\u53d6\u51fa\u5176\u5bf9\u5e94\u7684python\u5bf9\u8c61\u7684\u6570\u503c scalar . item () 3.143322229385376 \u7279\u522b\u7684\uff1a\u5982\u679c\u5f20\u91cf\u4e2d\u53ea\u6709\u4e00\u4e2a\u5143\u7d20\u7684tensor\u4e5f\u53ef\u4ee5\u8c03\u7528 tensor.item \u65b9\u6cd5 tensor = torch . tensor ([ 3.1433223 ]) print ( tensor ) tensor . size () tensor([3.1433]) torch.Size([1]) tensor . item () 3.143322229385376","title":"\u5f20\u91cf(Tensor)"},{"location":"chapter02_basics/2_1_pytorch-basics-tensor/#_1","text":"Tensor\u7684\u57fa\u672c\u6570\u636e\u7c7b\u578b\u6709\u4e94\u79cd\uff1a - 32\u4f4d\u6d6e\u70b9\u578b\uff1atorch.FloatTensor\u3002 (\u9ed8\u8ba4) - 64\u4f4d\u6574\u578b\uff1atorch.LongTensor\u3002 - 32\u4f4d\u6574\u578b\uff1atorch.IntTensor\u3002 - 16\u4f4d\u6574\u578b\uff1atorch.ShortTensor\u3002 - 64\u4f4d\u6d6e\u70b9\u578b\uff1atorch.DoubleTensor\u3002 \u9664\u4ee5\u4e0a\u6570\u5b57\u7c7b\u578b\u5916\uff0c\u8fd8\u6709 byte\u548cchart\u578b long = tensor . long () long tensor([3]) half = tensor . half () half tensor([3.1426], dtype=torch.float16) int_t = tensor . int () int_t tensor([3], dtype=torch.int32) flo = tensor . float () flo tensor([3.1433]) short = tensor . short () short tensor([3], dtype=torch.int16) ch = tensor . char () ch tensor([3], dtype=torch.int8) bt = tensor . byte () bt tensor([3], dtype=torch.uint8)","title":"\u57fa\u672c\u7c7b\u578b"},{"location":"chapter02_basics/2_1_pytorch-basics-tensor/#numpy","text":"\u4f7f\u7528numpy\u65b9\u6cd5\u5c06Tensor\u8f6c\u4e3andarray a = torch . randn (( 3 , 2 )) # tensor\u8f6c\u5316\u4e3anumpy numpy_a = a . numpy () print ( numpy_a ) [[ 0.46819344 1.3774964 ] [ 0.9491934 1.4543315 ] [-0.42792308 0.99790514]] numpy\u8f6c\u5316\u4e3aTensor torch_a = torch . from_numpy ( numpy_a ) torch_a tensor([[ 0.4682, 1.3775], [ 0.9492, 1.4543], [-0.4279, 0.9979]]) Tensor\u548cnumpy\u5bf9\u8c61\u5171\u4eab\u5185\u5b58\uff0c\u6240\u4ee5\u4ed6\u4eec\u4e4b\u95f4\u7684\u8f6c\u6362\u5f88\u5feb\uff0c\u800c\u4e14\u51e0\u4e4e\u4e0d\u4f1a\u6d88\u8017\u4ec0\u4e48\u8d44\u6e90\u3002\u4f46\u8fd9\u4e5f\u610f\u5473\u7740\uff0c\u5982\u679c\u5176\u4e2d\u4e00\u4e2a\u53d8\u4e86\uff0c\u53e6\u5916\u4e00\u4e2a\u4e5f\u4f1a\u968f\u4e4b\u6539\u53d8\u3002","title":"Numpy\u8f6c\u6362"},{"location":"chapter02_basics/2_1_pytorch-basics-tensor/#_2","text":"\u4e00\u822c\u60c5\u51b5\u4e0b\u53ef\u4ee5\u4f7f\u7528.cuda\u65b9\u6cd5\u5c06tensor\u79fb\u52a8\u5230gpu\uff0c\u8fd9\u6b65\u64cd\u4f5c\u9700\u8981cuda\u8bbe\u5907\u652f\u6301 cpu_a = torch . rand ( 4 , 3 ) cpu_a . type () 'torch.FloatTensor' gpu_a = cpu_a . cuda () gpu_a . type () 'torch.cuda.FloatTensor' \u4f7f\u7528.cpu\u65b9\u6cd5\u5c06tensor\u79fb\u52a8\u5230cpu cpu_b = gpu_a . cpu () cpu_b . type () 'torch.FloatTensor' \u5982\u679c\u6211\u4eec\u6709\u591aGPU\u7684\u60c5\u51b5\uff0c\u53ef\u4ee5\u4f7f\u7528to\u65b9\u6cd5\u6765\u786e\u5b9a\u4f7f\u7528\u90a3\u4e2a\u8bbe\u5907\uff0c\u8fd9\u91cc\u53ea\u505a\u4e2a\u7b80\u5355\u7684\u5b9e\u4f8b\uff1a #\u4f7f\u7528torch.cuda.is_available()\u6765\u786e\u5b9a\u662f\u5426\u6709cuda\u8bbe\u5907 device = torch . device ( \"cuda\" if torch . cuda . is_available () else \"cpu\" ) print ( device ) #\u5c06tensor\u4f20\u9001\u5230\u8bbe\u5907 gpu_b = cpu_b . to ( device ) gpu_b . type () cuda 'torch.cuda.FloatTensor'","title":"\u8bbe\u5907\u95f4\u8f6c\u6362"},{"location":"chapter02_basics/2_1_pytorch-basics-tensor/#_3","text":"Pytorch\u4e2d\u6709\u8bb8\u591a\u9ed8\u8ba4\u7684\u521d\u59cb\u5316\u65b9\u6cd5\u53ef\u4ee5\u4f7f\u7528 # \u4f7f\u7528[0,1]\u5747\u5300\u5206\u5e03\u968f\u673a\u521d\u59cb\u5316\u4e8c\u7ef4\u6570\u7ec4 rnd = torch . rand ( 5 , 3 ) rnd tensor([[0.3804, 0.0297, 0.5241], [0.4111, 0.8887, 0.4642], [0.7302, 0.5913, 0.7182], [0.3048, 0.8055, 0.2176], [0.6195, 0.1620, 0.7726]]) ##\u521d\u59cb\u5316\uff0c\u4f7f\u75281\u586b\u5145 one = torch . ones ( 2 , 2 ) one tensor([[1., 1.], [1., 1.]]) ##\u521d\u59cb\u5316\uff0c\u4f7f\u75280\u586b\u5145 zero = torch . zeros ( 2 , 2 ) zero tensor([[0., 0.], [0., 0.]]) #\u521d\u59cb\u5316\u4e00\u4e2a\u5355\u4f4d\u77e9\u9635\uff0c\u5373\u5bf9\u89d2\u7ebf\u4e3a1 \u5176\u4ed6\u4e3a0 eye = torch . eye ( 2 , 2 ) eye tensor([[1., 0.], [0., 1.]])","title":"\u521d\u59cb\u5316"},{"location":"chapter02_basics/2_1_pytorch-basics-tensor/#_4","text":"PyTorch\u4e2d\u5bf9\u5f20\u91cf\u7684\u64cd\u4f5capi \u548c NumPy \u975e\u5e38\u76f8\u4f3c\uff0c\u5982\u679c\u719f\u6089 NumPy \u4e2d\u7684\u64cd\u4f5c\uff0c\u90a3\u4e48 \u4ed6\u4eec\u4e8c\u8005 \u57fa\u672c\u662f\u4e00\u81f4\u7684\uff1a x = torch . randn ( 3 , 3 ) print ( x ) tensor([[ 0.6922, -0.4824, 0.8594], [ 0.4509, -0.8155, -0.0368], [ 1.3533, 0.5545, -0.0509]]) # \u6cbf\u7740\u884c\u53d6\u6700\u5927\u503c max_value , max_idx = torch . max ( x , dim = 1 ) print ( max_value , max_idx ) tensor([0.8594, 0.4509, 1.3533]) tensor([2, 0, 0]) # \u6bcf\u884c x \u6c42\u548c sum_x = torch . sum ( x , dim = 1 ) print ( sum_x ) tensor([ 1.0692, -0.4014, 1.8568]) y = torch . randn ( 3 , 3 ) z = x + y print ( z ) tensor([[-0.3821, -2.6932, -1.3884], [ 0.7468, -0.7697, -0.0883], [ 0.7688, -1.3485, 0.7517]]) \u6b63\u5982\u5b98\u65b960\u5206\u949f\u6559\u7a0b\u4e2d\u6240\u8bf4\uff0c\u4ee5_\u4e3a\u7ed3\u5c3e\u7684\uff0c\u5747\u4f1a\u6539\u53d8\u8c03\u7528\u503c # add \u5b8c\u6210\u540ex\u7684\u503c\u6539\u53d8\u4e86 x . add_ ( y ) print ( x ) tensor([[-0.3821, -2.6932, -1.3884], [ 0.7468, -0.7697, -0.0883], [ 0.7688, -1.3485, 0.7517]]) \u5f20\u91cf\u7684\u57fa\u672c\u64cd\u4f5c\u90fd\u4ecb\u7ecd\u7684\u7684\u5dee\u4e0d\u591a\u4e86\uff0c\u4e0b\u4e00\u7ae0\u4ecb\u7ecdPyTorch\u7684\u81ea\u52a8\u6c42\u5bfc\u673a\u5236","title":"\u5e38\u7528\u65b9\u6cd5"}]}